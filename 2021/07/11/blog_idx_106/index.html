<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"e-x.top","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.27.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":false,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="PS：要转载请注明出处，本人版权所有。 PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。  环境说明   Windows 10   VSCode   Python 3.8.10   Pytorch 1.8.1   Cuda 10.2   前言    在《DL基础补全计划(一)—线性回归及示例（Pytorch，平方损失）》（https:&#x2F;&#x2F;blog.csdn.ne">
<meta property="og:type" content="article">
<meta property="og:title" content="DL基础补全计划(二)---Softmax回归及示例（Pytorch，交叉熵损失）">
<meta property="og:url" content="https://e-x.top/2021/07/11/blog_idx_106/index.html">
<meta property="og:site_name" content="Sky&#39;s Blogs">
<meta property="og:description" content="PS：要转载请注明出处，本人版权所有。 PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。  环境说明   Windows 10   VSCode   Python 3.8.10   Pytorch 1.8.1   Cuda 10.2   前言    在《DL基础补全计划(一)—线性回归及示例（Pytorch，平方损失）》（https:&#x2F;&#x2F;blog.csdn.ne">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/show_datasets.png">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/train_log.png">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/predict_log.png">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg">
<meta property="article:published_time" content="2021-07-11T14:23:46.000Z">
<meta property="article:modified_time" content="2024-05-18T11:06:02.648Z">
<meta property="article:author" content="Sky">
<meta property="article:tag" content="Pytorch">
<meta property="article:tag" content="Softmax">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/show_datasets.png">


<link rel="canonical" href="https://e-x.top/2021/07/11/blog_idx_106/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://e-x.top/2021/07/11/blog_idx_106/","path":"2021/07/11/blog_idx_106/","title":"DL基础补全计划(二)---Softmax回归及示例（Pytorch，交叉熵损失）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>DL基础补全计划(二)---Softmax回归及示例（Pytorch，交叉熵损失） | Sky's Blogs</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  




<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8677552300382028"
     crossorigin="anonymous"></script>
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Sky's Blogs</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">A normal star</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E8%AF%B4%E6%98%8E"><span class="nav-number">1.</span> <span class="nav-text">环境说明</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number"></span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Softmax%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%9E%E4%BE%8B"><span class="nav-number"></span> <span class="nav-text">Softmax介绍及实例</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E5%B9%B6%E5%A4%84%E7%90%86FashionMNIST%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number"></span> <span class="nav-text">获取并处理FashionMNIST数据集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%BE%E8%AE%A1%E7%BD%91%E7%BB%9C"><span class="nav-number"></span> <span class="nav-text">设计网络</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%BE%E8%AE%A1Loss%E5%87%BD%E6%95%B0%E5%8F%8A%E4%BC%98%E5%8C%96%E5%87%BD%E6%95%B0"><span class="nav-number"></span> <span class="nav-text">设计Loss函数及优化函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%BE%E8%AE%A1%E5%87%86%E7%A1%AE%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%87%BD%E6%95%B0%E4%BB%A5%E5%8F%8A%E8%AF%84%E4%BC%B0%E5%87%86%E7%A1%AE%E7%8E%87%E5%87%BD%E6%95%B0"><span class="nav-number"></span> <span class="nav-text">设计准确率统计函数以及评估准确率函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%BE%E8%AE%A1%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0"><span class="nav-number"></span> <span class="nav-text">设计预测函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number"></span> <span class="nav-text">训练模型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%8E%E8%AE%B0"><span class="nav-number"></span> <span class="nav-text">后记</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number"></span> <span class="nav-text">参考文献</span></a></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Sky</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">139</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">92</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">222</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/07/11/blog_idx_106/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="DL基础补全计划(二)---Softmax回归及示例（Pytorch，交叉熵损失） | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DL基础补全计划(二)---Softmax回归及示例（Pytorch，交叉熵损失）
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-11 22:23:46" itemprop="dateCreated datePublished" datetime="2021-07-11T22:23:46+08:00">2021-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky
 * @LastEditTime: 2021-07-01 17:32:12
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=106） 
&emsp;&emsp;本文发布于 2021-07-11 22:23:46     （BlogID=106） 
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Windows 10</p>
</li>
<li class="lvl-2">
<p>VSCode</p>
</li>
<li class="lvl-2">
<p>Python 3.8.10</p>
</li>
<li class="lvl-2">
<p>Pytorch 1.8.1</p>
</li>
<li class="lvl-2">
<p>Cuda 10.2</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  在《DL基础补全计划(一)—线性回归及示例（Pytorch，平方损失）》（<a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/118463588">https://blog.csdn.net/u011728480/article/details/118463588</a> ）一文中我们对深度学习中的非常基础的知识进行了简单介绍，按照常见深度学习中的基本流程设计了一个简单的线性模型。同时，基于基本的语法，展示了数据收集，数据小批量随机获取，网络forward, loss设计，基于loss的bp，随机小批量梯度下降，模型训练，模型预测等基本的流程。 记录这篇文章的原因也很简单，为了将自己从学校里面带出来的知识和深度学习中的基础知识关联起来，不要出现大的断层和空洞。</p>
<p>  在上文我们提到，我们已经能够设计一类模型能够求解特定函数的数值，但是在实际应用场景中，我们还有一些问题主要还是关注他们的分类。比如我们有一堆数据，怎么把他们分为N类。这里就要介绍深度学习中一类常见的模型，softmax回归模型。本文的主要目的就是基于FashionMNIST数据集（60000 * 28 * 28 训练集，10000 * 28 * 28 测试集），从基础的语法开始设计一个softmax分类模型，并介绍一些softmax相关的重点，在本文之后，其实我们就可以做一些深度学习的简单分类任务了。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="Softmax介绍及实例">Softmax介绍及实例</h3>
<hr>
<p>  我们可以知道，Softmax这个函数其实就是对N个类别进行打分，输出N个类别的概率，那么它的实际底层工作原理到底是什么呢？</p>
<p>  假如我们定义输出类别为N，输入特征为X, 输出类别分数为Y，参数为W，偏置为b，那么我们可以设计一个函数为：$Y=WX+b$，W.shape是(N, len(X)), X.shape是(len(X), 1)， b.shape 是(N, len(X))，Y.shape是(N , 1)，通过这样的一个线性运算后，我们就可以将len(X)个输入变换为N个输出，其实这个时候的N个输出就是我们不同类别的分数，理论上来说，我们就可以用这个当做每个类别的分数或者说概率。由于这里的Y是实数范围，有正有负，有大有小，存在数据不稳定性，而且我们需要把输出的类别当做概率使用，这里如果存在负数的话，不满足概率的一些定义。因此我们在经过一个线性变换后，再通过softmax运算，才能够将这些分数转换为相应的概率。</p>
<p>  Y.shape是(N , 1)，Softmax定义为：$Softmax(Yi)=exp(Yi)/\sum\limits_{j=0}^{N-1}Yj$ ，因此我们可以通过Softmax得到每个类别的分数。$Y’=Softmax(Y)$，通过这样的运算后，就把Y归一化到0~1，而且满足概率的一些定义和保持了和Y同样的性质。</p>
<p>  下面我们基于FashionMNIST数据集（此数据集有10个类别，60000个训练集，10000个测试集，图片为单通道28*28），设计一个简单的分类模型。下面是python需要导入的依赖</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> numpy<span class="token punctuation">.</span>core<span class="token punctuation">.</span>numeric <span class="token keyword">import</span> cross
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToTensor
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="获取并处理FashionMNIST数据集">获取并处理FashionMNIST数据集</h5>
<p>  通过Pytorch的设计好的api直接获取数据集，并得到解析后的数据</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">LoadFashionMNISTByTorchApi</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 60000*28*28</span>
    training_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># 10000*28*28</span>
    test_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    labels_map <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"T-Shirt"</span><span class="token punctuation">,</span>
        <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"Trouser"</span><span class="token punctuation">,</span>
        <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">"Pullover"</span><span class="token punctuation">,</span>
        <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">"Dress"</span><span class="token punctuation">,</span>
        <span class="token number">4</span><span class="token punctuation">:</span> <span class="token string">"Coat"</span><span class="token punctuation">,</span>
        <span class="token number">5</span><span class="token punctuation">:</span> <span class="token string">"Sandal"</span><span class="token punctuation">,</span>
        <span class="token number">6</span><span class="token punctuation">:</span> <span class="token string">"Shirt"</span><span class="token punctuation">,</span>
        <span class="token number">7</span><span class="token punctuation">:</span> <span class="token string">"Sneaker"</span><span class="token punctuation">,</span>
        <span class="token number">8</span><span class="token punctuation">:</span> <span class="token string">"Bag"</span><span class="token punctuation">,</span>
        <span class="token number">9</span><span class="token punctuation">:</span> <span class="token string">"Ankle Boot"</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#125;</span>
    figure <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cols<span class="token punctuation">,</span> rows <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> cols <span class="token operator">*</span> rows <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        sample_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>training_data<span class="token punctuation">)</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        img<span class="token punctuation">,</span> label <span class="token operator">=</span> training_data<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span>
        figure<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span>rows<span class="token punctuation">,</span> cols<span class="token punctuation">,</span> i<span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>labels_map<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">"gray"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> training_data<span class="token punctuation">,</span> test_data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/show_datasets.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  通过面的代码可以知道，datasets.FashionMNIST()返回的是集合，集合里面存的是每个图的数据以及其标签。这里其实Pytorch帮我们做了解析工作，实际FashionMNIST的二进制存储格式如下，我们也可以自己写代码按照此规则解析数据集，这里就不关注这个问题了。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">'''
Image:
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000803(2051) magic number
0004     32 bit integer  60000            number of images
0008     32 bit integer  28               number of rows
0012     32 bit integer  28               number of columns
0016     unsigned byte   ??               pixel
0017     unsigned byte   ??               pixel
........
xxxx     unsigned byte   ??               pixel
'''</span>

<span class="token triple-quoted-string string">'''
Label：
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  60000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........
xxxx     unsigned byte   ??               label
The labels values are 0 to 9.
'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  还记得我们前文的随机小批量怎么实现的吗？首先随机打乱数据集中的每个数据（图片和标签为一个数据）的顺序，然后根据batch_size参数构造一个可迭代的对象返回出来，最后训练的时候我们通过for xx in data_iter 来访问这一批的数据。这里我们也不需要自己来写这个了，直接调用Pytorch的函数来生成这样的一个data_iter，我们应该把更多注意力放到其他地方去。代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">training_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> LoadFashionMNISTByTorchApi<span class="token punctuation">(</span><span class="token punctuation">)</span>
batch_size <span class="token operator">=</span> <span class="token number">200</span>

<span class="token comment"># 返回训练集和测试集的可迭代对象</span>
train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="设计网络">设计网络</h5>
<p>  我们的网络由两个部分构成，一个是从28*28到10的一个映射函数，一个是softmax函数。我们定义一个$Y=WX+b, Y’=Softmax(Y)$，因此我们可以看到，我们所需要学习的参数有W和b。</p>
<p>  根据前文介绍，我们可以知道Y’/Y.shape是(10, 1), X.shape是(784, 1), W.shape是(10, 784), b.shape(10, 1)</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># example:</span>
    <span class="token comment"># out = (p1, p2, p3)</span>
    <span class="token comment"># set Sum=p1+p2+p3</span>
    <span class="token comment"># softmax(out) = (p1/Sum, p2/Sum, p3/Sum)</span>
    exp_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
    partition <span class="token operator">=</span> exp_out<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> exp_out<span class="token operator">/</span>partition

<span class="token keyword">def</span> <span class="token function">my_net</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># print(X.shape)</span>
    <span class="token comment"># print(w.shape)</span>
    <span class="token comment"># print(b.shape)</span>
    liear_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b
    <span class="token comment"># print(liear_out.shape)</span>
    <span class="token keyword">return</span> softmax<span class="token punctuation">(</span>liear_out<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="设计Loss函数及优化函数">设计Loss函数及优化函数</h5>
<p>  在前文的线性回归中，我们使用了平方误差来作为Loss函数，在分类这一问题里面，我们需要引入交叉熵来作为Loss函数。交叉熵作为信息论中的概念，我们简单的通过几个前置知识来引入：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>信息论研究的是一个随机事件携带的信息量，基本思想是事件发生概率越大，所携带的信息量越小。因此这里可以引入一个自信息定义：$I(x)=-\log_{2}(P(x))$。通过这个定义我们可以得到同样的趋势，一个事件发生的概率越小，携带的信息量越大。</p>
</li>
<li class="lvl-2">
<p>熵(Entropy)，自信息是对单个随机事件的信息量大小描述，我们需要定义来描述整个随机分布的信息量大小的描述。假设随机分布是离散的，熵的定义为：$H(X)=-\sum\limits_{i=0}^{n-1}P(Xi)\log_{2}(P(Xi))$</p>
</li>
<li class="lvl-2">
<p>KL差异（Kullback-Leibler (KL) divergence），主要就是用来描述两个分布的差异。因为在有些时候，一个概率分布很复杂，我们可以用一个简单的概率分布来替代，但是我们需要知道这两个分布的差异。定义原概率分布为P(X),近似概率分布为Q(X)，假如X是离散随机变量，KL差异定义为：$D_{KL}(P(X)||Q(X))=\sum\limits_{i=0}<sup>{n-1}P(Xi)\log_{2}(P(Xi)/Q(Xi))=\sum\limits_{i=0}</sup>{n-1}P(Xi)[\log_{2}(P(Xi)) - \log_{2}(Q(Xi))]$</p>
</li>
<li class="lvl-2">
<p>交叉熵（cross-entropy），交叉熵定义为：$H(P,Q)=-\sum\limits_{i=0}^{n-1}P(Xi)\log_{2}(Q(Xi))$，我们可以看到$H(P,Q)=H(P)+D_{KL}(P||Q)$。</p>
</li>
<li class="lvl-2">
<p>在上文中，我们一步一步引出了交叉熵，这个时候，我们来看为什么在深度学习中可以引入交叉熵作为Loss函数，对于特定的一组Feature，我们可以通过标签得到这组feature代表什么，相当于其概率为1，因此在原概率分布上面，$P(Xi)=1, H(Xi)=0$，我们可以看到这个时候交叉熵和KL差异是相等的，那么交叉熵其实就是描述我们训练时得到的概率分布和原分布的差异。因此，在分类问题中我们得到的是当前的每个分类的概率，那么我们分别求每个分类当前概率分布相对于原分布的KL差异，那么我们就知道我们的训练参数和真实参数的差异。我们求交叉熵的最小值，也就代表我们参数越接近真实值。</p>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 信息论，熵，kl熵（相对），交叉熵</span>
<span class="token keyword">def</span> <span class="token function">cross_entropy</span><span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># l = -y*log(y')</span>
    
    <span class="token comment"># print(y_train.shape)</span>
    <span class="token comment"># print(y_label.shape)</span>
    <span class="token comment"># print(y_train)</span>
    <span class="token comment"># print(y_label)</span>
    <span class="token comment"># print(y_train[0][:].sum())</span>
    <span class="token comment"># call pick</span>
    my_loss <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y_train<span class="token punctuation">[</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_label<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># nll_loss = torch.nn.NLLLoss()</span>
    <span class="token comment"># th_loss = nll_loss(torch.log(y_train), y_label)</span>
    <span class="token comment"># print(my_loss.sum()/len(y_label))</span>
    <span class="token comment"># print(th_loss)</span>
    <span class="token keyword">return</span> my_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="设计准确率统计函数以及评估准确率函数">设计准确率统计函数以及评估准确率函数</h5>
<p>  在前一小节，我们已经设计了损失函数，我们在训练的过程中，除了要关注损失函数的值外，还需要关注我们模型的准确率。</p>
<p>  模型的准确率代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_label<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""计算预测正确的数量。"""</span>
    <span class="token comment"># y_train = n*num_class</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">1</span> <span class="token keyword">and</span> y_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token comment"># argmax get the max-element-index</span>
        y_train <span class="token operator">=</span> y_train<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment"># cmp = n*1 , eg: [0 0 0 1 1 1 0 0 0]</span>
    <span class="token comment"># print(y_train.dtype)</span>
    <span class="token comment"># print(y_label.dtype)</span>
    <span class="token builtin">cmp</span> <span class="token operator">=</span> y_train <span class="token operator">==</span> y_label
    <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token builtin">cmp</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>y_label<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  从上面的代码可以知道，我们的网络输出是当前feature在每个类别上的概率，因此我们求出网络输出中，概率最大的索引，和真实label进行对比，相等就代表预测成功一个，反之。我们对最终数据求和后除以batch_size，就可以得到在batch_size个特征中，我们的预测正确的个数占比是多少。</p>
<p>  我们还需要在指定的数据集上评估我们的准确率，其代码如下（就是分批调用获得准确率后求平均）：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">evaluate_accuracy</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> data_iter<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""计算在指定数据集上模型的精度。"""</span>
    test_acc_sum <span class="token operator">=</span> <span class="token number">0.0</span>
    times <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">for</span> img<span class="token punctuation">,</span> label <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        test_acc_sum <span class="token operator">+=</span> accuracy<span class="token punctuation">(</span>net<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> img<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        times <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">return</span> test_acc_sum<span class="token operator">/</span>times<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="设计预测函数">设计预测函数</h5>
<p>  预测函数就是在特定数据上面，通过我们训练的网络，求出类别，并与真实label进行对比，其代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> test_iter<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""预测标签（定义⻅第3章）。"""</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> test_iter<span class="token punctuation">:</span>
        <span class="token keyword">break</span>
    labels_map <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"T-Shirt"</span><span class="token punctuation">,</span>
        <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"Trouser"</span><span class="token punctuation">,</span>
        <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">"Pullover"</span><span class="token punctuation">,</span>
        <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">"Dress"</span><span class="token punctuation">,</span>
        <span class="token number">4</span><span class="token punctuation">:</span> <span class="token string">"Coat"</span><span class="token punctuation">,</span>
        <span class="token number">5</span><span class="token punctuation">:</span> <span class="token string">"Sandal"</span><span class="token punctuation">,</span>
        <span class="token number">6</span><span class="token punctuation">:</span> <span class="token string">"Shirt"</span><span class="token punctuation">,</span>
        <span class="token number">7</span><span class="token punctuation">:</span> <span class="token string">"Sneaker"</span><span class="token punctuation">,</span>
        <span class="token number">8</span><span class="token punctuation">:</span> <span class="token string">"Bag"</span><span class="token punctuation">,</span>
        <span class="token number">9</span><span class="token punctuation">:</span> <span class="token string">"Ankle Boot"</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#125;</span>
    trues <span class="token operator">=</span> <span class="token punctuation">[</span>labels_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    preds <span class="token operator">=</span> <span class="token punctuation">[</span>labels_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> net<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'pre-idx </span><span class="token interpolation"><span class="token punctuation">&#123;</span>i<span class="token punctuation">&#125;</span></span><span class="token string"> \n true_label/pred_label: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>trues<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>preds<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="训练模型">训练模型</h5>
<p>  训练模型的话，其实就是将上面的代码缝合起来。代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    training_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> LoadFashionMNISTByTorchApi<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    batch_size <span class="token operator">=</span> <span class="token number">200</span>
    train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># train_features, train_labels = next(iter(train_dataloader))</span>
    <span class="token comment"># print(f"Feature batch shape: &#123;train_features.size()&#125;")</span>
    <span class="token comment"># print(f"Labels batch shape: &#123;train_labels.size()&#125;")</span>
    <span class="token comment"># img = train_features[1].squeeze()</span>
    <span class="token comment"># label = train_labels[1]</span>
    <span class="token comment"># plt.imshow(img, cmap="gray")</span>
    <span class="token comment"># plt.show()</span>
    <span class="token comment"># print(f"Label: &#123;label&#125;")</span>

    <span class="token comment"># 28*28</span>
    num_inputs <span class="token operator">=</span> <span class="token number">784</span>
    
    <span class="token comment"># num of class</span>
    num_outputs <span class="token operator">=</span> <span class="token number">10</span>

    <span class="token comment"># (748, 10)</span>
    w <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    w <span class="token operator">=</span> w<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    w<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w = '</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token comment"># (10, 1)</span>
    b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
    b <span class="token operator">=</span> b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    b<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b = '</span><span class="token punctuation">,</span> b<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>




    num_epochs <span class="token operator">=</span> <span class="token number">10</span>
    lr <span class="token operator">=</span> <span class="token number">0.1</span>

    net <span class="token operator">=</span> my_net

    loss <span class="token operator">=</span> cross_entropy

    <span class="token comment"># if torch.cuda.is_available():</span>
    <span class="token comment">#     w = w.to('cuda')</span>
    <span class="token comment">#     b = b.to('cuda')</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        times <span class="token operator">=</span> <span class="token number">1</span>
        train_acc_sum <span class="token operator">=</span> <span class="token number">0.0</span>
        train_loss_sum <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> img<span class="token punctuation">,</span> label <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
            <span class="token comment"># if torch.cuda.is_available():</span>
            <span class="token comment">#     img = img.to('cuda')</span>
            <span class="token comment">#     label = label.to('cuda')            </span>
            <span class="token comment"># print(img.shape, label.shape)</span>
            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> img<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">)</span>
            <span class="token comment"># print(l.shape)</span>
            <span class="token comment"># print(l)</span>

            <span class="token comment"># clean grad of w,b</span>
            w<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>
            b<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span> 

            <span class="token comment"># bp</span>
            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># update param</span>
            sgd<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span> b<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>

            train_acc_sum <span class="token operator">+=</span> accuracy<span class="token punctuation">(</span>net<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> img<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">)</span>
            train_loss_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>l<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>batch_size<span class="token punctuation">)</span>
            times <span class="token operator">+=</span> <span class="token number">1</span>

            <span class="token comment"># break</span>
        
        test_acc <span class="token operator">=</span> evaluate_accuracy<span class="token punctuation">(</span>net<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> test_dataloader<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch = '</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_loss = '</span><span class="token punctuation">,</span> train_loss_sum<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>times<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_acc = '</span><span class="token punctuation">,</span> train_acc_sum<span class="token operator">/</span>times<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'test_acc = '</span><span class="token punctuation">,</span> test_acc<span class="token punctuation">)</span>

        <span class="token comment"># break</span>
    
    <span class="token comment"># predict</span>
    predict<span class="token punctuation">(</span>net<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> test_dataloader<span class="token punctuation">,</span> n <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  从如上的代码可知，首先从数据集中得到小批量数据迭代器，然后随机生成初始化参数，最后在小批量数据上推理，求loss之，bp，更新参数，记录loss和acc，最终训练次数完了后，去预测。</p>
<p>  训练截图如下：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/train_log.png" alt="rep_img"/></center>
    </div>
</div> 
<p>  预测截图如下：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/predict_log.png" alt="rep_img"/></center>
    </div>
</div> 
&emsp;&emsp;从预测的截图来看，预测成功的准确率大于1/10。说明我们的模型的有效的。此图中看起来准确率较高，这是偶然现象，但是真实不应该这样的，因为在测试集上，准确率只有81%左右。
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  此外，我们这里仅仅是按照数学定义来做计算，在计算机中，我们现在设计的一些函数可能不合理，比如softmax会产生溢出，我们会用到LogExpSum技巧，把softmax和交叉熵一起计算，通过冥函数和对数函数的一些性质，我们可以化简后抵消一些exp的计算，保证数值的稳定性，我们只需要知道有这么一个事情即可。但是这一切都不需要我们来弄，我们只需要调用别人设计的好的函数即可，比如pythorch中的torch.nn.CrossEntropyLoss()。如果真的有需要，可以根据LogExpSum的定义来直接编写就行，在这里，本文就不关注这个。</p>
<p>  从线性回归到softmax回归，我们算是基本了解清楚了深度学习的一些基本的概念，这为我们去看和改一些比较好的、公开的模型打下了基础。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V1.0.0)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V2.0.0 alpha1)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html">https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html</a></p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Pytorch/" rel="tag"># Pytorch</a>
              <a href="/tags/Softmax/" rel="tag"># Softmax</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/07/04/blog_idx_105/" rel="prev" title="DL基础补全计划(一)---线性回归及示例（Pytorch，平方损失）">
                  <i class="fa fa-angle-left"></i> DL基础补全计划(一)---线性回归及示例（Pytorch，平方损失）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/07/18/blog_idx_107/" rel="next" title="DL基础补全计划(三)---模型选择、欠拟合、过拟合">
                  DL基础补全计划(三)---模型选择、欠拟合、过拟合 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Sky</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">286k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">17:19</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":250,"hOffset":50,"vOffset":5},"mobile":{"show":false,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.8},"log":false});</script></body>
</html>
