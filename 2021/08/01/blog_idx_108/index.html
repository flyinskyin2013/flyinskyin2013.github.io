<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"e-x.top","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.27.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":false,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="PS：要转载请注明出处，本人版权所有。 PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。  环境说明   Windows 10   VSCode   Python 3.8.10   Pytorch 1.8.1   Cuda 10.2   前言    在《DL基础补全计划(三)—模型选择、欠拟合、过拟合》（ https:&#x2F;&#x2F;blog.csdn.net&#x2F;u01172">
<meta property="og:type" content="article">
<meta property="og:title" content="DL基础补全计划(四)---对抗过拟合：权重衰减、Dropout">
<meta property="og:url" content="https://e-x.top/2021/08/01/blog_idx_108/index.html">
<meta property="og:site_name" content="Sky&#39;s Blogs">
<meta property="og:description" content="PS：要转载请注明出处，本人版权所有。 PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。  环境说明   Windows 10   VSCode   Python 3.8.10   Pytorch 1.8.1   Cuda 10.2   前言    在《DL基础补全计划(三)—模型选择、欠拟合、过拟合》（ https:&#x2F;&#x2F;blog.csdn.net&#x2F;u01172">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting.png">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/w_weight_decay.png">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/wb_weight_decay1.png">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/wb_weight_decay2.png">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting_dp.png">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting_dp_sov.png">
<meta property="og:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg">
<meta property="article:published_time" content="2021-08-01T09:35:43.000Z">
<meta property="article:modified_time" content="2024-05-18T11:06:02.651Z">
<meta property="article:author" content="Sky">
<meta property="article:tag" content="Dropout">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting.png">


<link rel="canonical" href="https://e-x.top/2021/08/01/blog_idx_108/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://e-x.top/2021/08/01/blog_idx_108/","path":"2021/08/01/blog_idx_108/","title":"DL基础补全计划(四)---对抗过拟合：权重衰减、Dropout"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>DL基础补全计划(四)---对抗过拟合：权重衰减、Dropout | Sky's Blogs</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8677552300382028"
     crossorigin="anonymous"></script>


  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Sky's Blogs</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">A normal star</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>
<div class="custom-middle-nav animated fadeInDown">
  <div class="custom-nav-item">
    <a href="/archives/"><i class="fa fa-archive"></i> 日志历程</a>
  </div>
  <div class="custom-nav-item">
    <a href="/categories/"><i class="fa fa-th"></i> 全部分类</a>
  </div>
  <div class="custom-nav-item">
    <a href="/tags/"><i class="fa fa-tags"></i> 热门标签</a>
  </div>
  <div class="custom-nav-item">
    <a href="javascript:;" class="my-search-btn"><i class="fa fa-search"></i> 本站搜索</a>
  </div>
</div>


<script>
// 使用脚本手动触发 NexT 的搜索弹窗
document.addEventListener('DOMContentLoaded', () => {
  const customBtn = document.querySelector('.my-search-btn');
  customBtn.addEventListener('click', (e) => {
    e.preventDefault();
    // 找到 NexT 原生的那个搜索触发按钮并模拟点击
    const originalBtn = document.querySelector('.site-nav-right .popup-trigger');
    if (originalBtn) {
      originalBtn.click();
    } else {
      // 如果原生的没找到，尝试直接调用 NexT 的 Search 内部变量（针对某些版本）
      if (typeof CONFIG.local_search !== 'undefined') {
        // 尝试手动激活弹窗
        document.querySelector('.search-pop-overlay').style.display = 'block';
        document.body.style.overflow = 'hidden';
        document.querySelector('.search-input').focus();
      }
    }
  });
});
</script>
</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Sky"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Sky</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">139</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">92</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">222</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/flyinskyin2013" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;flyinskyin2013" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>
<div id="days" style="margin-top: 10px; font-size: 13px; color: #555;"></div>
<script>
  function show_date_time(){
    window.setTimeout("show_date_time()", 1000);
    BirthDay=new Date("01/07/2014 00:00:00"); // 这里改成你建站的时间
    today=new Date();
    timeold=(today.getTime()-BirthDay.getTime());
    sectimeold=timeold/1000
    secondsold=Math.floor(sectimeold);
    msPerDay=24*60*60*1000
    e_daysold=timeold/msPerDay
    daysold=Math.floor(e_daysold);
    document.getElementById("days").innerHTML="本站已运行 "+daysold+" 天";
  }
  show_date_time();
</script>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/08/01/blog_idx_108/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="DL基础补全计划(四)---对抗过拟合：权重衰减、Dropout | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DL基础补全计划(四)---对抗过拟合：权重衰减、Dropout
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-08-01 17:35:43" itemprop="dateCreated datePublished" datetime="2021-08-01T17:35:43+08:00">2021-08-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky sky@sky-home.com
 * @LastEditTime: 2023-04-08 11:10:23
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=108） 
&emsp;&emsp;本文发布于 2021-08-01 17:35:43     （BlogID=108） 
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Windows 10</p>
</li>
<li class="lvl-2">
<p>VSCode</p>
</li>
<li class="lvl-2">
<p>Python 3.8.10</p>
</li>
<li class="lvl-2">
<p>Pytorch 1.8.1</p>
</li>
<li class="lvl-2">
<p>Cuda 10.2</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  在《DL基础补全计划(三)—模型选择、欠拟合、过拟合》（ <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/118881125">https://blog.csdn.net/u011728480/article/details/118881125</a> ）一文中，我们已经了解了我们训练过程中的一些现象，对于欠拟合问题我们一般是增加训练集大小。对于过拟合，我们也提供了一个解决方案，那就是限制模型的复杂度（参数个数）。</p>
<p>  在以后我们构造的模型里面，其参数都是成百上千的，如果通过限制参数（更换模型）来解决过拟合问题太简单粗暴了，于是我们需要一些更加细腻的手段来抑制过拟合。此外，我们还必须知道，我们增加训练集总是能够缓解过拟合的问题，但是这不是根本办法。于是深度学习大佬们又引出了其他的两个方案，他们分别是权重衰减和Dropout。</p>
<p>  到此为止，我们可以有如下的方法缓解过拟合问题：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>控制模型复杂度</p>
</li>
<li class="lvl-2">
<p>增大训练集</p>
</li>
<li class="lvl-2">
<p>权重衰减</p>
</li>
<li class="lvl-2">
<p>Dropout</p>
</li>
</ul>
<br/>
<br/>
<br/>
<br/>
<h3 id="权重衰减-L2正则化">权重衰减(L2正则化)</h3>
<hr>
<p>  其实书上对于权重衰减的定义还是比较好理解的，我们定义我们的模型为M(X)，当M(X)=0时，此时，我们的模型最简单，因为所有的输入都是0。我们最终想要的是M(X)的值越来越接近于0，那么我们权重的范数也需要越来越接近于0，这样M(X)的复杂度越来越小。</p>
<p>  出于以上的目的，我们可以将权重的范数给加到Loss函数结果里面去，通过BP算法，这样我们可以让权重的范数越来越接近于0。其中我们常用的L2范数，其可以限制权重中的大值，也可以使权重均匀分布，不会出现极端值，这是一般情况下我们想看到的。</p>
<p>  下面，我们通过一个实例及图示来感性的认知权重衰减。</p>
<br/>
<br/>
<h5 id="实例代码">实例代码</h5>
<p>  首先我们设计了一个200个权重和1个偏置的数据生成器，加上噪声，得到我们数据集。这里我们采集了100个测试集和20个训练集。从这里我们马上就可以知道，这个肯定会过拟合，因为训练集太小了，而模型复杂度太大了。</p>
<p>  下面是完整代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils <span class="token keyword">import</span> data
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">import</span> MultipleLocator

fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
xdata0<span class="token punctuation">,</span> ydata0 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
xdata1<span class="token punctuation">,</span> ydata1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
line0<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TrainError'</span><span class="token punctuation">)</span>
line1<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'b-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TestError'</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">init_and_show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Train/Test Loss'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token number">10e-5</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_yscale<span class="token punctuation">(</span><span class="token string">'log'</span><span class="token punctuation">)</span>
    <span class="token comment"># y_locator = MultipleLocator(0.1)</span>
    <span class="token comment"># ax.yaxis.set_major_locator(y_locator)</span>
    ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span>line0<span class="token punctuation">,</span> line1<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'TrainError'</span><span class="token punctuation">,</span> <span class="token string">'TestError'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># ax.legend([line1], ('TestError', ))</span>
    line0<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata0<span class="token punctuation">,</span> ydata0<span class="token punctuation">)</span>
    line1<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata1<span class="token punctuation">,</span> ydata1<span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">l2_penalty</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> b <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>w<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>w<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>b<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>

<span class="token keyword">def</span> <span class="token function">synthetic_data</span><span class="token punctuation">(</span>true_w<span class="token punctuation">,</span> true_b<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""⽣成y = ax1 + bx2 + cx3 .... ....  + b + 噪声。"""</span>

    X <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>true_w<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    y <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token punctuation">,</span> true_w<span class="token punctuation">)</span> <span class="token operator">+</span> true_b
    
    <span class="token comment"># 噪声</span>
    y <span class="token operator">+=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> X<span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>



<span class="token keyword">class</span> <span class="token class-name">TestNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_nums<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TestNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>test_net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># y=X*W+B</span>
            <span class="token comment"># x.shape(batch_size, input_nums), w.shape(input_nums, output_nums)</span>
            <span class="token comment"># y.shape(batch_size, output_nums)</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_nums<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>   

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print(x.dtype)</span>
        <span class="token comment"># </span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>test_net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># copy from d2l/torch.py</span>
<span class="token keyword">def</span> <span class="token function">load_array</span><span class="token punctuation">(</span>data_arrays<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Construct a PyTorch data iterator."""</span>
    dataset <span class="token operator">=</span> data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span><span class="token operator">*</span>data_arrays<span class="token punctuation">)</span>
    <span class="token keyword">return</span> data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span>is_train<span class="token punctuation">)</span>

<span class="token comment"># def data_loader(batch_size, features, labels):</span>
<span class="token comment">#     num_examples = len(features)</span>
<span class="token comment">#     indices = list(range(num_examples))</span>
<span class="token comment">#     np.random.shuffle(indices) # 样本的读取顺序是随机的</span>

<span class="token comment">#     for i in range(0, num_examples, batch_size):</span>
<span class="token comment">#         j = np.array(indices[i: min(i + batch_size, num_examples)])</span>
<span class="token comment">#         yield torch.tensor(features.take(j, 0)), torch.tensor(labels.take(j)) # take函数根据索引返回对应元素</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> train_examples
    num_batches <span class="token operator">=</span> train_examples <span class="token operator">/</span> batch_size
    train_loss_sum <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> batch<span class="token punctuation">,</span> <span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># move X, y to gpu</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token comment"># Compute prediction and loss</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        param_iter <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># loss = loss_fn(pred, y) + lambda_val*l2_penalty(next(param_iter), next(param_iter))</span>
        <span class="token comment"># next(model.parameters())</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">+</span> lambda_val<span class="token operator">*</span>l2_penalty<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># Backpropagation</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        train_loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>


        <span class="token keyword">if</span> batch <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            loss<span class="token punctuation">,</span> current <span class="token operator">=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">:</span><span class="token format-spec">>7f</span><span class="token punctuation">&#125;</span></span><span class="token string">  [</span><span class="token interpolation"><span class="token punctuation">&#123;</span>current<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>size<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">]"</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Train Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss_sum<span class="token operator">/</span>num_batches<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> train_loss_sum<span class="token operator">/</span>num_batches


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_batches <span class="token operator">=</span> test_examples <span class="token operator">/</span> batch_size
    test_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            <span class="token comment"># move X, y to gpu</span>
            <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
                y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            test_loss <span class="token operator">+=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    test_loss <span class="token operator">/=</span> num_batches
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> test_loss
    
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using &#123;&#125; device'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    num_inputs <span class="token operator">=</span> <span class="token number">200</span>

    true_w <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>num_inputs<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.01</span>

    true_b <span class="token operator">=</span> <span class="token number">0.78</span>  

    test_examples <span class="token operator">=</span> <span class="token number">100</span>
    train_examples <span class="token operator">=</span> <span class="token number">20</span>
    
    num_examples <span class="token operator">=</span> test_examples <span class="token operator">+</span> train_examples

    f1<span class="token punctuation">,</span> labels <span class="token operator">=</span> synthetic_data<span class="token punctuation">(</span>true_w<span class="token punctuation">,</span> true_b<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>


    l1_loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    learning_rate <span class="token operator">=</span> <span class="token number">0.01</span>

    model <span class="token operator">=</span> TestNet<span class="token punctuation">(</span>num_inputs<span class="token punctuation">)</span>

    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>

    epochs <span class="token operator">=</span> <span class="token number">100</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>


    batch_size <span class="token operator">=</span> <span class="token number">5</span>

    train_data <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>f1<span class="token punctuation">[</span><span class="token punctuation">:</span>train_examples<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">[</span><span class="token punctuation">:</span>train_examples<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_data <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>f1<span class="token punctuation">[</span>train_examples<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">[</span>train_examples<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    train_dataloader <span class="token operator">=</span> load_array<span class="token punctuation">(</span>train_data <span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> load_array<span class="token punctuation">(</span>test_data <span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># verify dataloader</span>
    <span class="token comment"># for x,y in train_dataloader:</span>
    <span class="token comment">#     print(x.shape)</span>
    <span class="token comment">#     print(y.shape)</span>
    <span class="token comment">#     print(torch.matmul( x , torch.tensor(true_w)) + torch.tensor(true_b))</span>
    <span class="token comment">#     print(y)</span>
    <span class="token comment">#     break</span>
    param_iter <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'W = '</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b = '</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>t<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">\n-------------------------------"</span></span><span class="token punctuation">)</span>
        train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
        test_l <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">)</span>
        ydata0<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_l<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
        ydata1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_l<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
        xdata0<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        xdata1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        <span class="token comment"># print(test_l)</span>
        <span class="token comment"># print(train_l)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done!"</span><span class="token punctuation">)</span>

    init_and_show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    param_iter <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># print('W = ')</span>
    <span class="token comment"># print(next(param_iter).shape)</span>
    <span class="token comment"># print('b = ')</span>
    <span class="token comment"># print(next(param_iter).shape)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w的L2范数是：'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b的L2范数是：'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="过拟合">过拟合</h5>
<p>  这个时候是未添加l2到损失函数的。<br>
  train函数如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>  训练结果如下，存在严重的过拟合现象：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting.png" alt="rep_img"/></center>
    </div>
</div>    
<br/>
<br/>
<h5 id="权重衰减">权重衰减</h5>
<p>  我们先对w进行权重衰减。<br>
  train函数如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>  训练结果如下，过拟合现象出现了缓解：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/w_weight_decay.png" alt="rep_img"/></center>
    </div>
</div>  
<br/>
<br/>
<br/>
<br/>
<h5 id="权重衰减适应性">权重衰减适应性</h5>
<p>  我们对w和b同时进行权重衰减。train函数如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>  训练结果如下，我们发现，过拟合现象并没有缓解：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/wb_weight_decay1.png" alt="rep_img"/></center>
    </div>
</div>  
<p>  就是上图引起了我的兴趣，因为我们引入了权重衰减，但是其并没有缓解，这是为什么呢？还记得我们权重衰减的目标是将权重的范数逼近于0吗？但是我们b是一个不接近于0的常量，因此过拟合并没有缓解。</p>
<p>  我们对w和b同时进行权重衰减。我们修改，train函数如下，主要将true_b调整为接近于0，这样我们同时对w，b进行衰减就是合理的：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">true_b <span class="token operator">=</span> <span class="token number">0.01</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/wb_weight_decay2.png" alt="rep_img"/></center>
    </div>
</div>  
&emsp;&emsp;我们通过上面两张图的结果，说明的权重衰减的适应性以及目标。注意我们一般情况下不会对b进行权重衰减，因为其是常量。我看学习资料上并没有介绍为什么偏置不能够进行权重衰减，这里我做的这个实验可以当做一个原因吧。
<p>  pytorch的优化器里面的weight_decay参数是对所有参数进行衰减，要注意这个问题，若想单独对w进行衰减，请分别对不同的参数设定不同的优化器。这一块网上资料很多，我就不多说了。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="Dropout">Dropout</h3>
<hr>
<p>  首先，Dropout是在([Srivastava et al., 2014] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1), 1929‒1958.)一文中引出的。</p>
<p>  对于Dropout，我们可以从资料里面的代码里面看到其相关的原理：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dropout_layer</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">assert</span> <span class="token number">0</span> <span class="token operator">&lt;=</span> dropout <span class="token operator">&lt;=</span> <span class="token number">1</span>
    <span class="token comment"># 在本情况中，所有元素都被丢弃。</span>
    <span class="token keyword">if</span> dropout <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    <span class="token comment"># 在本情况中，所有元素都被保留。</span>
    <span class="token keyword">if</span> dropout <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> X
    mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">></span> dropout
    <span class="token keyword">print</span><span class="token punctuation">(</span>mask<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> mask<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">*</span> X <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> dropout<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  其工作如下：在训练的时候，按照传入的概率p丢弃一部分输出，并除以1-p。在测试的时候，跳过dropout_layer。其能正常工作的关键就是‘玄学’，打破了前一层和后一层的特定关联，破坏了两层之间的特定关联，缓解了过拟合。这个部分，建议多体会，虽然随机置0了部分值，但是输出规模是的趋势是一定的。</p>
<p>  虽然我们从这里说明了其生效的原理，但是我们并没有解释为啥这样写是合理的？注意为何我们要在训练的时候除以1-p呢？</p>
<p>  其实我们可以看到，Dropout是针对输出的，当我们只要保证训练和测试的输出规模保持一致，就可以保证测试和训练的结果是一致的。这里的规模保持一致，其实就是他们两个的期望保持一致。定义输入为X, dropout概率为p(以p的概率丢弃)，那么$E(x) = ((1-p)X + p*0)/(1-p) = X$。因此，我们也可以得到结论，我们在训练时dropout生效，测试时直接跳过dropout层，这两种情况下的X的规模是一致的，不影响我们的网络结果。</p>
<p>  此外，我们从这里可以看到，dropout是以概率来丢弃相关的输入X，那么我们必须在X规模足够大的情况下使用dropout，才能保证剩下的X能够学到足够的特征。因此，我们平常一般把dropout放在全连接层后。</p>
<p>  下面，我们自己构造一个分类网络，使用FashionMNIST数据集（60000训练，10000测试）。然后在全连接层后面接dropout层，默认是不丢弃任何项，dropout的p=0，代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils <span class="token keyword">import</span> data
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">import</span> MultipleLocator
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
xdata<span class="token punctuation">,</span> ydata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
line0<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TrainError'</span><span class="token punctuation">)</span>
line1<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'b-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TrainAcc'</span><span class="token punctuation">)</span>
line2<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'g-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TestError'</span><span class="token punctuation">)</span>
line3<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'y-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TestAcc'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">init_and_show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'loss/acc'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Train/Test Loss/Acc'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># ax.set_yscale('log')</span>
    <span class="token comment"># y_locator = MultipleLocator(0.1)</span>
    <span class="token comment"># ax.yaxis.set_major_locator(y_locator)</span>
    ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span>line0<span class="token punctuation">,</span> line1<span class="token punctuation">,</span> line2<span class="token punctuation">,</span> line3<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'TrainError'</span><span class="token punctuation">,</span> <span class="token string">'TrainAcc'</span><span class="token punctuation">,</span> <span class="token string">"TestError"</span><span class="token punctuation">,</span> <span class="token string">"TestAcc"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># ax.legend([line1], ('TestError', ))</span>
    line0<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    line1<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    line2<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    line3<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">dropout_layer</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">assert</span> <span class="token number">0</span> <span class="token operator">&lt;=</span> dropout <span class="token operator">&lt;=</span> <span class="token number">1</span>
    <span class="token comment"># 在本情况中，所有元素都被丢弃。</span>
    <span class="token keyword">if</span> dropout <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    <span class="token comment"># 在本情况中，所有元素都被保留。</span>
    <span class="token keyword">if</span> dropout <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> X
    mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">></span> dropout
    <span class="token keyword">print</span><span class="token punctuation">(</span>mask<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> mask<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">*</span> X <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> dropout<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">TestNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dropout_p_arr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TestNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>test_net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>

            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout_p_arr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout_p_arr<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

        <span class="token punctuation">)</span>   

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print(x.dtype)</span>
        <span class="token comment"># </span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>test_net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">LoadFashionMNISTByTorchApi</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    resize<span class="token operator">=</span><span class="token number">28</span>
    trans <span class="token operator">=</span> <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> resize<span class="token punctuation">:</span>
        trans<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span>resize<span class="token punctuation">)</span><span class="token punctuation">)</span>
    trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>trans<span class="token punctuation">)</span>
    <span class="token comment"># 60000*28*28</span>
    training_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"..\data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>trans
    <span class="token punctuation">)</span>

    <span class="token comment"># 10000*28*28</span>
    test_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"..\data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>trans
    <span class="token punctuation">)</span>

    <span class="token comment"># labels_map = &#123;</span>
    <span class="token comment">#     0: "T-Shirt",</span>
    <span class="token comment">#     1: "Trouser",</span>
    <span class="token comment">#     2: "Pullover",</span>
    <span class="token comment">#     3: "Dress",</span>
    <span class="token comment">#     4: "Coat",</span>
    <span class="token comment">#     5: "Sandal",</span>
    <span class="token comment">#     6: "Shirt",</span>
    <span class="token comment">#     7: "Sneaker",</span>
    <span class="token comment">#     8: "Bag",</span>
    <span class="token comment">#     9: "Ankle Boot",</span>
    <span class="token comment"># &#125;</span>
    <span class="token comment"># figure = plt.figure(figsize=(8, 8))</span>
    <span class="token comment"># cols, rows = 3, 3</span>
    <span class="token comment"># for i in range(1, cols * rows + 1):</span>
    <span class="token comment">#     sample_idx = torch.randint(len(training_data), size=(1,)).item()</span>
    <span class="token comment">#     img, label = training_data[sample_idx]</span>
    <span class="token comment">#     figure.add_subplot(rows, cols, i)</span>
    <span class="token comment">#     plt.title(labels_map[label])</span>
    <span class="token comment">#     plt.axis("off")</span>
    <span class="token comment">#     plt.imshow(img.squeeze(), cmap="gray")</span>
    <span class="token comment"># plt.show()</span>
    <span class="token keyword">return</span> training_data<span class="token punctuation">,</span> test_data
    
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>
    size <span class="token operator">=</span> num_batches<span class="token operator">*</span>batch_size
    train_loss_sum <span class="token operator">=</span> <span class="token number">0</span>
    train_acc_sum <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> batch<span class="token punctuation">,</span> <span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># move X, y to gpu</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
        <span class="token comment"># Compute prediction and loss</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># print(pred.shape)</span>
        <span class="token comment"># print(y.shape)</span>
        
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

        <span class="token comment"># Backpropagation</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        train_loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># cal train acc</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        train_acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>batch_size

        <span class="token keyword">if</span> batch <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            loss<span class="token punctuation">,</span> current <span class="token operator">=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">:</span><span class="token format-spec">>7f</span><span class="token punctuation">&#125;</span></span><span class="token string">  [</span><span class="token interpolation"><span class="token punctuation">&#123;</span>current<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>size<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">]"</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Train Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss_sum<span class="token operator">/</span>num_batches<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Train Acc  : \n Avg acc : </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_acc_sum<span class="token operator">/</span>num_batches<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> train_loss_sum<span class="token operator">/</span>num_batches<span class="token punctuation">,</span> train_acc_sum<span class="token operator">/</span>num_batches


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>
    test_loss <span class="token operator">=</span> <span class="token number">0</span>
    test_acc <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            <span class="token comment"># move X, y to gpu</span>
            <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
                y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            test_loss <span class="token operator">+=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            test_acc <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>batch_size
    test_loss <span class="token operator">/=</span> num_batches
    test_acc <span class="token operator">/=</span> num_batches
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Acc  : \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_acc<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string">  \n"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> test_loss<span class="token punctuation">,</span> test_acc
    
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using &#123;&#125; device'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    learning_rate <span class="token operator">=</span> <span class="token number">0.5</span>
    <span class="token comment"># [0.4, 0.7]</span>
    model <span class="token operator">=</span> TestNet<span class="token punctuation">(</span><span class="token punctuation">)</span>

    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>

    epochs <span class="token operator">=</span> <span class="token number">10</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>


    batch_size <span class="token operator">=</span> <span class="token number">200</span>

    train_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> LoadFashionMNISTByTorchApi<span class="token punctuation">(</span><span class="token punctuation">)</span>
    

    train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># #verify dataloader</span>
    <span class="token comment"># for x,y in train_dataloader:</span>
    <span class="token comment">#     print(x.shape)</span>
    <span class="token comment">#     print(y.shape)</span>
    <span class="token comment">#     break</span>

    param_iter <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    
    
    <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>t<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">\n-------------------------------"</span></span><span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_l<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>
        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        test_l<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span>

        xdata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        xdata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        xdata<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        xdata<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>

        ydata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_l<span class="token punctuation">)</span>
        ydata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
        ydata<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_l<span class="token punctuation">)</span>
        ydata<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span>
        
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done!"</span><span class="token punctuation">)</span>

    init_and_show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="正常过拟合">正常过拟合</h5>
<p>  直接用上面代码进行训练后得到结果如下：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting_dp.png" alt="rep_img"/></center>
    </div>
</div>    
&emsp;&emsp;我们可以发现，测试准确率比训练准确率低，满足过拟合的现象。
<h5 id="启用dropout">启用dropout</h5>
<p>  修改训练代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">    <span class="token comment"># [0.4, 0.7]</span>
model <span class="token operator">=</span> TestNet<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>  训练结果如图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting_dp_sov.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  我们可以很直观的发现，训练和测试的acc和error出现了重合的情况，至少证明了过拟合现象出现了缓解。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  对于权重衰减，一般就是要将参数的L2范数尽量学习来趋近于0，这样模型复杂度变小。此外权重衰减还可以将参数限制到一个稳定的范围，避免出现了较大的波动。对于稳定的学习过程是有帮助的。</p>
<p>  对于Dropout来说，就是打破一些输出比较大的相关层的关联性，注意，其是针对输出，并不是针对权重。有些时候，相关层的关联性就是我们要学的，但是有些时候，这种关联性可能就是不需要的，所以通过这种‘玄学’的方式，在训练的时候，以概率性来丢弃某些输出，打破这项输出和下一层的关联性。这对于大的网络来说，是有意义的。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V1.0.0)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V2.0.0 alpha1)</p>
</li>
<li class="lvl-2">
<p>Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1), 1929‒1958.</p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Dropout/" rel="tag"># Dropout</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/07/18/blog_idx_107/" rel="prev" title="DL基础补全计划(三)---模型选择、欠拟合、过拟合">
                  <i class="fa fa-angle-left"></i> DL基础补全计划(三)---模型选择、欠拟合、过拟合
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/08/08/blog_idx_109/" rel="next" title="DL基础补全计划(五)---数值稳定性及参数初始化（梯度消失、梯度爆炸）">
                  DL基础补全计划(五)---数值稳定性及参数初始化（梯度消失、梯度爆炸） <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Sky</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">286k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">17:19</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":250,"hOffset":50,"vOffset":5},"mobile":{"show":false,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.8},"log":false});</script></body>
</html>
