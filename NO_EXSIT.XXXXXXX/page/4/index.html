<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"e-x.top","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.27.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":false,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Sky&#39;s Blogs">
<meta property="og:url" content="https://e-x.top/NO_EXSIT.XXXXXXX/page/4/index.html">
<meta property="og:site_name" content="Sky&#39;s Blogs">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Sky">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://e-x.top/NO_EXSIT.XXXXXXX/page/4/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"NO_EXSIT.XXXXXXX/page/4/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Sky's Blogs</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8677552300382028"
     crossorigin="anonymous"></script>


  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Sky's Blogs</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">A normal star</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>
<div class="custom-middle-nav animated fadeInDown">
  <div class="custom-nav-item">
    <a href="/archives/"><i class="fa fa-archive"></i> 日志历程</a>
  </div>
  <div class="custom-nav-item">
    <a href="/categories/"><i class="fa fa-th"></i> 全部分类</a>
  </div>
  <div class="custom-nav-item">
    <a href="/tags/"><i class="fa fa-tags"></i> 热门标签</a>
  </div>
  <div class="custom-nav-item">
    <a href="javascript:;" class="my-search-btn"><i class="fa fa-search"></i> 本站搜索</a>
  </div>
</div>


<script>
// 使用脚本手动触发 NexT 的搜索弹窗
document.addEventListener('DOMContentLoaded', () => {
  const customBtn = document.querySelector('.my-search-btn');
  customBtn.addEventListener('click', (e) => {
    e.preventDefault();
    // 找到 NexT 原生的那个搜索触发按钮并模拟点击
    const originalBtn = document.querySelector('.site-nav-right .popup-trigger');
    if (originalBtn) {
      originalBtn.click();
    } else {
      // 如果原生的没找到，尝试直接调用 NexT 的 Search 内部变量（针对某些版本）
      if (typeof CONFIG.local_search !== 'undefined') {
        // 尝试手动激活弹窗
        document.querySelector('.search-pop-overlay').style.display = 'block';
        document.body.style.overflow = 'hidden';
        document.querySelector('.search-input').focus();
      }
    }
  });
});
</script>
</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Sky"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Sky</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">139</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">92</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">222</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/flyinskyin2013" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;flyinskyin2013" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>
<div id="days" style="margin-top: 10px; font-size: 13px; color: #555;"></div>
<script>
  function show_date_time(){
    window.setTimeout("show_date_time()", 1000);
    BirthDay=new Date("01/07/2014 00:00:00"); // 这里改成你建站的时间
    today=new Date();
    timeold=(today.getTime()-BirthDay.getTime());
    sectimeold=timeold/1000
    secondsold=Math.floor(sectimeold);
    msPerDay=24*60*60*1000
    e_daysold=timeold/msPerDay
    daysold=Math.floor(e_daysold);
    document.getElementById("days").innerHTML="本站已运行 "+daysold+" 天";
  }
  show_date_time();
</script>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/11/21/blog_idx_113/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/11/21/blog_idx_113/" class="post-title-link" itemprop="url">寒武纪加速平台(MLU200系列) 摸鱼指南（三）--- 模型移植-分割网络实例</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-11-21 17:29:37" itemprop="dateCreated datePublished" datetime="2021-11-21T17:29:37+08:00">2021-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">嵌入式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/DL/%E5%B8%B8%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">常识</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>9 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky sky@sky-home.com
 * @LastEditTime: 2023-04-08 11:14:11
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=113） 
&emsp;&emsp;本文发布于 2021-11-21 17:29:37     （BlogID=113） 
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Ubuntu 18.04</p>
</li>
<li class="lvl-2">
<p>MLU270 加速卡一张</p>
</li>
<li class="lvl-2">
<p>寒武纪Pytorch-Docker移植环境</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  阅读本文前，请务必须知以下前置文章概念：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 ( <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/121194076">https://blog.csdn.net/u011728480/article/details/121194076</a> )</p>
</li>
<li class="lvl-2">
<p>《寒武纪加速平台(MLU200系列) 摸鱼指南（二）— 模型移植-环境搭建》 ( <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/121320982">https://blog.csdn.net/u011728480/article/details/121320982</a> )</p>
</li>
</ul>
<p>  经过了前面两篇文章的介绍，我们也对寒武纪加速平台有了一个朴实的了解。为了加深我们对寒武纪平台的理解，我这里将会使用一个分割网络的实例来展示寒武纪平台整个模型移植和部署过程。</p>
<p>  若文中引用部分存在侵权，请及时联系我删除。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="实例基本介绍">实例基本介绍</h3>
<hr>
<p>  这里对这个简单的分割网络做一个简介，这里训练使用的是CamVid数据集。输入是1*3*480*480。输出是480*480。</p>
<p>  这里最终的效果就是分割出输入图片里面的汽车。最终网络效果测试如下图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_113/seg_result.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  这个时候，我们也得到了一个可以用于移植和测试的pth模型文件。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="移植模型基本步骤">移植模型基本步骤</h3>
<hr>
<p>  其实Pytorch的模型移植还是比较简单的，按照一定流程进行测试即可。我总结的基本流程如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>在docker里面，跑cpu版本的模型推理代码。</p>
</li>
<li class="lvl-2">
<p>在docker里面，跑cpu版本的量化模型生成代码，同时进行量化模型的测试。</p>
</li>
<li class="lvl-2">
<p>在docker里面，将量化模型转换为离线模型。</p>
</li>
</ul>
<br/>
<br/>
<h5 id="在Docker里运行cpu推理代码">在Docker里运行cpu推理代码</h5>
<p>  至今为止，根据寒武纪官方文档描述，现在的docker环境里面存在的是pytorch1.3环境，这个可能和主流模型支持的pytorch 1.7+有差异。所以，为了后续工作的顺利展开，我们不要一上来就开始量化模型，先保证模型能够在pytorch 1.3环境能够正常工作。</p>
<p>  当我们训练好模型后，得到pth文件，然后在训练环境里面还会做一个测试pth文件的脚本，判断模型的效果。同理，我们应该将此测试脚本放到移植环境里面再跑一次，一般来说都会多多少少出点问题。</p>
<p>  至今为止，我们遇到过两大类问题，一类为pytorch1.3某些算子不支持，可以更换为其他类似算子，或者自己实现这个算子。第二类为一些版本问题，比如模型保存的格式在pytorch1.6后使用的是zip格式（详情见torch.save api说明注释里面），旧版本要加载模型，需要使用_use_new_zipfile_serialization=False重新存储一下模型文件。</p>
<p>  一般来说，大致的模型转换代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 存在一个模型test.pth(zip格式)</span>
<span class="token comment"># 存在一个获取的模型网络结构类：TestModel</span>
<span class="token keyword">import</span> torch

model <span class="token operator">=</span> TestModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'test.pth'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>           

torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">'new_test.pth'</span><span class="token punctuation">,</span> _use_new_zipfile_serialization<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment"># 得到了旧版本的pth文件。方便pytorch 1.6以下进行加载</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="在Docker里处理量化模型">在Docker里处理量化模型</h5>
<p>  这里有两个步骤，首先是使用寒武纪的pytorch接口生成量化模型，然后对量化模型进行测试。注意，这里生成的量化模型有两种，一种是INT8，一种是INT16，具体怎么选择，根据实际情况。一般来说，分类、分割算法可以尝试直接使用INT8，目标检测需要测试再下结论。此外INT8由于运算量的减少，也意味着推理速度的提升。如果不特殊说明，后续默认采用的是INT8模式。</p>
<p>  此外，还需要说明的是，量化一般是量化卷积、全连接等这些参数量较大的层，其他的模型参数依旧是FP16或者FP32存在。</p>
<p>  首先生成量化模型：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 存在一个模型new_test.pth(非zip格式)</span>
<span class="token comment"># 存在一个获取的模型网络结构类：TestModel</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch_mlu<span class="token punctuation">.</span>core<span class="token punctuation">.</span>mlu_quantize <span class="token keyword">as</span> mlu_quantize

model <span class="token operator">=</span> TestModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'new_test.pth'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>          
mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span> 
<span class="token comment"># 注意此接口，这里不使用firstconv优化，它的作用是将归一化放到第一层去一起加速做，但是有些模型的前处理是不需要这样做的，具体信息，请参考寒武纪官方文档。</span>
net_quantization <span class="token operator">=</span> mlu_quantize<span class="token punctuation">.</span>quantize_dynamic_mlu<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'mean'</span><span class="token punctuation">:</span>mean<span class="token punctuation">,</span> <span class="token string">'std'</span><span class="token punctuation">:</span>std<span class="token punctuation">,</span> <span class="token string">'firstconv'</span><span class="token punctuation">:</span><span class="token boolean">False</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int8'</span><span class="token punctuation">,</span> gen_quant<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net_quantization<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'test_quantization.pth'</span><span class="token punctuation">)</span>

<span class="token comment"># 得到了INT8的量化模型文件test_quantization.pth</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  然后在量化模型上测试，此步骤的内容是验证模型量化之后，使用寒武纪定制的pytorch量化算子能否正常得到结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 存在一个INT8的量化模型文件test_quantization.pth</span>
<span class="token comment"># 存在一个获取的模型网络结构类：TestModel</span>
<span class="token keyword">import</span> torch_mlu
<span class="token keyword">import</span> torch_mlu<span class="token punctuation">.</span>core<span class="token punctuation">.</span>mlu_model <span class="token keyword">as</span> ct
<span class="token keyword">import</span> torch_mlu<span class="token punctuation">.</span>core<span class="token punctuation">.</span>mlu_quantize <span class="token keyword">as</span> mlu_quantize

model <span class="token operator">=</span> TestModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment"># step 1</span>
net <span class="token operator">=</span> mlu_quantize<span class="token punctuation">.</span>quantize_dynamic_mlu<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
<span class="token comment"># step 2</span>
net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'test_quantization.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 这里是</span>
input_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">480</span><span class="token punctuation">,</span><span class="token number">480</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># step 3</span>
net_mlu <span class="token operator">=</span> net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>ct<span class="token punctuation">.</span>mlu_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
input_mlu <span class="token operator">=</span> input_data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>ct<span class="token punctuation">.</span>mlu_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># step 4</span>
output<span class="token operator">=</span>net_mlu<span class="token punctuation">(</span>input_mlu<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># output的shape是480*480</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  如果这里量化之后的推理结果都是准确无误的，那么基本证明了模型移植成功了。其实从这里可以看出，这里的mlu其实就可以类比cuda，就可以大致猜想mlu是什么样的存在了。</p>
<br/>
<br/>
<h5 id="在Docker里生成离线模型">在Docker里生成离线模型</h5>
<p>  在之前的基础上，其实我们很快很方便的就生成了离线模型，不过这里的离线模型同样也有两种，还记得前文说的量化只会量化一些特殊层的参数，而模型中的其他层也是用的FP16或者，FP32,因此，离线模型也具备两种，一种是FP16,一种是FP32。通常来说，一个INT8版本的FP16离线模型是最佳的离线模型。</p>
<p>  生成MLU220离线模型：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 存在一个INT8的量化模型文件test_quantization.pth</span>
<span class="token comment"># 存在一个获取的模型网络结构类：TestModel</span>
<span class="token keyword">import</span> torch_mlu
<span class="token keyword">import</span> torch_mlu<span class="token punctuation">.</span>core<span class="token punctuation">.</span>mlu_model <span class="token keyword">as</span> ct
<span class="token keyword">import</span> torch_mlu<span class="token punctuation">.</span>core<span class="token punctuation">.</span>mlu_quantize <span class="token keyword">as</span> mlu_quantize

model <span class="token operator">=</span> TestModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment"># step 1</span>
net <span class="token operator">=</span> mlu_quantize<span class="token punctuation">.</span>quantize_dynamic_mlu<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
<span class="token comment"># step 2</span>
net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'test_quantization.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># </span>
input_data<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">480</span><span class="token punctuation">,</span><span class="token number">480</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># step 3</span>
net_mlu <span class="token operator">=</span> net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>ct<span class="token punctuation">.</span>mlu_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
input_mlu <span class="token operator">=</span> input_data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>ct<span class="token punctuation">.</span>mlu_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># 详细查看文档，一般4</span>
core_number <span class="token operator">=</span> <span class="token number">4</span>
ct<span class="token punctuation">.</span>set_core_number<span class="token punctuation">(</span>core_number<span class="token punctuation">)</span>
ct<span class="token punctuation">.</span>set_core_version<span class="token punctuation">(</span><span class="token string">'MLU220'</span><span class="token punctuation">)</span>
<span class="token comment"># torch_mlu.core.mlu_model.set_input_format(input_format)</span>
ct<span class="token punctuation">.</span>save_as_cambricon<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span>


net_trace <span class="token operator">=</span> torch<span class="token punctuation">.</span>jit<span class="token punctuation">.</span>trace<span class="token punctuation">(</span>net_mlu<span class="token punctuation">,</span> input_mlu<span class="token punctuation">,</span> check_trace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

net_trace<span class="token punctuation">(</span>input_mlu<span class="token punctuation">)</span> 

torch_mlu<span class="token punctuation">.</span>core<span class="token punctuation">.</span>mlu_model<span class="token punctuation">.</span>save_as_cambricon<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>

<span class="token comment"># 最终，我们得到了test.cambricon 和 test.cambricon_twins。test.cambricon_twins是离线模型的说明文件，包含输入数据格式通道等信息，也包含输出相关的信息。</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  到此，我们已经得到了离线模型，也完成了我们模型移植的前面一半的工作。</p>
<p>  此外，如果想得到MLU270的离线模型，也可以将set_core_version参数改为MLU270。如果将模型和输入tensor调用half()之后，就会得到fp16的模型格式，具体参考寒武纪官方文档。</p>
<p>  .cambricon_twins文件有一个重要的作用就是描述离线模型网络是输入输出格式及通道，毕竟我们的网络一般结果对不上，很大的原因都是预处理和后处理的毛病。下面我会给出.cambricon_twins的两个实例，一个是INT8FP32,一个是INT8FP16。</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_113/offline_info_fp32.png" alt="rep_img"/></center>
    </div>
</div>    
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_113/offline_info_fp16.png" alt="rep_img"/></center>
    </div>
</div>    
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  模型的移植流程，基本上都是固定的，一旦熟悉之后，其实就不会改了。</p>
<p>  最终一般有6个模型生成，两个INT8和INT16的量化模型。4个离线模型，INT8-FP32，INT8-FP16，INT16-FP32，INT16-FP16。不同的模型对应不同的速度和精度，根据模型实际情况酌情选择。</p>
<p>  注意，寒武纪除了支持Pytorch模型移植外，还支持caffe和tensorflow，因此如果需要转换这些模型，请查看对应文档。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 ( <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/121194076">https://blog.csdn.net/u011728480/article/details/121194076</a> )</p>
</li>
<li class="lvl-2">
<p>《寒武纪加速平台(MLU200系列) 摸鱼指南（二）— 模型移植-环境搭建》 ( <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/121320982">https://blog.csdn.net/u011728480/article/details/121320982</a> )</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://www.cambricon.com/">https://www.cambricon.com/</a></p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://www.cambricon.com/docs/pytorch/index.html">https://www.cambricon.com/docs/pytorch/index.html</a></p>
</li>
<li class="lvl-2">
<p>其他相关保密资料。</p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/11/14/blog_idx_112/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/11/14/blog_idx_112/" class="post-title-link" itemprop="url">寒武纪加速平台(MLU200系列) 摸鱼指南（二）--- 模型移植-环境搭建</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-11-14 18:13:51" itemprop="dateCreated datePublished" datetime="2021-11-14T18:13:51+08:00">2021-11-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">嵌入式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/DL/%E5%B8%B8%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">常识</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>8 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky sky@sky-home.com
 * @LastEditTime: 2023-04-08 11:13:38
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=112） 
&emsp;&emsp;本文发布于 2021-11-14 18:13:51     （BlogID=112） 
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Ubuntu 18.04</p>
</li>
<li class="lvl-2">
<p>MLU270 加速卡一张</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  阅读本文前，请务必须知以下前置文章概念：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 （ <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/121194076">https://blog.csdn.net/u011728480/article/details/121194076</a> ）</p>
</li>
</ul>
<p>  前文我们已经介绍一些基本的概念。在本文，将会从安装加速卡，到模型环境移植搭建完成，都会做一个简单的介绍。</p>
<p>  若文中引用部分存在侵权，请及时联系我删除。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="安装MLU270加速卡到主机">安装MLU270加速卡到主机</h3>
<hr>
<p>  首先MLU270加速卡你可以直接把他看为一张普通的独立显卡就行。只需要安装在主机的PCIE x16 口即可，并连接好供电线，其供电线是特制的接口，需要官方提供的线缆进行转换一下接口。其官网渲染图如图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_112/MLU270.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  开机后通过查看pcie设备即可发现刚刚安装的设备（lspci命令）：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_112/MLU270_pcie.png" alt="rep_img"/></center>
    </div>
</div>    
<br/>
<br/>
<br/>
<br/>
<h3 id="安装驱动">安装驱动</h3>
<hr>
<p>  根据其官网资料（ <a target="_blank" rel="noopener" href="https://www.cambricon.com/docs/driver/index.html">https://www.cambricon.com/docs/driver/index.html</a> ），我简要说明部分内容。</p>
<p>  首先根据其资料，我们可以看到大概支持两个系列的os，一个是ubuntu/debian，一个是centos。这里，我建议使用ubuntu，具体原因，有兴趣的可以去查看此文档的注意部分。</p>
<br/>
<br/>
<h5 id="在Ubuntu18-04上安装驱动">在Ubuntu18.04上安装驱动</h5>
<p>  首先从你的供应商拿到驱动包，名字如：neuware-mlu270-driver-dkms_xxx_all.deb。然后不用客气，直接执行：sudo dpkg -i neuware-mlu270-driver-dkms_xxx_all.deb。</p>
<p>  我们其实可以看到，其用DKMS来管理驱动，和安装N卡驱动非常类似。具体显示信息，请查看如上官网资料。这里只有一个问题要注意，就是内核版本一定要在其文档说明支持的范围内。</p>
<p>  当安装成功后，执行：cnmon，可以看到一个类似nvidia-smi的信息，包含了加速卡的一些基本信息。</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_112/cnmon.png" alt="rep_img"/></center>
    </div>
</div>    
<br/>
<br/>
<br/>
<br/>
<h3 id="安装CNToolKit">安装CNToolKit</h3>
<hr>
<p>  其实和我们前置文章里面讲的软件框架部分，当我们准备好驱动之后，其实下一步就是安装运行时层。运行时层就是CNToolKit，里面包含了好几个模块。其具体介绍请查看其官网： <a target="_blank" rel="noopener" href="https://www.cambricon.com/docs/cntoolkit/index.html">https://www.cambricon.com/docs/cntoolkit/index.html</a> 。</p>
<p>  在CNToolKit模块里面，我接触的最多的就是CNRT，因为这是离线模型推理部分的底层支持部分。也就是说前文我提到的EasyDK就是大部分基于CNRT进行设计的。</p>
<br/>
<br/>
<h5 id="在Ubuntu18-04上安装CNToolKit">在Ubuntu18.04上安装CNToolKit</h5>
<p>  官方路子：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>sudo dpkg -i cntoolkit_xxx.deb</p>
</li>
<li class="lvl-2">
<p>sudo apt update</p>
</li>
<li class="lvl-2">
<p>sudo apt-get install cnas cncc cncodec cndev cndrv cnlicense cnpapi cnperf cnrt cnrtc cnstudio</p>
</li>
</ul>
<p>  野路子：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>解压cntoolkit_xxx.deb。</p>
</li>
<li class="lvl-2">
<p>找到里面的所有deb文件，选择自己需要的，直接解压安装。</p>
</li>
</ul>
<p>注意，野路子在边缘端环境配置的时候、边缘端程序生成的时候有奇效。</p>
<p>  配置相关环境变量：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>export NEUWARE_HOME=“/usr/local/neuware”</p>
</li>
<li class="lvl-2">
<p>export PATH=“${NEUWARE_HOME}/bin:${PATH}”</p>
</li>
</ul>
<p>注意，此变量NEUWARE_HOME将会伴随着你移植模型，生成边缘端程序等阶段，需要注意。</p>
<p>  安装好进行测试，执行命令：/usr/local/neuware/bin/cncc --version  得到如图输出：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_112/cncc.png" alt="rep_img"/></center>
    </div>
</div>    
<br/>
<br/>
<br/>
<br/>
<h3 id="配置模型移植开发环境">配置模型移植开发环境</h3>
<hr>
<p>  寒武纪官方支持3种常见框架的模型移植，他们分别是caffe/tensorflow/pytorch，他们的官方资料如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>caffe: <a target="_blank" rel="noopener" href="https://www.cambricon.com/docs/caffe/index.html">https://www.cambricon.com/docs/caffe/index.html</a></p>
</li>
<li class="lvl-2">
<p>tensorflow: <a target="_blank" rel="noopener" href="https://www.cambricon.com/docs/tensorflow/user_guide/index.html">https://www.cambricon.com/docs/tensorflow/user_guide/index.html</a></p>
</li>
<li class="lvl-2">
<p>pytorch: <a target="_blank" rel="noopener" href="https://www.cambricon.com/docs/pytorch/index.html">https://www.cambricon.com/docs/pytorch/index.html</a></p>
</li>
</ul>
<p>  寒武纪官方支持的环境配置方式有两种，一种是全程手动搭建环境。第二种是docker。</p>
<p>  对于手动搭建环境，这里仁者见仁智者见智，我个人认为新手可以尝试着搭建一次就行，后续还是使用docker。因为手动搭建可以让你更加的了解整个移植工作的流程。以pytorch为例，因为手动搭建，大概包含了安装virtualenv，解压源码，设定NEUWARE_HOME环境，打patch，安装依赖，编译编译生成对应的库，运行单元测试，最终检测即可。</p>
<p>  对于业务开发来说，我建议还是docker来的快点。</p>
<br/>
<br/>
<h5 id="搭建模型移植docker环境">搭建模型移植docker环境</h5>
<p>  docker的安装我就不说了，自己百度把docker基本环境搭好，能够跑hello-world就行。</p>
<p>  首先我们在寒武纪那里可以拿到对应环境的docker镜像，下载到我们的安装了MLU270的主机电脑。然后执行命令： sudo docker load -i pytorch-xxxx-ubuntu18.04.tar，然后执行sudo docker images 查看你已经导入的image文件。如图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_112/docker_image.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  然后执行寒武纪提供的run脚本即可。根据脚本中的配置，默认会将当期目录映射到docker的/home/share目录。</p>
<p>  当我们第一次进入一个docker环境时，需要执行寒武纪提供的patch脚本（联系供应商），在docker根目录生成一个env_pytorch.sh文件，配设定相关的环境。</p>
<p>  此外，每当我们执行run脚本进入docker后（docker run），每一次都需要执行：cd / &amp;&amp; source env_pytorch.sh 进入pytorch虚拟环境。这个时候执行如下命令，并反馈如图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_112/test.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  使用docker还有一个好处是更新升级方便，更重要的是方便建立多个不同算法移植环境。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  对于寒武纪加速平台来说，我们不要将它视为一个新的事物，可以将它类比为Nvidia的显卡加速平台。加速卡驱动对应n卡驱动。cncc类比nvcc。bang c类比为cuda。更高级的算法推理和训练框架其实底层加速部分就是使用cuda/bang c/cpu-simd来构建的。对于我们用户来说，一般情况下，我们只需要普通的了解pytorch/tensorflow/caffe的api即可。只有当对某些特殊算子需要加速的时候，这个时候你有可能去涉及这些cuda/bang c/cpu-simd。这里寒武纪加速平台根据其提供的一些资料来看，直接在算子里面集成了例如ssd/yolov3/yolov5等目标检测的最后一个解码层，详情见相关文档。</p>
<p>  这里介绍了寒武纪算法移植环境搭建的方法，同时也对整个流程做了一个简要的说明。其实如果你能够和供应商联系上，应该还可以得到一些其他的相关支持和资料。我这里由于一些原因，只引用了其官方公开的内容。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 （ <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/121194076">https://blog.csdn.net/u011728480/article/details/121194076</a> ）</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://www.cambricon.com/">https://www.cambricon.com/</a></p>
</li>
<li class="lvl-2">
<p>其他相关保密资料。</p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/11/07/blog_idx_111/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/11/07/blog_idx_111/" class="post-title-link" itemprop="url">寒武纪加速平台(MLU200系列) 摸鱼指南（一）--- 基本概念及相关介绍</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-11-07 17:18:31" itemprop="dateCreated datePublished" datetime="2021-11-07T17:18:31+08:00">2021-11-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">嵌入式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/DL/%E5%B8%B8%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">常识</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>8 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Please set LastEditors
 * @LastEditTime: 2021-11-07 17:15:57
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=111） 
&emsp;&emsp;本文发布于 2021-11-07 17:18:31     （BlogID=111）
-->
<h6 id="环境说明">环境说明</h6>
<p>  无</p>
<h3 id="前言">前言</h3>
<hr>
<p>  从2019年开始，我们公司的智能分析平台核心架构就开始逐渐的转向了RK3399PRO，这是我们公司的第三代智能分析平台，前面两代分别是TK1和TX2，但是因为众所周知的原因，这一代分析平台选择了国内的一些替代商。经过了2019年和2020年的实际部署和使用，对于第三代智能分析平台来说，有一个硬性缺陷就是NPU算力过低（INT8 3T），导致了某些算法达不到实时帧率，其其他的性能还是不错的，如CPU计算力、编解码等等。正是由于这个算力的缺陷，所以在2020年，我们调研了市场上的其他算力平台的情况，经过某些渠道，我们和寒武纪联系上了。寒武纪给我们介绍了他们的MLU200系列智能分析平台的情况，并提供了相应测试板卡，经过相应的测试后，我们技术人员及公司领导对其比较认可，因此决定第四代平台会加入寒武纪的推理模块，最终形成了以RK作为主控，寒武纪作为推理模块的形式，为什么这样搭建，后文有所提及。由于现在市场上已经出现了类似我们公司的第四代智能分析平台的产品，于是相关介绍可以进行解密脱敏发布。本系列文章就是对这个寒武纪平台做一些简单的介绍及总结。</p>
<p>  若文中引用部分存在侵权，请及时联系我删除。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="寒武纪加速平台简介">寒武纪加速平台简介</h3>
<hr>
<p>  寒武纪加速平台是有两个部分构成，一个部分是算力硬件，一部分是配套的软件。</p>
<br/>
<br/>
<h5 id="寒武纪硬件部分">寒武纪硬件部分</h5>
<p>  首先，这里介绍的是寒武纪的MLU200系列，在本文发布时，其实其MLU200系列的升级版，MLU300系列也在寒武纪内部及其相关的合作伙伴正在测试。</p>
<p>  对于MLU200系列来说，我们从其官网可以看到，大概存在3个系列，一个是边缘端推理MLU220（只支持推理），一个是服务器端推理MLU270（只支持推理），一个是MLU290（支持训练和推理）。可以从其官网（<a target="_blank" rel="noopener" href="https://www.cambricon.com/%EF%BC%89">https://www.cambricon.com/）</a> 查看更加详细的介绍。</p>
<p>  对于MLU220来说，这里介绍两个比较重要的参数，具备两种形态，一种是INT8 8T算力+8.25W功耗，一种是INT8 16T算力+16.5W功耗。MLU220边缘端模块正是我们公司第四代智能分析平台的核心部件之一，但是由于其CPU计算能力较弱，导致不能够进行大量的业务逻辑运算，这也是某些场景可能需要其他主控的原因。</p>
<p>  对于MLU270来说，除了部署服务端的智能分析算法外，其对我们来说最重要的功能是作为模型移植的硬件。我们的智能分析算法想要比较好的工作在MLU220边缘端，就必须要经过MLU270上进行模型移植，这也是后续文章的重点之一。</p>
<p>  对于MLU290来说，我们公司没有使用，但是看其介绍，一般来说都是应用在各云厂商、机房和服务中心等，其的最大亮点是支持模型训练。</p>
<br/>
<br/>
<h5 id="寒武纪软件部分">寒武纪软件部分</h5>
<p>  寒武纪软件部分我大概可以分为3类，一个是驱动，一个是运行时库，一个是其相关的算法框架等。如其官网的结构图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_111/software_framework.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  从上图来看，在相关的算法框架那块里面，还包含了两个我们实际用到了，但是其图中没有给出的介绍。图中的相关算法框架部分都是用于算法训练、推理、移植使用的。其实在推理部分来看（运行时之上），还应该包含寒武纪出的两个开源工程：EasyDK以及CNStream。</p>
<p>  EasyDK是其基于其运行时库封装的一些常用和简易接口，对我们来说，可能最常用的就是关于离线模型推理部分。相关介绍请参见其官网： <a target="_blank" rel="noopener" href="https://github.com/Cambricon/easydk">https://github.com/Cambricon/easydk</a></p>
<p>  CNStream是其基于EasyDK封装的一套应用层库，我觉得其和deepstream和MediaPipe有异曲同工之妙。相关介绍请参见其官网：<a target="_blank" rel="noopener" href="https://github.com/Cambricon/CNStream">https://github.com/Cambricon/CNStream</a></p>
<p>  其实从这里我们可以看出，一般来说，我们自己的推理端的程序和服务，有三种形态：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>基于CNStream进行开发，其封装的还不错，并行处理的还行，但是可能就是不能够很好的和自己以前的程序框架移植和融合。</p>
</li>
<li class="lvl-2">
<p>基于EasyDK进行开发，简化调用及开发流程，但是会有些坑需要去阅读EasyDk源码和运行时相关的SDK文档。</p>
</li>
<li class="lvl-2">
<p>基于其运行时相关的SDK文档进行开发，需要花大量的时间进行学习，适合长期工作在此平台的相关人员。</p>
</li>
</ul>
<p>  对于我们公司来说，我们现在基本工作在EasyDK和其运行时之间，基于这两个进行混合编程，最终的理想状态是直接基于其运行时库进行开发。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="寒武纪加速平台使用简介">寒武纪加速平台使用简介</h3>
<hr>
<p>  在前言部分已经介绍过了，我们公司的第四代智能分析平台的核心构成部分是MLU220。因此，我们公司做的事情其实将已经训练好的Caffe、Pytorch等框架的模型移植到寒武纪平台。寒武纪平台根据其定位做了云端和终端的商业定位。其官网介绍图如下：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_111/deployment.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  下面我对我司使用的基本流程做一个简介。</p>
<br/>
<br/>
<h5 id="部署流程简介">部署流程简介</h5>
<p>  寒武纪平台的部署流程有一条主线是将一个原始模型转为一个离线模型。基本流程如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>得到算法的原始模型，如caffe/pytorch/tensorflow等框架的模型。</p>
</li>
<li class="lvl-2">
<p>配置对应框架模型的模型转换环境，有两种一种是手动配置，一种是docker。</p>
</li>
<li class="lvl-2">
<p>使用对应的框架模型转换环境，进行模型量化、转换得到离线模型。</p>
</li>
<li class="lvl-2">
<p>开发支持离线模型的程序应用，调用离线模型进行推理并做其他处理。</p>
</li>
</ul>
<p>  关于我司使用的基本流程，后续文章将会有一个实例来详细展开说明，这里就不多介绍了。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  本文主要介绍了寒武纪加速平台的一些概念。更多的详情，请查看寒武纪官网相关的介绍。</p>
<p>  其实看到国内的各个软硬一体厂商发展的还是不错的，希望他们可以取得更加长足的发展，希望他们为国产争光。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://www.cambricon.com/">https://www.cambricon.com/</a></p>
</li>
<li class="lvl-2">
<p>其他相关保密资料。</p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/08/15/blog_idx_110/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/08/15/blog_idx_110/" class="post-title-link" itemprop="url">DL基础补全计划(六)---卷积和池化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-08-15 22:34:40" itemprop="dateCreated datePublished" datetime="2021-08-15T22:34:40+08:00">2021-08-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky sky@sky-home.com
 * @LastEditTime: 2023-04-08 11:11:52
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=110） 
&emsp;&emsp;本文发布于 2021-08-15 22:34:40     （BlogID=110） 
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Windows 10</p>
</li>
<li class="lvl-2">
<p>VSCode</p>
</li>
<li class="lvl-2">
<p>Python 3.8.10</p>
</li>
<li class="lvl-2">
<p>Pytorch 1.8.1</p>
</li>
<li class="lvl-2">
<p>Cuda 10.2</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  本文是此基础补全计划的最终篇，因为从我的角度来说，如果前面这些基础知识都能够了解及理解，再加上本文的这篇基础知识，那么我们算是小半只脚踏入了大门。从这个时候，其实我们就已经可以做图像上的基本的分类任务了。除了分类任务，我们还有两类重要的图像任务是目标检测和图像分割，这两项任务都和分类任务有一定的关联，可以说，分类可以说是这两类的基础。</p>
<p>  卷积神经网络是一个专门为处理图像数据的网络。下面我们简单的来看看卷积、池化的含义和怎么计算的，然后我们通过一个LeNet5的经典网络，训练一个分类模型。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="卷积">卷积</h3>
<hr>
<p>  卷积是一种运算，类似加减乘除。卷积是一种运算，类似加减乘除。卷积是一种运算，类似加减乘除。重要的事情说三次。</p>
<p>  在数学上的定义是:连续n的情况$(f<em>g)(x) = \int f(n)g(x-n)dn$， 离散n的情况$(f</em>g)(x) = \sum\limits_{n} f(n)g(x-n)$。从这里我们可以看到，卷积就是测量函数f和函数g的翻转且平移x后的重叠。其二维离散a,b的表达是$(f*g)(x1,x2) = \sum\limits_{a}\sum\limits_{b} f(a, b)g(x1-a, x2-b)$</p>
<p>  卷积是一种运算，类似加减乘除。卷积是一种运算，类似加减乘除。卷积是一种运算，类似加减乘除。重要的事情再说三次。</p>
<p>  我们再次想一想，在之前的文章中，我们普遍都建立了一种想法是，把输入数据拉成一条直线输入的，这就意味着我们在之前的任务里面只建立了相邻输入数据之间的左右关联。但是我们可以想一想，是不是所有的数据只建立左右关联就行了呢？显而易见的，并不是这样的，比如我们图片，可能上下左右4个像素加起来才是一个猫，如果我们只关联了左右，那么它可能是狗或者猫。那么我们应该通过什么样的方式来对图片像素的这种二维关联性进行描述或者计算呢？这种方法就是卷积运算。</p>
<p>  卷积网上有许许多多的介绍，大家都做了许多详细的解答，包含信号分析、复利、概率以及图像滤波等等方面的解释。我个人认为我们可以抛开这些方面，从数据之间的关联性来看这个问题可能是最好理解的，因为我们之前只关注了数据之间左右关联，我们应该同时关注上下左右的关联才对，我们要从空间的角度来考虑数据之间的关联性。而卷积作为一种数学运算，他恰好是计算了数据的上下左右关联性，因此卷积这种数学运算很适合拿来代替之前的一条线的线性运算。</p>
<p>  下面我们来看一下一个基本的卷积计算过程是什么样子的。</p>
<br/>
<br/>
<h5 id="图像边缘检测实例">图像边缘检测实例</h5>
<p>  计算代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">corr2d</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> K<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""计算⼆维互相关运算。"""</span>
    h<span class="token punctuation">,</span> w <span class="token operator">=</span> K<span class="token punctuation">.</span>shape
    Y <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> h <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> w <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            Y<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>X<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> h<span class="token punctuation">,</span> j<span class="token punctuation">:</span>j <span class="token operator">+</span> w<span class="token punctuation">]</span> <span class="token operator">*</span> K<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            
    <span class="token keyword">return</span> Y

_X <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
_X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
_X<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>_X<span class="token punctuation">)</span>
_K <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
_Y <span class="token operator">=</span> corr2d<span class="token punctuation">(</span>_X<span class="token punctuation">,</span> _K<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>_Y<span class="token punctuation">)</span>
_Y <span class="token operator">=</span> corr2d<span class="token punctuation">(</span>_X<span class="token punctuation">,</span> _K<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>_Y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  结果如图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_110/conv_example.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  我们可以分别的看到，图像边缘的数值在经过我们手动构造的滤波器后，成功的检测到边缘信息。</p>
<p>  在实际情况中，我们可能要学习边缘，角点等等特征，这个时候我们不可能手动去构造我们的滤波器，那么我们可不可以通过学习的方式把滤波器学习出来呢？下面通过实例来演示：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">_X <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
_X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
_X<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>_X<span class="token punctuation">)</span>
_K <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
_Y <span class="token operator">=</span> corr2d<span class="token punctuation">(</span>_X<span class="token punctuation">,</span> _K<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>_Y<span class="token punctuation">)</span>
<span class="token comment"># _Y = corr2d(_X, _K.T)</span>
<span class="token comment"># print(_Y)</span>

X <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>_X<span class="token punctuation">)</span>
X<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
X <span class="token operator">=</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>

Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>_Y<span class="token punctuation">)</span>
Y<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>

conv2d <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_train <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    l <span class="token operator">=</span> <span class="token punctuation">(</span>y_train <span class="token operator">-</span> Y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span>

    conv2d<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># print(l.shape)</span>
    l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">)</span>

    
    <span class="token comment"># print(conv2d.weight)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print('grad = ', conv2d.weight.grad)</span>
        conv2d<span class="token punctuation">.</span>weight<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-=</span> <span class="token number">0.02</span> <span class="token operator">*</span> conv2d<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>grad
    <span class="token comment"># print(conv2d.weight)</span>
    <span class="token comment"># print(conv2d.weight.shape)</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'batch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">, loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">float</span><span class="token punctuation">(</span>l<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>conv2d<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  结果如图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_110/conv_train.png" alt="rep_img"/></center>
    </div>
</div>
<p>  我们通过corr2d函数构造出特征Y，然后我们通过训练特征Y，我们可以看到最终卷积层的权重就是接近与1和-1，恰好等于我们构造的特殊滤波器。</p>
<p>  这个实例说明了，我们可以通过学习的方式来学习出一个我们想要的滤波器，不需要手动构造。</p>
<p>  此外卷积还有卷积核、步长、填充等等资料，我就不造轮子了，网上有很多大佬写的很好的，大家去看看。此外这里有个公式非常有用：N=(W-K+2P)/S+1。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="池化">池化</h3>
<hr>
<p>  我们在上文知道了卷积的输出结果代表了一片上下左右数据的关联性，比如一个像素和之前的9个像素有关联，比如一个$9<em>9$的图，经过一个卷积后，假如还是$9</em>9$，这个时候输出的$9<em>9$里面的每个像素我们已经和之前对应位置的一片像素建立了关联。但是某些时候，我们希望这种关联性聚合起来，通过求最大值或者平均等等，这就是池化的概念。以之前例子为例：卷积输出了$9</em>9$的像素，经过池化之后，假如变成了$3<em>3$，我们可以看到池化输出的每个像素代表之前卷积输出的$3</em>3$个像素，这代表我们的信息聚集了，因为一个像素代表了上一层的多个像素。</p>
<p>  注意池化，我们还可以从视野的角度来看待，还是和上面的例子一样，假如原图上的猫是$9<em>9$的像素，经过卷积池化之后，假如变成了$3</em>3$， 这意味着我们从像素的角度来说，之前81个像素代表猫，现在9个像素就可以代表了，也就是之前的一个像素和现在的一个像素代表的原图视野不一样了，形成了视野放大的感觉。但是有一个缺点就是，这可能导致小目标丢失了，这个在目标检测里面会关注到。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="一个经典神经网络LeNet5">一个经典神经网络LeNet5</h3>
<hr>
<p>  在2017年12月份，我的这篇文章中《LeNet-5 论文及原理分析(笨鸟角度)》 （ <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/78799672">https://blog.csdn.net/u011728480/article/details/78799672</a> ）其实当时我为了学习一些基本知识，也对LeNet5的论文中网络结构部分做了细致的分析。</p>
<p>  注意本文中的C3层和论文中的C3层不一样。本文的C3层是$16<em>6</em>(5<em>5+1) = 2496$个参数。论文原文是$6</em>(3<em>5</em>5+1)+6*(4<em>5</em>5+1)+3*(4<em>5</em>5+1)+1* (6<em>5</em>5+1)=1516$个参数。</p>
<p>  训练代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>utils <span class="token keyword">import</span> lookfor
<span class="token keyword">import</span> torch

<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToTensor
<span class="token keyword">import</span> os
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules <span class="token keyword">import</span> activation
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules <span class="token keyword">import</span> linear
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>linear <span class="token keyword">import</span> Linear
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms

<span class="token keyword">import</span> visdom

vis <span class="token operator">=</span> visdom<span class="token punctuation">.</span>Visdom<span class="token punctuation">(</span>env<span class="token operator">=</span><span class="token string">'main'</span><span class="token punctuation">)</span>

title <span class="token operator">=</span> <span class="token string">'LeNet5 on '</span> <span class="token operator">+</span> <span class="token string">'FashionMNIST'</span>
legend <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'TrainLoss'</span><span class="token punctuation">,</span> <span class="token string">'TestLoss'</span><span class="token punctuation">,</span> <span class="token string">'TestAcc'</span><span class="token punctuation">]</span>

epoch_plot_window <span class="token operator">=</span> vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>        
        X<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Y<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        win<span class="token operator">=</span><span class="token string">'epoch_win'</span><span class="token punctuation">,</span>
        opts<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>
            xlabel<span class="token operator">=</span><span class="token string">'Epoch'</span><span class="token punctuation">,</span>
            ylabel<span class="token operator">=</span><span class="token string">'Loss/Acc'</span><span class="token punctuation">,</span>
            title<span class="token operator">=</span>title<span class="token punctuation">,</span>
            legend<span class="token operator">=</span>legend
        <span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">corr2d</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""计算⼆维互相关运算。"""</span>
    h<span class="token punctuation">,</span> w <span class="token operator">=</span> W<span class="token punctuation">.</span>shape
    Y <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> h <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> w <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            Y<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>X<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> h<span class="token punctuation">,</span> j<span class="token punctuation">:</span>j <span class="token operator">+</span> w<span class="token punctuation">]</span> <span class="token operator">*</span> W<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            
    <span class="token keyword">return</span> Y


<span class="token keyword">def</span> <span class="token function">TrainConv2d</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    _X <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    _X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    _X<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>_X<span class="token punctuation">)</span>
    _K <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    _Y <span class="token operator">=</span> corr2d<span class="token punctuation">(</span>_X<span class="token punctuation">,</span> _K<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>_Y<span class="token punctuation">)</span>
    <span class="token comment"># _Y = corr2d(_X, _K.T)</span>
    <span class="token comment"># print(_Y)</span>

    X <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>_X<span class="token punctuation">)</span>
    X<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
    X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    X <span class="token operator">=</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>

    Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>_Y<span class="token punctuation">)</span>
    Y<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>

    conv2d <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_train <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        l <span class="token operator">=</span> <span class="token punctuation">(</span>y_train <span class="token operator">-</span> Y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span>

        conv2d<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># print(l.shape)</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">)</span>

        
        <span class="token comment"># print(conv2d.weight)</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># print('grad = ', conv2d.weight.grad)</span>
            conv2d<span class="token punctuation">.</span>weight<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-=</span> <span class="token number">0.02</span> <span class="token operator">*</span> conv2d<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>grad
        <span class="token comment"># print(conv2d.weight)</span>
        <span class="token comment"># print(conv2d.weight.shape)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'batch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">, loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">float</span><span class="token punctuation">(</span>l<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span>conv2d<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">NeuralNetwork</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>NeuralNetwork<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lenet5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 6*28*28---->6*28*28</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

            <span class="token comment"># 6*28*28----->6*14*14</span>
            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

            <span class="token comment"># 6*14*14----->16*10*10</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

            <span class="token comment"># 16*10*10------>16*5*5</span>
            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">*</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">*</span><span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>lenet5<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logits


<span class="token keyword">def</span> <span class="token function">LoadFashionMNISTByTorchApi</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 60000*28*28</span>
    training_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"..\data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># 10000*28*28</span>
    test_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"..\data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># labels_map = &#123;</span>
    <span class="token comment">#     0: "T-Shirt",</span>
    <span class="token comment">#     1: "Trouser",</span>
    <span class="token comment">#     2: "Pullover",</span>
    <span class="token comment">#     3: "Dress",</span>
    <span class="token comment">#     4: "Coat",</span>
    <span class="token comment">#     5: "Sandal",</span>
    <span class="token comment">#     6: "Shirt",</span>
    <span class="token comment">#     7: "Sneaker",</span>
    <span class="token comment">#     8: "Bag",</span>
    <span class="token comment">#     9: "Ankle Boot",</span>
    <span class="token comment"># &#125;</span>
    <span class="token comment"># figure = plt.figure(figsize=(8, 8))</span>
    <span class="token comment"># cols, rows = 3, 3</span>
    <span class="token comment"># for i in range(1, cols * rows + 1):</span>
    <span class="token comment">#     sample_idx = torch.randint(len(training_data), size=(1,)).item()</span>
    <span class="token comment">#     img, label = training_data[sample_idx]</span>
    <span class="token comment">#     figure.add_subplot(rows, cols, i)</span>
    <span class="token comment">#     plt.title(labels_map[label])</span>
    <span class="token comment">#     plt.axis("off")</span>
    <span class="token comment">#     plt.imshow(img.squeeze(), cmap="gray")</span>
    <span class="token comment"># plt.show()</span>
    <span class="token keyword">return</span> training_data<span class="token punctuation">,</span> test_data


<span class="token keyword">def</span> <span class="token function">train_loop</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>
    loss_sum <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> batch<span class="token punctuation">,</span> <span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># move X, y to gpu</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
        <span class="token comment"># Compute prediction and loss</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

        <span class="token comment"># Backpropagation</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> batch <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            loss1<span class="token punctuation">,</span> current <span class="token operator">=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss1<span class="token punctuation">:</span><span class="token format-spec">>7f</span><span class="token punctuation">&#125;</span></span><span class="token string">  [</span><span class="token interpolation"><span class="token punctuation">&#123;</span>current<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>size<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">]"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> loss_sum<span class="token operator">/</span>num_batches

<span class="token keyword">def</span> <span class="token function">test_loop</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>
    test_loss<span class="token punctuation">,</span> correct <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            <span class="token comment"># move X, y to gpu</span>
            <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
                y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            test_loss <span class="token operator">+=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    test_loss <span class="token operator">/=</span> num_batches
    correct <span class="token operator">/=</span> size
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Error: \n Accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token operator">*</span>correct<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">>0.1f</span><span class="token punctuation">&#125;</span></span><span class="token string">%, Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> test_loss<span class="token punctuation">,</span> correct

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment"># TrainConv2d()</span>

    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using &#123;&#125; device'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">init_weights</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span> <span class="token operator">==</span> nn<span class="token punctuation">.</span>Linear <span class="token keyword">or</span> <span class="token builtin">type</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span> <span class="token operator">==</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">:</span>
            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>

    model <span class="token operator">=</span> NeuralNetwork<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>init_weights<span class="token punctuation">)</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    
    batch_size <span class="token operator">=</span> <span class="token number">200</span>
    learning_rate <span class="token operator">=</span> <span class="token number">0.9</span>
    
    
    training_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> LoadFashionMNISTByTorchApi<span class="token punctuation">(</span><span class="token punctuation">)</span>
    train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>

    epochs <span class="token operator">=</span> <span class="token number">1000</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>t<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">\n-------------------------------"</span></span><span class="token punctuation">)</span>
        train_loss <span class="token operator">=</span> train_loop<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>
        test_loss<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> test_loop<span class="token punctuation">(</span>test_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span>

        vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>train_loss<span class="token punctuation">,</span> test_loss<span class="token punctuation">,</span> test_acc<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
            np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">*</span>t<span class="token punctuation">,</span> 
            win<span class="token operator">=</span><span class="token string">'epoch_win'</span><span class="token punctuation">,</span> 
            update<span class="token operator">=</span><span class="token boolean">None</span> <span class="token keyword">if</span> t <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">'append'</span><span class="token punctuation">,</span> 
            opts<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>
                xlabel<span class="token operator">=</span><span class="token string">'Epoch'</span><span class="token punctuation">,</span>
                ylabel<span class="token operator">=</span><span class="token string">'Loss/Acc'</span><span class="token punctuation">,</span>
                title<span class="token operator">=</span>title<span class="token punctuation">,</span>
                legend<span class="token operator">=</span>legend
            <span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done!"</span><span class="token punctuation">)</span>

    <span class="token comment"># only save param</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'lenet5.pth'</span><span class="token punctuation">)</span>

    <span class="token comment"># save param and net</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">'lenet5-all.pth'</span><span class="token punctuation">)</span>

    <span class="token comment"># export onnx</span>
    input_image <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    input_image <span class="token operator">=</span> input_image<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>export<span class="token punctuation">(</span>model<span class="token punctuation">,</span> input_image<span class="token punctuation">,</span> <span class="token string">'model.onnx'</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  结果如图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_110/train_lenet5.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  我们从训练可视化界面上可以看到，我们的模型确实是收敛了，但是不幸的是准确率大概有90%左右，而且存在过拟合现象。注意这里我们这个模型，由于有Sigmoid层，导致了很容易出现梯度消失的情况，为了加快训练，所以学习率设置的很大。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  整理本系列的基础知识的原因是需要加深对深度学习的理解。同时跟着参考资料，重复试验，重复运行。对我个人而言，只有真实的写了代码之后，才能够理解的更加透彻。</p>
<p>  本文也是此系列的终篇，以后更新随缘。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V1.0.0)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V2.0.0 alpha1)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/78799672">https://blog.csdn.net/u011728480/article/details/78799672</a> （《LeNet-5 论文及原理分析(笨鸟角度)》）</p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/08/08/blog_idx_109/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/08/08/blog_idx_109/" class="post-title-link" itemprop="url">DL基础补全计划(五)---数值稳定性及参数初始化（梯度消失、梯度爆炸）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-08-08 23:30:38" itemprop="dateCreated datePublished" datetime="2021-08-08T23:30:38+08:00">2021-08-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>8 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky sky@sky-home.com
 * @LastEditTime: 2023-04-08 11:11:21
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=109） 
&emsp;&emsp;本文发布于 2021-08-08 23:30:38     （BlogID=109）
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Windows 10</p>
</li>
<li class="lvl-2">
<p>VSCode</p>
</li>
<li class="lvl-2">
<p>Python 3.8.10</p>
</li>
<li class="lvl-2">
<p>Pytorch 1.8.1</p>
</li>
<li class="lvl-2">
<p>Cuda 10.2</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  如果有计算机背景的相关童鞋，都应该知道数值计算中的上溢和下溢的问题。关于计算机中的数值表示，在我的《数与计算机 （编码、原码、反码、补码、移码、IEEE 754、定点数、浮点数）》 (<a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/100277582">https://blog.csdn.net/u011728480/article/details/100277582</a>) 一文中有比较好的介绍。计算机中的数值表示，相对于实数数轴来说是离散且有限的，意思就是计算机中的能表示的数有最大值和最小值以及最小单位，特别是浮点数表示，有兴趣的可以看看上文。</p>
<p>  其实很好理解，深度学习里面具有大量的乘法加法，一不小心你就会遇见上溢和下溢的问题，因此我们一不小心就会遇见NAN和INF的问题（NAN和INF详见上文提到的文章）。此外，由于一些特殊的情况，可能会导致我们的参数的偏导数接近于0，让我们的模型收敛的非常的慢。因此我们可能需要从模型的初始化以及相关的模型构造方面来好好的讨论一下我们在训练过程中可能出现的问题。</p>
<p>  一般来说，我们训练的时候都非常的关注我们的损失函数，如果损失函数值异常，会导致相关的偏导数出现接近于0或者接近于无限大，那么就会直接导致模型训练及其困难。此外，我们的权重参数也会参与网络计算，按照上述的描述，权重参数的初始值也可能导致损失函数的值异常。因此大佬们也引入了另外一种常见的初始化方式Xavier，比较具有普适性。下面我们简单的验证一下我们训练过程中出现梯度接近于0和接近于无限大的情况，这里也就是说的梯度消失和梯度爆炸问题。同时也简单说明参数初始化相关的问题。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="梯度消失（gradient-vanishing）">梯度消失（gradient vanishing）</h3>
<hr>
<p>  在深度学习中有一个激活层叫做Sigmoid层，其定义如下是:$Sigmoid(x)=1/(1+\exp(-x))$,如果我们的模型里面接入了这种激活函数，很容易构造出梯度消失的情况，下面我们看一下其导数和函数值相对于X的相关关系。</p>
<p>  代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt


fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
xdata<span class="token punctuation">,</span> ydata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
line0<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>
line1<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'b-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'gradient-sigmoid'</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">init_and_show</span><span class="token punctuation">(</span>xlim_min<span class="token punctuation">,</span> xlim_max<span class="token punctuation">,</span> ylim_min<span class="token punctuation">,</span> ylim_max<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'x'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'sigmoid(x)'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'sigmoid/gradient-sigmoid'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span>xlim_min<span class="token punctuation">,</span> xlim_max<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span>ylim_min<span class="token punctuation">,</span> ylim_max<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span>line0<span class="token punctuation">,</span> line1<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'sigmoid'</span><span class="token punctuation">,</span> <span class="token string">'gradient-sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    line0<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    line1<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">sigmoid_test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
    
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    sig_fun <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    y <span class="token operator">=</span> sig_fun<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>

    xdata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    xdata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ydata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ydata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

    init_and_show<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">multi_mat_dot</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    M <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'⼀个矩阵\n'</span><span class="token punctuation">,</span> M<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        M <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>M<span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'乘以100个矩阵后\n'</span><span class="token punctuation">,</span> M<span class="token punctuation">)</span>
            
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    sigmoid_test<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  结果图如下</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_109/sigmoid.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  我们可以从图中看到，当x小于-5和大于+5的时候，其导数的值接近于0，导致bp的时候，参数更新小，模型收敛的特别的慢。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="梯度爆炸（gradient-exploding）">梯度爆炸（gradient exploding）</h3>
<hr>
<p>  现在我们假设我们有一个模型，其有N个线性层构成，定义输入为X，标签为Y，模型为 $M(X) = X*W_1 … W_{n-2}*W_{n-1}<em>W_n$，损失函数为$L(X) = M(X) - Y = X</em>W_1 … W_{n-2}*W_{n-1}<em>W_n - Y$，求W1关于损失函数的偏导数$\frac{dL(X)}{dW_1} = X</em>W_2 … W_{n-2}*W_{n-1}*W_n$。从这里我们可以看到W2到Wn与输入的X的乘积构成了W1的偏导数。</p>
<p>  下面我们简单的构造一个矩阵，然后让他计算100次乘法。代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt


fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
xdata<span class="token punctuation">,</span> ydata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
line0<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>
line1<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'b-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'gradient-sigmoid'</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">init_and_show</span><span class="token punctuation">(</span>xlim_min<span class="token punctuation">,</span> xlim_max<span class="token punctuation">,</span> ylim_min<span class="token punctuation">,</span> ylim_max<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'x'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'sigmoid(x)'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'sigmoid/gradient-sigmoid'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span>xlim_min<span class="token punctuation">,</span> xlim_max<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span>ylim_min<span class="token punctuation">,</span> ylim_max<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span>line0<span class="token punctuation">,</span> line1<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'sigmoid'</span><span class="token punctuation">,</span> <span class="token string">'gradient-sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    line0<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    line1<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">sigmoid_test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
    
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    sig_fun <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    y <span class="token operator">=</span> sig_fun<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>

    xdata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    xdata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ydata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ydata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

    init_and_show<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">multi_mat_dot</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    M <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'⼀个矩阵\n'</span><span class="token punctuation">,</span> M<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        M <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>M<span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'乘以100个矩阵后\n'</span><span class="token punctuation">,</span> M<span class="token punctuation">)</span>
            
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    multi_mat_dot<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  他计算100次乘法后结果如下：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_109/multi_mul_dot.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  我们可以看到，经过100次乘法后，其值已经非常大（小）了指数都是到了25了。这个时候算出来的损失非常大的，这个时候梯度也非常大，很容易导致训练异常。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="参数初始化之Xavier">参数初始化之Xavier</h3>
<hr>
<p>  文首我们提到，我们之前的参数初始化都是基于期望为0，方差为一个指定值初始化的，这里面的指定值是随个人定义的，这个可能会给我们的训练过程带来困扰。</p>
<p>  但是我们可以从以下的角度来看待这个事情，我们的权重参数W是一个期望为0，方差为$\delta<sup>2$的特定分布。我们的输入特征X是一个期望为0，方差为$\lambda</sup>2$的特定分布（注意这里不仅仅是正态分布）。我们假设我们的模型是线性模型，那么其输出为：$O_i = \sum\limits_{j=1}^{n}W_{ij}X_{j}$，$O_i$是代表第i层的输出。这个时候，我们求出$O_i$的期望是:$E(O_i) = \sum\limits_{j=1}^{n}E(W_{ij}X_{j}) = \sum\limits_{j=1}^{n}E(W_{ij})E(X_{j}) = 0$，其方差为：$Variance(O_i) = E(O_i^2) - (E(O_i))^2 = \sum\limits_{j=1}<sup>{n}E(W_{ij}</sup>2X_{j}^2) - 0 = \sum\limits_{j=1}<sup>{n}E(W_{ij}</sup>2)E(X_{j}^2) = n*\delta<sup>2*\lambda</sup>2$。我们现在假设如果要$O_i$的方差等于X的方差，那么$n*\delta^2 = 1$才能够满足要求。现在我们考虑BP的时候，也需要$n_{out}<em>\delta^2 = 1$才能够保证方差不会变，至少从数值稳定性来说，我们应该保证方差尽量稳定，不应该放大。我们同时考虑n和$n_{out}$，那么我们可以认为当$1/2</em>(n+n_{out})*\delta^2 = 1$时，我们保证了输出O的方差在约定范围内，尽量保证了其数值的稳定性，这就是Xavier方法的核心内容。</p>
<p>  初始化方法有很多，但是Xavier方法有较大的普适性。对于某些模型，特定的初始化方法有奇效。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  到本文结束，其实我们可以训练一些简单的模型了，但是本文所介绍的3个概念会一直伴随着我们以后的学习过程，如果训练出现了INF，NAN这些特殊的值，基本我们就需要往这方面去想和解决问题。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V1.0.0)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V2.0.0 alpha1)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/100277582">https://blog.csdn.net/u011728480/article/details/100277582</a> 《数与计算机 （编码、原码、反码、补码、移码、IEEE 754、定点数、浮点数）》</p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/08/01/blog_idx_108/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/08/01/blog_idx_108/" class="post-title-link" itemprop="url">DL基础补全计划(四)---对抗过拟合：权重衰减、Dropout</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-08-01 17:35:43" itemprop="dateCreated datePublished" datetime="2021-08-01T17:35:43+08:00">2021-08-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky sky@sky-home.com
 * @LastEditTime: 2023-04-08 11:10:23
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=108） 
&emsp;&emsp;本文发布于 2021-08-01 17:35:43     （BlogID=108） 
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Windows 10</p>
</li>
<li class="lvl-2">
<p>VSCode</p>
</li>
<li class="lvl-2">
<p>Python 3.8.10</p>
</li>
<li class="lvl-2">
<p>Pytorch 1.8.1</p>
</li>
<li class="lvl-2">
<p>Cuda 10.2</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  在《DL基础补全计划(三)—模型选择、欠拟合、过拟合》（ <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/118881125">https://blog.csdn.net/u011728480/article/details/118881125</a> ）一文中，我们已经了解了我们训练过程中的一些现象，对于欠拟合问题我们一般是增加训练集大小。对于过拟合，我们也提供了一个解决方案，那就是限制模型的复杂度（参数个数）。</p>
<p>  在以后我们构造的模型里面，其参数都是成百上千的，如果通过限制参数（更换模型）来解决过拟合问题太简单粗暴了，于是我们需要一些更加细腻的手段来抑制过拟合。此外，我们还必须知道，我们增加训练集总是能够缓解过拟合的问题，但是这不是根本办法。于是深度学习大佬们又引出了其他的两个方案，他们分别是权重衰减和Dropout。</p>
<p>  到此为止，我们可以有如下的方法缓解过拟合问题：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>控制模型复杂度</p>
</li>
<li class="lvl-2">
<p>增大训练集</p>
</li>
<li class="lvl-2">
<p>权重衰减</p>
</li>
<li class="lvl-2">
<p>Dropout</p>
</li>
</ul>
<br/>
<br/>
<br/>
<br/>
<h3 id="权重衰减-L2正则化">权重衰减(L2正则化)</h3>
<hr>
<p>  其实书上对于权重衰减的定义还是比较好理解的，我们定义我们的模型为M(X)，当M(X)=0时，此时，我们的模型最简单，因为所有的输入都是0。我们最终想要的是M(X)的值越来越接近于0，那么我们权重的范数也需要越来越接近于0，这样M(X)的复杂度越来越小。</p>
<p>  出于以上的目的，我们可以将权重的范数给加到Loss函数结果里面去，通过BP算法，这样我们可以让权重的范数越来越接近于0。其中我们常用的L2范数，其可以限制权重中的大值，也可以使权重均匀分布，不会出现极端值，这是一般情况下我们想看到的。</p>
<p>  下面，我们通过一个实例及图示来感性的认知权重衰减。</p>
<br/>
<br/>
<h5 id="实例代码">实例代码</h5>
<p>  首先我们设计了一个200个权重和1个偏置的数据生成器，加上噪声，得到我们数据集。这里我们采集了100个测试集和20个训练集。从这里我们马上就可以知道，这个肯定会过拟合，因为训练集太小了，而模型复杂度太大了。</p>
<p>  下面是完整代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils <span class="token keyword">import</span> data
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">import</span> MultipleLocator

fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
xdata0<span class="token punctuation">,</span> ydata0 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
xdata1<span class="token punctuation">,</span> ydata1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
line0<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TrainError'</span><span class="token punctuation">)</span>
line1<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'b-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TestError'</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">init_and_show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Train/Test Loss'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token number">10e-5</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_yscale<span class="token punctuation">(</span><span class="token string">'log'</span><span class="token punctuation">)</span>
    <span class="token comment"># y_locator = MultipleLocator(0.1)</span>
    <span class="token comment"># ax.yaxis.set_major_locator(y_locator)</span>
    ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span>line0<span class="token punctuation">,</span> line1<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'TrainError'</span><span class="token punctuation">,</span> <span class="token string">'TestError'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># ax.legend([line1], ('TestError', ))</span>
    line0<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata0<span class="token punctuation">,</span> ydata0<span class="token punctuation">)</span>
    line1<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata1<span class="token punctuation">,</span> ydata1<span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">l2_penalty</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> b <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>w<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>w<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>b<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>

<span class="token keyword">def</span> <span class="token function">synthetic_data</span><span class="token punctuation">(</span>true_w<span class="token punctuation">,</span> true_b<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""⽣成y = ax1 + bx2 + cx3 .... ....  + b + 噪声。"""</span>

    X <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>true_w<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    y <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token punctuation">,</span> true_w<span class="token punctuation">)</span> <span class="token operator">+</span> true_b
    
    <span class="token comment"># 噪声</span>
    y <span class="token operator">+=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> X<span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>



<span class="token keyword">class</span> <span class="token class-name">TestNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_nums<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TestNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>test_net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># y=X*W+B</span>
            <span class="token comment"># x.shape(batch_size, input_nums), w.shape(input_nums, output_nums)</span>
            <span class="token comment"># y.shape(batch_size, output_nums)</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_nums<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>   

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print(x.dtype)</span>
        <span class="token comment"># </span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>test_net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># copy from d2l/torch.py</span>
<span class="token keyword">def</span> <span class="token function">load_array</span><span class="token punctuation">(</span>data_arrays<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Construct a PyTorch data iterator."""</span>
    dataset <span class="token operator">=</span> data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span><span class="token operator">*</span>data_arrays<span class="token punctuation">)</span>
    <span class="token keyword">return</span> data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span>is_train<span class="token punctuation">)</span>

<span class="token comment"># def data_loader(batch_size, features, labels):</span>
<span class="token comment">#     num_examples = len(features)</span>
<span class="token comment">#     indices = list(range(num_examples))</span>
<span class="token comment">#     np.random.shuffle(indices) # 样本的读取顺序是随机的</span>

<span class="token comment">#     for i in range(0, num_examples, batch_size):</span>
<span class="token comment">#         j = np.array(indices[i: min(i + batch_size, num_examples)])</span>
<span class="token comment">#         yield torch.tensor(features.take(j, 0)), torch.tensor(labels.take(j)) # take函数根据索引返回对应元素</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> train_examples
    num_batches <span class="token operator">=</span> train_examples <span class="token operator">/</span> batch_size
    train_loss_sum <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> batch<span class="token punctuation">,</span> <span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># move X, y to gpu</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token comment"># Compute prediction and loss</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        param_iter <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># loss = loss_fn(pred, y) + lambda_val*l2_penalty(next(param_iter), next(param_iter))</span>
        <span class="token comment"># next(model.parameters())</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">+</span> lambda_val<span class="token operator">*</span>l2_penalty<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># Backpropagation</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        train_loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>


        <span class="token keyword">if</span> batch <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            loss<span class="token punctuation">,</span> current <span class="token operator">=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">:</span><span class="token format-spec">>7f</span><span class="token punctuation">&#125;</span></span><span class="token string">  [</span><span class="token interpolation"><span class="token punctuation">&#123;</span>current<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>size<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">]"</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Train Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss_sum<span class="token operator">/</span>num_batches<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> train_loss_sum<span class="token operator">/</span>num_batches


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_batches <span class="token operator">=</span> test_examples <span class="token operator">/</span> batch_size
    test_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            <span class="token comment"># move X, y to gpu</span>
            <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
                y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            test_loss <span class="token operator">+=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    test_loss <span class="token operator">/=</span> num_batches
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> test_loss
    
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using &#123;&#125; device'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    num_inputs <span class="token operator">=</span> <span class="token number">200</span>

    true_w <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>num_inputs<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.01</span>

    true_b <span class="token operator">=</span> <span class="token number">0.78</span>  

    test_examples <span class="token operator">=</span> <span class="token number">100</span>
    train_examples <span class="token operator">=</span> <span class="token number">20</span>
    
    num_examples <span class="token operator">=</span> test_examples <span class="token operator">+</span> train_examples

    f1<span class="token punctuation">,</span> labels <span class="token operator">=</span> synthetic_data<span class="token punctuation">(</span>true_w<span class="token punctuation">,</span> true_b<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>


    l1_loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    learning_rate <span class="token operator">=</span> <span class="token number">0.01</span>

    model <span class="token operator">=</span> TestNet<span class="token punctuation">(</span>num_inputs<span class="token punctuation">)</span>

    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>

    epochs <span class="token operator">=</span> <span class="token number">100</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>


    batch_size <span class="token operator">=</span> <span class="token number">5</span>

    train_data <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>f1<span class="token punctuation">[</span><span class="token punctuation">:</span>train_examples<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">[</span><span class="token punctuation">:</span>train_examples<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_data <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>f1<span class="token punctuation">[</span>train_examples<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">[</span>train_examples<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    train_dataloader <span class="token operator">=</span> load_array<span class="token punctuation">(</span>train_data <span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> load_array<span class="token punctuation">(</span>test_data <span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># verify dataloader</span>
    <span class="token comment"># for x,y in train_dataloader:</span>
    <span class="token comment">#     print(x.shape)</span>
    <span class="token comment">#     print(y.shape)</span>
    <span class="token comment">#     print(torch.matmul( x , torch.tensor(true_w)) + torch.tensor(true_b))</span>
    <span class="token comment">#     print(y)</span>
    <span class="token comment">#     break</span>
    param_iter <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'W = '</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b = '</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>t<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">\n-------------------------------"</span></span><span class="token punctuation">)</span>
        train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
        test_l <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">)</span>
        ydata0<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_l<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
        ydata1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_l<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
        xdata0<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        xdata1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        <span class="token comment"># print(test_l)</span>
        <span class="token comment"># print(train_l)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done!"</span><span class="token punctuation">)</span>

    init_and_show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    param_iter <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># print('W = ')</span>
    <span class="token comment"># print(next(param_iter).shape)</span>
    <span class="token comment"># print('b = ')</span>
    <span class="token comment"># print(next(param_iter).shape)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w的L2范数是：'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b的L2范数是：'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="过拟合">过拟合</h5>
<p>  这个时候是未添加l2到损失函数的。<br>
  train函数如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>  训练结果如下，存在严重的过拟合现象：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting.png" alt="rep_img"/></center>
    </div>
</div>    
<br/>
<br/>
<h5 id="权重衰减">权重衰减</h5>
<p>  我们先对w进行权重衰减。<br>
  train函数如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>  训练结果如下，过拟合现象出现了缓解：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/w_weight_decay.png" alt="rep_img"/></center>
    </div>
</div>  
<br/>
<br/>
<br/>
<br/>
<h5 id="权重衰减适应性">权重衰减适应性</h5>
<p>  我们对w和b同时进行权重衰减。train函数如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>  训练结果如下，我们发现，过拟合现象并没有缓解：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/wb_weight_decay1.png" alt="rep_img"/></center>
    </div>
</div>  
<p>  就是上图引起了我的兴趣，因为我们引入了权重衰减，但是其并没有缓解，这是为什么呢？还记得我们权重衰减的目标是将权重的范数逼近于0吗？但是我们b是一个不接近于0的常量，因此过拟合并没有缓解。</p>
<p>  我们对w和b同时进行权重衰减。我们修改，train函数如下，主要将true_b调整为接近于0，这样我们同时对w，b进行衰减就是合理的：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">true_b <span class="token operator">=</span> <span class="token number">0.01</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> lambda_val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/wb_weight_decay2.png" alt="rep_img"/></center>
    </div>
</div>  
&emsp;&emsp;我们通过上面两张图的结果，说明的权重衰减的适应性以及目标。注意我们一般情况下不会对b进行权重衰减，因为其是常量。我看学习资料上并没有介绍为什么偏置不能够进行权重衰减，这里我做的这个实验可以当做一个原因吧。
<p>  pytorch的优化器里面的weight_decay参数是对所有参数进行衰减，要注意这个问题，若想单独对w进行衰减，请分别对不同的参数设定不同的优化器。这一块网上资料很多，我就不多说了。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="Dropout">Dropout</h3>
<hr>
<p>  首先，Dropout是在([Srivastava et al., 2014] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1), 1929‒1958.)一文中引出的。</p>
<p>  对于Dropout，我们可以从资料里面的代码里面看到其相关的原理：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dropout_layer</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">assert</span> <span class="token number">0</span> <span class="token operator">&lt;=</span> dropout <span class="token operator">&lt;=</span> <span class="token number">1</span>
    <span class="token comment"># 在本情况中，所有元素都被丢弃。</span>
    <span class="token keyword">if</span> dropout <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    <span class="token comment"># 在本情况中，所有元素都被保留。</span>
    <span class="token keyword">if</span> dropout <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> X
    mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">></span> dropout
    <span class="token keyword">print</span><span class="token punctuation">(</span>mask<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> mask<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">*</span> X <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> dropout<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  其工作如下：在训练的时候，按照传入的概率p丢弃一部分输出，并除以1-p。在测试的时候，跳过dropout_layer。其能正常工作的关键就是‘玄学’，打破了前一层和后一层的特定关联，破坏了两层之间的特定关联，缓解了过拟合。这个部分，建议多体会，虽然随机置0了部分值，但是输出规模是的趋势是一定的。</p>
<p>  虽然我们从这里说明了其生效的原理，但是我们并没有解释为啥这样写是合理的？注意为何我们要在训练的时候除以1-p呢？</p>
<p>  其实我们可以看到，Dropout是针对输出的，当我们只要保证训练和测试的输出规模保持一致，就可以保证测试和训练的结果是一致的。这里的规模保持一致，其实就是他们两个的期望保持一致。定义输入为X, dropout概率为p(以p的概率丢弃)，那么$E(x) = ((1-p)X + p*0)/(1-p) = X$。因此，我们也可以得到结论，我们在训练时dropout生效，测试时直接跳过dropout层，这两种情况下的X的规模是一致的，不影响我们的网络结果。</p>
<p>  此外，我们从这里可以看到，dropout是以概率来丢弃相关的输入X，那么我们必须在X规模足够大的情况下使用dropout，才能保证剩下的X能够学到足够的特征。因此，我们平常一般把dropout放在全连接层后。</p>
<p>  下面，我们自己构造一个分类网络，使用FashionMNIST数据集（60000训练，10000测试）。然后在全连接层后面接dropout层，默认是不丢弃任何项，dropout的p=0，代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils <span class="token keyword">import</span> data
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">import</span> MultipleLocator
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
xdata<span class="token punctuation">,</span> ydata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
line0<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TrainError'</span><span class="token punctuation">)</span>
line1<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'b-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TrainAcc'</span><span class="token punctuation">)</span>
line2<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'g-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TestError'</span><span class="token punctuation">)</span>
line3<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'y-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TestAcc'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">init_and_show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'loss/acc'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Train/Test Loss/Acc'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># ax.set_yscale('log')</span>
    <span class="token comment"># y_locator = MultipleLocator(0.1)</span>
    <span class="token comment"># ax.yaxis.set_major_locator(y_locator)</span>
    ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span>line0<span class="token punctuation">,</span> line1<span class="token punctuation">,</span> line2<span class="token punctuation">,</span> line3<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'TrainError'</span><span class="token punctuation">,</span> <span class="token string">'TrainAcc'</span><span class="token punctuation">,</span> <span class="token string">"TestError"</span><span class="token punctuation">,</span> <span class="token string">"TestAcc"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># ax.legend([line1], ('TestError', ))</span>
    line0<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    line1<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    line2<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    line3<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ydata<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">dropout_layer</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">assert</span> <span class="token number">0</span> <span class="token operator">&lt;=</span> dropout <span class="token operator">&lt;=</span> <span class="token number">1</span>
    <span class="token comment"># 在本情况中，所有元素都被丢弃。</span>
    <span class="token keyword">if</span> dropout <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    <span class="token comment"># 在本情况中，所有元素都被保留。</span>
    <span class="token keyword">if</span> dropout <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> X
    mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">></span> dropout
    <span class="token keyword">print</span><span class="token punctuation">(</span>mask<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> mask<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">*</span> X <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> dropout<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">TestNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dropout_p_arr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TestNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>test_net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>

            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout_p_arr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout_p_arr<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

        <span class="token punctuation">)</span>   

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print(x.dtype)</span>
        <span class="token comment"># </span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>test_net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">LoadFashionMNISTByTorchApi</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    resize<span class="token operator">=</span><span class="token number">28</span>
    trans <span class="token operator">=</span> <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> resize<span class="token punctuation">:</span>
        trans<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span>resize<span class="token punctuation">)</span><span class="token punctuation">)</span>
    trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>trans<span class="token punctuation">)</span>
    <span class="token comment"># 60000*28*28</span>
    training_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"..\data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>trans
    <span class="token punctuation">)</span>

    <span class="token comment"># 10000*28*28</span>
    test_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"..\data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>trans
    <span class="token punctuation">)</span>

    <span class="token comment"># labels_map = &#123;</span>
    <span class="token comment">#     0: "T-Shirt",</span>
    <span class="token comment">#     1: "Trouser",</span>
    <span class="token comment">#     2: "Pullover",</span>
    <span class="token comment">#     3: "Dress",</span>
    <span class="token comment">#     4: "Coat",</span>
    <span class="token comment">#     5: "Sandal",</span>
    <span class="token comment">#     6: "Shirt",</span>
    <span class="token comment">#     7: "Sneaker",</span>
    <span class="token comment">#     8: "Bag",</span>
    <span class="token comment">#     9: "Ankle Boot",</span>
    <span class="token comment"># &#125;</span>
    <span class="token comment"># figure = plt.figure(figsize=(8, 8))</span>
    <span class="token comment"># cols, rows = 3, 3</span>
    <span class="token comment"># for i in range(1, cols * rows + 1):</span>
    <span class="token comment">#     sample_idx = torch.randint(len(training_data), size=(1,)).item()</span>
    <span class="token comment">#     img, label = training_data[sample_idx]</span>
    <span class="token comment">#     figure.add_subplot(rows, cols, i)</span>
    <span class="token comment">#     plt.title(labels_map[label])</span>
    <span class="token comment">#     plt.axis("off")</span>
    <span class="token comment">#     plt.imshow(img.squeeze(), cmap="gray")</span>
    <span class="token comment"># plt.show()</span>
    <span class="token keyword">return</span> training_data<span class="token punctuation">,</span> test_data
    
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>
    size <span class="token operator">=</span> num_batches<span class="token operator">*</span>batch_size
    train_loss_sum <span class="token operator">=</span> <span class="token number">0</span>
    train_acc_sum <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> batch<span class="token punctuation">,</span> <span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># move X, y to gpu</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
        <span class="token comment"># Compute prediction and loss</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># print(pred.shape)</span>
        <span class="token comment"># print(y.shape)</span>
        
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

        <span class="token comment"># Backpropagation</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        train_loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># cal train acc</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        train_acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>batch_size

        <span class="token keyword">if</span> batch <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            loss<span class="token punctuation">,</span> current <span class="token operator">=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">:</span><span class="token format-spec">>7f</span><span class="token punctuation">&#125;</span></span><span class="token string">  [</span><span class="token interpolation"><span class="token punctuation">&#123;</span>current<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>size<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">]"</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Train Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss_sum<span class="token operator">/</span>num_batches<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Train Acc  : \n Avg acc : </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_acc_sum<span class="token operator">/</span>num_batches<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> train_loss_sum<span class="token operator">/</span>num_batches<span class="token punctuation">,</span> train_acc_sum<span class="token operator">/</span>num_batches


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>
    test_loss <span class="token operator">=</span> <span class="token number">0</span>
    test_acc <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            <span class="token comment"># move X, y to gpu</span>
            <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
                y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            test_loss <span class="token operator">+=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            test_acc <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>batch_size
    test_loss <span class="token operator">/=</span> num_batches
    test_acc <span class="token operator">/=</span> num_batches
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Acc  : \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_acc<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string">  \n"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> test_loss<span class="token punctuation">,</span> test_acc
    
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using &#123;&#125; device'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    learning_rate <span class="token operator">=</span> <span class="token number">0.5</span>
    <span class="token comment"># [0.4, 0.7]</span>
    model <span class="token operator">=</span> TestNet<span class="token punctuation">(</span><span class="token punctuation">)</span>

    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>

    epochs <span class="token operator">=</span> <span class="token number">10</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>


    batch_size <span class="token operator">=</span> <span class="token number">200</span>

    train_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> LoadFashionMNISTByTorchApi<span class="token punctuation">(</span><span class="token punctuation">)</span>
    

    train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># #verify dataloader</span>
    <span class="token comment"># for x,y in train_dataloader:</span>
    <span class="token comment">#     print(x.shape)</span>
    <span class="token comment">#     print(y.shape)</span>
    <span class="token comment">#     break</span>

    param_iter <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    
    
    <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>t<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">\n-------------------------------"</span></span><span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_l<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>
        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        test_l<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span>

        xdata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        xdata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        xdata<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        xdata<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>

        ydata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_l<span class="token punctuation">)</span>
        ydata<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
        ydata<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_l<span class="token punctuation">)</span>
        ydata<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span>
        
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done!"</span><span class="token punctuation">)</span>

    init_and_show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="正常过拟合">正常过拟合</h5>
<p>  直接用上面代码进行训练后得到结果如下：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting_dp.png" alt="rep_img"/></center>
    </div>
</div>    
&emsp;&emsp;我们可以发现，测试准确率比训练准确率低，满足过拟合的现象。
<h5 id="启用dropout">启用dropout</h5>
<p>  修改训练代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">    <span class="token comment"># [0.4, 0.7]</span>
model <span class="token operator">=</span> TestNet<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>  训练结果如图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_108/overfitting_dp_sov.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  我们可以很直观的发现，训练和测试的acc和error出现了重合的情况，至少证明了过拟合现象出现了缓解。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  对于权重衰减，一般就是要将参数的L2范数尽量学习来趋近于0，这样模型复杂度变小。此外权重衰减还可以将参数限制到一个稳定的范围，避免出现了较大的波动。对于稳定的学习过程是有帮助的。</p>
<p>  对于Dropout来说，就是打破一些输出比较大的相关层的关联性，注意，其是针对输出，并不是针对权重。有些时候，相关层的关联性就是我们要学的，但是有些时候，这种关联性可能就是不需要的，所以通过这种‘玄学’的方式，在训练的时候，以概率性来丢弃某些输出，打破这项输出和下一层的关联性。这对于大的网络来说，是有意义的。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V1.0.0)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V2.0.0 alpha1)</p>
</li>
<li class="lvl-2">
<p>Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1), 1929‒1958.</p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/07/18/blog_idx_107/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/18/blog_idx_107/" class="post-title-link" itemprop="url">DL基础补全计划(三)---模型选择、欠拟合、过拟合</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-18 18:39:57" itemprop="dateCreated datePublished" datetime="2021-07-18T18:39:57+08:00">2021-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky sky@sky-home.com
 * @LastEditTime: 2023-04-08 11:09:38
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=107）
&emsp;&emsp;本文发布于 2021-07-18 18:39:57      （BlogID=107）
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Windows 10</p>
</li>
<li class="lvl-2">
<p>VSCode</p>
</li>
<li class="lvl-2">
<p>Python 3.8.10</p>
</li>
<li class="lvl-2">
<p>Pytorch 1.8.1</p>
</li>
<li class="lvl-2">
<p>Cuda 10.2</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  在前文中，我们已经接触了两种回归模型，也接触了深度学习中的一些常见的概念。其中有趣的信息是，我们在《DL基础补全计划(二)—Softmax回归及示例（Pytorch，交叉熵损失）》中已经发现了，在softmax回归的时候，我们使用一个线性的隐藏层在其数据集上都能够达到不错的不错的准确率，这里的不错是指瞎猜和我们的模型推测的准确率，一个是10%，一个是80%左右。这至少说明了我们这个分类模型是有效的。其实后续我们就会更换线性隐藏层为其他层来实现我们的模型，比如：CNN、RNN等等，不同的隐藏层是后续我们要接触和学习的内容，这里不先做详解。</p>
<p>  我们假设我们已经设计出了许多的不同隐藏层的模型，这个时候有一个重要的问题就是选择哪一个模型为我们实际的要应用的模型，本文将会介绍一些方法来实现怎么选择模型的问题。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="一些基本概念简介">一些基本概念简介</h3>
<hr>
<p>  基本概念简介：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>训练误差 是指模型在参数更新后，在训练集上做一次测试，算出的和真实值的误差。</p>
</li>
<li class="lvl-2">
<p>泛化误差 是指模型在真实数据分布下，算出的和真实值的误差，但是一般情况下数据是无穷多的，我们只能够采集一些真实数据，并算出泛化误差。常见的情况是我们构造一个测试集来计算泛化误差。</p>
</li>
<li class="lvl-2">
<p>欠拟合 模型拟合能力差，训练误差和泛化误差差异小，但是两个误差都比较大，一般来说，就是模型基本没有学习到我们需要学习的规律和特征。</p>
</li>
<li class="lvl-2">
<p>过拟合 训练误差小，泛化误差大。一般来说就是在训练集上学习的太过分了，类似强行记住了训练集上的所有规律和特征，导致泛化能力太弱了。</p>
</li>
</ul>
<p>  一般来说欠拟合的话，就是换网络，加深加大网络等解决问题，欠拟合其实很明显，解决方向比较明确。</p>
<p>  其实我们更多是遇到过拟合，因为随着发展，我们的模型越来越深和宽，但是我们能够收集到的数据是有限的，导致了我们的模型可能出现‘死记硬背’下我们的训练集，然后泛化能力就令人担忧，为了缓解这个问题，后续我们将会介绍几种缓解过拟合的方法。</p>
<p>  下面我们将会通过一个实例来体会一下正常拟合、欠拟合、过拟合。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="一个正常拟合、过拟合、欠拟合的实例">一个正常拟合、过拟合、欠拟合的实例</h3>
<hr>
<p>  这里我们通过pytorch的高级API来设计一个线性规划的实例。</p>
<p>  首先通过如下的代码生成$Y=(X^3/3!)*W1 + (X^2/2!)<em>W2 + X</em>W3 + b + \epsilon, \epsilon=N(0, 0.1^2)$的特征和标签。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">synthetic_data</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""⽣成y = (X1^3/3!)*W1 + (X2^2/2!)*W1 + X3*W3 + b + 噪声。"""</span>

    X <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token operator">**</span><span class="token number">3</span><span class="token operator">/</span>np<span class="token punctuation">.</span>math<span class="token punctuation">.</span>factorial<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token operator">**</span><span class="token number">2</span><span class="token operator">/</span>np<span class="token punctuation">.</span>math<span class="token punctuation">.</span>factorial<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token operator">/</span>np<span class="token punctuation">.</span>math<span class="token punctuation">.</span>factorial<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> w<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
    
    <span class="token comment"># 噪声</span>
    y <span class="token operator">+=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> X<span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  然后通过自定义Pytorch层，通过传入参数N，计算N项多项式的结果。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TestLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TestLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>n <span class="token operator">=</span> n
        self<span class="token punctuation">.</span>w_array <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">cal</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>b
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># print(X.shape)</span>
            <span class="token comment"># print(self.w_array.shape)</span>
            <span class="token comment"># print(Y.shape)</span>

            Y  <span class="token operator">=</span> Y <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token operator">**</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>math<span class="token punctuation">.</span>factorial<span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>w_array<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> Y

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cal<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>n<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">TestNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TestNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>test_net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            TestLayer<span class="token punctuation">(</span>n<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>   

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>test_net<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  最终完整代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils <span class="token keyword">import</span> data
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">import</span> MultipleLocator

fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
xdata0<span class="token punctuation">,</span> ydata0 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
xdata1<span class="token punctuation">,</span> ydata1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
line0<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TrainError'</span><span class="token punctuation">)</span>
line1<span class="token punctuation">,</span> <span class="token operator">=</span> ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'b-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'TestError'</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">init_and_show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Train/Test Loss'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_yscale<span class="token punctuation">(</span><span class="token string">'log'</span><span class="token punctuation">)</span>
    <span class="token comment"># y_locator = MultipleLocator(0.1)</span>
    <span class="token comment"># ax.yaxis.set_major_locator(y_locator)</span>
    ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span>line0<span class="token punctuation">,</span> line1<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'TrainError'</span><span class="token punctuation">,</span> <span class="token string">'TestError'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># ax.legend([line1], ('TestError', ))</span>
    line0<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata0<span class="token punctuation">,</span> ydata0<span class="token punctuation">)</span>
    line1<span class="token punctuation">.</span>set_data<span class="token punctuation">(</span>xdata1<span class="token punctuation">,</span> ydata1<span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>



<span class="token keyword">def</span> <span class="token function">synthetic_data</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""⽣成y = X1^3*W1 + X2^2*W1 + X3*W3 + b + 噪声。"""</span>

    X <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token operator">**</span><span class="token number">3</span><span class="token operator">/</span>np<span class="token punctuation">.</span>math<span class="token punctuation">.</span>factorial<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token operator">**</span><span class="token number">2</span><span class="token operator">/</span>np<span class="token punctuation">.</span>math<span class="token punctuation">.</span>factorial<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token operator">/</span>np<span class="token punctuation">.</span>math<span class="token punctuation">.</span>factorial<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> w<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
    
    <span class="token comment"># 噪声</span>
    y <span class="token operator">+=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> X<span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>



<span class="token keyword">class</span> <span class="token class-name">TestLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TestLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>n <span class="token operator">=</span> n
        self<span class="token punctuation">.</span>w_array <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">cal</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>b
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># print(X.shape)</span>
            <span class="token comment"># print(self.w_array.shape)</span>
            <span class="token comment"># print(Y.shape)</span>

            Y  <span class="token operator">=</span> Y <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token operator">**</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>math<span class="token punctuation">.</span>factorial<span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>w_array<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> Y

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cal<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>n<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">TestNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TestNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>test_net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            TestLayer<span class="token punctuation">(</span>n<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>   

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>test_net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># copy from d2l/torch.py</span>
<span class="token keyword">def</span> <span class="token function">load_array</span><span class="token punctuation">(</span>data_arrays<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Construct a PyTorch data iterator."""</span>
    dataset <span class="token operator">=</span> data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span><span class="token operator">*</span>data_arrays<span class="token punctuation">)</span>
    <span class="token keyword">return</span> data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span>is_train<span class="token punctuation">)</span>

<span class="token comment"># def data_loader(batch_size, features, labels):</span>
<span class="token comment">#     num_examples = len(features)</span>
<span class="token comment">#     indices = list(range(num_examples))</span>
<span class="token comment">#     np.random.shuffle(indices) # 样本的读取顺序是随机的</span>

<span class="token comment">#     for i in range(0, num_examples, batch_size):</span>
<span class="token comment">#         j = np.array(indices[i: min(i + batch_size, num_examples)])</span>
<span class="token comment">#         yield torch.tensor(features.take(j, 0)), torch.tensor(labels.take(j)) # take函数根据索引返回对应元素</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> train_examples
    num_batches <span class="token operator">=</span> train_examples <span class="token operator">/</span> batch_size
    train_loss_sum <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> batch<span class="token punctuation">,</span> <span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># move X, y to gpu</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
        <span class="token comment"># Compute prediction and loss</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

        <span class="token comment"># Backpropagation</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        train_loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> batch <span class="token operator">%</span> <span class="token number">5</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            loss<span class="token punctuation">,</span> current <span class="token operator">=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">:</span><span class="token format-spec">>7f</span><span class="token punctuation">&#125;</span></span><span class="token string">  [</span><span class="token interpolation"><span class="token punctuation">&#123;</span>current<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>size<span class="token punctuation">:</span><span class="token format-spec">>5d</span><span class="token punctuation">&#125;</span></span><span class="token string">]"</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Train Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss_sum<span class="token operator">/</span>num_batches<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> train_loss_sum<span class="token operator">/</span>num_batches


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_batches <span class="token operator">=</span> test_examples <span class="token operator">/</span> batch_size
    test_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            <span class="token comment"># move X, y to gpu</span>
            <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
                y <span class="token operator">=</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            test_loss <span class="token operator">+=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    test_loss <span class="token operator">/=</span> num_batches
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Error: \n Avg loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">>8f</span><span class="token punctuation">&#125;</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> test_loss
    
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using &#123;&#125; device'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    true_w1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1.65</span><span class="token punctuation">]</span>

    true_w2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.46</span><span class="token punctuation">]</span>

    true_w3 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3.54</span><span class="token punctuation">]</span>

    true_b <span class="token operator">=</span> <span class="token number">0.78</span>    

    test_examples <span class="token operator">=</span> <span class="token number">100</span>
    train_examples <span class="token operator">=</span> <span class="token number">100</span>
    
    num_examples <span class="token operator">=</span> test_examples <span class="token operator">+</span> train_examples

    f1<span class="token punctuation">,</span> labels <span class="token operator">=</span> synthetic_data<span class="token punctuation">(</span><span class="token punctuation">[</span>true_w1<span class="token punctuation">,</span> true_w2<span class="token punctuation">,</span> true_w3<span class="token punctuation">,</span> true_b<span class="token punctuation">]</span><span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    num_weight <span class="token operator">=</span> <span class="token number">3</span>

    l1_loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    learning_rate <span class="token operator">=</span> <span class="token number">0.01</span>

    model <span class="token operator">=</span> TestNet<span class="token punctuation">(</span>num_weight<span class="token punctuation">)</span>

    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>

    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>

    epochs <span class="token operator">=</span> <span class="token number">1500</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>


    batch_size <span class="token operator">=</span> <span class="token number">10</span>

    train_data <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>f1<span class="token punctuation">[</span><span class="token punctuation">:</span>train_examples<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">[</span><span class="token punctuation">:</span>train_examples<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_data <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>f1<span class="token punctuation">[</span>train_examples<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">[</span>train_examples<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    train_dataloader <span class="token operator">=</span> load_array<span class="token punctuation">(</span>train_data <span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> load_array<span class="token punctuation">(</span>test_data <span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># verify dataloader</span>
    <span class="token comment"># for x,y in train_dataloader:</span>
    <span class="token comment">#     print(x.shape)</span>
    <span class="token comment">#     print(y.shape)</span>
    <span class="token comment">#     print(torch.matmul(x**3, torch.tensor(true_w1, dtype=torch.double)) + torch.matmul(x**2, torch.tensor(true_w2, dtype=torch.double)) + torch.matmul(x, torch.tensor(true_w3, dtype=torch.double)) + true_b)</span>
    <span class="token comment">#     print(y)</span>
    <span class="token comment">#     break</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>t<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">\n-------------------------------"</span></span><span class="token punctuation">)</span>
        train_l <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>
        test_l <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> l1_loss_fn<span class="token punctuation">)</span>
        ydata0<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_l<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
        ydata1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_l<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
        xdata0<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        xdata1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done!"</span><span class="token punctuation">)</span>

    init_and_show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    param_iter <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'W = '</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> num_weight<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b = '</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>param_iter<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  注意，此最终代码首先生成了100个训练集和100个测试集。通过num_weight可以控制参与训练的多项式个数，话句话说，可以控制参与拟合训练的参数个数。下面通过三个说明我们来看看，不同num_weight下，TrainErr和TestErr和迭代次数，参与拟合训练的参数的关系。</p>
<br/>
<br/>
<h5 id="正常拟合-num-weight-3">正常拟合(num_weight = 3)</h5>
<p>  当num_weight = 3时，运行我们的训练脚本，我们可以清楚的看到，我们拟合出来的结果和我们的真实参数是几乎一样的。同时我们也可以看到TrainErr和TestErr快速的收敛接近0而且差别不是很大。</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_107/normal_train.png" alt="rep_img"/></center>
    </div>
</div>    
<br/>
<br/>
<h5 id="欠拟合-num-weight-1">欠拟合(num_weight = 1)</h5>
<p>  当num_weight = 1时，运行我们的训练脚本，我们可以清楚的看到，损失图像到了一定程度就不下降了，不能够收敛。</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_107/underfitting_train.png" alt="rep_img"/></center>
    </div>
</div>    
<h5 id="过拟合-num-weight-20">过拟合(num_weight = 20)</h5>
<p>  当num_weight = 20时，按照我们的猜测，我们的模型应该会出现过拟合。</p>
<p>  正常过拟合现象, 注意观察最终输出前面3项的w和b和真实w和b存在差异。</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_107/overfitting_train_nor.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  从我多次的实验的结果来看，除了上面的真实出现的过拟合情况，还有一些情况是，不会出现过拟合现象，如下图。注意观察最终输出前面3项的w和b和真实w和b。</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_107/overfitting_train_abnor.png" alt="rep_img"/></center>
    </div>
</div> 
<p>  我们通过观察，发现了w的4到20项参数接近于0，前面3项的w和b和真实w和b是比较接近的，因此我们猜测没有出现过拟合的原因是w的4到20项的权重在整个表达式中占比非常小，因此不会过拟合。可以直接理解为w的4到20项的权重为0。</p>
<p>  注意过拟合这个例子，需要多次运行才会出现过拟合现象，其是波动的，其实就是我们初始化的参数充满了随机性，导致了不容易收敛。而欠拟合和正常拟合的例子不管你怎么运行，都能稳定的得到结果。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  这里我们从模型选择的角度出发，发现了我们训练的过程中会出现的3种现象，欠拟合，正常拟合，过拟合。其中正常拟合状态下的模型是我们需要的。</p>
<p>  对于欠拟合来说，就是参与训练的参数少了，换句话说我们的模型太简单了，不能够代表我们要学习的特征，导致完全不能够收敛。</p>
<p>  对于过拟合来说，远不止我们看到的这么简单和清晰。在这里我们只是看到了一个主要的导致训练出现大波动的原因就是参数过多，这种情况下会出现过拟合现象。由于在后面的模型中，参数都是成百上千，我们不可能一个个尝试，因此在后续，我们还会学习一些手段来抑制过拟合现象。</p>
<p>  这里我们也要引出一个问题，我们知道模型的复杂度（参数个数）在一个特定数据集上可能会导致过拟合，那么我们除了控制模型复杂度之外，还有其他的方案可以选择吗?</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V1.0.0)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V2.0.0 alpha1)</p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/07/11/blog_idx_106/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/11/blog_idx_106/" class="post-title-link" itemprop="url">DL基础补全计划(二)---Softmax回归及示例（Pytorch，交叉熵损失）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-11 22:23:46" itemprop="dateCreated datePublished" datetime="2021-07-11T22:23:46+08:00">2021-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky
 * @LastEditTime: 2021-07-01 17:32:12
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=106） 
&emsp;&emsp;本文发布于 2021-07-11 22:23:46     （BlogID=106） 
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Windows 10</p>
</li>
<li class="lvl-2">
<p>VSCode</p>
</li>
<li class="lvl-2">
<p>Python 3.8.10</p>
</li>
<li class="lvl-2">
<p>Pytorch 1.8.1</p>
</li>
<li class="lvl-2">
<p>Cuda 10.2</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  在《DL基础补全计划(一)—线性回归及示例（Pytorch，平方损失）》（<a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/118463588">https://blog.csdn.net/u011728480/article/details/118463588</a> ）一文中我们对深度学习中的非常基础的知识进行了简单介绍，按照常见深度学习中的基本流程设计了一个简单的线性模型。同时，基于基本的语法，展示了数据收集，数据小批量随机获取，网络forward, loss设计，基于loss的bp，随机小批量梯度下降，模型训练，模型预测等基本的流程。 记录这篇文章的原因也很简单，为了将自己从学校里面带出来的知识和深度学习中的基础知识关联起来，不要出现大的断层和空洞。</p>
<p>  在上文我们提到，我们已经能够设计一类模型能够求解特定函数的数值，但是在实际应用场景中，我们还有一些问题主要还是关注他们的分类。比如我们有一堆数据，怎么把他们分为N类。这里就要介绍深度学习中一类常见的模型，softmax回归模型。本文的主要目的就是基于FashionMNIST数据集（60000 * 28 * 28 训练集，10000 * 28 * 28 测试集），从基础的语法开始设计一个softmax分类模型，并介绍一些softmax相关的重点，在本文之后，其实我们就可以做一些深度学习的简单分类任务了。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="Softmax介绍及实例">Softmax介绍及实例</h3>
<hr>
<p>  我们可以知道，Softmax这个函数其实就是对N个类别进行打分，输出N个类别的概率，那么它的实际底层工作原理到底是什么呢？</p>
<p>  假如我们定义输出类别为N，输入特征为X, 输出类别分数为Y，参数为W，偏置为b，那么我们可以设计一个函数为：$Y=WX+b$，W.shape是(N, len(X)), X.shape是(len(X), 1)， b.shape 是(N, len(X))，Y.shape是(N , 1)，通过这样的一个线性运算后，我们就可以将len(X)个输入变换为N个输出，其实这个时候的N个输出就是我们不同类别的分数，理论上来说，我们就可以用这个当做每个类别的分数或者说概率。由于这里的Y是实数范围，有正有负，有大有小，存在数据不稳定性，而且我们需要把输出的类别当做概率使用，这里如果存在负数的话，不满足概率的一些定义。因此我们在经过一个线性变换后，再通过softmax运算，才能够将这些分数转换为相应的概率。</p>
<p>  Y.shape是(N , 1)，Softmax定义为：$Softmax(Yi)=exp(Yi)/\sum\limits_{j=0}^{N-1}Yj$ ，因此我们可以通过Softmax得到每个类别的分数。$Y’=Softmax(Y)$，通过这样的运算后，就把Y归一化到0~1，而且满足概率的一些定义和保持了和Y同样的性质。</p>
<p>  下面我们基于FashionMNIST数据集（此数据集有10个类别，60000个训练集，10000个测试集，图片为单通道28*28），设计一个简单的分类模型。下面是python需要导入的依赖</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> numpy<span class="token punctuation">.</span>core<span class="token punctuation">.</span>numeric <span class="token keyword">import</span> cross
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToTensor
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="获取并处理FashionMNIST数据集">获取并处理FashionMNIST数据集</h5>
<p>  通过Pytorch的设计好的api直接获取数据集，并得到解析后的数据</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">LoadFashionMNISTByTorchApi</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 60000*28*28</span>
    training_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># 10000*28*28</span>
    test_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"data"</span><span class="token punctuation">,</span>
        train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    labels_map <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"T-Shirt"</span><span class="token punctuation">,</span>
        <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"Trouser"</span><span class="token punctuation">,</span>
        <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">"Pullover"</span><span class="token punctuation">,</span>
        <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">"Dress"</span><span class="token punctuation">,</span>
        <span class="token number">4</span><span class="token punctuation">:</span> <span class="token string">"Coat"</span><span class="token punctuation">,</span>
        <span class="token number">5</span><span class="token punctuation">:</span> <span class="token string">"Sandal"</span><span class="token punctuation">,</span>
        <span class="token number">6</span><span class="token punctuation">:</span> <span class="token string">"Shirt"</span><span class="token punctuation">,</span>
        <span class="token number">7</span><span class="token punctuation">:</span> <span class="token string">"Sneaker"</span><span class="token punctuation">,</span>
        <span class="token number">8</span><span class="token punctuation">:</span> <span class="token string">"Bag"</span><span class="token punctuation">,</span>
        <span class="token number">9</span><span class="token punctuation">:</span> <span class="token string">"Ankle Boot"</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#125;</span>
    figure <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cols<span class="token punctuation">,</span> rows <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> cols <span class="token operator">*</span> rows <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        sample_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>training_data<span class="token punctuation">)</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        img<span class="token punctuation">,</span> label <span class="token operator">=</span> training_data<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span>
        figure<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span>rows<span class="token punctuation">,</span> cols<span class="token punctuation">,</span> i<span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>labels_map<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">"gray"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> training_data<span class="token punctuation">,</span> test_data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/show_datasets.png" alt="rep_img"/></center>
    </div>
</div>    
<p>  通过面的代码可以知道，datasets.FashionMNIST()返回的是集合，集合里面存的是每个图的数据以及其标签。这里其实Pytorch帮我们做了解析工作，实际FashionMNIST的二进制存储格式如下，我们也可以自己写代码按照此规则解析数据集，这里就不关注这个问题了。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">'''
Image:
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000803(2051) magic number
0004     32 bit integer  60000            number of images
0008     32 bit integer  28               number of rows
0012     32 bit integer  28               number of columns
0016     unsigned byte   ??               pixel
0017     unsigned byte   ??               pixel
........
xxxx     unsigned byte   ??               pixel
'''</span>

<span class="token triple-quoted-string string">'''
Label：
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  60000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........
xxxx     unsigned byte   ??               label
The labels values are 0 to 9.
'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  还记得我们前文的随机小批量怎么实现的吗？首先随机打乱数据集中的每个数据（图片和标签为一个数据）的顺序，然后根据batch_size参数构造一个可迭代的对象返回出来，最后训练的时候我们通过for xx in data_iter 来访问这一批的数据。这里我们也不需要自己来写这个了，直接调用Pytorch的函数来生成这样的一个data_iter，我们应该把更多注意力放到其他地方去。代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">training_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> LoadFashionMNISTByTorchApi<span class="token punctuation">(</span><span class="token punctuation">)</span>
batch_size <span class="token operator">=</span> <span class="token number">200</span>

<span class="token comment"># 返回训练集和测试集的可迭代对象</span>
train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="设计网络">设计网络</h5>
<p>  我们的网络由两个部分构成，一个是从28*28到10的一个映射函数，一个是softmax函数。我们定义一个$Y=WX+b, Y’=Softmax(Y)$，因此我们可以看到，我们所需要学习的参数有W和b。</p>
<p>  根据前文介绍，我们可以知道Y’/Y.shape是(10, 1), X.shape是(784, 1), W.shape是(10, 784), b.shape(10, 1)</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># example:</span>
    <span class="token comment"># out = (p1, p2, p3)</span>
    <span class="token comment"># set Sum=p1+p2+p3</span>
    <span class="token comment"># softmax(out) = (p1/Sum, p2/Sum, p3/Sum)</span>
    exp_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
    partition <span class="token operator">=</span> exp_out<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> exp_out<span class="token operator">/</span>partition

<span class="token keyword">def</span> <span class="token function">my_net</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># print(X.shape)</span>
    <span class="token comment"># print(w.shape)</span>
    <span class="token comment"># print(b.shape)</span>
    liear_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b
    <span class="token comment"># print(liear_out.shape)</span>
    <span class="token keyword">return</span> softmax<span class="token punctuation">(</span>liear_out<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="设计Loss函数及优化函数">设计Loss函数及优化函数</h5>
<p>  在前文的线性回归中，我们使用了平方误差来作为Loss函数，在分类这一问题里面，我们需要引入交叉熵来作为Loss函数。交叉熵作为信息论中的概念，我们简单的通过几个前置知识来引入：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>信息论研究的是一个随机事件携带的信息量，基本思想是事件发生概率越大，所携带的信息量越小。因此这里可以引入一个自信息定义：$I(x)=-\log_{2}(P(x))$。通过这个定义我们可以得到同样的趋势，一个事件发生的概率越小，携带的信息量越大。</p>
</li>
<li class="lvl-2">
<p>熵(Entropy)，自信息是对单个随机事件的信息量大小描述，我们需要定义来描述整个随机分布的信息量大小的描述。假设随机分布是离散的，熵的定义为：$H(X)=-\sum\limits_{i=0}^{n-1}P(Xi)\log_{2}(P(Xi))$</p>
</li>
<li class="lvl-2">
<p>KL差异（Kullback-Leibler (KL) divergence），主要就是用来描述两个分布的差异。因为在有些时候，一个概率分布很复杂，我们可以用一个简单的概率分布来替代，但是我们需要知道这两个分布的差异。定义原概率分布为P(X),近似概率分布为Q(X)，假如X是离散随机变量，KL差异定义为：$D_{KL}(P(X)||Q(X))=\sum\limits_{i=0}<sup>{n-1}P(Xi)\log_{2}(P(Xi)/Q(Xi))=\sum\limits_{i=0}</sup>{n-1}P(Xi)[\log_{2}(P(Xi)) - \log_{2}(Q(Xi))]$</p>
</li>
<li class="lvl-2">
<p>交叉熵（cross-entropy），交叉熵定义为：$H(P,Q)=-\sum\limits_{i=0}^{n-1}P(Xi)\log_{2}(Q(Xi))$，我们可以看到$H(P,Q)=H(P)+D_{KL}(P||Q)$。</p>
</li>
<li class="lvl-2">
<p>在上文中，我们一步一步引出了交叉熵，这个时候，我们来看为什么在深度学习中可以引入交叉熵作为Loss函数，对于特定的一组Feature，我们可以通过标签得到这组feature代表什么，相当于其概率为1，因此在原概率分布上面，$P(Xi)=1, H(Xi)=0$，我们可以看到这个时候交叉熵和KL差异是相等的，那么交叉熵其实就是描述我们训练时得到的概率分布和原分布的差异。因此，在分类问题中我们得到的是当前的每个分类的概率，那么我们分别求每个分类当前概率分布相对于原分布的KL差异，那么我们就知道我们的训练参数和真实参数的差异。我们求交叉熵的最小值，也就代表我们参数越接近真实值。</p>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 信息论，熵，kl熵（相对），交叉熵</span>
<span class="token keyword">def</span> <span class="token function">cross_entropy</span><span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># l = -y*log(y')</span>
    
    <span class="token comment"># print(y_train.shape)</span>
    <span class="token comment"># print(y_label.shape)</span>
    <span class="token comment"># print(y_train)</span>
    <span class="token comment"># print(y_label)</span>
    <span class="token comment"># print(y_train[0][:].sum())</span>
    <span class="token comment"># call pick</span>
    my_loss <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y_train<span class="token punctuation">[</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_label<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># nll_loss = torch.nn.NLLLoss()</span>
    <span class="token comment"># th_loss = nll_loss(torch.log(y_train), y_label)</span>
    <span class="token comment"># print(my_loss.sum()/len(y_label))</span>
    <span class="token comment"># print(th_loss)</span>
    <span class="token keyword">return</span> my_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="设计准确率统计函数以及评估准确率函数">设计准确率统计函数以及评估准确率函数</h5>
<p>  在前一小节，我们已经设计了损失函数，我们在训练的过程中，除了要关注损失函数的值外，还需要关注我们模型的准确率。</p>
<p>  模型的准确率代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_label<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""计算预测正确的数量。"""</span>
    <span class="token comment"># y_train = n*num_class</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">1</span> <span class="token keyword">and</span> y_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token comment"># argmax get the max-element-index</span>
        y_train <span class="token operator">=</span> y_train<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment"># cmp = n*1 , eg: [0 0 0 1 1 1 0 0 0]</span>
    <span class="token comment"># print(y_train.dtype)</span>
    <span class="token comment"># print(y_label.dtype)</span>
    <span class="token builtin">cmp</span> <span class="token operator">=</span> y_train <span class="token operator">==</span> y_label
    <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token builtin">cmp</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>y_label<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  从上面的代码可以知道，我们的网络输出是当前feature在每个类别上的概率，因此我们求出网络输出中，概率最大的索引，和真实label进行对比，相等就代表预测成功一个，反之。我们对最终数据求和后除以batch_size，就可以得到在batch_size个特征中，我们的预测正确的个数占比是多少。</p>
<p>  我们还需要在指定的数据集上评估我们的准确率，其代码如下（就是分批调用获得准确率后求平均）：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">evaluate_accuracy</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> data_iter<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""计算在指定数据集上模型的精度。"""</span>
    test_acc_sum <span class="token operator">=</span> <span class="token number">0.0</span>
    times <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">for</span> img<span class="token punctuation">,</span> label <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        test_acc_sum <span class="token operator">+=</span> accuracy<span class="token punctuation">(</span>net<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> img<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        times <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token keyword">return</span> test_acc_sum<span class="token operator">/</span>times<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="设计预测函数">设计预测函数</h5>
<p>  预测函数就是在特定数据上面，通过我们训练的网络，求出类别，并与真实label进行对比，其代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> test_iter<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""预测标签（定义⻅第3章）。"""</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> test_iter<span class="token punctuation">:</span>
        <span class="token keyword">break</span>
    labels_map <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"T-Shirt"</span><span class="token punctuation">,</span>
        <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"Trouser"</span><span class="token punctuation">,</span>
        <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">"Pullover"</span><span class="token punctuation">,</span>
        <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">"Dress"</span><span class="token punctuation">,</span>
        <span class="token number">4</span><span class="token punctuation">:</span> <span class="token string">"Coat"</span><span class="token punctuation">,</span>
        <span class="token number">5</span><span class="token punctuation">:</span> <span class="token string">"Sandal"</span><span class="token punctuation">,</span>
        <span class="token number">6</span><span class="token punctuation">:</span> <span class="token string">"Shirt"</span><span class="token punctuation">,</span>
        <span class="token number">7</span><span class="token punctuation">:</span> <span class="token string">"Sneaker"</span><span class="token punctuation">,</span>
        <span class="token number">8</span><span class="token punctuation">:</span> <span class="token string">"Bag"</span><span class="token punctuation">,</span>
        <span class="token number">9</span><span class="token punctuation">:</span> <span class="token string">"Ankle Boot"</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#125;</span>
    trues <span class="token operator">=</span> <span class="token punctuation">[</span>labels_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    preds <span class="token operator">=</span> <span class="token punctuation">[</span>labels_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> net<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'pre-idx </span><span class="token interpolation"><span class="token punctuation">&#123;</span>i<span class="token punctuation">&#125;</span></span><span class="token string"> \n true_label/pred_label: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>trues<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>preds<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="训练模型">训练模型</h5>
<p>  训练模型的话，其实就是将上面的代码缝合起来。代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    training_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> LoadFashionMNISTByTorchApi<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    batch_size <span class="token operator">=</span> <span class="token number">200</span>
    train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># train_features, train_labels = next(iter(train_dataloader))</span>
    <span class="token comment"># print(f"Feature batch shape: &#123;train_features.size()&#125;")</span>
    <span class="token comment"># print(f"Labels batch shape: &#123;train_labels.size()&#125;")</span>
    <span class="token comment"># img = train_features[1].squeeze()</span>
    <span class="token comment"># label = train_labels[1]</span>
    <span class="token comment"># plt.imshow(img, cmap="gray")</span>
    <span class="token comment"># plt.show()</span>
    <span class="token comment"># print(f"Label: &#123;label&#125;")</span>

    <span class="token comment"># 28*28</span>
    num_inputs <span class="token operator">=</span> <span class="token number">784</span>
    
    <span class="token comment"># num of class</span>
    num_outputs <span class="token operator">=</span> <span class="token number">10</span>

    <span class="token comment"># (748, 10)</span>
    w <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    w <span class="token operator">=</span> w<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    w<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w = '</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token comment"># (10, 1)</span>
    b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
    b <span class="token operator">=</span> b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    b<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b = '</span><span class="token punctuation">,</span> b<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>




    num_epochs <span class="token operator">=</span> <span class="token number">10</span>
    lr <span class="token operator">=</span> <span class="token number">0.1</span>

    net <span class="token operator">=</span> my_net

    loss <span class="token operator">=</span> cross_entropy

    <span class="token comment"># if torch.cuda.is_available():</span>
    <span class="token comment">#     w = w.to('cuda')</span>
    <span class="token comment">#     b = b.to('cuda')</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        times <span class="token operator">=</span> <span class="token number">1</span>
        train_acc_sum <span class="token operator">=</span> <span class="token number">0.0</span>
        train_loss_sum <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> img<span class="token punctuation">,</span> label <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
            <span class="token comment"># if torch.cuda.is_available():</span>
            <span class="token comment">#     img = img.to('cuda')</span>
            <span class="token comment">#     label = label.to('cuda')            </span>
            <span class="token comment"># print(img.shape, label.shape)</span>
            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> img<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">)</span>
            <span class="token comment"># print(l.shape)</span>
            <span class="token comment"># print(l)</span>

            <span class="token comment"># clean grad of w,b</span>
            w<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>
            b<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span> 

            <span class="token comment"># bp</span>
            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># update param</span>
            sgd<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span> b<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>

            train_acc_sum <span class="token operator">+=</span> accuracy<span class="token punctuation">(</span>net<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> img<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">)</span>
            train_loss_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>l<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>batch_size<span class="token punctuation">)</span>
            times <span class="token operator">+=</span> <span class="token number">1</span>

            <span class="token comment"># break</span>
        
        test_acc <span class="token operator">=</span> evaluate_accuracy<span class="token punctuation">(</span>net<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> test_dataloader<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch = '</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_loss = '</span><span class="token punctuation">,</span> train_loss_sum<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>times<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_acc = '</span><span class="token punctuation">,</span> train_acc_sum<span class="token operator">/</span>times<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'test_acc = '</span><span class="token punctuation">,</span> test_acc<span class="token punctuation">)</span>

        <span class="token comment"># break</span>
    
    <span class="token comment"># predict</span>
    predict<span class="token punctuation">(</span>net<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> test_dataloader<span class="token punctuation">,</span> n <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  从如上的代码可知，首先从数据集中得到小批量数据迭代器，然后随机生成初始化参数，最后在小批量数据上推理，求loss之，bp，更新参数，记录loss和acc，最终训练次数完了后，去预测。</p>
<p>  训练截图如下：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/train_log.png" alt="rep_img"/></center>
    </div>
</div> 
<p>  预测截图如下：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_106/predict_log.png" alt="rep_img"/></center>
    </div>
</div> 
&emsp;&emsp;从预测的截图来看，预测成功的准确率大于1/10。说明我们的模型的有效的。此图中看起来准确率较高，这是偶然现象，但是真实不应该这样的，因为在测试集上，准确率只有81%左右。
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  此外，我们这里仅仅是按照数学定义来做计算，在计算机中，我们现在设计的一些函数可能不合理，比如softmax会产生溢出，我们会用到LogExpSum技巧，把softmax和交叉熵一起计算，通过冥函数和对数函数的一些性质，我们可以化简后抵消一些exp的计算，保证数值的稳定性，我们只需要知道有这么一个事情即可。但是这一切都不需要我们来弄，我们只需要调用别人设计的好的函数即可，比如pythorch中的torch.nn.CrossEntropyLoss()。如果真的有需要，可以根据LogExpSum的定义来直接编写就行，在这里，本文就不关注这个。</p>
<p>  从线性回归到softmax回归，我们算是基本了解清楚了深度学习的一些基本的概念，这为我们去看和改一些比较好的、公开的模型打下了基础。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V1.0.0)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V2.0.0 alpha1)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html">https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html</a></p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/07/04/blog_idx_105/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/07/04/blog_idx_105/" class="post-title-link" itemprop="url">DL基础补全计划(一)---线性回归及示例（Pytorch，平方损失）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-04 16:15:16" itemprop="dateCreated datePublished" datetime="2021-07-04T16:15:16+08:00">2021-07-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DL/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky
 * @LastEditTime: 2021-06-29 15:04:05
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=105） 
&emsp;&emsp;本文发布于 2021-07-04 16:15:16    （BlogID=105）       
-->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Windows 10</p>
</li>
<li class="lvl-2">
<p>VSCode</p>
</li>
<li class="lvl-2">
<p>Python 3.8.10</p>
</li>
<li class="lvl-2">
<p>Pytorch 1.8.1</p>
</li>
<li class="lvl-2">
<p>Cuda 10.2</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  从我2017毕业到现在为止，我的工作一直都是AI在边缘端部署落地等相关内容。所以我的工作基本都集中在嵌入式+Linux+DL三者之内的范围，由于个人兴趣和一些工作安排，就会去做一些模型移植的工作，所以我会经常接触模型基本结构，前处理、后处理等等基本的知识，但是其实我很少去接触模型怎么来的这个问题。虽然以前也硬啃过Lenet5和BP算法，也按照别人弄好的脚本训练过一些简单的模型，但是从来没有认真仔细的看过这些脚本，这些脚本为什么这样写。</p>
<p>  在2019年下半年，随着我移植模型的工作深入，接触的各种硬件平台越来越多，经常遇见一些层在此平台无法移植，需要拆出来特殊处理。这让我产生了为啥这些层在这些特定平台不能够移植的疑问？为啥替换为别的层就能正常工作？为啥此平台不提供这个层？于是我去请教我们的算法小伙伴们，他们建议我如果要解决这个问题，建议我学习一下DL的基本知识，至少要简单了解从数据采集及处理、模型搭建及训练、模型部署等知识，其中模型部署可能是我最了解的内容了。利用一些闲暇时间和工作中的一些机会，我对以上需要了解的知识有了一个大概的认知。随着了解的深入，可能我也大概知道我比较缺一些基础知识。经过小伙伴的推荐和自己的搜索，我选择了《动⼿学深度学习.pdf》作为我的基础补全资料。</p>
<p>  本文是以‘补全资料’的Chapter3中线性规划为基础来编写的，主要是对‘补全资料’之前的基础知识的一个简单汇总，包含了深度学习中一些基本的知识点，同时会对这些基本知识点进行一些解释。</p>
<p>  由于我也是一个初学者，文中的解释是基于我的知识水平结构做的‘特色适配’，如果解释有误，请及时提出，我这里及时更正。写本文的原因也是记录我的学习历程，算是我的学习笔记。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="回归概念">回归概念</h3>
<hr>
<p>  回归是一种建模方法，得到的模型表示了自变量和因变量的关系。因此回归还可以解释为一种事与事之间的联系。对我们来说最常见的例子就是我们学习过的函数。例如函数Y=aX+b，这里的Y=aX+b就是我们模型， X代表自变量，Y代表因变量。</p>
<p>  这里顺便多说一句，深度学习是机器学习的子集。建模方法很多，回归只是其中的一种。</p>
<br/>
<br/>
<h5 id="线性回归">线性回归</h5>
<p>  线性回归就是自变量和因变量是线性关系，感觉跟废话一样，换个方式表达就是自变量是一次。例如：Y=aX+b, Y=aX1+bX2+c, 这里的X、X1、X2都是一次的，不是二次或者更高的。</p>
<br/>
<br/>
<h5 id="非线性回归">非线性回归</h5>
<p>  非线性回归就是自变量和因变量不是是线性关系，同样感觉跟废话一样，换个方式表达就是自变量是二次及以上的。这里和线性回归对比一下就行。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="基于y-aX12-bX12-cX2-dX2-e的回归Pytorch实例">基于y=aX1<sup>2+bX1</sup>2+cX2+dX2+e的回归Pytorch实例</h3>
<hr>
<p>  此实例是《动⼿学深度学习.pdf》中线性回归的从零实现的变种。从零实现，可以了解到许多的基本知识。<br>
  此小节基本按照数据采集及处理、模型搭建及训练和模型部署来描述。</p>
<br/>
<br/>
<h5 id="带噪声数据采集及处理">带噪声数据采集及处理</h5>
<p>  我们知道，在我们准备数据时，肯定由于各种各样的原因，会有各种干扰，导致我们根据实际场景采集到的数据，其实不是精准的，但是这并不影响我们建模，因为我们的模型是尽量去拟合真实场景的情况。</p>
<p>  生成我们的实际模型的噪声数据，也就是我们常见的数据集的说法。如下是代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">def</span> <span class="token function">synthetic_data</span><span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> b<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""⽣成y = X1^2w1 + X2w2 + b + 噪声。"""</span>
    <span class="token comment"># 根据正太分布，随机生成我们的X1和X2</span>
    <span class="token comment"># X1和X2都是(1000, 2)的矩阵</span>
    X1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    X2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 基于X1,X2,true_w1, true_w2, true_b， 通过向量内积、广播等方法计算模型的真实结果</span>
    y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X1<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> w1<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X2<span class="token punctuation">,</span> w2<span class="token punctuation">)</span> <span class="token operator">+</span> b

    <span class="token comment"># 通过随机噪声加上真实结果，生成我们的数据集。</span>
    <span class="token comment"># y是(1000, 1)的矩阵</span>
    y <span class="token operator">+=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> X1<span class="token punctuation">,</span> X2<span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
true_w1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5.7</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
true_w2 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4.8</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
true_b <span class="token operator">=</span> <span class="token number">4.2</span>

<span class="token comment"># 这里我们得到了我们的数据集，包含了特征和标签</span>
features1<span class="token punctuation">,</span> features2<span class="token punctuation">,</span> labels <span class="token operator">=</span> synthetic_data<span class="token punctuation">(</span>true_w1<span class="token punctuation">,</span> true_w2<span class="token punctuation">,</span> true_b<span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span>

<span class="token comment"># 因为我们知道我们的模型是y=aX1^2+bX1^2+cX2+dX2+e，于是我们知道a的数据分布是类似y=ax^2+b的这种形状。于是我们知道c的数据分布是类似y=ax+b的这种形状。</span>
<span class="token comment"># 我们可以通过如下代码验证一下</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>features1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>features2<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_105/feature_label.png" alt="rep_img"/></center>
    </div>
</div>   
其实从图中可以看到，红色的是类似y=ax^2+b的这种形状，蓝色是类似y=ax+b这种形状，但是他们都不是在一条线，说明我们的设置的噪声项是有效的。
<p>  同时这里我们还要准备一个函数用来随机抽取特征和标签，一批一批的进行训练。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">data_iter</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> features1<span class="token punctuation">,</span> features2<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_examples <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>features1<span class="token punctuation">)</span>
    indices <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_examples<span class="token punctuation">)</span><span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>indices<span class="token punctuation">)</span> <span class="token comment"># 样本的读取顺序是随机的</span>
    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_examples<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        j <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>indices<span class="token punctuation">[</span>i<span class="token punctuation">:</span> <span class="token builtin">min</span><span class="token punctuation">(</span>i <span class="token operator">+</span> batch_size<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># print(features1.take(j, axis=0).shape)</span>
        <span class="token keyword">yield</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>features1<span class="token punctuation">.</span>take<span class="token punctuation">(</span>j<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>features2<span class="token punctuation">.</span>take<span class="token punctuation">(</span>j<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>take<span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># take函数根据索引返回对应元素</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="模型搭建及训练">模型搭建及训练</h5>
<p>  对于我们这个实例来说，模型就是一个二元二次函数，此外这里的模型也叫作目标函数。所以，下面我们用torch来实现它就行。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">our_func</span><span class="token punctuation">(</span>X1<span class="token punctuation">,</span> X2<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> B<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># print(X1.shape) (100, 2)</span>
    <span class="token comment"># print(W1.shape) (2, 1)</span>
    net_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X1<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> W1<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X2<span class="token punctuation">,</span> W2<span class="token punctuation">)</span> <span class="token operator">+</span> B
    <span class="token comment"># print(net_out.shape) (100, 1)</span>
    <span class="token keyword">return</span> net_out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意哟，这里的X1,X2,W1,W2,B都是torch的tensor格式。</p>
<p>  由数据采集及处理可知，在我们设定的真实true_w1,true_w2和true_b的情况下，我们得到了许许多多的X1,X2和y。我们要做的事情是求出W1、W2和b，这里看起是不是很矛盾？我们已知了true_w1,true_w2,true_b然后去求w1,w2,b。这里其实是一个错觉，由于在实际情况中，我们可能会得到许许多多的X1,X2和y，这些数据不是我们模拟生成的，而是某种关系实际产生的数据，只是这些数据被我们收集到了。在实际情况下，而且我们仅仅只能够得到X1,X2和y，我们通过观察X1,X2和y的关系，发现他们有一元二次和一元一次关系，所以我们建立的模型为y=aX1<sup>2+bX1</sup>2+cX2+dX2+e，这个过程称为建模。</p>
<p>  通过上面的说明，我们知道这个模型我们要求a,b,c,d,e这些参数的值，我们求这些参数的过程叫做训练。对于这个实例来说，这个过程也叫作求解方程，这里其实我们可以通过解方程的方法把这5个参数解出来，但是在实际情况中，我们建立的模型可能参数较多，可能手动解不出来，于是我们要通过训练的方式，去拟合这些参数。所以这里一个重要的问题就是怎么拟合这些参数？</p>
<p>  如果学习过《数值分析》这门课程的话，其实就比较好理解了，如果要拟合这些参数，我们有许多的方法可以使用，但是基本分为两类，一类是针对误差进行分析，一类是针对模型进行分析。那么在深度学习中，我们一般是对误差进行分析，也就是我们常说的梯度下降法，我们需要随机生成这些参数初始值(w1,w2,b)，然后根据我们得到的X1,X2和y，通过梯度下降方法可以得到新的w1’,w2’,b’，且w1’,w2’,b’更加接近true_w1,true_w2和true_b。这就是一种优化过程，经过多次优化，我们就有可能求出跟接近与true_w1,true_w2和true_b的值。</p>
<p>  上面啰嗦了一大堆之后，我这里正式引入损失函数这个概念，然后我们根据损失函数去优化我们的w1,w2,b。我们定义这个实例的损失函数如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">loss_func</span><span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># print(y_train.shape)</span>
    <span class="token comment"># print(y_label.shape)</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>y_train <span class="token operator">-</span> y_label<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>  这里我们y_train就是我们得到的训练值，y_label就是我们采集到数值，这里的损失函数就是描述训练值和标签的差多少，那么我们只需要让这个损失函数的值越来越小就行，那么可能问题就变成了求损失函数的极小值问题，我们在这里还是用梯度下降的方法来求损失函数的极小值。</p>
<p>  这里要回忆起来一个概念，梯度是一个函数在这个方向增长最快的方向。我们求损失函数的极小值的话，就减去梯度就行了。</p>
<p>  这里还要说一句，损失函数有很多(L1,MSE,交叉熵等等)，大家以后可以自己选一个合适的即可，这里的合适需要大家去学习每种损失函数的适用场景。这里的平方损失的合理性我个人认为有两种：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1 直观法，平方损失函数描述的是在数据集上，训练值和真实值的误差趋势，我要想得到的参数最准确，就要求误差最小，误差最小就要求我去求解损失函数的极小值，这是我所了解的数学知识的直观反映。 （直觉大法）</p>
</li>
<li class="lvl-2">
<p>2 数学证明如下：我们生成数据或者采样数据的时候，他们的误差服从正态分布（ $P(x) = 1/\sqrt{2\pi\sigma<sup>2}*exp((-1/2\sigma</sup>2)(x-\mu)^2)$ ），于是我们根据条件概率得到特定feature得到特定y的概率为: $P(y|X) = 1/\sqrt{2\pi\sigma<sup>2}*exp((-1/2\sigma</sup>2)(y-w1X1<sup>2-w2X2-b)</sup>2)$,根据最大似然估计$P(y|X) = \prod\limits_{i=0}<sup>{n-1}P(y</sup>{i}|X^{i})$，此时最大似然估计最大，w1,w2,b就是最佳的参数，但是乘积函数的最大值不好求，我们用对数转换一下，变为各项求和，只需要保证含义一致就行。由于一般的优化一般是说最小化，所以我们要取负的对数和$-\log(P(y|X))$，此时我们把最大似然估计函数转换为对数形式：$-\log(P(y|X)) = \sum\limits_{i=0}<sup>{n-1}1/2\log(2\pi\sigma</sup>2)+1/2\sigma<sup>2(y-w1X1</sup>2-w2X2-b)^2)$,我们可以看到要求此函数的最小值，其实就是后半部分的平方是最小值就行，因为其余的都是常数项，而后面部分恰好就是我们的平方损失函数。（Copy书上大法）</p>
</li>
</ul>
<p>  这里的梯度下降法就是(w1,w2,b)-lr*(w1,w2,b).grad/batch_size,代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sgd</span><span class="token punctuation">(</span>params<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""⼩批量随机梯度下降。"""</span>
    <span class="token keyword">for</span> param <span class="token keyword">in</span> params<span class="token punctuation">:</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            param<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> param <span class="token operator">-</span> lr <span class="token operator">*</span> param<span class="token punctuation">.</span>grad <span class="token operator">/</span> batch_size<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  这里我画出我们的损失函数的三维图像,我们把损失函数简化为Z=aX^2+bY+c的形式。其图像如下图：</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_105/loss_surface.png" alt="rep_img"/></center>
    </div>
</div>   
<p>我们可以看到这个曲面有很多极小值，当我们随机初始化a,b,c的时候，我们会根据X和Y得到部分损失点，这时我们求出a,b,c的梯度，当我们对a,b,c减去偏导数时，就会更快的靠近损失函数的谷底，我们的当我们的损失函数到极小值时，我们就认为此时的a,b,c是我们要找的参数。这就是我们的梯度下降法的意义所在。</p>
<p>  下面就直接写训练代码就行。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">w1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># print(w1.grad)</span>
<span class="token comment"># print(w1.grad_fn)</span>
<span class="token comment"># </span>
lr <span class="token operator">=</span> <span class="token number">0.001</span>
num_epochs <span class="token operator">=</span> <span class="token number">10000</span>
net <span class="token operator">=</span> our_func
loss <span class="token operator">=</span> loss_func

batch_size <span class="token operator">=</span> <span class="token number">200</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> X1<span class="token punctuation">,</span> X2<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> features1<span class="token punctuation">,</span> features2<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print(X1.shape) (100, 2)</span>
        <span class="token comment"># print(y.shape) (100, 1)</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X1<span class="token punctuation">,</span> X2<span class="token punctuation">,</span> w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># `X`和`y`的⼩批量损失</span>
        <span class="token comment"># print(f'epoch &#123;epoch + 1&#125;, before sdg loss &#123;float(l.mean()):f&#125;')</span>
        <span class="token comment"># 计算l关于[`w`, `b`]的梯度</span>
        <span class="token comment"># print(l.shape)</span>
        
        <span class="token comment"># l.backward() default call, loss.backward(torch.Tensor(1.0))</span>
        w1<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>
        w2<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>
        b<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>

        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        sgd<span class="token punctuation">(</span><span class="token punctuation">[</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> b<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span> <span class="token comment"># 使⽤参数的梯度更新参数</span>
        
        l1 <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X1<span class="token punctuation">,</span> X2<span class="token punctuation">,</span> w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># `X`和`y`的⼩批量损失</span>
        <span class="token comment"># print(f'epoch &#123;epoch + 1&#125;, after sdg loss &#123;float(l1.mean()):f&#125;')</span>
    
    train_l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>features1<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>features2<span class="token punctuation">)</span><span class="token punctuation">,</span> w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># print(train_l.sum())</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">, loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">float</span><span class="token punctuation">(</span>train_l<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_w1 '</span><span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_w2 '</span><span class="token punctuation">,</span>w2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_b '</span><span class="token punctuation">,</span>b<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  这里做的事情就是首先设定训了次数，学习率，批次数量参数，然后随机生成了w1,w2,b，然后通过data_iter取一批数据，算出loss，清空w1,w2,b的梯度，对loss求w1,w2,b的偏导数，调用sdg求新的w1,w2,b。最后计算新参数在整个数据集上的损失。</p>
<p>  这里尤其需要注意的是在多次迭代过程中，一定要清空w1,w2,b的梯度，因为它的梯度是累加的，不会覆盖。这里用的Pytorch的自动求导模块，其实底层就是调用的bp算法，利用了链式法则，反向从loss开始，能够算出w1,w2,b的偏导数。</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_105/train_log.png" alt="rep_img"/></center>
    </div>
</div>   
这里我们看到最终的平均误差到了一定值后就下降不了，这和我们的数据有关系，我们只需要关心这个误差我们能够接受吗？能接受，我们就训练得到了成功的模型，如果不能接受，我们就改参数重新来，这是一个多次试验尝试的过程。
<p>  我们从上文可知，true_w1 = np.array([5.7, -3.4])，true_w2 = np.array([4.8, -3.4])，true_b = 4.2。我们训练出来的值是w1=(5.7012, -3.3955),w2=(4.8042, -3.4071),b=4.2000。可以看到其实训练得到的值还是非常接近的，但是这个任务其实太简单了。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  这里主要用到了许多基本的概念，一个是数据集的收集和处理，模型搭建，模型训练，优化方法、损失函数等等。至少通过本文，我们知道了得到一个模型的基本过程，其实普遍性的深度学习就是使用新的损失函数、搭建新的模型、使用新的优化方法等等。</p>
<p>  从文中特例我们可以发现，我们只利用了Pytorch自带的自动求导模块，其他的一些常见的深度学习概念都是我们手动实现了，其实这些好多内容都是Pytorch这些框架封装好的，我们没有必要自己手写，但是如果是初次学习的话，建议手动来写，这样认知更加深刻。</p>
<h3 id="参考文献">参考文献</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V1.0.0)</p>
</li>
<li class="lvl-2">
<p><a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/releases">https://github.com/d2l-ai/d2l-zh/releases</a> (V2.0.0 alpha1)</p>
</li>
</ul>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://e-x.top/2021/04/24/blog_idx_104/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Sky">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sky's Blogs">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Sky's Blogs">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/04/24/blog_idx_104/" class="post-title-link" itemprop="url">Mediapipe 在RK3399PRO上的初探（二）(自定义Calculator)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-04-24 19:45:03" itemprop="dateCreated datePublished" datetime="2021-04-24T19:45:03+08:00">2021-04-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-18 19:06:02" itemprop="dateModified" datetime="2024-05-18T19:06:02+08:00">2024-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/C-CPP/" itemprop="url" rel="index"><span itemprop="name">C&CPP</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/C-CPP/%E5%B5%8C%E5%85%A5%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">嵌入式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/C-CPP/%E5%B5%8C%E5%85%A5%E5%BC%8F/linux%E5%BC%80%E5%8F%91/" itemprop="url" rel="index"><span itemprop="name">linux开发</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/C-CPP/%E5%B5%8C%E5%85%A5%E5%BC%8F/linux%E5%BC%80%E5%8F%91/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <script src="\assets\js\APlayer.min.js"> </script><!--
 * @Description: 
 * @Author: Sky
 * @Date: 2020-08-24 16:37:34
 * @LastEditors: Sky
 * @LastEditTime: 2021-06-23 09:56:54
 * @Github: https://github.com/flyinskyin2013/
-->
<p><font color="red" size="7">PS：要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 这个只是基于《我自己》的理解，</font><br/><font color="red" size="7">如果和你的原则及想法相冲突，请谅解，勿喷。</font><br/></p>
<!-- ###### 前置说明
&emsp;&emsp;本文作为本人csdn blog的主站的备份。（BlogID=104）
&emsp;&emsp;本文发布于 2021-04-24 19:45:03    （BlogID=104） -->
<h6 id="环境说明">环境说明</h6>
<ul class="lvl-0">
<li class="lvl-2">
<p>Ubuntu 18.04</p>
</li>
<li class="lvl-2">
<p>gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)</p>
</li>
<li class="lvl-2">
<p>RK3399PRO 板卡</p>
</li>
</ul>
<h3 id="前言">前言</h3>
<hr>
<p>  本文有一篇前置文章为《Mediapipe 在RK3399PRO上的初探（一）(编译、运行CPU和GPU Demo, RK OpenglES 填坑，编译bazel)》 <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011728480/article/details/115838306">https://blog.csdn.net/u011728480/article/details/115838306</a> ，本文是在前置文章上的一点点探索与发现。</p>
<p>  在前置文章中，我们介绍了一些编译和使用Mediapipe的注意事项，也初步跑起来了一点点demo，算是对这个框架有了一个初步的认知。但是前置文章也说了，了解这个框架的意义是替换我们小组现有的框架，而且能够支撑我们的板卡产品。于是我们还需要一个最最最最最最重要的功能就是“Custormer Calculator”，就是自定义计算节点，因为这个框架的核心就是计算节点。下文我们将会讲到这个框架的一些基本概念，这些概念都是来至于官方文档的机翻+我自己的理解。同时，我会给出一个我定义的计算节点的实例，算是给大家一个感性认知。</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="Mediapipe的一些概念（本小节基本来至于官方文档的机翻-我自己的理解，不感兴趣，请直接看下一小节）">Mediapipe的一些概念（本小节基本来至于官方文档的机翻+我自己的理解，不感兴趣，请直接看下一小节）</h3>
<hr>
<p>  本小节内容，主要参考 <a target="_blank" rel="noopener" href="https://github.com/google/mediapipe/tree/master/docs/framework_concepts">https://github.com/google/mediapipe/tree/master/docs/framework_concepts</a> 的几个介绍概念的md文件。<br>
  MediaPipe 感觉中文直译为“媒体管道”，为啥会有这个名字呢？因为它把数据+处理组合成一个计算节点，然后把一个一个节点连接起来，用数据来驱动整个核心逻辑。如果大家对Caffe、ncnn类似的框架源码有一点点了解的话，就会觉得他们非常像，但是又不像。像是说，都是通过配置文件定义计算节点逻辑图，然后通过运算，得到我们想得到的逻辑图中节点的数据。不像的话，就是说的是Mediapipe的调度机制了，极大的增加了节点计算的并行功能，而那些框架是按照图节点的上下顺序进行执行的。<br>
  上面这段话可能有点抽象，我想表达的就是 Mediapipe 就是把任何一个“操作”都可以变为一个Calculator，因为我们的每一个项目的逻辑抽象出来都是 Calculator0+Data0-&gt;Calculator1+Data1-&gt;Calculator2+Data2-&gt;… …，然后，Mediapipe 做的是基于这种calculator的调度和执行。这里我举个栗子：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>人脸图+检测算法=人脸检测结果，这是一个Calculator</p>
</li>
<li class="lvl-2">
<p>RTSP流+解码模块=解码之后的图片，这是一个Calculator</p>
</li>
</ul>
<p>好了，其他的就不过分的解读了，下面就使用MediaPipe的helloworld example（ <a target="_blank" rel="noopener" href="https://github.com/google/mediapipe/blob/master/mediapipe/examples/desktop/hello_world/hello_world.cc">https://github.com/google/mediapipe/blob/master/mediapipe/examples/desktop/hello_world/hello_world.cc</a> ）为例，简单的说说以下几个概念。</p>
<br/>
<br/>
<h5 id="Packet">Packet</h5>
<p>  Packet，是mediapipe中的数据单元，它可以接收任意类型的数据。也是mediapipe中的数据流动单元。就是在mediapipe中，我们设计的Graph中，所有的逻辑流动都是通过packet流动来实现的。</p>
<p>  实例代码片段：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token comment">//MakePacket&lt;std::string>("Hello World!") 创建一个packet，顺带说一句，我不喜欢这里的宏，不利于维护</span>
<span class="token function">MP_RETURN_IF_ERROR</span><span class="token punctuation">(</span>graph<span class="token punctuation">.</span><span class="token function">AddPacketToInputStream</span><span class="token punctuation">(</span><span class="token string">"in"</span><span class="token punctuation">,</span> <span class="token generic-function"><span class="token function">MakePacket</span><span class="token generic class-name"><span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>string<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token string">"Hello World!"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">At</span><span class="token punctuation">(</span><span class="token function">Timestamp</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">//从packet中获取数据</span>
mediapipe<span class="token double-colon punctuation">::</span>Packet packet<span class="token punctuation">;</span>
packet<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>string<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="Graph">Graph</h5>
<p>  Graph是由各个Calculator组成的，可以直接把Calculator理解为数据结构中图的节点。而Graph直接把他当做图就行了。Graph是我们定义的逻辑流程的具体载体，也就是说我们的业务逻辑是什么样子的，那么Graph里面就会有相应的逻辑流程。可以具备多输入输出。</p>
<p>  实例代码片段：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">CalculatorGraph graph<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<br/>
<br/>
<h5 id="Caculator-Node">Caculator(Node)</h5>
<p>  上面不是介绍了Graph和Packet嘛，这里的Calculator就是Graph里面的节点，也是处理Packet的具体单元。可以具备多输入输出。</p>
<p>  实例代码片段：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token comment">//比如mediapipe/calculators/core/pass_through_calculator.h里面的定义，这个Calculator被Helloworld这个例子使用，作用就是把输入的数据直接传递到输出，不做任何处理，类似NOP</span>
<span class="token keyword">class</span> <span class="token class-name">PassThroughCalculator</span> <span class="token operator">:</span> <span class="token keyword">public</span> CalculatorBase <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="Stream">Stream</h5>
<p>  Stream 就是 Caculator 之间的连接起来后，形成的一个数据流动路径。</p>
<br/>
<br/>
<h5 id="Side-packets">Side packets</h5>
<p>  Side packets 可以直接理解为一些静态的数据packet，在graph创建之后就不会改变的数据。</p>
<p>… …</p>
<br/>
<br/>
<br/>
<br/>
<h3 id="自定义实现Calculator">自定义实现Calculator</h3>
<hr>
<p>  Talk is cheap, show me the code.</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token comment">/*
 * @Description: 
 * @Author: Sky
 * @Date: 
 * @LastEditors: Sky
 * @LastEditTime: 
 * @Github: 
 */</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;cstdio></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"mediapipe/framework/calculator_graph.h"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"mediapipe/framework/port/logging.h"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"mediapipe/framework/port/parse_text_proto.h"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"mediapipe/framework/port/status.h"</span></span>

<span class="token comment">//customer calculator</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"mediapipe/framework/calculator_framework.h"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"mediapipe/framework/port/canonical_errors.h"</span></span>


<span class="token keyword">class</span> <span class="token class-name">CustomerDataType</span><span class="token punctuation">&#123;</span>

  <span class="token keyword">public</span><span class="token operator">:</span>
  <span class="token function">CustomerDataType</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token punctuation">,</span> <span class="token keyword">float</span> f<span class="token punctuation">,</span> <span class="token keyword">bool</span> b<span class="token punctuation">,</span> <span class="token keyword">const</span> std<span class="token double-colon punctuation">::</span>string <span class="token operator">&amp;</span> str<span class="token punctuation">)</span><span class="token operator">:</span>
  <span class="token function">val_i</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token function">val_f</span><span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token function">val_b</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token function">s_str</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span>
  <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
  <span class="token keyword">int</span> val_i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
  <span class="token keyword">float</span> val_f <span class="token operator">=</span> <span class="token number">11.f</span><span class="token punctuation">;</span>
  <span class="token keyword">bool</span> val_b <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
  std<span class="token double-colon punctuation">::</span>string s_str <span class="token operator">=</span> <span class="token string">"customer str."</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">;</span>



<span class="token keyword">namespace</span> mediapipe <span class="token punctuation">&#123;</span>

  <span class="token keyword">class</span> <span class="token class-name">MyStringProcessCalculator</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> <span class="token class-name">CalculatorBase</span></span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">public</span><span class="token operator">:</span>
    <span class="token comment">/*
    Calculator authors can specify the expected types of inputs and outputs of a calculator in GetContract(). 
    When a graph is initialized, the framework calls a static method to verify if the packet types of the connected inputs and outputs match the information in this specification.
    */</span>
    <span class="token keyword">static</span> absl<span class="token double-colon punctuation">::</span>Status <span class="token function">GetContract</span><span class="token punctuation">(</span>CalculatorContract<span class="token operator">*</span> cc<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      
      <span class="token comment">/*
      class InputStreamShard;
      typedef internal::Collection&lt;InputStreamShard> InputStreamShardSet;
      class OutputStreamShard;
      typedef internal::Collection&lt;OutputStreamShard> OutputStreamShardSet;
      */</span>
      <span class="token comment">//cc->Inputs().NumEntries() returns the number of input streams</span>
      <span class="token comment">// if (!cc->Inputs().TagMap()->SameAs(*cc->Outputs().TagMap())) &#123;</span>

      <span class="token comment">//   return absl::InvalidArgumentError("Input and output streams's TagMap can't be same.");</span>
      <span class="token comment">// &#125;</span>

      <span class="token comment">//set stream</span>
      <span class="token comment">// for (CollectionItemId id = cc->Inputs().BeginId(); id &lt; cc->Inputs().EndId(); ++id) &#123;</span>

      <span class="token comment">//   cc->Inputs().Get(id).SetAny();</span>
      <span class="token comment">//   cc->Outputs().Get(id).SetSameAs(&amp;cc->Inputs().Get(id));</span>
      <span class="token comment">// &#125;</span>
      cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">SetAny</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Set</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      cc<span class="token operator">-></span><span class="token function">Outputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">SetSameAs</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


      <span class="token comment">//set stream package</span>
      <span class="token comment">// for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;</span>
        
      <span class="token comment">//   cc->InputSidePackets().Get(id).SetAny();</span>
      <span class="token comment">// &#125;</span>
      <span class="token comment">// cc->InputSidePackets().Index(0).SetAny();</span>
      <span class="token comment">// cc->InputSidePackets().Index(1).Set&lt;CustomerDataType>();//set customer data-type</span>


      <span class="token keyword">if</span> <span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">OutputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">NumEntries</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

        <span class="token comment">// if (!cc->InputSidePackets().TagMap()->SameAs(*cc->OutputSidePackets().TagMap())) &#123;</span>

        <span class="token comment">//   return absl::InvalidArgumentError("Input and output side packets's TagMap can't be same.");</span>
        <span class="token comment">// &#125;</span>
        
        <span class="token comment">// for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;</span>

        <span class="token comment">//   cc->OutputSidePackets().Get(id).SetSameAs(&amp;cc->InputSidePackets().Get(id));</span>
        <span class="token comment">// &#125;</span>

        cc<span class="token operator">-></span><span class="token function">OutputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">SetSameAs</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cc<span class="token operator">-></span><span class="token function">InputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>      

      <span class="token keyword">return</span> absl<span class="token double-colon punctuation">::</span><span class="token function">OkStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    absl<span class="token double-colon punctuation">::</span>Status <span class="token function">Open</span><span class="token punctuation">(</span>CalculatorContext<span class="token operator">*</span> cc<span class="token punctuation">)</span> <span class="token keyword">final</span> <span class="token punctuation">&#123;</span>

      <span class="token keyword">for</span> <span class="token punctuation">(</span>CollectionItemId id <span class="token operator">=</span> cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">BeginId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>id <span class="token operator">&lt;</span> cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">EndId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">++</span>id<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Header</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">IsEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

          cc<span class="token operator">-></span><span class="token function">Outputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">SetHeader</span><span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Header</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
      <span class="token punctuation">&#125;</span>

      <span class="token keyword">if</span> <span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">OutputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">NumEntries</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

        <span class="token keyword">for</span> <span class="token punctuation">(</span>CollectionItemId id <span class="token operator">=</span> cc<span class="token operator">-></span><span class="token function">InputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">BeginId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> id <span class="token operator">&lt;</span> cc<span class="token operator">-></span><span class="token function">InputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">EndId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">++</span>id<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
          
          cc<span class="token operator">-></span><span class="token function">OutputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Set</span><span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">InputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
      <span class="token punctuation">&#125;</span>

      <span class="token comment">// Sets this packet timestamp offset for Packets going to all outputs.</span>
      <span class="token comment">// If you only want to set the offset for a single output stream then</span>
      <span class="token comment">// use OutputStream::SetOffset() directly.</span>
      cc<span class="token operator">-></span><span class="token function">SetOffset</span><span class="token punctuation">(</span><span class="token function">TimestampDiff</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      <span class="token keyword">return</span> absl<span class="token double-colon punctuation">::</span><span class="token function">OkStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    absl<span class="token double-colon punctuation">::</span>Status <span class="token function">Process</span><span class="token punctuation">(</span>CalculatorContext<span class="token operator">*</span> cc<span class="token punctuation">)</span> <span class="token keyword">final</span> <span class="token punctuation">&#123;</span>

      <span class="token keyword">if</span> <span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">NumEntries</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> tool<span class="token double-colon punctuation">::</span><span class="token function">StatusStop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>

      <span class="token comment">//get node input data</span>
      mediapipe<span class="token double-colon punctuation">::</span>Packet  _data0 <span class="token operator">=</span> cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      mediapipe<span class="token double-colon punctuation">::</span>Packet  _data1 <span class="token operator">=</span> cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      <span class="token comment">//not safety.</span>
      <span class="token keyword">char</span> _tmp_buf<span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
      
      <span class="token double-colon punctuation">::</span><span class="token function">memset</span><span class="token punctuation">(</span>_tmp_buf<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      <span class="token function">snprintf</span><span class="token punctuation">(</span>_tmp_buf<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> _data0<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>string<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">c_str</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> _data1<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>val_i<span class="token punctuation">,</span> _data1<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>val_f<span class="token punctuation">,</span> _data1<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>val_b<span class="token punctuation">,</span> _data1<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>s_str<span class="token punctuation">.</span><span class="token function">c_str</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      std<span class="token double-colon punctuation">::</span>string _out_data <span class="token operator">=</span> _tmp_buf<span class="token punctuation">;</span>
      cc<span class="token operator">-></span><span class="token function">Outputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">AddPacket</span><span class="token punctuation">(</span><span class="token generic-function"><span class="token function">MakePacket</span><span class="token generic class-name"><span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>string<span class="token operator">></span></span></span><span class="token punctuation">(</span>_out_data<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">At</span><span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">InputTimestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      <span class="token keyword">return</span> absl<span class="token double-colon punctuation">::</span><span class="token function">OkStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    absl<span class="token double-colon punctuation">::</span>Status <span class="token function">Close</span><span class="token punctuation">(</span>CalculatorContext<span class="token operator">*</span> cc<span class="token punctuation">)</span> <span class="token keyword">final</span> <span class="token punctuation">&#123;</span> 

      <span class="token keyword">return</span> absl<span class="token double-colon punctuation">::</span><span class="token function">OkStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>

  <span class="token function">REGISTER_CALCULATOR</span><span class="token punctuation">(</span>MyStringProcessCalculator<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>




<span class="token keyword">namespace</span> mediapipe <span class="token punctuation">&#123;</span>

  absl<span class="token double-colon punctuation">::</span>Status  <span class="token function">RunMyGraph</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

    <span class="token comment">// Configures a simple graph, which concatenates 2 PassThroughCalculators.</span>
    CalculatorGraphConfig config <span class="token operator">=</span> <span class="token generic-function"><span class="token function">ParseTextProtoOrDie</span><span class="token generic class-name"><span class="token operator">&lt;</span>CalculatorGraphConfig<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token raw-string string">R"(
      input_stream: "in"
      input_stream: "customer_in"
      output_stream: "out"
      node &#123;
        calculator: "PassThroughCalculator"
        input_stream: "in"
        output_stream: "out1"
      &#125;
      node &#123;
        calculator: "MyStringProcessCalculator"
        input_stream: "out1"
        input_stream: "customer_in"
        output_stream: "out2"        
      &#125;      
      node &#123;
        calculator: "PassThroughCalculator"
        input_stream: "out2"
        output_stream: "out"
      &#125;
    )"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">LOG</span><span class="token punctuation">(</span>INFO<span class="token punctuation">)</span><span class="token operator">&lt;&lt;</span><span class="token string">"parse graph cfg-str done ... ..."</span><span class="token punctuation">;</span>

    CalculatorGraph graph<span class="token punctuation">;</span>
    <span class="token function">MP_RETURN_IF_ERROR</span><span class="token punctuation">(</span>graph<span class="token punctuation">.</span><span class="token function">Initialize</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">LOG</span><span class="token punctuation">(</span>INFO<span class="token punctuation">)</span><span class="token operator">&lt;&lt;</span><span class="token string">"init graph done ... ..."</span><span class="token punctuation">;</span>

    <span class="token function">ASSIGN_OR_RETURN</span><span class="token punctuation">(</span>OutputStreamPoller poller<span class="token punctuation">,</span>
                    graph<span class="token punctuation">.</span><span class="token function">AddOutputStreamPoller</span><span class="token punctuation">(</span><span class="token string">"out"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">LOG</span><span class="token punctuation">(</span>INFO<span class="token punctuation">)</span><span class="token operator">&lt;&lt;</span><span class="token string">"add out-node to output-streampoller done ... ..."</span><span class="token punctuation">;</span>


    <span class="token function">MP_RETURN_IF_ERROR</span><span class="token punctuation">(</span>graph<span class="token punctuation">.</span><span class="token function">StartRun</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">LOG</span><span class="token punctuation">(</span>INFO<span class="token punctuation">)</span><span class="token operator">&lt;&lt;</span><span class="token string">"start run graph done ... ..."</span><span class="token punctuation">;</span>
    

    <span class="token comment">// Give 10 input packets that contains the same std::string "Hello World!".</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

      <span class="token function">MP_RETURN_IF_ERROR</span><span class="token punctuation">(</span>graph<span class="token punctuation">.</span><span class="token function">AddPacketToInputStream</span><span class="token punctuation">(</span>
          <span class="token string">"in"</span><span class="token punctuation">,</span> <span class="token generic-function"><span class="token function">MakePacket</span><span class="token generic class-name"><span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>string<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token string">"CustomerCalculator: val_i %d, val_f %f, val_b %d, val_str %s"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">At</span><span class="token punctuation">(</span><span class="token function">Timestamp</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      <span class="token function">MP_RETURN_IF_ERROR</span><span class="token punctuation">(</span>graph<span class="token punctuation">.</span><span class="token function">AddPacketToInputStream</span><span class="token punctuation">(</span>
          <span class="token string">"customer_in"</span><span class="token punctuation">,</span> <span class="token generic-function"><span class="token function">MakePacket</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1.f</span><span class="token punctuation">,</span> i<span class="token operator">%</span><span class="token number">2</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"s"</span> <span class="token operator">+</span> std<span class="token double-colon punctuation">::</span><span class="token function">to_string</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">At</span><span class="token punctuation">(</span><span class="token function">Timestamp</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token comment">// Close the input stream "in".</span>
    <span class="token function">MP_RETURN_IF_ERROR</span><span class="token punctuation">(</span>graph<span class="token punctuation">.</span><span class="token function">CloseInputStream</span><span class="token punctuation">(</span><span class="token string">"in"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">MP_RETURN_IF_ERROR</span><span class="token punctuation">(</span>graph<span class="token punctuation">.</span><span class="token function">CloseInputStream</span><span class="token punctuation">(</span><span class="token string">"customer_in"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    mediapipe<span class="token double-colon punctuation">::</span>Packet packet<span class="token punctuation">;</span>
    <span class="token comment">// Get the output packets std::string.</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span>poller<span class="token punctuation">.</span><span class="token function">Next</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>packet<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token function">LOG</span><span class="token punctuation">(</span>INFO<span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> packet<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>string<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token function">LOG</span><span class="token punctuation">(</span>INFO<span class="token punctuation">)</span><span class="token operator">&lt;&lt;</span><span class="token string">"RunGraph Done"</span><span class="token punctuation">;</span>
    <span class="token keyword">return</span> graph<span class="token punctuation">.</span><span class="token function">WaitUntilDone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

<span class="token punctuation">&#125;</span>  <span class="token comment">// namespace mediapipe</span>



<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span><span class="token operator">*</span><span class="token operator">*</span> argv<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  
  gflags<span class="token double-colon punctuation">::</span><span class="token function">ParseCommandLineFlags</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>argc<span class="token punctuation">,</span> <span class="token operator">&amp;</span>argv<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  FLAGS_minloglevel <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
  FLAGS_stderrthreshold <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
  FLAGS_alsologtostderr <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>

  google<span class="token double-colon punctuation">::</span><span class="token function">InitGoogleLogging</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token function">LOG</span><span class="token punctuation">(</span>INFO<span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"glog init success ... ..."</span><span class="token punctuation">;</span>

  absl<span class="token double-colon punctuation">::</span>Status run_status <span class="token operator">=</span> mediapipe<span class="token double-colon punctuation">::</span><span class="token function">RunMyGraph</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>run_status<span class="token punctuation">.</span><span class="token function">ok</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token function">LOG</span><span class="token punctuation">(</span>ERROR<span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"Failed to run the graph: "</span> <span class="token operator">&lt;&lt;</span> run_status<span class="token punctuation">.</span><span class="token function">message</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  google<span class="token double-colon punctuation">::</span><span class="token function">ShutdownGoogleLogging</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>下面简单介绍这段代码。</p>
<br/>
<br/>
<h5 id="自定义Calculator：MyStringProcessCalculator">自定义Calculator：MyStringProcessCalculator</h5>
<p>   这里自定义了一个Calculator，主要作用就是传入snprintf的fmt字符串和fmt字符串所需要的数据。所以可以看到有两个输入，一个是string，一个是我自定义的data-type。输出是一个格式化之后的字符串，所以输出是string。</p>
<p>   自定义Calculator主要还是实现4个接口，分别是GetContract，Open，Process，Close。其中GetContract是Graph初始化的时候，检查Calculator用的。Open接口是在Graph开始后，对Calculator做一些初始化工作，例如设定一些Calculator初始状态等。Process是实际的Calculator功能。</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">namespace</span> mediapipe <span class="token punctuation">&#123;</span>

  <span class="token keyword">class</span> <span class="token class-name">MyStringProcessCalculator</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> <span class="token class-name">CalculatorBase</span></span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">public</span><span class="token operator">:</span>
    <span class="token comment">/*
    Calculator authors can specify the expected types of inputs and outputs of a calculator in GetContract(). 
    When a graph is initialized, the framework calls a static method to verify if the packet types of the connected inputs and outputs match the information in this specification.
    */</span>
    <span class="token keyword">static</span> absl<span class="token double-colon punctuation">::</span>Status <span class="token function">GetContract</span><span class="token punctuation">(</span>CalculatorContract<span class="token operator">*</span> cc<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      
      <span class="token comment">/*
      class InputStreamShard;
      typedef internal::Collection&lt;InputStreamShard> InputStreamShardSet;
      class OutputStreamShard;
      typedef internal::Collection&lt;OutputStreamShard> OutputStreamShardSet;
      */</span>
      <span class="token comment">//cc->Inputs().NumEntries() returns the number of input streams</span>
      <span class="token comment">// if (!cc->Inputs().TagMap()->SameAs(*cc->Outputs().TagMap())) &#123;</span>

      <span class="token comment">//   return absl::InvalidArgumentError("Input and output streams's TagMap can't be same.");</span>
      <span class="token comment">// &#125;</span>

      <span class="token comment">//set stream</span>
      <span class="token comment">// for (CollectionItemId id = cc->Inputs().BeginId(); id &lt; cc->Inputs().EndId(); ++id) &#123;</span>

      <span class="token comment">//   cc->Inputs().Get(id).SetAny();</span>
      <span class="token comment">//   cc->Outputs().Get(id).SetSameAs(&amp;cc->Inputs().Get(id));</span>
      <span class="token comment">// &#125;</span>
      cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">SetAny</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Set</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      cc<span class="token operator">-></span><span class="token function">Outputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">SetSameAs</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


      <span class="token comment">//set stream package</span>
      <span class="token comment">// for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;</span>
        
      <span class="token comment">//   cc->InputSidePackets().Get(id).SetAny();</span>
      <span class="token comment">// &#125;</span>
      <span class="token comment">// cc->InputSidePackets().Index(0).SetAny();</span>
      <span class="token comment">// cc->InputSidePackets().Index(1).Set&lt;CustomerDataType>();//set customer data-type</span>


      <span class="token keyword">if</span> <span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">OutputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">NumEntries</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

        <span class="token comment">// if (!cc->InputSidePackets().TagMap()->SameAs(*cc->OutputSidePackets().TagMap())) &#123;</span>

        <span class="token comment">//   return absl::InvalidArgumentError("Input and output side packets's TagMap can't be same.");</span>
        <span class="token comment">// &#125;</span>
        
        <span class="token comment">// for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;</span>

        <span class="token comment">//   cc->OutputSidePackets().Get(id).SetSameAs(&amp;cc->InputSidePackets().Get(id));</span>
        <span class="token comment">// &#125;</span>

        cc<span class="token operator">-></span><span class="token function">OutputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">SetSameAs</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cc<span class="token operator">-></span><span class="token function">InputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>      

      <span class="token keyword">return</span> absl<span class="token double-colon punctuation">::</span><span class="token function">OkStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    absl<span class="token double-colon punctuation">::</span>Status <span class="token function">Open</span><span class="token punctuation">(</span>CalculatorContext<span class="token operator">*</span> cc<span class="token punctuation">)</span> <span class="token keyword">final</span> <span class="token punctuation">&#123;</span>

      <span class="token keyword">for</span> <span class="token punctuation">(</span>CollectionItemId id <span class="token operator">=</span> cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">BeginId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>id <span class="token operator">&lt;</span> cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">EndId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">++</span>id<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Header</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">IsEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

          cc<span class="token operator">-></span><span class="token function">Outputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">SetHeader</span><span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Header</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
      <span class="token punctuation">&#125;</span>

      <span class="token keyword">if</span> <span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">OutputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">NumEntries</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>

        <span class="token keyword">for</span> <span class="token punctuation">(</span>CollectionItemId id <span class="token operator">=</span> cc<span class="token operator">-></span><span class="token function">InputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">BeginId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> id <span class="token operator">&lt;</span> cc<span class="token operator">-></span><span class="token function">InputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">EndId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">++</span>id<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
          
          cc<span class="token operator">-></span><span class="token function">OutputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Set</span><span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">InputSidePackets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
      <span class="token punctuation">&#125;</span>

      <span class="token comment">// Sets this packet timestamp offset for Packets going to all outputs.</span>
      <span class="token comment">// If you only want to set the offset for a single output stream then</span>
      <span class="token comment">// use OutputStream::SetOffset() directly.</span>
      cc<span class="token operator">-></span><span class="token function">SetOffset</span><span class="token punctuation">(</span><span class="token function">TimestampDiff</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      <span class="token keyword">return</span> absl<span class="token double-colon punctuation">::</span><span class="token function">OkStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token comment">//这里是整个Calculator的核心，就是调用snprintf</span>
    absl<span class="token double-colon punctuation">::</span>Status <span class="token function">Process</span><span class="token punctuation">(</span>CalculatorContext<span class="token operator">*</span> cc<span class="token punctuation">)</span> <span class="token keyword">final</span> <span class="token punctuation">&#123;</span>

      <span class="token keyword">if</span> <span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">NumEntries</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> tool<span class="token double-colon punctuation">::</span><span class="token function">StatusStop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>

      <span class="token comment">//get node input data</span>
      mediapipe<span class="token double-colon punctuation">::</span>Packet  _data0 <span class="token operator">=</span> cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      mediapipe<span class="token double-colon punctuation">::</span>Packet  _data1 <span class="token operator">=</span> cc<span class="token operator">-></span><span class="token function">Inputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      <span class="token comment">//not safety.</span>
      <span class="token keyword">char</span> _tmp_buf<span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
      
      <span class="token double-colon punctuation">::</span><span class="token function">memset</span><span class="token punctuation">(</span>_tmp_buf<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      <span class="token function">snprintf</span><span class="token punctuation">(</span>_tmp_buf<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> _data0<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>string<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">c_str</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> _data1<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>val_i<span class="token punctuation">,</span> _data1<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>val_f<span class="token punctuation">,</span> _data1<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>val_b<span class="token punctuation">,</span> _data1<span class="token punctuation">.</span><span class="token generic-function"><span class="token function">Get</span><span class="token generic class-name"><span class="token operator">&lt;</span>CustomerDataType<span class="token operator">></span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>s_str<span class="token punctuation">.</span><span class="token function">c_str</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      std<span class="token double-colon punctuation">::</span>string _out_data <span class="token operator">=</span> _tmp_buf<span class="token punctuation">;</span>
      cc<span class="token operator">-></span><span class="token function">Outputs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">AddPacket</span><span class="token punctuation">(</span><span class="token generic-function"><span class="token function">MakePacket</span><span class="token generic class-name"><span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>string<span class="token operator">></span></span></span><span class="token punctuation">(</span>_out_data<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">At</span><span class="token punctuation">(</span>cc<span class="token operator">-></span><span class="token function">InputTimestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      <span class="token keyword">return</span> absl<span class="token double-colon punctuation">::</span><span class="token function">OkStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    absl<span class="token double-colon punctuation">::</span>Status <span class="token function">Close</span><span class="token punctuation">(</span>CalculatorContext<span class="token operator">*</span> cc<span class="token punctuation">)</span> <span class="token keyword">final</span> <span class="token punctuation">&#123;</span> 

      <span class="token keyword">return</span> absl<span class="token double-colon punctuation">::</span><span class="token function">OkStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>

  <span class="token function">REGISTER_CALCULATOR</span><span class="token punctuation">(</span>MyStringProcessCalculator<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<br/>
<br/>
<h5 id="然后开始编译运行得到结果">然后开始编译运行得到结果</h5>
<p>   编译。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">
<span class="token comment"># 注意，这里的--check_visibility=false 为了关闭bazel关于target之间的可见性检查，因为我的Calculator自定义放在我自己的目录的，有一个target对这个目录不可见，编译会报错。</span>

bazel build <span class="token parameter variable">-c</span> dbg <span class="token parameter variable">--define</span> <span class="token assign-left variable">MEDIAPIPE_DISABLE_GPU</span><span class="token operator">=</span><span class="token number">1</span> <span class="token parameter variable">--copt</span> <span class="token parameter variable">-DMESA_EGL_NO_X11_HEADERS</span> <span class="token parameter variable">--copt</span> <span class="token parameter variable">-DEGL_NO_X11</span> my_target <span class="token parameter variable">--check_visibility</span><span class="token operator">=</span>false <span class="token parameter variable">--verbose_failures</span>  <span class="token parameter variable">--local_cpu_resources</span><span class="token operator">=</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>   然后运行。得到如下图的结果。</p>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_104/result.png" alt="result"/></center>
    </div>
</div>   
<br/>
<br/>
<br/>
<br/>
<h3 id="后记">后记</h3>
<hr>
<p>  好了，一个超级简单的自定义calculator已经实现了，相信你已经明白了吧。本系列也就此终结吧，以后随缘更新。</p>
<br/>
<br/>
<div style="margin:50px auto;">
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <hr/>
        <center><font color = #91e0b0 size = 5>打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）</font></center>
    </div>
</div>
<div style="text-align:center">
    <div style="margin:0 auto;">
        <center><img src="https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg" alt="qrc_img"/></center>
    </div>
</div>
<!-- ![alt 公众号图片](https://flyinskyin2013.github.io/ImageBed0/blogs/qrcode_for_wx_official_account.jpg "公众号图片") -->
<p><font color="red" size="7">PS: 请尊重原创，不喜勿喷。</font><br/><br>
<font color="red" size="7">PS: 要转载请注明出处，本人版权所有。</font><br/><br>
<font color="red" size="7">PS: 有问题请留言，看到后我会第一时间回复。</font><br/></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/NO_EXSIT.XXXXXXX/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/NO_EXSIT.XXXXXXX/">1</a><span class="space">&hellip;</span><a class="page-number" href="/NO_EXSIT.XXXXXXX/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/NO_EXSIT.XXXXXXX/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/NO_EXSIT.XXXXXXX/page/14/">14</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/NO_EXSIT.XXXXXXX/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Sky</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">286k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">17:19</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":250,"hOffset":50,"vOffset":5},"mobile":{"show":false,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.8},"log":false});</script></body>
</html>
